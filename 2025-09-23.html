
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-09-23 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* 卡片容器样式 - 新增 */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            height: 600px; /* 固定高度 */
            cursor: pointer; /* 增加指针样式提示可点击 */
        }
        
        /* 卡片通用样式 */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* 轮播卡片样式 - 新增 */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%;
            transition: transform 0.5s ease, opacity 0.5s ease;
        }
        
        /* 非激活卡片的样式 - 新增 */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* 激活卡片的样式 - 新增 */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* 第一张卡片（文本内容）不需要滚动 */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* 第二张卡片（流程图）支持滚动 */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow: auto !important;
            padding-bottom: 50px; /* 添加底部填充 */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-height: none; /* 移除任何高度限制 */
        }
        
        /* 传统卡片样式 */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        
        .paper-card p {
            margin: 5px 0;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* 卡片计数器 - 新增 */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* 改为固定定位，不随滚动而移动 */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* 居中显示 */
            width: 90%;
            max-width: 500px; /* 增加最大宽度，适应长内容 */
            max-height: 80vh; /* 限制最大高度 */
            overflow-y: auto; /* 内容过多时可滚动 */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* 确保显示在最上层 */
        }
        
        /* 添加遮罩层，防止问题卡被其他内容遮挡 */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* 使用JavaScript控制问题卡的显示和隐藏，不再使用hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* 确保长单词自动换行 */
            overflow-wrap: break-word;
            hyphens: auto; /* 在必要时使用连字符 */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* 确保长单词自动换行 */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* 长文本左对齐 */
            display: block; /* 确保是块级元素 */
            white-space: normal; /* 允许自动换行 */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* 长文本选项的特殊样式 */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* 确保弹窗中的按钮文本不会溢出 */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* 适应超长选项文本 */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        @media (max-width: 768px) {
            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* 移动设备上高度调整 */
            }
            
            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <h1>2025-09-23 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/dark-geometric.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion
  Transformer Models</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-22</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.17627" target="_blank">http://arxiv.org/pdf/2509.17627</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> Video editing and generation using AI, specifically focusing on mask-free video insertion of reference subjects into existing videos using diffusion transformer models.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous video diffusion models and video insertion techniques that relied on masks and complex control signals, this paper introduces a novel mask-free approach with multi-stage training and specialized feature injection mechanisms.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> The paper addresses three key challenges in mask-free video insertion: data scarcity for training, maintaining balance between subject and scene elements, and achieving natural harmonization of inserted content.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> The paper introduces InsertPipe for data generation, OmniInsert framework with Condition-Specific Feature Injection, Progressive Training strategy, Subject-Focused Loss, and Context-Aware Rephraser for inference.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> The method outperformed commercial solutions in both quantitative metrics and user studies on their new InsertBench dataset, showing superior subject consistency, text-video alignment, and overall video quality.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion
  Transformer Models</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="#2c3e50">OmniInsert: Mask-Free Video Insertion Workflow</text>
  
  <!-- Data Pipeline Section -->
  <rect x="50" y="60" width="300" height="180" fill="#e8f4fd" stroke="#3498db" stroke-width="2" rx="10"/>
  <text x="200" y="80" text-anchor="middle" font-size="14" font-weight="bold" fill="#2980b9">InsertPipe Data Pipeline</text>
  
  <!-- RealCapture Pipe -->
  <rect x="70" y="100" width="80" height="50" fill="#ff9999" stroke="#e74c3c" stroke-width="1" rx="5"/>
  <text x="110" y="120" text-anchor="middle" font-size="10" fill="#c0392b">RealCapture</text>
  <text x="110" y="135" text-anchor="middle" font-size="10" fill="#c0392b">Pipe</text>
  
  <!-- SynthGen Pipe -->
  <rect x="160" y="100" width="80" height="50" fill="#99ff99" stroke="#27ae60" stroke-width="1" rx="5"/>
  <text x="200" y="120" text-anchor="middle" font-size="10" fill="#27ae60">SynthGen</text>
  <text x="200" y="135" text-anchor="middle" font-size="10" fill="#27ae60">Pipe</text>
  
  <!-- SimInteract Pipe -->
  <rect x="250" y="100" width="80" height="50" fill="#ffcc99" stroke="#f39c12" stroke-width="1" rx="5"/>
  <text x="290" y="120" text-anchor="middle" font-size="10" fill="#e67e22">SimInteract</text>
  <text x="290" y="135" text-anchor="middle" font-size="10" fill="#e67e22">Pipe</text>
  
  <!-- Data Components -->
  <text x="70" y="180" font-size="9" fill="#7f8c8d">• Cross-pair videos</text>
  <text x="70" y="195" font-size="9" fill="#7f8c8d">• Detection & tracking</text>
  <text x="70" y="210" font-size="9" fill="#7f8c8d">• Video erasing</text>
  <text x="70" y="225" font-size="9" fill="#7f8c8d">• VLM filtering</text>
  
  <!-- OmniInsert Framework -->
  <rect x="400" y="60" width="350" height="200" fill="#f0f8ff" stroke="#8e44ad" stroke-width="2" rx="10"/>
  <text x="575" y="80" text-anchor="middle" font-size="14" font-weight="bold" fill="#8e44ad">OmniInsert Framework</text>
  
  <!-- CFI Module -->
  <rect x="420" y="100" width="140" height="60" fill="#dda0dd" stroke="#8e44ad" stroke-width="1" rx="5"/>
  <text x="490" y="120" text-anchor="middle" font-size="11" font-weight="bold" fill="#663399">Condition-Specific</text>
  <text x="490" y="135" text-anchor="middle" font-size="11" font-weight="bold" fill="#663399">Feature Injection</text>
  <text x="490" y="150" text-anchor="middle" font-size="11" font-weight="bold" fill="#663399">(CFI)</text>
  
  <!-- DiT Blocks -->
  <rect x="580" y="100" width="150" height="60" fill="#b19cd9" stroke="#8e44ad" stroke-width="1" rx="5"/>
  <text x="655" y="120" text-anchor="middle" font-size="11" fill="#663399">Diffusion Transformer</text>
  <text x="655" y="135" text-anchor="middle" font-size="11" fill="#663399">with LoRA</text>
  <text x="655" y="150" text-anchor="middle" font-size="11" fill="#663399">Integration</text>
  
  <!-- Input conditions -->
  <text x="420" y="185" font-size="9" fill="#7f8c8d">Video: Channel concatenation</text>
  <text x="420" y="200" font-size="9" fill="#7f8c8d">Subject: Temporal concatenation</text>
  <text x="420" y="215" font-size="9" fill="#7f8c8d">Text: Prompt embedding</text>
  <text x="420" y="230" font-size="9" fill="#7f8c8d">Multi-condition guidance</text>
  
  <!-- Training Pipeline -->
  <rect x="50" y="300" width="450" height="180" fill="#fff8dc" stroke="#d35400" stroke-width="2" rx="10"/>
  <text x="275" y="320" text-anchor="middle" font-size="14" font-weight="bold" fill="#d35400">Progressive Training Strategy</text>
  
  <!-- Phase boxes -->
  <rect x="70" y="340" width="90" height="50" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="1" rx="5"/>
  <text x="115" y="360" text-anchor="middle" font-size="10" font-weight="bold" fill="#e17055">Phase 1</text>
  <text x="115" y="375" text-anchor="middle" font-size="9" fill="#e17055">Subject-to-Video</text>
  
  <rect x="170" y="340" width="90" height="50" fill="#fab1a0" stroke="#e17055" stroke-width="1" rx="5"/>
  <text x="215" y="360" text-anchor="middle" font-size="10" font-weight="bold" fill="#d63031">Phase 2</text>
  <text x="215" y="375" text-anchor="middle" font-size="9" fill="#d63031">MVI Pretraining</text>
  
  <rect x="270" y="340" width="90" height="50" fill="#fd79a8" stroke="#e84393" stroke-width="1" rx="5"/>
  <text x="315" y="360" text-anchor="middle" font-size="10" font-weight="bold" fill="#a29bfe">Phase 3</text>
  <text x="315" y="375" text-anchor="middle" font-size="9" fill="#a29bfe">Refinement</text>
  
  <rect x="370" y="340" width="90" height="50" fill="#a29bfe" stroke="#6c5ce7" stroke-width="1" rx="5"/>
  <text x="415" y="360" text-anchor="middle" font-size="10" font-weight="bold" fill="#6c5ce7">Phase 4</text>
  <text x="415" y="375" text-anchor="middle" font-size="9" fill="#6c5ce7">IPO</text>
  
  <!-- Loss Functions -->
  <rect x="70" y="410" width="130" height="40" fill="#81ecec" stroke="#00b894" stroke-width="1" rx="5"/>
  <text x="135" y="430" text-anchor="middle" font-size="10" font-weight="bold" fill="#00b894">Subject-Focused</text>
  <text x="135" y="445" text-anchor="middle" font-size="10" font-weight="bold" fill="#00b894">Loss (SL)</text>
  
  <rect x="220" y="410" width="130" height="40" fill="#74b9ff" stroke="#0984e3" stroke-width="1" rx="5"/>
  <text x="285" y="430" text-anchor="middle" font-size="10" font-weight="bold" fill="#0984e3">Insertive Preference</text>
  <text x="285" y="445" text-anchor="middle" font-size="10" font-weight="bold" fill="#0984e3">Optimization (IPO)</text>
  
  <rect x="370" y="410" width="100" height="40" fill="#fd79a8" stroke="#e84393" stroke-width="1" rx="5"/>
  <text x="420" y="430" text-anchor="middle" font-size="10" font-weight="bold" fill="#e84393">Flow Matching</text>
  <text x="420" y="445" text-anchor="middle" font-size="10" font-weight="bold" fill="#e84393">Loss</text>
  
  <!-- Inference Pipeline -->
  <rect x="550" y="300" width="400" height="180" fill="#f0fff0" stroke="#00b894" stroke-width="2" rx="10"/>
  <text x="750" y="320" text-anchor="middle" font-size="14" font-weight="bold" fill="#00b894">Inference Pipeline</text>
  
  <!-- CAR Module -->
  <rect x="570" y="340" width="150" height="60" fill="#55efc4" stroke="#00b894" stroke-width="1" rx="5"/>
  <text x="645" y="360" text-anchor="middle" font-size="11" font-weight="bold" fill="#00b894">Context-Aware</text>
  <text x="645" y="375" text-anchor="middle" font-size="11" font-weight="bold" fill="#00b894">Rephraser</text>
  <text x="645" y="390" text-anchor="middle" font-size="11" font-weight="bold" fill="#00b894">(CAR)</text>
  
  <!-- Guidance -->
  <rect x="750" y="340" width="170" height="60" fill="#a7f3d0" stroke="#10b981" stroke-width="1" rx="5"/>
  <text x="835" y="360" text-anchor="middle" font-size="11" fill="#059669">Joint Classifier-Free</text>
  <text x="835" y="375" text-anchor="middle" font-size="11" fill="#059669">Guidance</text>
  <text x="835" y="390" text-anchor="middle" font-size="11" fill="#059669">Multi-condition Balance</text>
  
  <!-- Enhancement features -->
  <text x="570" y="425" font-size="9" fill="#7f8c8d">• Scene-aware prompt enhancement</text>
  <text x="570" y="440" font-size="9" fill="#7f8c8d">• VLM-based context understanding</text>
  <text x="570" y="455" font-size="9" fill="#7f8c8d">• Dynamic guidance scaling</text>
  
  <!-- Evaluation -->
  <rect x="50" y="520" width="900" height="120" fill="#fef7ff" stroke="#9333ea" stroke-width="2" rx="10"/>
  <text x="500" y="540" text-anchor="middle" font-size="14" font-weight="bold" fill="#9333ea">Evaluation & Benchmark</text>
  
  <!-- InsertBench -->
  <rect x="70" y="560" width="200" height="60" fill="#ddd6fe" stroke="#8b5cf6" stroke-width="1" rx="5"/>
  <text x="170" y="580" text-anchor="middle" font-size="12" font-weight="bold" fill="#7c3aed">InsertBench</text>
  <text x="170" y="595" text-anchor="middle" font-size="10" fill="#7c3aed">120 videos + subjects</text>
  <text x="170" y="610" text-anchor="middle" font-size="10" fill="#7c3aed">Comprehensive evaluation</text>
  
  <!-- Metrics -->
  <rect x="300" y="560" width="280" height="60" fill="#e0e7ff" stroke="#6366f1" stroke-width="1" rx="5"/>
  <text x="440" y="575" text-anchor="middle" font-size="10" font-weight="bold" fill="#4f46e5">Evaluation Metrics</text>
  <text x="320" y="590" font-size="9" fill="#6366f1">• Subject Consistency: CLIP-I, DINO-I, FaceSim</text>
  <text x="320" y="605" font-size="9" fill="#6366f1">• Text-Video Alignment: ViCLIP-T</text>
  <text x="320" y="620" font-size="9" fill="#6366f1">• Video Quality: Dynamic, Aesthetics, Consistency</text>
  
  <!-- Baselines -->
  <rect x="610" y="560" width="150" height="60" fill="#fef3c7" stroke="#f59e0b" stroke-width="1" rx="5"/>
  <text x="685" y="580" text-anchor="middle" font-size="11" font-weight="bold" fill="#d97706">Baselines</text>
  <text x="685" y="595" text-anchor="middle" font-size="10" fill="#d97706">Pika-Pro</text>
  <text x="685" y="610" text-anchor="middle" font-size="10" fill="#d97706">Kling</text>
  
  <!-- Results -->
  <rect x="780" y="560" width="150" height="60" fill="#dcfce7" stroke="#22c55e" stroke-width="1" rx="5"/>
  <text x="855" y="580" text-anchor="middle" font-size="11" font-weight="bold" fill="#16a34a">Superior Results</text>
  <text x="855" y="595" text-anchor="middle" font-size="10" fill="#16a34a">Quantitative &</text>
  <text x="855" y="610" text-anchor="middle" font-size="10" fill="#16a34a">Qualitative</text>
  
  <!-- Key Innovations -->
  <rect x="50" y="670" width="900" height="100" fill="#f1f5f9" stroke="#64748b" stroke-width="2" rx="10"/>
  <text x="500" y="690" text-anchor="middle" font-size="14" font-weight="bold" fill="#475569">Key Technical Innovations</text>
  
  <rect x="70" y="710" width="160" height="40" fill="#fee2e2" stroke="#ef4444" stroke-width="1" rx="5"/>
  <text x="150" y="725" text-anchor="middle" font-size="10" font-weight="bold" fill="#dc2626">Mask-Free</text>
  <text x="150" y="740" text-anchor="middle" font-size="10" font-weight="bold" fill="#dc2626">Video Insertion</text>
  
  <rect x="250" y="710" width="160" height="40" fill="#dbeafe" stroke="#3b82f6" stroke-width="1" rx="5"/>
  <text x="330" y="725" text-anchor="middle" font-size="10" font-weight="bold" fill="#2563eb">Unified Framework</text>
  <text x="330" y="740" text-anchor="middle" font-size="10" font-weight="bold" fill="#2563eb">Single/Multi Subject</text>
  
  <rect x="430" y="710" width="160" height="40" fill="#f0fdf4" stroke="#22c55e" stroke-width="1" rx="5"/>
  <text x="510" y="725" text-anchor="middle" font-size="10" font-weight="bold" fill="#16a34a">Subject-Scene</text>
  <text x="510" y="740" text-anchor="middle" font-size="10" font-weight="bold" fill="#16a34a">Equilibrium</text>
  
  <rect x="610" y="710" width="160" height="40" fill="#fef7ff" stroke="#a855f7" stroke-width="1" rx="5"/>
  <text x="690" y="725" text-anchor="middle" font-size="10" font-weight="bold" fill="#9333ea">Insertion</text>
  <text x="690" y="740" text-anchor="middle" font-size="10" font-weight="bold" fill="#9333ea">Harmonization</text>
  
  <rect x="790" y="710" width="140" height="40" fill="#fffbeb" stroke="#f59e0b" stroke-width="1" rx="5"/>
  <text x="860" y="725" text-anchor="middle" font-size="10" font-weight="bold" fill="#d97706">Commercial-Grade</text>
  <text x="860" y="740" text-anchor="middle" font-size="10" font-weight="bold" fill="#d97706">Quality</text>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It eliminates the need for masks while maintaining high quality insertion">
                        <div class="quiz-question">1. What is the main innovation of OmniInsert compared to previous video insertion methods?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a completely new type of neural network architecture">It uses a completely new type of neural network architecture</div><div class="quiz-choice" data-value="It eliminates the need for masks while maintaining high quality insertion">It eliminates the need for masks while maintaining high quality insertion</div><div class="quiz-choice" data-value="It can only work with pre-defined subject categories">It can only work with pre-defined subject categories</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="About 90 seconds">
                        <div class="quiz-question">2. How long does it take for OmniInsert to generate a 5-second 480P video using 8 NVIDIA A100 GPUs?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="About 30 seconds">About 30 seconds</div><div class="quiz-choice" data-value="About 90 seconds">About 90 seconds</div><div class="quiz-choice" data-value="About 180 seconds">About 180 seconds</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Context-Aware Rephraser (CAR)">
                        <div class="quiz-question">3. Which component of OmniInsert helps achieve natural integration of subjects into scenes during inference?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Progressive Training (PT) strategy">Progressive Training (PT) strategy</div><div class="quiz-choice" data-value="Subject-Focused Loss (SL)">Subject-Focused Loss (SL)</div><div class="quiz-choice" data-value="Context-Aware Rephraser (CAR)">Context-Aware Rephraser (CAR)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/type.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>Qwen3-Omni Technical Report</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-22</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.17765" target="_blank">http://arxiv.org/pdf/2509.17765</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> A technical report introducing Qwen3-Omni, a multimodal large language model capable of processing and generating text, image, audio, and video content.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous Qwen models and the Thinker-Talker architecture from Qwen2.5-Omni, introducing new ideas including MoE architecture, Audio Transformer encoder, multi-codebook representation, and enhanced streaming capabilities.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> Addressing the challenge of developing a single multimodal model that can maintain state-of-the-art performance across all modalities without degradation while enabling real-time interaction.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> Implements a Thinker-Talker Mixture-of-Experts architecture with five key upgrades: MoE design, AuT encoder, multi-codebook representation, multi-track codec modeling, and reduced audio code rates for streaming.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> Achieves state-of-the-art performance on 32 out of 36 audio/audiovisual benchmarks, matches single-modal performance in text and vision tasks, supports 119 written languages and multiple spoken languages, with a first-packet latency of 234ms.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Qwen3-Omni Technical Report</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">Qwen3-Omni Technical Workflow</text>
  
  <!-- Stage 1: Architecture Design -->
  <rect x="50" y="80" width="200" height="120" rx="10" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="150" y="105" text-anchor="middle" font-size="14" font-weight="bold" fill="#1976d2">Architecture Design</text>
  <text x="150" y="125" text-anchor="middle" font-size="11" fill="#333">Thinker-Talker MoE</text>
  <text x="150" y="140" text-anchor="middle" font-size="11" fill="#333">AuT Audio Encoder</text>
  <text x="150" y="155" text-anchor="middle" font-size="11" fill="#333">Multi-codebook Scheme</text>
  <text x="150" y="170" text-anchor="middle" font-size="11" fill="#333">TM-RoPE Embedding</text>
  <text x="150" y="185" text-anchor="middle" font-size="11" fill="#333">ConvNet Code2Wav</text>
  
  <!-- Stage 2: Audio Transformer Training -->
  <rect x="300" y="80" width="180" height="120" rx="10" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="390" y="105" text-anchor="middle" font-size="14" font-weight="bold" fill="#f57c00">AuT Training</text>
  <text x="390" y="125" text-anchor="middle" font-size="11" fill="#333">20M hours audio data</text>
  <text x="390" y="140" text-anchor="middle" font-size="11" fill="#333">80% CN/EN ASR</text>
  <text x="390" y="155" text-anchor="middle" font-size="11" fill="#333">10% Multi-lang ASR</text>
  <text x="390" y="170" text-anchor="middle" font-size="11" fill="#333">10% Audio Understanding</text>
  <text x="390" y="185" text-anchor="middle" font-size="11" fill="#333">12.5Hz token rate</text>
  
  <!-- Stage 3: Pretraining -->
  <rect x="50" y="250" width="430" height="150" rx="10" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="265" y="275" text-anchor="middle" font-size="14" font-weight="bold" fill="#7b1fa2">Pretraining (3 Stages)</text>
  
  <!-- S1 -->
  <rect x="70" y="290" width="120" height="80" rx="5" fill="#ffffff" stroke="#9c27b0" stroke-width="1"/>
  <text x="130" y="310" text-anchor="middle" font-size="12" font-weight="bold" fill="#9c27b0">S1: Encoder Alignment</text>
  <text x="130" y="325" text-anchor="middle" font-size="10" fill="#333">Lock LLM</text>
  <text x="130" y="340" text-anchor="middle" font-size="10" fill="#333">Train Vision/Audio</text>
  <text x="130" y="355" text-anchor="middle" font-size="10" fill="#333">Adapters</text>
  
  <!-- S2 -->
  <rect x="210" y="290" width="120" height="80" rx="5" fill="#ffffff" stroke="#9c27b0" stroke-width="1"/>
  <text x="270" y="310" text-anchor="middle" font-size="12" font-weight="bold" fill="#9c27b0">S2: General Stage</text>
  <text x="270" y="325" text-anchor="middle" font-size="10" fill="#333">2T tokens</text>
  <text x="270" y="340" text-anchor="middle" font-size="10" fill="#333">Multimodal data</text>
  <text x="270" y="355" text-anchor="middle" font-size="10" fill="#333">All params unfrozen</text>
  
  <!-- S3 -->
  <rect x="350" y="290" width="120" height="80" rx="5" fill="#ffffff" stroke="#9c27b0" stroke-width="1"/>
  <text x="410" y="310" text-anchor="middle" font-size="12" font-weight="bold" fill="#9c27b0">S3: Long Context</text>
  <text x="410" y="325" text-anchor="middle" font-size="10" fill="#333">32K max length</text>
  <text x="410" y="340" text-anchor="middle" font-size="10" fill="#333">Long audio/video</text>
  <text x="410" y="355" text-anchor="middle" font-size="10" fill="#333">Enhanced understanding</text>
  
  <!-- Stage 4: Post-training -->
  <rect x="530" y="80" width="420" height="320" rx="10" fill="#e8f5e8" stroke="#388e3c" stroke-width="2"/>
  <text x="740" y="105" text-anchor="middle" font-size="14" font-weight="bold" fill="#388e3c">Post-training</text>
  
  <!-- Thinker Training -->
  <rect x="550" y="120" width="180" height="120" rx="5" fill="#ffffff" stroke="#4caf50" stroke-width="1"/>
  <text x="640" y="140" text-anchor="middle" font-size="12" font-weight="bold" fill="#4caf50">Thinker Training</text>
  <text x="640" y="160" text-anchor="middle" font-size="10" fill="#333">1. SFT</text>
  <text x="640" y="175" text-anchor="middle" font-size="10" fill="#333">2. Strong-to-Weak</text>
  <text x="640" y="190" text-anchor="middle" font-size="10" fill="#333">   Distillation</text>
  <text x="640" y="205" text-anchor="middle" font-size="10" fill="#333">3. GSPO</text>
  <text x="640" y="220" text-anchor="middle" font-size="10" fill="#333">Multi-modal tasks</text>
  
  <!-- Talker Training -->
  <rect x="750" y="120" width="180" height="120" rx="5" fill="#ffffff" stroke="#4caf50" stroke-width="1"/>
  <text x="840" y="140" text-anchor="middle" font-size="12" font-weight="bold" fill="#4caf50">Talker Training</text>
  <text x="840" y="160" text-anchor="middle" font-size="10" fill="#333">1. Speech mapping</text>
  <text x="840" y="175" text-anchor="middle" font-size="10" fill="#333">2. CPT + Long context</text>
  <text x="840" y="190" text-anchor="middle" font-size="10" fill="#333">3. DPO multilingual</text>
  <text x="840" y="205" text-anchor="middle" font-size="10" fill="#333">4. Speaker fine-tuning</text>
  
  <!-- Captioner Training -->
  <rect x="650" y="260" width="180" height="80" rx="5" fill="#ffffff" stroke="#4caf50" stroke-width="1"/>
  <text x="740" y="280" text-anchor="middle" font-size="12" font-weight="bold" fill="#4caf50">Captioner Training</text>
  <text x="740" y="300" text-anchor="middle" font-size="10" fill="#333">Fine-tune on audio</text>
  <text x="740" y="315" text-anchor="middle" font-size="10" fill="#333">description dataset</text>
  <text x="740" y="330" text-anchor="middle" font-size="10" fill="#333">Low-hallucination</text>
  
  <!-- Stage 5: Optimization -->
  <rect x="50" y="450" width="430" height="120" rx="10" fill="#fff8e1" stroke="#ffa000" stroke-width="2"/>
  <text x="265" y="475" text-anchor="middle" font-size="14" font-weight="bold" fill="#ffa000">Streaming Optimizations</text>
  <text x="265" y="500" text-anchor="middle" font-size="11" fill="#333">• Chunked Prefilling with MoE</text>
  <text x="265" y="520" text-anchor="middle" font-size="11" fill="#333">• Left-context Multi-codebook Generation</text>
  <text x="265" y="540" text-anchor="middle" font-size="11" fill="#333">• Lightweight MTP Module</text>
  <text x="265" y="560" text-anchor="middle" font-size="11" fill="#333">• End-to-end latency: 234ms</text>
  
  <!-- Stage 6: Evaluation -->
  <rect x="530" y="450" width="420" height="120" rx="10" fill="#fce4ec" stroke="#c2185b" stroke-width="2"/>
  <text x="740" y="475" text-anchor="middle" font-size="14" font-weight="bold" fill="#c2185b">Comprehensive Evaluation</text>
  <text x="740" y="500" text-anchor="middle" font-size="11" fill="#333">• Text→Text: 11 benchmarks</text>
  <text x="740" y="520" text-anchor="middle" font-size="11" fill="#333">• Audio→Text: ASR, Music, Reasoning</text>
  <text x="740" y="540" text-anchor="middle" font-size="11" fill="#333">• Vision→Text: VQA, Math, OCR</text>
  <text x="740" y="560" text-anchor="middle" font-size="11" fill="#333">• X→Speech: TTS, Multilingual</text>
  
  <!-- Final Output -->
  <rect x="200" y="620" width="600" height="100" rx="10" fill="#e1f5fe" stroke="#0277bd" stroke-width="2"/>
  <text x="500" y="645" text-anchor="middle" font-size="16" font-weight="bold" fill="#0277bd">Final Models</text>
  <text x="500" y="670" text-anchor="middle" font-size="12" fill="#333">Qwen3-Omni-30B-A3B-Instruct | Qwen3-Omni-30B-A3B-Thinking</text>
  <text x="500" y="690" text-anchor="middle" font-size="12" fill="#333">Qwen3-Omni-30B-A3B-Captioner | Qwen3-Omni-Flash variants</text>
  <text x="500" y="710" text-anchor="middle" font-size="11" fill="#333">119 text languages | 19 speech input | 10 speech output | 40min audio support</text>
  
  <!-- Connection lines -->
  <line x1="250" y1="140" x2="300" y2="140" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="150" y1="200" x2="150" y2="250" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="390" y1="200" x2="390" y2="250" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="480" y1="325" x2="530" y2="240" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="265" y1="400" x2="265" y2="450" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="740" y1="400" x2="740" y2="450" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="570" x2="500" y2="620" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Implementing a Thinker-Talker Mixture-of-Experts (MoE) design">
                        <div class="quiz-question">1. What is the key architectural innovation that enables Qwen3-Omni to achieve low latency and high throughput?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using a simple transformer architecture">Using a simple transformer architecture</div><div class="quiz-choice" data-value="Implementing a Thinker-Talker Mixture-of-Experts (MoE) design">Implementing a Thinker-Talker Mixture-of-Experts (MoE) design</div><div class="quiz-choice" data-value="Relying on traditional CNN networks">Relying on traditional CNN networks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="234 milliseconds">
                        <div class="quiz-question">2. What is the theoretical end-to-end first-packet latency achieved by Qwen3-Omni in cold-start settings?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="534 milliseconds">534 milliseconds</div><div class="quiz-choice" data-value="334 milliseconds">334 milliseconds</div><div class="quiz-choice" data-value="234 milliseconds">234 milliseconds</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="32 benchmarks">
                        <div class="quiz-question">3. How many benchmarks did Qwen3-Omni achieve state-of-the-art performance on out of the 36 audio and audio-visual benchmarks tested?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="22 benchmarks">22 benchmarks</div><div class="quiz-choice" data-value="32 benchmarks">32 benchmarks</div><div class="quiz-choice" data-value="36 benchmarks">36 benchmarks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning
  for Video LLMs</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-22</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.18056" target="_blank">http://arxiv.org/pdf/2509.18056</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> The paper focuses on improving temporal video understanding in multimodal large language models (MLLMs) through a reinforcement learning framework called TempSamp-R1.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on existing Group Relative Policy Optimization (GRPO) methods, the paper proposes integrating off-policy supervision with on-policy sampling and introduces non-linear soft advantage estimation for more stable training.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> The paper addresses the limitations of current reinforcement learning methods in temporal video grounding tasks, where large temporal search spaces make it difficult to identify accurate temporal solutions.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> The authors implement TempSamp-R1 which combines on-policy generation with off-policy guidance from ground-truth annotations, uses soft advantage computation, and employs a hybrid Chain-of-Thought training paradigm.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> TempSamp-R1 outperformed baselines on multiple benchmarks, achieving improvements on Charades-STA (R1@0.7: 52.9%), ActivityNet Captions (R1@0.5: 56.0%), and QVHighlights (mAP: 30.0%), while showing strong few-shot generalization capabilities.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning
  for Video LLMs</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="#2c3e50">TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning</text>
  
  <!-- Input Section -->
  <rect x="50" y="70" width="150" height="80" rx="10" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="125" y="95" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Video + Query</text>
  <text x="125" y="110" text-anchor="middle" font-size="10" fill="white">Input Data</text>
  <text x="125" y="125" text-anchor="middle" font-size="10" fill="white">(2 FPS, 2.8M pixels)</text>
  
  <!-- Policy Model -->
  <rect x="280" y="70" width="140" height="80" rx="10" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="350" y="95" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Policy Model</text>
  <text x="350" y="110" text-anchor="middle" font-size="10" fill="white">Qwen2.5-VL-7B</text>
  <text x="350" y="125" text-anchor="middle" font-size="10" fill="white">On-Policy Sampling</text>
  
  <!-- Off-Policy Guidance -->
  <rect x="480" y="70" width="140" height="80" rx="10" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
  <text x="550" y="95" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Off-Policy</text>
  <text x="550" y="110" text-anchor="middle" font-size="10" fill="white">Guidance</text>
  <text x="550" y="125" text-anchor="middle" font-size="10" fill="white">Ground Truth</text>
  
  <!-- Mixed Solutions -->
  <rect x="680" y="70" width="140" height="80" rx="10" fill="#f39c12" stroke="#e67e22" stroke-width="2"/>
  <text x="750" y="95" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Mixed Solutions</text>
  <text x="750" y="110" text-anchor="middle" font-size="10" fill="white">G-1 On-Policy +</text>
  <text x="750" y="125" text-anchor="middle" font-size="10" fill="white">1 Off-Policy</text>
  
  <!-- Reward Computation -->
  <rect x="150" y="200" width="200" height="100" rx="10" fill="#27ae60" stroke="#229954" stroke-width="2"/>
  <text x="250" y="225" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Reward Computation</text>
  <text x="250" y="245" text-anchor="middle" font-size="11" fill="white">• IoU Reward (Temporal)</text>
  <text x="250" y="260" text-anchor="middle" font-size="11" fill="white">• Timestamp Matching</text>
  <text x="250" y="275" text-anchor="middle" font-size="11" fill="white">• Format Reward (CoT)</text>
  <text x="250" y="290" text-anchor="middle" font-size="11" fill="white">R = {r₁, r₂, ..., rG}</text>
  
  <!-- Soft Advantage Estimation -->
  <rect x="400" y="200" width="250" height="100" rx="10" fill="#e67e22" stroke="#d35400" stroke-width="2"/>
  <text x="525" y="225" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Soft Advantage Estimation</text>
  <text x="525" y="245" text-anchor="middle" font-size="11" fill="white">Non-linear Reward Shaping:</text>
  <text x="525" y="260" text-anchor="middle" font-size="10" fill="white">τ + α₁·ln((rᵢ-τ) + 1) if rᵢ ≥ τ</text>
  <text x="525" y="275" text-anchor="middle" font-size="10" fill="white">τ - (e^(α₂·(τ-rᵢ)) - 1)/(e^α₂ - 1) if rᵢ < τ</text>
  <text x="525" y="290" text-anchor="middle" font-size="11" fill="white">A = {A₁, A₂, ..., AG}</text>
  
  <!-- Alternative Strategies Box -->
  <rect x="700" y="200" width="180" height="100" rx="10" fill="#8e44ad" stroke="#7d3c98" stroke-width="2"/>
  <text x="790" y="220" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Alternative Strategies</text>
  <text x="790" y="240" text-anchor="middle" font-size="10" fill="white">• Reward Downscaling</text>
  <text x="790" y="255" text-anchor="middle" font-size="10" fill="white">• Advantage Anchoring</text>
  <text x="790" y="270" text-anchor="middle" font-size="10" fill="white">• Non-linear Shaping</text>
  <text x="790" y="285" text-anchor="middle" font-size="10" fill="white">(Best Performance)</text>
  
  <!-- GRPO Update -->
  <rect x="200" y="350" width="300" height="80" rx="10" fill="#c0392b" stroke="#a93226" stroke-width="2"/>
  <text x="350" y="375" text-anchor="middle" font-size="14" font-weight="bold" fill="white">GRPO Policy Update</text>
  <text x="350" y="395" text-anchor="middle" font-size="11" fill="white">J_GRPO = min(π_θ(o|q)/π_θ_old(o|q)·A, clip(...)·A)</text>
  <text x="350" y="410" text-anchor="middle" font-size="11" fill="white">- β·KL(π_θ || π_ref)</text>
  
  <!-- Hybrid CoT Training -->
  <rect x="550" y="350" width="200" height="80" rx="10" fill="#16a085" stroke="#138d75" stroke-width="2"/>
  <text x="650" y="375" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Hybrid CoT Training</text>
  <text x="650" y="395" text-anchor="middle" font-size="11" fill="white">Unified Model:</text>
  <text x="650" y="410" text-anchor="middle" font-size="11" fill="white">CoT + Non-CoT modes</text>
  
  <!-- Training Phases -->
  <rect x="100" y="480" width="180" height="80" rx="10" fill="#2c3e50" stroke="#1b2631" stroke-width="2"/>
  <text x="190" y="505" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Phase 1:</text>
  <text x="190" y="520" text-anchor="middle" font-size="11" fill="white">Initialization</text>
  <text x="190" y="535" text-anchor="middle" font-size="10" fill="white">Direct answer generation</text>
  <text x="190" y="550" text-anchor="middle" font-size="10" fill="white">without reasoning</text>
  
  <rect x="320" y="480" width="180" height="80" rx="10" fill="#2c3e50" stroke="#1b2631" stroke-width="2"/>
  <text x="410" y="505" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Phase 2:</text>
  <text x="410" y="520" text-anchor="middle" font-size="11" fill="white">CoT Integration</text>
  <text x="410" y="535" text-anchor="middle" font-size="10" fill="white">Format rewards for</text>
  <text x="410" y="550" text-anchor="middle" font-size="10" fill="white">reasoning steps</text>
  
  <!-- Output Results -->
  <rect x="550" y="480" width="350" height="80" rx="10" fill="#d4ac0d" stroke="#b7950b" stroke-width="2"/>
  <text x="725" y="500" text-anchor="middle" font-size="12" font-weight="bold" fill="black">Performance Results</text>
  <text x="725" y="520" text-anchor="middle" font-size="10" fill="black">Charades-STA: R1@0.7: 52.9% (+2.7%)</text>
  <text x="725" y="535" text-anchor="middle" font-size="10" fill="black">ActivityNet: R1@0.5: 56.0% (+5.3%)</text>
  <text x="725" y="550" text-anchor="middle" font-size="10" fill="black">QVHighlights: mAP: 30.0% (+3.0%)</text>
  
  <!-- Evaluation Tasks -->
  <rect x="100" y="600" width="150" height="60" rx="10" fill="#17a2b8" stroke="#138496" stroke-width="2"/>
  <text x="175" y="620" text-anchor="middle" font-size="11" font-weight="bold" fill="white">Temporal</text>
  <text x="175" y="635" text-anchor="middle" font-size="11" font-weight="bold" fill="white">Grounding</text>
  <text x="175" y="650" text-anchor="middle" font-size="9" fill="white">Charades-STA, ActivityNet</text>
  
  <rect x="280" y="600" width="150" height="60" rx="10" fill="#17a2b8" stroke="#138496" stroke-width="2"/>
  <text x="355" y="620" text-anchor="middle" font-size="11" font-weight="bold" fill="white">Highlight</text>
  <text x="355" y="635" text-anchor="middle" font-size="11" font-weight="bold" fill="white">Detection</text>
  <text x="355" y="650" text-anchor="middle" font-size="9" fill="white">QVHighlights</text>
  
  <!-- Key Innovation Box -->
  <rect x="500" y="600" width="350" height="120" rx="10" fill="#6c757d" stroke="#495057" stroke-width="2"/>
  <text x="675" y="620" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Key Innovations</text>
  <text x="675" y="640" text-anchor="middle" font-size="11" fill="white">✓ Mixed-policy sampling (on + off-policy)</text>
  <text x="675" y="655" text-anchor="middle" font-size="11" fill="white">✓ Non-linear soft advantage estimation</text>
  <text x="675" y="670" text-anchor="middle" font-size="11" fill="white">✓ Hybrid CoT training paradigm</text>
  <text x="675" y="685" text-anchor="middle" font-size="11" fill="white">✓ Stable training with reduced variance</text>
  <text x="675" y="700" text-anchor="middle" font-size="11" fill="white">✓ Superior few-shot generalization</text>
  
  <!-- Flow connections (simplified lines instead of arrows) -->
  <line x1="200" y1="110" x2="280" y2="110" stroke="#34495e" stroke-width="2"/>
  <line x1="420" y1="110" x2="480" y2="110" stroke="#34495e" stroke-width="2"/>
  <line x1="620" y1="110" x2="680" y2="110" stroke="#34495e" stroke-width="2"/>
  <line x1="750" y1="150" x2="250" y2="200" stroke="#34495e" stroke-width="2"/>
  <line x1="250" y1="300" x2="525" y2="200" stroke="#34495e" stroke-width="2"/>
  <line x1="525" y1="300" x2="350" y2="350" stroke="#34495e" stroke-width="2"/>
  <line x1="350" y1="430" x2="190" y2="480" stroke="#34495e" stroke-width="2"/>
  <line x1="350" y1="430" x2="410" y2="480" stroke="#34495e" stroke-width="2"/>
  <line x1="650" y1="430" x2="725" y2="480" stroke="#34495e" stroke-width="2"/>
  <line x1="410" y1="560" x2="175" y2="600" stroke="#34495e" stroke-width="2"/>
  <line x1="410" y1="560" x2="355" y2="600" stroke="#34495e" stroke-width="2"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Ineffective exploration in large temporal search spaces">
                        <div class="quiz-question">1. What is the main limitation of existing GRPO-based methods that TempSamp-R1 aims to address?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="High computational costs">High computational costs</div><div class="quiz-choice" data-value="Ineffective exploration in large temporal search spaces">Ineffective exploration in large temporal search spaces</div><div class="quiz-choice" data-value="Inability to process long videos">Inability to process long videos</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By leveraging ground-truth annotations as external solutions">
                        <div class="quiz-question">2. How does TempSamp-R1 incorporate off-policy guidance into its training process?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By using predictions from other models">By using predictions from other models</div><div class="quiz-choice" data-value="By leveraging ground-truth annotations as external solutions">By leveraging ground-truth annotations as external solutions</div><div class="quiz-choice" data-value="By randomly generating temporal segments">By randomly generating temporal segments</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It supports both CoT and non-CoT inference modes in a single unified model">
                        <div class="quiz-question">3. What unique feature of TempSamp-R1's training paradigm allows it to handle queries with varying complexity?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses multiple separate models for different query types">It uses multiple separate models for different query types</div><div class="quiz-choice" data-value="It automatically categorizes queries by difficulty">It automatically categorizes queries by difficulty</div><div class="quiz-choice" data-value="It supports both CoT and non-CoT inference modes in a single unified model">It supports both CoT and non-CoT inference modes in a single unified model</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // 创建遮罩层
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // 获取所有问题标签
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // 设置点击事件处理
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // 点击标签切换问题卡的显示状态
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // 阻止事件冒泡
                    
                    // 如果当前问题卡已经显示，则隐藏它
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // 先隐藏所有其他问题卡
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // 将弹窗内容复制到页面最外层的弹窗中
                        document.body.appendChild(popup);
                        
                        // 显示当前问题卡和背景遮罩
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // 确保点击问题卡内部时不会关闭问题卡
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // 点击遮罩层或页面任何其他位置时隐藏所有问题卡
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // 为每个选项添加点击事件
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // 重置所有选项
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // 标记当前选项为已选
                    this.classList.add('selected');
                    
                    // 检查是否正确
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '✔️ Correct！';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '❌ Wrong！';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // 卡片轮播功能 - 新增
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // 更新计数器显示
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // 显示指定索引的卡片
                function showCard(index) {
                    // 处理循环
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // 更新当前索引
                    currentIndex = index;
                    
                    // 更新卡片显示
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // 更新计数器
                    updateCounter();
                }
                
                // 下一张卡片
                function nextCard(e) {
                    e.stopPropagation(); // 防止事件冒泡导致问题卡关闭
                    showCard(currentIndex + 1);
                }
                
                // 为卡片容器添加点击事件
                cardDeck.addEventListener('click', function(e) {
                    // 检查点击是否发生在流程图卡片内部的滚动区域
                    // 如果是在滚动条上点击，不切换卡片
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // 计算点击位置是否在滚动条区域
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // 键盘导航
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
