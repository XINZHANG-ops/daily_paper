
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-20 ËÆ∫ÊñáÊé®ÈÄÅ</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
        }
        .paper-card:hover {
            transform: translateY(-5px); /* Lift effect on hover */
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2); /* Shadow on hover */
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
        }
        .category-chunk:hover {
            transform: translateY(-3px); /* Slightly smaller lift for categories */
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15); /* Slightly smaller shadow for categories */
        }
        .category-chunk:nth-child(1) { /* 1. Topic and Domain */
            background-color: #d3e3fd; /* Blue */
        }
        .category-chunk:nth-child(2) { /* 2. Previous Research and New Ideas */
            background-color: #e6d6fa; /* Purple */
        }
        .category-chunk:nth-child(3) { /* 3. Problem */
            background-color: #d4f8d9; /* Green */
        }
        .category-chunk:nth-child(4) { /* 4. Methods */
            background-color: #ffd7d5; /* Pink */
        }
        .category-chunk:nth-child(5) { /* 5. Results and Evaluation */
            background-color: #d3e3fd; /* Reuse Blue */
        }
    </style>
</head>
<body>
    <h1>2025-03-20 ËÆ∫ÊñáÊé®ÈÄÅ</h1>
    
        <div class="paper-card">
            <h2>Paper: 1</h2>
            <p><strong>Temporal Regularization Makes Your Video Generator Stronger</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15417" target="_blank">http://arxiv.org/pdf/2503.15417</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on temporal data augmentation for video generation, specifically within the domain of computer vision and deep learning.  2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing video generation models (U-Net, DiT, AR-based) and proposes FLUX FLOW, a novel temporal augmentation strategy that perturbs frame order during training.  3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of temporal inconsistency and limited temporal diversity in generated videos, such as flickering and unnatural motion.  4.  <strong>üõ†Ô∏è Methods:</strong> The authors used FLUX FLOW, which includes frame-level and block-level temporal perturbations, applied as a pre-processing step during the training of video generation models.  5.  <strong>üìä Results and Evaluation:</strong> FLUX FLOW significantly improved temporal coherence and diversity across various video generation models, as evaluated on UCF-101 and VBench benchmarks using metrics like FVD, IS, and user studies.</div></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 2</h2>
            <p><strong>Optimizing Decomposition for Optimal Claim Verification</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15354" target="_blank">http://arxiv.org/pdf/2503.15354</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on fact-checking of long-form text, specifically optimizing the decomposition stage within the "Decompose-Then-Verify" paradigm in the domain of Natural Language Processing.  2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing "Decompose-Then-Verify" fact-checking methods that use handcrafted prompts, and proposes a novel reinforcement learning framework (dynamic decomposition) to learn a decomposition policy tailored to the verifier, introducing the concept of "atomicity" to quantify information density.  3.  <strong>‚ùì Problem:</strong> The paper aims to solve the misalignment between decomposers and verifiers in existing fact-checking systems, where static decomposition policies don't generate subclaims with optimal atomicity for downstream verification.  4.  <strong>üõ†Ô∏è Methods:</strong> The authors used a reinforcement learning (RL) framework, specifically Proximal Policy Optimization (PPO) in an Advantage Actor-Critic (A2C) style, to train a dynamic decomposition policy that interacts with a verifier and receives feedback.  5.  <strong>üìä Results and Evaluation:</strong> The results, evaluated on verification confidence and accuracy across various datasets and verifiers, show that dynamic decomposition outperforms existing static decomposition policies, improving verification confidence by 0.07 and accuracy by 0.12 on average.</div></div>
        </div>
        
</body>
</html>
