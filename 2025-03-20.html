
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-20 Paper</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>2025-03-20 Paper</h1>
    
        <div class="paper-card">
            <h2>Paper: 1</h2>
            <p><strong>Optimizing Decomposition for Optimal Claim Verification</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15354" target="_blank">http://arxiv.org/pdf/2503.15354</a></p>
            <div>Here's a concise analysis of the paper based on your requested format:<br><br>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on fact-checking of long-form text, specifically optimizing the decomposition stage within the "Decompose-Then-Verify" paradigm in the domain of natural language processing.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing "Decompose-Then-Verify" fact-checking systems that use hand-crafted prompts for decomposition, and proposes a new reinforcement learning framework (dynamic decomposition) that learns a decomposition policy based on verifier feedback and a novel "atomicity" metric.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the misalignment between decomposers and verifiers in existing fact-checking systems, where static decomposition policies don't generate subclaims with optimal "atomicity" for downstream verification.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used a reinforcement learning (RL) framework, specifically a Proximal Policy Optimization (PPO) algorithm in an Advantage Actor-Critic (A2C) style, to learn a dynamic decomposition policy modeled as a Markov Decision Process (MDP).<br><br>5.  <strong>üìä Results and Evaluation:</strong> The results, evaluated on verification confidence and accuracy across different verifiers and datasets, show that dynamic decomposition outperforms existing static decomposition policies, demonstrating improved alignment between the decomposition and verification stages.<br></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 2</h2>
            <p><strong>MetaLadder: Ascending Mathematical Solution Quality via
  Analogical-Problem Reasoning Transfer</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.14891" target="_blank">http://arxiv.org/pdf/2503.14891</a></p>
            <div>Here's a concise analysis of the paper based on your requested format:<br><br>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on improving mathematical reasoning capabilities of Large Language Models (LLMs) using analogical reasoning, falling within the domain of Natural Language Processing and Artificial Intelligence.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing Chain-of-Thought (CoT) prompting methods and proposes "MetaLadder," a novel framework that prompts LLMs to recall and reflect on analogous problems and their solutions before solving a target problem, along with a problem-restating mechanism.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the limitation of current LLMs in transferring learned reasoning patterns across mathematical problems, particularly those requiring abstract structural or semantic similarities.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used a framework called MetaLadder, involving reflective data generation (problem type, solution method, analogous problem, and solution), analogical reasoning activation through specific data formatting, a self-evolution process for data augmentation, and a shortcut inference mechanism.<br><br>5.  <strong>üìä Results and Evaluation:</strong> Experiments on mathematical benchmarks (GSM8K, MATH, and others) showed that MetaLadder significantly outperformed standard CoT methods and other baselines, achieving substantial accuracy gains and improved generalization, evaluated using Pass@1 accuracy.<br></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 3</h2>
            <p><strong>Decompositional Neural Scene Reconstruction with Generative Diffusion
  Prior</strong></p>
            <p><strong>Published: </strong>2025-03-18</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.14830" target="_blank">http://arxiv.org/pdf/2503.14830</a></p>
            <div>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on decompositional 3D scene reconstruction from sparse-view images, a topic within the domain of computer vision and 3D deep learning.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on neural implicit representations (NeRF, SDFs), sparse-view NeRF regularization techniques, and diffusion priors for 3D, and proposes a new method (DP-RECON) that uses a generative diffusion prior (SDS) with visibility guidance to improve object-level reconstruction.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of incomplete and inaccurate 3D scene reconstruction, particularly of individual objects, from sparse views, including issues with occluded regions.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used Score Distillation Sampling (SDS) with a pre-trained diffusion model (Stable Diffusion) to optimize neural implicit representations of individual objects, along with a novel visibility-guided approach to balance reconstruction and generative guidance.<br><br>5.  <strong>üìä Results and Evaluation:</strong> The results, evaluated on Replica and ScanNet++ datasets, show significant improvements over state-of-the-art methods in both geometry and appearance reconstruction, especially in occluded regions, and the method enables text-based scene editing and VFX editing.<br></div>
        </div>
        
</body>
</html>
