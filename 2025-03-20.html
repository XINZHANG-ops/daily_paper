
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-20 Paper</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>2025-03-20 Paper</h1>
    
        <div class="paper-card">
            <h2>Paper: 1</h2>
            <p><strong>Optimizing Decomposition for Optimal Claim Verification</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15354" target="_blank">http://arxiv.org/pdf/2503.15354</a></p>
            <div>Here's a concise analysis of the paper based on your requested format:<br><br>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on fact-checking of long-form text, specifically optimizing the decomposition step within the "Decompose-Then-Verify" paradigm.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing "Decompose-Then-Verify" fact-checking methods, but proposes a new reinforcement learning framework (dynamic decomposition) to optimize the decomposition policy based on verifier feedback and a novel "atomicity" metric.<br><br>3.  <strong>‚ùì Problem:</strong> Existing decomposition policies in fact-checking systems are often misaligned with verifiers, leading to suboptimal verification results.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a reinforcement learning (specifically, Proximal Policy Optimization) framework, formulated as a Markov Decision Process, to learn a dynamic decomposition policy.<br><br>5.  <strong>üìä Results and Evaluation:</strong> Dynamic decomposition outperforms existing decomposition policies, improving verification confidence by 0.07 and accuracy by 0.12 on average across various settings.<br></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 2</h2>
            <p><strong>MetaLadder: Ascending Mathematical Solution Quality via
  Analogical-Problem Reasoning Transfer</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.14891" target="_blank">http://arxiv.org/pdf/2503.14891</a></p>
            <div>Here's a concise analysis of the paper based on your requested format:<br><br>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on improving mathematical reasoning capabilities of Large Language Models (LLMs) using analogical reasoning, within the domain of artificial intelligence and natural language processing.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon Chain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG), proposing a new framework called MetaLadder that prompts LLMs to recall and reflect on analogous problems and restate the target problem.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the limitation of current LLMs in transferring learned reasoning patterns and generalizing to new problems, unlike human problem-solving that leverages analogous experiences.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used the MetaLadder framework, which includes generating reflective data (problem type, solution method, analogous problem, and its solution), a problem-restating mechanism, analogical self-evolution, and shortcut inference.<br><br>5.  <strong>üìä Results and Evaluation:</strong> MetaLadder significantly outperformed standard CoT and other methods on mathematical benchmarks (GSM8K, MATH, and others), showing improved accuracy and generalization, evaluated using Pass@1 accuracy.<br></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 3</h2>
            <p><strong>Decompositional Neural Scene Reconstruction with Generative Diffusion
  Prior</strong></p>
            <p><strong>Published: </strong>2025-03-18</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.14830" target="_blank">http://arxiv.org/pdf/2503.14830</a></p>
            <div>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on decompositional 3D scene reconstruction from sparse-view images, a topic within the domain of computer vision and 3D scene understanding.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon neural implicit representations, NeRF, and diffusion models, proposing a new method (DP-R ECON) that integrates a generative diffusion prior (SDS) with visibility guidance for improved object-level reconstruction.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of incomplete and inaccurate 3D scene reconstruction, especially in occluded or sparsely captured regions, when using only a few input views.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used a decompositional neural implicit surface representation, Score Distillation Sampling (SDS) with a pre-trained diffusion model (Stable Diffusion), and a novel visibility-guided approach to balance reconstruction and generative guidance.<br><br>5.  <strong>üìä Results and Evaluation:</strong> The results, evaluated on Replica and ScanNet++ datasets, demonstrate significant improvements in both geometry and appearance reconstruction compared to state-of-the-art methods, particularly in occluded areas, and enable text-based scene editing.<br></div>
        </div>
        
</body>
</html>
