
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-20 Paper</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>2025-03-20 Paper</h1>
    
        <div class="paper-card">
            <h2>Paper: 1</h2>
            <p><strong>Temporal Regularization Makes Your Video Generator Stronger</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15417" target="_blank">http://arxiv.org/pdf/2503.15417</a></p>
            <div>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on improving the temporal quality of generated videos, specifically addressing temporal coherence and diversity, within the domain of video generation.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing video generation methods (U-Net, DiT, AR-based) and temporal refinement techniques (architecture-centric, physics-informed, training dynamics optimization), and proposes a novel data-level temporal augmentation strategy called FLUX FLOW.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of temporal artifacts (flickering, discontinuous motion) and limited temporal diversity in videos produced by existing video generation models.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used FLUX FLOW, a data augmentation strategy that introduces controlled temporal perturbations at the frame level (random shuffling) and block level (reordering contiguous blocks) during training.<br><br>5.  <strong>üìä Results and Evaluation:</strong> Results on UCF-101 and VBench benchmarks demonstrate that FLUX FLOW significantly improves temporal coherence and diversity across various video generation models, while maintaining spatial fidelity, evaluated using metrics like FVD, IS, and various VBench temporal/frame-wise quality scores, further supported by a user study.<br></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 2</h2>
            <p><strong>Optimizing Decomposition for Optimal Claim Verification</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15354" target="_blank">http://arxiv.org/pdf/2503.15354</a></p>
            <div>Here's a concise analysis of the paper based on your requested format:<br><br>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on optimizing claim decomposition for fact-checking in the domain of natural language processing and computational linguistics.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon the "Decompose-Then-Verify" paradigm for fact-checking and introduces a new metric called "atomicity" and proposes Dynamic Decomposion, a reinforcement learning framework.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the misalignment between decomposition policies and verifiers in existing fact-checking systems, which leads to suboptimal verification results.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a reinforcement learning (specifically, Proximal Policy Optimization) framework, formulated as a Markov Decision Process, to learn a dynamic decomposition policy.<br><br>5.  <strong>üìä Results and Evaluation:</strong> The results, evaluated on verification confidence and accuracy across multiple datasets and verifiers, show that dynamic decomposition outperforms existing decomposition policies.<br></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 3</h2>
            <p><strong>Efficient Personalization of Quantized Diffusion Model without
  Backpropagation</strong></p>
            <p><strong>Published: </strong>2025-03-18</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.14868" target="_blank">http://arxiv.org/pdf/2503.14868</a></p>
            <div>1.  <strong>üìò Topic and Domain:</strong> The paper focuses on efficient personalization of diffusion models for image synthesis, specifically within the domain of low-memory and computationally constrained environments.<br><br>2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on prior work in diffusion model personalization (Textual Inversion, DreamBooth), quantization, and zeroth-order optimization, and proposes a new method called ZOODiP that combines these with Subspace Gradient and Partial Uniform Timestep Sampling.<br><br>3.  <strong>‚ùì Problem:</strong> The paper aims to solve the high memory and computational requirements of personalizing quantized diffusion models, making it feasible on devices with limited resources.<br><br>4.  <strong>üõ†Ô∏è Methods:</strong> The authors used zeroth-order optimization on a quantized diffusion model, Subspace Gradient projection, and Partial Uniform Timestep Sampling to achieve memory-efficient personalization.<br><br>5.  <strong>üìä Results and Evaluation:</strong> ZOODiP achieved comparable image and text alignment scores to existing methods while reducing training memory demand by up to 8.2x, evaluated using CLIP and DINO metrics on the DreamBooth dataset.<br></div>
        </div>
        
</body>
</html>
