
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-20 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
        }
        .paper-card:hover {
            transform: translateY(-5px); /* Lift effect on hover */
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2); /* Shadow on hover */
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
        }
        .category-chunk:hover {
            transform: translateY(-3px); /* Slightly smaller lift for categories */
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15); /* Slightly smaller shadow for categories */
        }
        .category-chunk:nth-child(1) { /* 1. Topic and Domain */
            background-color: #d3e3fd; /* Blue */
        }
        .category-chunk:nth-child(2) { /* 2. Previous Research and New Ideas */
            background-color: #e6d6fa; /* Purple */
        }
        .category-chunk:nth-child(3) { /* 3. Problem */
            background-color: #d4f8d9; /* Green */
        }
        .category-chunk:nth-child(4) { /* 4. Methods */
            background-color: #ffd7d5; /* Pink */
        }
        .category-chunk:nth-child(5) { /* 5. Results and Evaluation */
            background-color: #d3e3fd; /* Reuse Blue */
        }
    </style>
</head>
<body>
    <h1>2025-03-20 ËÆ∫ÊñáÊé®ÈÄÅ</h1>
    
        <div class="paper-card">
            <h2>Paper: 1</h2>
            <p><strong>Temporal Regularization Makes Your Video Generator Stronger</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15417" target="_blank">http://arxiv.org/pdf/2503.15417</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on temporal data augmentation for video generation, specifically within the domain of computer vision and deep learning.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing video generation models (U-Net, DiT, AR-based) and temporal refinement techniques (architecture-centric, physics-informed, training dynamics optimization), and proposes FLUX FLOW, a novel data-level temporal augmentation strategy.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of temporal inconsistency and limited temporal diversity in generated videos, which often exhibit flickering, discontinuous motion, and repetitive dynamics.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors used FLUX FLOW, which introduces controlled temporal perturbations at the data level through frame-level (random shuffling of individual frames) and block-level (reordering contiguous-frame blocks) operations during training.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> FLUX FLOW significantly improved temporal coherence and diversity across various video generation models on UCF-101 and VBench benchmarks, while preserving spatial fidelity, as evaluated by metrics like FVD, IS, and various VBench dimensions, along with user studies.</div></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 2</h2>
            <p><strong>Optimizing Decomposition for Optimal Claim Verification</strong></p>
            <p><strong>Published: </strong>2025-03-19</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.15354" target="_blank">http://arxiv.org/pdf/2503.15354</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on optimizing claim decomposition for improved fact-checking of long-form text, within the domain of natural language processing and computational fact verification.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on the "Decompose-Then-Verify" paradigm for fact-checking, introducing a new "atomicity" metric and proposing dynamic decomposition using reinforcement learning, unlike prior work's static, prompt-based approaches.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the misalignment between decomposition policies and verifiers in terms of subclaim atomicity, which leads to suboptimal verification results in existing fact-checking systems.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors formulate the problem as a bilevel optimization and approximate a solution using a reinforcement learning framework (specifically, an A2C-style PPO algorithm) to learn a dynamic decomposition policy.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Dynamic decomposition outperforms existing decomposition policies, improving verification confidence by 0.07 and accuracy by 0.12 on average across various verifiers, datasets, and input claim atomicities, as evaluated using verification confidence and accuracy metrics.</div></div>
        </div>
        
        <div class="paper-card">
            <h2>Paper: 3</h2>
            <p><strong>œÜ-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time
  Exploration and Exploitation</strong></p>
            <p><strong>Published: </strong>2025-03-17</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.13288" target="_blank">http://arxiv.org/pdf/2503.13288</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces a new decoding strategy for large language models (LLMs) in the domain of natural language processing, specifically focusing on reasoning tasks.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on search-based inference-time optimization methods like Tree-of-Thoughts (ToT) and Monte Carlo Tree Search (MCTS), proposing "œï-Decoding," which uses foresight sampling and clustering to estimate step value and dynamic pruning for efficiency.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the short-sightedness of auto-regressive generation in LLMs and the inefficiency of existing search-based methods, achieving a better balance between exploration and exploitation during inference.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors used foresight sampling to simulate future steps, clustering of foresight paths to assess alignment, dynamic advantage estimation, and in-width and in-depth pruning strategies to optimize computation.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The proposed œï-Decoding outperformed strong baselines on seven reasoning benchmarks, showing significant improvements in both performance and efficiency, and demonstrating generalization across various LLMs and scalability.</div></div>
        </div>
        
</body>
</html>
