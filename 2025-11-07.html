
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-11-07 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            height: 600px; /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%;
            transition: transform 0.5s ease, opacity 0.5s ease;
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow: auto !important;
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖ */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-height: none; /* ÁßªÈô§‰ªª‰ΩïÈ´òÂ∫¶ÈôêÂà∂ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        
        .paper-card p {
            margin: 5px 0;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        @media (max-width: 768px) {
            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }
            
            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <h1>2025-11-07 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/office.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Thinking with Video: Video Generation as a Promising Multimodal
  Reasoning Paradigm</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-11-06</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2511.04570" target="_blank">http://arxiv.org/pdf/2511.04570</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper explores video generation as a new paradigm for multimodal reasoning in artificial intelligence, specifically examining how video generation models can enhance reasoning capabilities compared to traditional text and image-based approaches.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous "Thinking with Text" (Chain-of-Thought) and "Thinking with Images" paradigms, the paper proposes "Thinking with Video" as a new unified paradigm that overcomes limitations of static images and separated modalities.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitations of current reasoning paradigms: images can only capture single moments and cannot represent dynamic processes, while text and vision are treated as separate modalities, hindering unified multimodal understanding.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors developed VideoThinkBench, a comprehensive benchmark with vision-centric tasks (eyeballing games, visual puzzles) and text-centric tasks (subsets of GSM8K, MMMU), and evaluated Sora-2's performance against state-of-the-art Vision Language Models.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Results showed Sora-2 performed comparably to SOTA VLMs on vision-centric tasks and even surpassed them in some cases, while achieving strong performance on text-centric tasks (92% accuracy on MATH, 75.53% on MMMU), demonstrating the potential of video generation as a unified multimodal reasoning approach.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Thinking with Video: Video Generation as a Promising Multimodal
  Reasoning Paradigm</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#2c3e50">
    Thinking with Video: Method Workflow
  </text>
  
  <!-- Main Framework Box -->
  <rect x="50" y="60" width="900" height="120" fill="#3498db" stroke="#2980b9" stroke-width="2" rx="10"/>
  <text x="500" y="85" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    "Thinking with Video" Paradigm
  </text>
  <text x="500" y="110" text-anchor="middle" font-size="14" fill="white">
    Video generation models (Sora-2) bridge visual and textual reasoning
  </text>
  <text x="500" y="130" text-anchor="middle" font-size="14" fill="white">
    through unified temporal framework for multimodal understanding
  </text>
  <text x="500" y="150" text-anchor="middle" font-size="14" fill="white">
    Enables dynamic reasoning via drawing and imagination
  </text>
  
  <!-- Benchmark Development -->
  <rect x="50" y="200" width="400" height="80" fill="#e74c3c" stroke="#c0392b" stroke-width="2" rx="8"/>
  <text x="250" y="225" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    VideoThinkBench Development
  </text>
  <text x="250" y="245" text-anchor="middle" font-size="12" fill="white">
    Two task categories: Vision-centric &amp; Text-centric
  </text>
  <text x="250" y="265" text-anchor="middle" font-size="12" fill="white">
    4,149 total samples across multiple reasoning types
  </text>
  
  <!-- Vision-Centric Tasks -->
  <rect x="550" y="200" width="400" height="80" fill="#9b59b6" stroke="#8e44ad" stroke-width="2" rx="8"/>
  <text x="750" y="225" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Vision-Centric Tasks (2,696 samples)
  </text>
  <text x="750" y="245" text-anchor="middle" font-size="12" fill="white">
    Spatial reasoning: Eyeballing puzzles, Mazes
  </text>
  <text x="750" y="265" text-anchor="middle" font-size="12" fill="white">
    Inductive reasoning: Visual puzzles, ARC-AGI-2
  </text>
  
  <!-- Vision Task Details -->
  <rect x="50" y="300" width="180" height="100" fill="#f39c12" stroke="#e67e22" stroke-width="2" rx="6"/>
  <text x="140" y="320" text-anchor="middle" font-size="12" font-weight="bold" fill="white">
    Eyeballing Puzzles
  </text>
  <text x="140" y="340" text-anchor="middle" font-size="10" fill="white">
    21 geometric tasks</text>
  <text x="140" y="355" text-anchor="middle" font-size="10" fill="white">
    Point/Line/Shape construction</text>
  <text x="140" y="370" text-anchor="middle" font-size="10" fill="white">
    Sora-2: 40.2% accuracy</text>
  <text x="140" y="385" text-anchor="middle" font-size="10" fill="white">
    Surpasses VLMs</text>
  
  <rect x="250" y="300" width="180" height="100" fill="#27ae60" stroke="#229954" stroke-width="2" rx="6"/>
  <text x="340" y="320" text-anchor="middle" font-size="12" font-weight="bold" fill="white">
    Visual Puzzles
  </text>
  <text x="340" y="340" text-anchor="middle" font-size="10" fill="white">
    Pattern recognition</text>
  <text x="340" y="355" text-anchor="middle" font-size="10" fill="white">
    Color-filling &amp; Shape-drawing</text>
  <text x="340" y="370" text-anchor="middle" font-size="10" fill="white">
    Inductive reasoning</text>
  <text x="340" y="385" text-anchor="middle" font-size="10" fill="white">
    Comparable to VLMs</text>
  
  <rect x="450" y="300" width="180" height="100" fill="#e67e22" stroke="#d35400" stroke-width="2" rx="6"/>
  <text x="540" y="320" text-anchor="middle" font-size="12" font-weight="bold" fill="white">
    ARC-AGI-2
  </text>
  <text x="540" y="340" text-anchor="middle" font-size="10" fill="white">
    Abstract reasoning</text>
  <text x="540" y="355" text-anchor="middle" font-size="10" fill="white">
    Few-shot learning</text>
  <text x="540" y="370" text-anchor="middle" font-size="10" fill="white">
    Pattern transformation</text>
  <text x="540" y="385" text-anchor="middle" font-size="10" fill="white">
    1.3% accuracy</text>
  
  <rect x="650" y="300" width="180" height="100" fill="#34495e" stroke="#2c3e50" stroke-width="2" rx="6"/>
  <text x="740" y="320" text-anchor="middle" font-size="12" font-weight="bold" fill="white">
    Mazes
  </text>
  <text x="740" y="340" text-anchor="middle" font-size="10" fill="white">
    Pathfinding tasks</text>
  <text x="740" y="355" text-anchor="middle" font-size="10" fill="white">
    Square/Hexagon/Circle</text>
  <text x="740" y="370" text-anchor="middle" font-size="10" fill="white">
    Square: 40% success</text>
  <text x="740" y="385" text-anchor="middle" font-size="10" fill="white">
    Others: 0% success</text>
  
  <!-- Text-Centric Tasks -->
  <rect x="50" y="420" width="400" height="80" fill="#8e44ad" stroke="#7d3c98" stroke-width="2" rx="8"/>
  <text x="250" y="445" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Text-Centric Tasks (1,453 samples)
  </text>
  <text x="250" y="465" text-anchor="middle" font-size="12" fill="white">
    Text-only: Math &amp; General knowledge reasoning</text>
  <text x="250" y="485" text-anchor="middle" font-size="12" fill="white">
    Multimodal: Math &amp; General knowledge reasoning</text>
  
  <!-- Evaluation Methods -->
  <rect x="550" y="420" width="400" height="80" fill="#16a085" stroke="#138d75" stroke-width="2" rx="8"/>
  <text x="750" y="445" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Evaluation Methods
  </text>
  <text x="750" y="465" text-anchor="middle" font-size="12" fill="white">
    Audio, Last Frame, Major Frame evaluation</text>
  <text x="750" y="485" text-anchor="middle" font-size="12" fill="white">
    LLM-as-a-Judge for text-centric tasks</text>
  
  <!-- Key Findings -->
  <rect x="50" y="520" width="280" height="120" fill="#2ecc71" stroke="#27ae60" stroke-width="2" rx="8"/>
  <text x="190" y="545" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Key Findings
  </text>
  <text x="190" y="565" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Sora-2 surpasses VLMs on eyeballing</text>
  <text x="190" y="580" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Strong text-centric performance</text>
  <text x="190" y="595" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Few-shot learning capability</text>
  <text x="190" y="610" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Self-consistency improves results</text>
  <text x="190" y="625" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Unified multimodal reasoning</text>
  
  <!-- Analysis Experiments -->
  <rect x="350" y="520" width="280" height="120" fill="#e74c3c" stroke="#c0392b" stroke-width="2" rx="8"/>
  <text x="490" y="545" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Analysis Experiments
  </text>
  <text x="490" y="565" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Test set leakage analysis</text>
  <text x="490" y="580" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Reasoning process evaluation</text>
  <text x="490" y="595" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Source of abilities investigation</text>
  <text x="490" y="610" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Prompt rewriter analysis</text>
  <text x="490" y="625" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Output modality comparison</text>
  
  <!-- Performance Results -->
  <rect x="650" y="520" width="300" height="120" fill="#f39c12" stroke="#e67e22" stroke-width="2" rx="8"/>
  <text x="800" y="545" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Performance Highlights
  </text>
  <text x="800" y="565" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ GSM8K: 98.9% (audio), 75.7% (video)</text>
  <text x="800" y="580" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ MATH: 92% accuracy</text>
  <text x="800" y="595" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ MMMU: 75.5% accuracy</text>
  <text x="800" y="610" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Major Frame > Last Frame eval</text>
  <text x="800" y="625" text-anchor="middle" font-size="11" fill="white">
    ‚Ä¢ Self-consistency: 68% ‚Üí 90%</text>
  
  <!-- Final Conclusion -->
  <rect x="50" y="660" width="900" height="60" fill="#34495e" stroke="#2c3e50" stroke-width="2" rx="10"/>
  <text x="500" y="685" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Conclusion: Video Generation as Unified Multimodal Reasoning Paradigm
  </text>
  <text x="500" y="705" text-anchor="middle" font-size="14" fill="white">
    "Thinking with Video" enables dynamic reasoning through drawing, imagination, and temporal consistency
  </text>
  
  <!-- Connecting lines -->
  <line x1="250" y1="180" x2="250" y2="200" stroke="#2c3e50" stroke-width="2"/>
  <line x1="750" y1="180" x2="750" y2="200" stroke="#2c3e50" stroke-width="2"/>
  <line x1="250" y1="280" x2="140" y2="300" stroke="#2c3e50" stroke-width="2"/>
  <line x1="250" y1="280" x2="340" y2="300" stroke="#2c3e50" stroke-width="2"/>
  <line x1="750" y1="280" x2="540" y2="300" stroke="#2c3e50" stroke-width="2"/>
  <line x1="750" y1="280" x2="740" y2="300" stroke="#2c3e50" stroke-width="2"/>
  <line x1="500" y1="520" x2="500" y2="500" stroke="#2c3e50" stroke-width="2"/>
  <line x1="500" y1="640" x2="500" y2="660" stroke="#2c3e50" stroke-width="2"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It can represent dynamic processes and temporal changes">
                        <div class="quiz-question">1. What is the key advantage of the 'Thinking with Video' paradigm over traditional image-based reasoning?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It can represent dynamic processes and temporal changes">It can represent dynamic processes and temporal changes</div><div class="quiz-choice" data-value="It requires less computational resources">It requires less computational resources</div><div class="quiz-choice" data-value="It is easier to implement and train">It is easier to implement and train</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="The ability to be a few-shot learner">
                        <div class="quiz-question">2. In the VideoThinkBench evaluation, what surprising capability did Sora-2 demonstrate?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Perfect accuracy on all tasks">Perfect accuracy on all tasks</div><div class="quiz-choice" data-value="The ability to be a few-shot learner">The ability to be a few-shot learner</div><div class="quiz-choice" data-value="Complete failure on visual tasks">Complete failure on visual tasks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It likely originated from its prompt rewriter component">
                        <div class="quiz-question">3. What was discovered about Sora-2's text-centric reasoning ability through analysis?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It was completely random guessing">It was completely random guessing</div><div class="quiz-choice" data-value="It came from pre-training on text data">It came from pre-training on text data</div><div class="quiz-choice" data-value="It likely originated from its prompt rewriter component">It likely originated from its prompt rewriter component</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-linen-2.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>V-Thinker: Interactive Thinking with Images</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-11-06</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2511.04460" target="_blank">http://arxiv.org/pdf/2511.04460</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces V-Thinker, a multimodal reasoning assistant that enables interactive visual reasoning through code-driven visual tools, operating in the domain of vision-language models and artificial intelligence.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous research in visual reasoning and chain-of-thought approaches, it proposes a novel paradigm of "Interactive Thinking with Images" where models can actively interact with and modify images during reasoning, rather than just passively analyzing them.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of enabling large multimodal models to deeply integrate image interaction with long-horizon reasoning capabilities, as current models often struggle with visual grounding and rely more on linguistic priors than visual perception.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The paper implements a two-component system: (1) a Data Evolution Flywheel that automatically synthesizes and verifies interactive reasoning datasets across diversity, quality, and difficulty dimensions, and (2) a Visual Progressive Training Curriculum that aligns perception via point-level supervision followed by reinforcement learning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> V-Thinker consistently outperformed baseline models on both VTBench (a new benchmark introduced by the authors) and general reasoning tasks, showing significant improvements in perception tasks (+8.4%), instruction-guided interaction (+25.8%), and interactive reasoning (+9.6%) compared to Qwen2.5-VL-7B.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>V-Thinker: Interactive Thinking with Images</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">V-Thinker: Interactive Thinking with Images - Method Flow</text>
  
  <!-- Data Evolution Flywheel Section -->
  <rect x="50" y="60" width="400" height="320" fill="#e8f4f8" stroke="#3498db" stroke-width="2" rx="10"/>
  <text x="250" y="85" text-anchor="middle" font-size="18" font-weight="bold" fill="#2980b9">Data Evolution Flywheel</text>
  
  <!-- Knowledge-driven Evolution -->
  <circle cx="120" cy="130" r="35" fill="#3498db"/>
  <text x="120" y="135" text-anchor="middle" font-size="12" fill="white" font-weight="bold">Knowledge</text>
  <text x="120" y="180" text-anchor="middle" font-size="10" fill="#2c3e50">Knowledge-driven Evolution</text>
  
  <!-- Coordinated Calibration -->
  <rect x="180" y="110" width="70" height="50" fill="#e74c3c" rx="5"/>
  <text x="215" y="130" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Checker</text>
  <text x="215" y="145" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Repairer</text>
  <text x="215" y="180" text-anchor="middle" font-size="10" fill="#2c3e50">Coordinated Calibration</text>
  
  <!-- Progressive Expansion -->
  <polygon points="300,110 350,135 300,160" fill="#27ae60"/>
  <text x="325" y="140" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Expand</text>
  <text x="325" y="180" text-anchor="middle" font-size="10" fill="#2c3e50">Progressive Expansion</text>
  
  <!-- Tool Evolution -->
  <rect x="120" y="220" width="80" height="40" fill="#f39c12" rx="5"/>
  <text x="160" y="245" text-anchor="middle" font-size="12" fill="white" font-weight="bold">Visual Tools</text>
  
  <!-- Data Output -->
  <ellipse cx="320" cy="280" rx="60" ry="30" fill="#9b59b6"/>
  <text x="320" y="275" text-anchor="middle" font-size="11" fill="white" font-weight="bold">V-Interaction</text>
  <text x="320" y="290" text-anchor="middle" font-size="11" fill="white" font-weight="bold">400K</text>
  
  <!-- Visual Progressive Training Curriculum Section -->
  <rect x="500" y="60" width="450" height="320" fill="#fff3cd" stroke="#f39c12" stroke-width="2" rx="10"/>
  <text x="725" y="85" text-anchor="middle" font-size="18" font-weight="bold" fill="#e67e22">Visual Progressive Training Curriculum</text>
  
  <!-- Perception Alignment -->
  <rect x="520" y="110" width="180" height="120" fill="#17a2b8" rx="5"/>
  <text x="610" y="130" text-anchor="middle" font-size="14" fill="white" font-weight="bold">Perception Alignment</text>
  <text x="610" y="150" text-anchor="middle" font-size="11" fill="white">‚Ä¢ Element Relations</text>
  <text x="610" y="165" text-anchor="middle" font-size="11" fill="white">‚Ä¢ Element Count</text>
  <text x="610" y="180" text-anchor="middle" font-size="11" fill="white">‚Ä¢ Knowledge Concepts</text>
  <text x="610" y="200" text-anchor="middle" font-size="11" fill="white">Point-level Supervision</text>
  <text x="610" y="215" text-anchor="middle" font-size="11" fill="white">V-Perception-40K</text>
  
  <!-- Interactive Reasoning Alignment -->
  <rect x="720" y="110" width="210" height="120" fill="#28a745" rx="5"/>
  <text x="825" y="130" text-anchor="middle" font-size="14" fill="white" font-weight="bold">Interactive Reasoning</text>
  <text x="825" y="150" text-anchor="middle" font-size="11" fill="white">Cold-Start Fine-tuning</text>
  <text x="825" y="165" text-anchor="middle" font-size="11" fill="white">Reinforcement Learning</text>
  <text x="825" y="180" text-anchor="middle" font-size="11" fill="white">GRPO Optimization</text>
  <text x="825" y="195" text-anchor="middle" font-size="11" fill="white">Reward Design</text>
  <text x="825" y="210" text-anchor="middle" font-size="11" fill="white">Code-driven Interaction</text>
  
  <!-- VTBench Section -->
  <rect x="50" y="420" width="300" height="320" fill="#f8d7da" stroke="#dc3545" stroke-width="2" rx="10"/>
  <text x="200" y="445" text-anchor="middle" font-size="18" font-weight="bold" fill="#721c24">VTBench Evaluation</text>
  
  <!-- Three evaluation dimensions -->
  <rect x="70" y="470" width="80" height="60" fill="#fd7e14" rx="5"/>
  <text x="110" y="490" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Perception</text>
  <text x="110" y="505" text-anchor="middle" font-size="10" fill="white">Point</text>
  <text x="110" y="518" text-anchor="middle" font-size="10" fill="white">Localization</text>
  
  <rect x="160" y="470" width="80" height="60" fill="#20c997" rx="5"/>
  <text x="200" y="485" text-anchor="middle" font-size="10" fill="white" font-weight="bold">Instruction-</text>
  <text x="200" y="498" text-anchor="middle" font-size="10" fill="white" font-weight="bold">Guided</text>
  <text x="200" y="511" text-anchor="middle" font-size="10" fill="white" font-weight="bold">Interaction</text>
  <text x="200" y="524" text-anchor="middle" font-size="10" fill="white">Visual Editing</text>
  
  <rect x="250" y="470" width="80" height="60" fill="#6f42c1" rx="5"/>
  <text x="290" y="485" text-anchor="middle" font-size="10" fill="white" font-weight="bold">Interactive</text>
  <text x="290" y="498" text-anchor="middle" font-size="10" fill="white" font-weight="bold">Reasoning</text>
  <text x="290" y="511" text-anchor="middle" font-size="10" fill="white">Complex</text>
  <text x="290" y="524" text-anchor="middle" font-size="10" fill="white">Problem Solving</text>
  
  <!-- Benchmark details -->
  <text x="200" y="560" text-anchor="middle" font-size="12" fill="#721c24" font-weight="bold">1,500 Question-Answer Pairs</text>
  <text x="200" y="580" text-anchor="middle" font-size="11" fill="#721c24">‚Ä¢ 9 Open-source Benchmarks</text>
  <text x="200" y="595" text-anchor="middle" font-size="11" fill="#721c24">‚Ä¢ 4 Domains: Logic, Geometry, Algebra, Statistics</text>
  <text x="200" y="610" text-anchor="middle" font-size="11" fill="#721c24">‚Ä¢ Expert Verification Protocol</text>
  <text x="200" y="625" text-anchor="middle" font-size="11" fill="#721c24">‚Ä¢ 500 samples per task type</text>
  
  <!-- Results Section -->
  <rect x="400" y="420" width="550" height="320" fill="#d1ecf1" stroke="#0c5460" stroke-width="2" rx="10"/>
  <text x="675" y="445" text-anchor="middle" font-size="18" font-weight="bold" fill="#0c5460">Key Results & Innovations</text>
  
  <!-- Training Process Flow -->
  <rect x="420" y="470" width="120" height="40" fill="#6c757d" rx="5"/>
  <text x="480" y="485" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Base Model</text>
  <text x="480" y="498" text-anchor="middle" font-size="11" fill="white">Qwen2.5-VL-7B</text>
  
  <rect x="560" y="470" width="120" height="40" fill="#17a2b8" rx="5"/>
  <text x="620" y="485" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Perception</text>
  <text x="620" y="498" text-anchor="middle" font-size="11" fill="white">SFT Training</text>
  
  <rect x="700" y="470" width="120" height="40" fill="#28a745" rx="5"/>
  <text x="760" y="485" text-anchor="middle" font-size="11" fill="white" font-weight="bold">Interactive RL</text>
  <text x="760" y="498" text-anchor="middle" font-size="11" fill="white">GRPO</text>
  
  <rect x="840" y="470" width="90" height="40" fill="#dc3545" rx="5"/>
  <text x="885" y="485" text-anchor="middle" font-size="11" fill="white" font-weight="bold">V-Thinker</text>
  <text x="885" y="498" text-anchor="middle" font-size="11" fill="white">Final Model</text>
  
  <!-- Performance Improvements -->
  <text x="675" y="540" text-anchor="middle" font-size="14" fill="#0c5460" font-weight="bold">Performance Gains vs Baseline</text>
  
  <rect x="450" y="560" width="150" height="30" fill="#28a745" rx="5"/>
  <text x="525" y="580" text-anchor="middle" font-size="12" fill="white" font-weight="bold">Perception: +8.4%</text>
  
  <rect x="620" y="560" width="200" height="30" fill="#17a2b8" rx="5"/>
  <text x="720" y="580" text-anchor="middle" font-size="12" fill="white" font-weight="bold">Instruction-Guided: +25.8%</text>
  
  <rect x="450" y="600" width="200" height="30" fill="#6f42c1" rx="5"/>
  <text x="550" y="620" text-anchor="middle" font-size="12" fill="white" font-weight="bold">Interactive Reasoning: +9.6%</text>
  
  <rect x="670" y="600" width="150" height="30" fill="#fd7e14" rx="5"/>
  <text x="745" y="620" text-anchor="middle" font-size="12" fill="white" font-weight="bold">General: +6.3%</text>
  
  <!-- Key Innovation Points -->
  <text x="675" y="660" text-anchor="middle" font-size="13" fill="#0c5460" font-weight="bold">Key Innovations</text>
  <text x="675" y="680" text-anchor="middle" font-size="11" fill="#0c5460">‚Ä¢ End-to-end code-driven visual interaction</text>
  <text x="675" y="695" text-anchor="middle" font-size="11" fill="#0c5460">‚Ä¢ Automatic dataset synthesis and evolution</text>
  <text x="675" y="710" text-anchor="middle" font-size="11" fill="#0c5460">‚Ä¢ Progressive curriculum from perception to reasoning</text>
  <text x="675" y="725" text-anchor="middle" font-size="11" fill="#0c5460">‚Ä¢ Expert-verified benchmark for interactive reasoning</text>
  
  <!-- Connection lines with minimal arrows -->
  <line x1="380" y1="280" x2="480" y2="280" stroke="#666" stroke-width="2"/>
  <polygon points="475,275 485,280 475,285" fill="#666"/>
  
  <line x1="700" y1="170" x2="760" y2="170" stroke="#666" stroke-width="2"/>
  <polygon points="755,165 765,170 755,175" fill="#666"/>
  
  <line x1="540" y1="490" x2="560" y2="490" stroke="#666" stroke-width="2"/>
  <polygon points="555,485 565,490 555,495" fill="#666"/>
  
  <line x1="680" y1="490" x2="700" y2="490" stroke="#666" stroke-width="2"/>
  <polygon points="695,485 705,490 695,495" fill="#666"/>
  
  <line x1="820" y1="490" x2="840" y2="490" stroke="#666" stroke-width="2"/>
  <polygon points="835,485 845,490 835,495" fill="#666"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It can actively modify and interact with images during reasoning">
                        <div class="quiz-question">1. What is the main innovation of V-Thinker compared to previous visual reasoning models?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It can understand more languages">It can understand more languages</div><div class="quiz-choice" data-value="It can actively modify and interact with images during reasoning">It can actively modify and interact with images during reasoning</div><div class="quiz-choice" data-value="It has a larger training dataset">It has a larger training dataset</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By automatically synthesizing and evolving datasets across diversity, quality and difficulty dimensions">
                        <div class="quiz-question">2. How does the Data Evolution Flywheel improve the training data?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By collecting more images from the internet">By collecting more images from the internet</div><div class="quiz-choice" data-value="By copying existing datasets">By copying existing datasets</div><div class="quiz-choice long-text" data-value="By automatically synthesizing and evolving datasets across diversity, quality and difficulty dimensions">By automatically synthesizing and evolving datasets across diversity, quality and difficulty dimensions</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Instruction-guided interaction (+25.8%)">
                        <div class="quiz-question">3. What was the most significant performance improvement of V-Thinker compared to Qwen2.5-VL-7B?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Interactive reasoning (+9.6%)">Interactive reasoning (+9.6%)</div><div class="quiz-choice" data-value="Perception tasks (+8.4%)">Perception tasks (+8.4%)</div><div class="quiz-choice" data-value="Instruction-guided interaction (+25.8%)">Instruction-guided interaction (+25.8%)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/use-your-illusion.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>Scaling Agent Learning via Experience Synthesis</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-11-05</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2511.03773" target="_blank">http://arxiv.org/pdf/2511.03773</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on scaling reinforcement learning (RL) for training large language model (LLM) agents through synthetic experience generation in a framework called DreamGym.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Prior work relied on costly real-environment rollouts and static trajectories for agent training; this paper proposes using a reasoning-based experience model to synthesize diverse training experiences.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenges of training LLM agents with RL, including high costs of real-world interactions, limited task diversity, unreliable reward signals, and complex infrastructure requirements.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> DreamGym uses a reasoning-based experience model that generates synthetic state transitions, an experience replay buffer for knowledge retention, and a curriculum task generator that creates progressively challenging variations.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> DreamGym outperformed baselines by over 30% on WebArena, matched traditional RL performance while using only synthetic data, and achieved 40% better performance with 90% fewer real-world interactions when used for sim-to-real transfer.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Scaling Agent Learning via Experience Synthesis</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">DreamGym: Scaling Agent Learning via Experience Synthesis</text>
  
  <!-- Main Components -->
  
  <!-- 1. Task Instructions (Top Left) -->
  <rect x="50" y="70" width="180" height="80" rx="10" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="140" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Task Instructions</text>
  <text x="140" y="115" text-anchor="middle" font-size="12" fill="white">"Find food shopping</text>
  <text x="140" y="130" text-anchor="middle" font-size="12" fill="white">expenses from Jan 2023"</text>
  
  <!-- 2. Experience Replay Buffer (Top Center) -->
  <rect x="280" y="70" width="180" height="80" rx="10" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="370" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Experience</text>
  <text x="370" y="110" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Replay Buffer</text>
  <text x="370" y="130" text-anchor="middle" font-size="12" fill="white">Retrieve & Update</text>
  
  <!-- 3. Agent (Top Right) -->
  <rect x="510" y="70" width="120" height="80" rx="10" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
  <text x="570" y="100" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Agent</text>
  <text x="570" y="120" text-anchor="middle" font-size="12" fill="white">Policy œÄ_Œ∏</text>
  
  <!-- 4. Reasoning Experience Model (Center) -->
  <rect x="200" y="200" width="300" height="120" rx="15" fill="#f39c12" stroke="#e67e22" stroke-width="3"/>
  <text x="350" y="225" text-anchor="middle" font-size="16" font-weight="bold" fill="white">Reasoning Experience Model</text>
  <text x="350" y="245" text-anchor="middle" font-size="14" fill="white">M_exp</text>
  
  <!-- CoT Reasoning Box -->
  <rect x="220" y="260" width="260" height="45" rx="8" fill="#ffffff" stroke="#d35400" stroke-width="2"/>
  <text x="350" y="275" text-anchor="middle" font-size="12" font-weight="bold" fill="#d35400">Chain-of-Thought Reasoning</text>
  <text x="350" y="290" text-anchor="middle" font-size="11" fill="#d35400">(s_{t+1}, r_{t+1}) = M_exp(history, task, demos)</text>
  
  <!-- 5. State Transitions (Bottom Left) -->
  <rect x="50" y="380" width="200" height="100" rx="10" fill="#27ae60" stroke="#229954" stroke-width="2"/>
  <text x="150" y="405" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Informative States</text>
  <text x="150" y="425" text-anchor="middle" font-size="12" fill="white">[227] link: 'MyAccount'</text>
  <text x="150" y="440" text-anchor="middle" font-size="12" fill="white">[1238] menuitem: 'Grocery'</text>
  <text x="150" y="455" text-anchor="middle" font-size="12" fill="white">[1474] table: Orders</text>
  
  <!-- 6. Reward Signals (Bottom Center) -->
  <rect x="300" y="380" width="150" height="100" rx="10" fill="#e67e22" stroke="#d35400" stroke-width="2"/>
  <text x="375" y="405" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Reward</text>
  <text x="375" y="420" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Signals</text>
  <text x="375" y="440" text-anchor="middle" font-size="12" fill="white">Done: True</text>
  <text x="375" y="455" text-anchor="middle" font-size="12" fill="white">Success: False</text>
  
  <!-- 7. Curriculum Task Generator (Right) -->
  <rect x="700" y="200" width="220" height="160" rx="10" fill="#8e44ad" stroke="#7d3c98" stroke-width="2"/>
  <text x="810" y="225" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Curriculum Task</text>
  <text x="810" y="240" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Generator</text>
  
  <!-- Task Value Estimation -->
  <rect x="720" y="260" width="180" height="40" rx="5" fill="#ffffff" stroke="#7d3c98" stroke-width="1"/>
  <text x="810" y="275" text-anchor="middle" font-size="12" font-weight="bold" fill="#7d3c98">Task Value Estimation</text>
  <text x="810" y="290" text-anchor="middle" font-size="11" fill="#7d3c98">V_œÑ = Reward Entropy</text>
  
  <!-- Task Examples -->
  <circle cx="740" cy="320" r="15" fill="#f1c40f"/>
  <text x="760" y="325" font-size="10" fill="#7d3c98">T3</text>
  <circle cx="790" cy="320" r="15" fill="#e74c3c"/>
  <text x="810" y="325" font-size="10" fill="#7d3c98">T7</text>
  <circle cx="840" cy="320" r="15" fill="#2ecc71"/>
  <text x="860" y="325" font-size="10" fill="#7d3c98">T15</text>
  
  <!-- 8. Scalable LLM Infrastructure (Bottom Right) -->
  <rect x="500" y="380" width="200" height="100" rx="10" fill="#34495e" stroke="#2c3e50" stroke-width="2"/>
  <text x="600" y="405" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Scalable LLM</text>
  <text x="600" y="420" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Serving Infra</text>
  <text x="600" y="440" text-anchor="middle" font-size="12" fill="white">Vectorized & Unified</text>
  <text x="600" y="455" text-anchor="middle" font-size="12" fill="white">Abundant & Adaptable</text>
  
  <!-- 9. RL Training Loop (Bottom) -->
  <rect x="750" y="550" width="200" height="80" rx="10" fill="#16a085" stroke="#138d75" stroke-width="2"/>
  <text x="850" y="575" text-anchor="middle" font-size="14" font-weight="bold" fill="white">RL Training</text>
  <text x="850" y="595" text-anchor="middle" font-size="12" fill="white">PPO / GRPO</text>
  <text x="850" y="610" text-anchor="middle" font-size="12" fill="white">Policy Update</text>
  
  <!-- Flow indicators (using simple lines instead of arrows) -->
  
  <!-- Task to Experience Model -->
  <line x1="230" y1="110" x2="300" y2="200" stroke="#3498db" stroke-width="3"/>
  
  <!-- Buffer to Experience Model -->
  <line x1="370" y1="150" x2="350" y2="200" stroke="#e74c3c" stroke-width="3"/>
  
  <!-- Agent to Experience Model -->
  <line x1="570" y1="150" x2="400" y2="200" stroke="#9b59b6" stroke-width="3"/>
  
  <!-- Experience Model to States -->
  <line x1="300" y1="320" x2="200" y2="380" stroke="#f39c12" stroke-width="3"/>
  
  <!-- Experience Model to Rewards -->
  <line x1="350" y1="320" x2="375" y2="380" stroke="#f39c12" stroke-width="3"/>
  
  <!-- Experience Model to Infrastructure -->
  <line x1="450" y1="320" x2="550" y2="380" stroke="#f39c12" stroke-width="3"/>
  
  <!-- Curriculum Generator to Experience Model -->
  <line x1="700" y1="280" x2="500" y2="260" stroke="#8e44ad" stroke-width="3"/>
  
  <!-- Infrastructure to RL Training -->
  <line x1="650" y1="480" x2="750" y2="550" stroke="#34495e" stroke-width="3"/>
  
  <!-- Key Features Labels -->
  <text x="50" y="550" font-size="14" font-weight="bold" fill="#2c3e50">Key Features:</text>
  <text x="50" y="575" font-size="12" fill="#34495e">‚Ä¢ Reasoning-based state transitions</text>
  <text x="50" y="595" font-size="12" fill="#34495e">‚Ä¢ Curriculum-driven task generation</text>
  <text x="50" y="615" font-size="12" fill="#34495e">‚Ä¢ Experience replay with retrieval</text>
  <text x="50" y="635" font-size="12" fill="#34495e">‚Ä¢ Scalable synthetic rollouts</text>
  
  <!-- Benefits Box -->
  <rect x="350" y="550" width="300" height="80" rx="10" fill="#ecf0f1" stroke="#bdc3c7" stroke-width="2"/>
  <text x="500" y="575" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Benefits</text>
  <text x="500" y="595" text-anchor="middle" font-size="12" fill="#34495e">30%+ improvement on WebArena</text>
  <text x="500" y="610" text-anchor="middle" font-size="12" fill="#34495e">Zero real environment interactions</text>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It generates synthetic experiences through reasoning-based models">
                        <div class="quiz-question">1. What is the primary innovation of DreamGym compared to traditional RL approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses more real-world training data">It uses more real-world training data</div><div class="quiz-choice" data-value="It generates synthetic experiences through reasoning-based models">It generates synthetic experiences through reasoning-based models</div><div class="quiz-choice" data-value="It only works with small language models">It only works with small language models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="90%">
                        <div class="quiz-question">2. When using DreamGym for sim-to-real transfer, what percentage of real-world interactions was reduced while still improving performance?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="50%">50%</div><div class="quiz-choice" data-value="70%">70%</div><div class="quiz-choice" data-value="90%">90%</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Real-time video rendering engine">
                        <div class="quiz-question">3. Which of the following is NOT a component of the DreamGym framework?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Experience replay buffer">Experience replay buffer</div><div class="quiz-choice" data-value="Real-time video rendering engine">Real-time video rendering engine</div><div class="quiz-choice" data-value="Curriculum task generator">Curriculum task generator</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
