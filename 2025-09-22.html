
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-09-22 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* 卡片容器样式 - 新增 */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            height: 600px; /* 固定高度 */
            cursor: pointer; /* 增加指针样式提示可点击 */
        }
        
        /* 卡片通用样式 */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* 轮播卡片样式 - 新增 */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%;
            transition: transform 0.5s ease, opacity 0.5s ease;
        }
        
        /* 非激活卡片的样式 - 新增 */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* 激活卡片的样式 - 新增 */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* 第一张卡片（文本内容）不需要滚动 */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* 第二张卡片（流程图）支持滚动 */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow: auto !important;
            padding-bottom: 50px; /* 添加底部填充 */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-height: none; /* 移除任何高度限制 */
        }
        
        /* 传统卡片样式 */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        
        .paper-card p {
            margin: 5px 0;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* 卡片计数器 - 新增 */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* 改为固定定位，不随滚动而移动 */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* 居中显示 */
            width: 90%;
            max-width: 500px; /* 增加最大宽度，适应长内容 */
            max-height: 80vh; /* 限制最大高度 */
            overflow-y: auto; /* 内容过多时可滚动 */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* 确保显示在最上层 */
        }
        
        /* 添加遮罩层，防止问题卡被其他内容遮挡 */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* 使用JavaScript控制问题卡的显示和隐藏，不再使用hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* 确保长单词自动换行 */
            overflow-wrap: break-word;
            hyphens: auto; /* 在必要时使用连字符 */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* 确保长单词自动换行 */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* 长文本左对齐 */
            display: block; /* 确保是块级元素 */
            white-space: normal; /* 允许自动换行 */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* 长文本选项的特殊样式 */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* 确保弹窗中的按钮文本不会溢出 */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* 适应超长选项文本 */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        @media (max-width: 768px) {
            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* 移动设备上高度调整 */
            }
            
            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <h1>2025-09-22 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/office.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid
  Vision Tokenizer</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-19</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.16197" target="_blank">http://arxiv.org/pdf/2509.16197</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> A unified multimodal large language model called MANZANO that can both understand and generate visual content, operating in the domain of computer vision and natural language processing.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous unified multimodal models that struggled with performance trade-offs between understanding and generation capabilities, this paper proposes a novel hybrid vision tokenizer that uses a single shared encoder with specialized adapters for both tasks.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> The paper addresses the conflict between visual tokenization methods in existing unified models, where discrete tokens work better for generation but continuous embeddings are superior for understanding tasks.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> Implements a three-component architecture: a hybrid vision tokenizer (producing both continuous and discrete tokens), a unified LLM decoder (for text/image token prediction), and a diffusion-based image decoder (for pixel generation), trained through a three-stage process of pre-training, continued pre-training, and supervised fine-tuning.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> Achieves state-of-the-art performance among unified models, with their 3B model matching or exceeding larger models' performance on understanding tasks while maintaining strong generation capabilities, and shows consistent improvements when scaled up to 30B parameters.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid
  Vision Tokenizer</h2>
                        <svg width="100%" viewBox="0 0 1200 900">
  <!-- Background -->
  <rect width="1200" height="900" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="600" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">MANZANO: Unified Multimodal Model Workflow</text>
  
  <!-- Stage 1: Hybrid Image Tokenizer Training -->
  <rect x="50" y="80" width="300" height="200" fill="#e8f4f8" stroke="#3498db" stroke-width="2" rx="10"/>
  <text x="200" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Stage 1: Hybrid Tokenizer Training</text>
  
  <!-- Vision Encoder -->
  <rect x="70" y="120" width="80" height="40" fill="#3498db" rx="5"/>
  <text x="110" y="143" text-anchor="middle" font-size="12" fill="white">Vision Encoder (ViT)</text>
  
  <!-- Continuous Adapter -->
  <rect x="170" y="120" width="70" height="40" fill="#27ae60" rx="5"/>
  <text x="205" y="135" text-anchor="middle" font-size="10" fill="white">Continuous</text>
  <text x="205" y="150" text-anchor="middle" font-size="10" fill="white">Adapter</text>
  
  <!-- Discrete Adapter -->
  <rect x="260" y="120" width="70" height="40" fill="#e74c3c" rx="5"/>
  <text x="295" y="135" text-anchor="middle" font-size="10" fill="white">Discrete</text>
  <text x="295" y="150" text-anchor="middle" font-size="10" fill="white">Adapter</text>
  
  <!-- Small LLM -->
  <rect x="170" y="180" width="100" height="40" fill="#9b59b6" rx="5"/>
  <text x="220" y="203" text-anchor="middle" font-size="12" fill="white">300M LLM Decoder</text>
  
  <!-- Random Sampling -->
  <circle cx="220" cy="240" r="15" fill="#f39c12"/>
  <text x="220" y="245" text-anchor="middle" font-size="10" fill="white">Random</text>
  
  <!-- Stage 2: Unified LLM Training -->
  <rect x="400" y="80" width="350" height="300" fill="#fff3cd" stroke="#f39c12" stroke-width="2" rx="10"/>
  <text x="575" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Stage 2: Unified LLM Training</text>
  
  <!-- Data Types -->
  <rect x="420" y="120" width="90" height="30" fill="#17a2b8" rx="5"/>
  <text x="465" y="138" text-anchor="middle" font-size="10" fill="white">Understanding Data</text>
  
  <rect x="520" y="120" width="90" height="30" fill="#dc3545" rx="5"/>
  <text x="565" y="138" text-anchor="middle" font-size="10" fill="white">Generation Data</text>
  
  <rect x="620" y="120" width="90" height="30" fill="#6c757d" rx="5"/>
  <text x="665" y="138" text-anchor="middle" font-size="10" fill="white">Text-only Data</text>
  
  <!-- Training Phases -->
  <rect x="420" y="170" width="310" height="30" fill="#28a745" rx="5"/>
  <text x="575" y="188" text-anchor="middle" font-size="12" fill="white">Pre-training (1.6T tokens)</text>
  
  <rect x="420" y="210" width="310" height="30" fill="#ffc107" rx="5"/>
  <text x="575" y="228" text-anchor="middle" font-size="12" fill="#2c3e50">Continued Pre-training (83B tokens)</text>
  
  <rect x="420" y="250" width="310" height="30" fill="#fd7e14" rx="5"/>
  <text x="575" y="268" text-anchor="middle" font-size="12" fill="white">Supervised Fine-tuning</text>
  
  <!-- Unified LLM -->
  <rect x="450" y="300" width="250" height="60" fill="#6f42c1" rx="10"/>
  <text x="575" y="325" text-anchor="middle" font-size="14" fill="white">Unified LLM Decoder</text>
  <text x="575" y="345" text-anchor="middle" font-size="12" fill="white">(300M - 30B parameters)</text>
  
  <!-- Stage 3: Image Decoder Training -->
  <rect x="800" y="80" width="300" height="200" fill="#d1ecf1" stroke="#17a2b8" stroke-width="2" rx="10"/>
  <text x="950" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Stage 3: Image Decoder Training</text>
  
  <!-- Progressive Training -->
  <rect x="820" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="850" y="145" text-anchor="middle" font-size="10" fill="white">256x256</text>
  
  <rect x="890" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="920" y="145" text-anchor="middle" font-size="10" fill="white">512x512</text>
  
  <rect x="960" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="990" y="145" text-anchor="middle" font-size="10" fill="white">1024x1024</text>
  
  <rect x="1030" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="1060" y="145" text-anchor="middle" font-size="10" fill="white">2048x2048</text>
  
  <!-- DiT Architecture -->
  <rect x="850" y="180" width="200" height="40" fill="#20c997" rx="5"/>
  <text x="950" y="203" text-anchor="middle" font-size="12" fill="white">DiT-Air Architecture (0.9B-3.5B)</text>
  
  <!-- Flow Matching -->
  <rect x="850" y="230" width="200" height="30" fill="#6610f2" rx="5"/>
  <text x="950" y="248" text-anchor="middle" font-size="12" fill="white">Flow Matching Pipeline</text>
  
  <!-- Inference Pipeline -->
  <rect x="100" y="420" width="1000" height="200" fill="#f8f9fa" stroke="#6c757d" stroke-width="2" rx="10"/>
  <text x="600" y="445" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Inference Pipeline</text>
  
  <!-- Understanding Task -->
  <rect x="150" y="470" width="350" height="120" fill="#e8f5e8" stroke="#28a745" stroke-width="2" rx="8"/>
  <text x="325" y="490" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Understanding Task</text>
  
  <rect x="170" y="510" width="80" height="30" fill="#28a745" rx="5"/>
  <text x="210" y="528" text-anchor="middle" font-size="10" fill="white">Image Input</text>
  
  <rect x="270" y="510" width="100" height="30" fill="#17a2b8" rx="5"/>
  <text x="320" y="528" text-anchor="middle" font-size="10" fill="white">Continuous Tokens</text>
  
  <rect x="390" y="510" width="80" height="30" fill="#6f42c1" rx="5"/>
  <text x="430" y="528" text-anchor="middle" font-size="10" fill="white">LLM Output</text>
  
  <rect x="250" y="560" width="100" height="20" fill="#ffc107" rx="3"/>
  <text x="300" y="572" text-anchor="middle" font-size="10" fill="#2c3e50">Text Answer</text>
  
  <!-- Generation Task -->
  <rect x="650" y="470" width="350" height="120" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2" rx="8"/>
  <text x="825" y="490" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Generation Task</text>
  
  <rect x="670" y="510" width="80" height="30" fill="#fd7e14" rx="5"/>
  <text x="710" y="528" text-anchor="middle" font-size="10" fill="white">Text Input</text>
  
  <rect x="770" y="510" width="100" height="30" fill="#e74c3c" rx="5"/>
  <text x="820" y="528" text-anchor="middle" font-size="10" fill="white">Discrete Tokens</text>
  
  <rect x="890" y="510" width="80" height="30" fill="#20c997" rx="5"/>
  <text x="930" y="528" text-anchor="middle" font-size="10" fill="white">Image Output</text>
  
  <!-- Key Features -->
  <rect x="200" y="660" width="800" height="180" fill="#f1f3f4" stroke="#495057" stroke-width="2" rx="10"/>
  <text x="600" y="685" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Key Design Principles</text>
  
  <!-- Feature boxes -->
  <rect x="220" y="710" width="180" height="60" fill="#e3f2fd" stroke="#1976d2" stroke-width="1" rx="5"/>
  <text x="310" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#1976d2">Unified Semantic Space</text>
  <text x="310" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">Both adapters share</text>
  <text x="310" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">same encoder backbone</text>
  
  <rect x="420" y="710" width="180" height="60" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="1" rx="5"/>
  <text x="510" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#7b1fa2">Simple & Scalable</text>
  <text x="510" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">Standard AR objective</text>
  <text x="510" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">Decoupled components</text>
  
  <rect x="620" y="710" width="180" height="60" fill="#e8f5e8" stroke="#388e3c" stroke-width="1" rx="5"/>
  <text x="710" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#388e3c">Minimal Task Conflict</text>
  <text x="710" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">Hybrid tokenizer reduces</text>
  <text x="710" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">understanding-generation gap</text>
  
  <rect x="820" y="710" width="160" height="60" fill="#fff3e0" stroke="#f57c00" stroke-width="1" rx="5"/>
  <text x="900" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">Progressive Scaling</text>
  <text x="900" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">300M to 30B LLM</text>
  <text x="900" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">0.9B to 3.5B decoder</text>
  
  <!-- Evaluation Results -->
  <rect x="250" y="790" width="700" height="40" fill="#d4edda" stroke="#155724" stroke-width="2" rx="8"/>
  <text x="600" y="810" text-anchor="middle" font-size="14" font-weight="bold" fill="#155724">Results: SOTA on understanding tasks, competitive generation performance</text>
  <text x="600" y="825" text-anchor="middle" font-size="12" fill="#155724">Especially strong on text-rich benchmarks (DocVQA, ChartQA, OCRBench)</text>
  
  <!-- Connection lines -->
  <line x1="350" y1="180" x2="400" y2="180" stroke="#666" stroke-width="2"/>
  <line x1="750" y1="180" x2="800" y2="180" stroke="#666" stroke-width="2"/>
  <line x1="575" y1="380" x2="325" y2="470" stroke="#28a745" stroke-width="2"/>
  <line x1="575" y1="380" x2="825" y2="470" stroke="#fd7e14" stroke-width="2"/>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A hybrid vision tokenizer with shared encoder and specialized adapters">
                        <div class="quiz-question">1. What is the key innovation in MANZANO's architecture that helps resolve the conflict between understanding and generation tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using two completely separate vision encoders for each task">Using two completely separate vision encoders for each task</div><div class="quiz-choice" data-value="A hybrid vision tokenizer with shared encoder and specialized adapters">A hybrid vision tokenizer with shared encoder and specialized adapters</div><div class="quiz-choice" data-value="Removing the tokenizer entirely and using raw pixel values">Removing the tokenizer entirely and using raw pixel values</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Consistent improvements across both understanding and generation tasks">
                        <div class="quiz-question">2. When scaling up MANZANO from 3B to 30B parameters, what was observed?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Performance decreased due to overfitting">Performance decreased due to overfitting</div><div class="quiz-choice" data-value="Only generation capabilities improved while understanding stayed the same">Only generation capabilities improved while understanding stayed the same</div><div class="quiz-choice" data-value="Consistent improvements across both understanding and generation tasks">Consistent improvements across both understanding and generation tasks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It employs a three-stage process: pre-training, continued pre-training, and supervised fine-tuning">
                        <div class="quiz-question">3. How does MANZANO's training process differ from conventional approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a single-stage training process focused only on generation">It uses a single-stage training process focused only on generation</div><div class="quiz-choice" data-value="It requires no pre-training and starts directly with fine-tuning">It requires no pre-training and starts directly with fine-tuning</div><div class="quiz-choice" data-value="It employs a three-stage process: pre-training, continued pre-training, and supervised fine-tuning">It employs a three-stage process: pre-training, continued pre-training, and supervised fine-tuning</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model
  via Training-Free Guidance</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-18</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.15130" target="_blank">http://arxiv.org/pdf/2509.15130</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> The paper focuses on trajectory-controlled video generation using pre-trained video diffusion models, specifically in the domain of 3D/4D computer vision and generative AI.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous work in video diffusion models and trajectory control methods that required model retraining, this paper proposes a novel training-free approach that leverages existing model knowledge.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> The paper addresses the challenge of achieving precise camera trajectory control in video generation while maintaining high visual quality, without requiring expensive model retraining or fine-tuning.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> The authors develop a three-part framework called WorldForge that includes: Intra-Step Recursive Refinement (IRR) for step-wise trajectory guidance, Flow-Gated Latent Fusion (FLF) for separating motion from appearance features, and Dual-Path Self-Corrective Guidance (DSG) for maintaining visual quality.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> The method achieves state-of-the-art performance in both static 3D scene generation and dynamic 4D trajectory control, outperforming existing approaches in terms of FID, CLIP similarity, and trajectory accuracy metrics while requiring no additional training.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model
  via Training-Free Guidance</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#2c3e50">WorldForge: Training-Free 3D/4D Video Generation Framework</text>
  
  <!-- Input Section -->
  <rect x="50" y="60" width="120" height="80" rx="10" fill="#e8f4fd" stroke="#3498db" stroke-width="2"/>
  <text x="110" y="90" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Input</text>
  <text x="110" y="110" text-anchor="middle" font-size="10" fill="#34495e">Single Image/</text>
  <text x="110" y="125" text-anchor="middle" font-size="10" fill="#34495e">Video Frame</text>
  
  <!-- 3D Vision Foundation Model -->
  <rect x="220" y="60" width="140" height="80" rx="10" fill="#fff2e8" stroke="#e67e22" stroke-width="2"/>
  <text x="290" y="85" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">3D Vision</text>
  <text x="290" y="100" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">Foundation Model</text>
  <text x="290" y="120" text-anchor="middle" font-size="9" fill="#34495e">Depth + Camera Poses</text>
  
  <!-- Point Cloud Generation -->
  <rect x="410" y="40" width="100" height="50" rx="8" fill="#e8f8f5" stroke="#27ae60" stroke-width="2"/>
  <text x="460" y="60" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Static Point</text>
  <text x="460" y="75" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Cloud</text>
  
  <rect x="410" y="110" width="100" height="50" rx="8" fill="#fdf2e9" stroke="#f39c12" stroke-width="2"/>
  <text x="460" y="130" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Dynamic Point</text>
  <text x="460" y="145" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Cloud</text>
  
  <!-- Trajectory Warping -->
  <rect x="560" y="60" width="120" height="80" rx="10" fill="#f4e8fd" stroke="#9b59b6" stroke-width="2"/>
  <text x="620" y="85" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">Trajectory</text>
  <text x="620" y="100" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">Warping</text>
  <text x="620" y="120" text-anchor="middle" font-size="9" fill="#34495e">Warped Frames + Masks</text>
  
  <!-- Video Diffusion Model -->
  <rect x="50" y="200" width="200" height="100" rx="15" fill="#e8f6f3" stroke="#16a085" stroke-width="3"/>
  <text x="150" y="230" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Video Diffusion Model</text>
  <text x="150" y="250" text-anchor="middle" font-size="12" fill="#34495e">(Frozen Weights)</text>
  <text x="150" y="270" text-anchor="middle" font-size="10" fill="#7f8c8d">Wan 2.1 / SVD</text>
  
  <!-- Three Core Components -->
  <g id="components">
    <!-- IRR -->
    <rect x="320" y="180" width="180" height="60" rx="10" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2"/>
    <text x="410" y="200" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Intra-Step Recursive</text>
    <text x="410" y="215" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Refinement (IRR)</text>
    <text x="410" y="230" text-anchor="middle" font-size="9" fill="#636e72">Trajectory injection at each step</text>
    
    <!-- FLF -->
    <rect x="320" y="260" width="180" height="60" rx="10" fill="#fab1a0" stroke="#e17055" stroke-width="2"/>
    <text x="410" y="280" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Flow-Gated Latent</text>
    <text x="410" y="295" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Fusion (FLF)</text>
    <text x="410" y="310" text-anchor="middle" font-size="9" fill="#636e72">Motion/appearance decoupling</text>
    
    <!-- DSG -->
    <rect x="320" y="340" width="180" height="60" rx="10" fill="#a29bfe" stroke="#6c5ce7" stroke-width="2"/>
    <text x="410" y="360" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Dual-Path Self-Corrective</text>
    <text x="410" y="375" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Guidance (DSG)</text>
    <text x="410" y="390" text-anchor="middle" font-size="9" fill="#636e72">Artifact suppression</text>
  </g>
  
  <!-- Denoising Process Detail -->
  <rect x="550" y="200" width="400" height="200" rx="15" fill="#f8f9fa" stroke="#95a5a6" stroke-width="2"/>
  <text x="750" y="220" text-anchor="middle" font-size="13" font-weight="bold" fill="#2c3e50">Single-Step Denoising Process</text>
  
  <!-- Noise Input -->
  <circle cx="580" cy="250" r="20" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="580" y="255" text-anchor="middle" font-size="10" fill="white">xₜ</text>
  
  <!-- Network Prediction -->
  <rect x="630" y="235" width="80" height="30" rx="5" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="670" y="255" text-anchor="middle" font-size="10" fill="white">NN Predict</text>
  
  <!-- Guided/Unguided Paths -->
  <rect x="580" y="290" width="70" height="25" rx="5" fill="#27ae60" stroke="#229954" stroke-width="2"/>
  <text x="615" y="307" text-anchor="middle" font-size="9" fill="white">Unguided</text>
  
  <rect x="670" y="290" width="70" height="25" rx="5" fill="#f39c12" stroke="#e67e22" stroke-width="2"/>
  <text x="705" y="307" text-anchor="middle" font-size="9" fill="white">Guided</text>
  
  <!-- Fusion -->
  <rect x="620" y="340" width="80" height="25" rx="5" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
  <text x="660" y="357" text-anchor="middle" font-size="10" fill="white">FLF Fusion</text>
  
  <!-- Corrected Output -->
  <rect x="750" y="290" width="80" height="40" rx="5" fill="#16a085" stroke="#138d75" stroke-width="2"/>
  <text x="790" y="305" text-anchor="middle" font-size="10" fill="white">Corrected</text>
  <text x="790" y="320" text-anchor="middle" font-size="10" fill="white">Output</text>
  
  <!-- Output Results -->
  <rect x="100" y="480" width="150" height="80" rx="10" fill="#d5f4e6" stroke="#27ae60" stroke-width="2"/>
  <text x="175" y="510" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">3D Scene</text>
  <text x="175" y="525" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Generation</text>
  <text x="175" y="545" text-anchor="middle" font-size="9" fill="#34495e">Novel view synthesis</text>
  
  <rect x="300" y="480" width="150" height="80" rx="10" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2"/>
  <text x="375" y="510" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">4D Trajectory</text>
  <text x="375" y="525" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Control</text>
  <text x="375" y="545" text-anchor="middle" font-size="9" fill="#34495e">Dynamic re-rendering</text>
  
  <rect x="500" y="480" width="150" height="80" rx="10" fill="#fab1a0" stroke="#e17055" stroke-width="2"/>
  <text x="575" y="510" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Video Effects</text>
  <text x="575" y="530" text-anchor="middle" font-size="9" fill="#34495e">Stabilization, Editing</text>
  <text x="575" y="545" text-anchor="middle" font-size="9" fill="#34495e">Object manipulation</text>
  
  <!-- Key Features -->
  <rect x="700" y="480" width="250" height="100" rx="10" fill="#e8f4fd" stroke="#3498db" stroke-width="2"/>
  <text x="825" y="500" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Key Features</text>
  <text x="720" y="520" font-size="10" fill="#34495e">• Training-free inference</text>
  <text x="720" y="535" font-size="10" fill="#34495e">• Plug-and-play framework</text>
  <text x="720" y="550" font-size="10" fill="#34495e">• Model-agnostic design</text>
  <text x="720" y="565" font-size="10" fill="#34495e">• Precise trajectory control</text>
  
  <!-- Process Flow Indicators -->
  <path d="M 170 100 L 210 100" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 360 100 L 400 100" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 510 100 L 550 100" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 150 300 L 150 470" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 410 400 L 410 470" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#34495e"/>
    </marker>
  </defs>
  
  <!-- Training-Free Label -->
  <rect x="20" y="600" width="960" height="40" rx="20" fill="#e8f8f5" stroke="#27ae60" stroke-width="3"/>
  <text x="500" y="625" text-anchor="middle" font-size="16" font-weight="bold" fill="#27ae60">TRAINING-FREE • PLUG-AND-PLAY • MODEL-AGNOSTIC</text>
  
  <!-- Performance Metrics -->
  <text x="50" y="680" font-size="12" font-weight="bold" fill="#2c3e50">Performance Highlights:</text>
  <text x="50" y="700" font-size="10" fill="#34495e">• Superior FID scores on LLFF, MipNeRF-360, Tanks-and-Temples</text>
  <text x="50" y="715" font-size="10" fill="#34495e">• Best trajectory accuracy (ATE, RPE-T, RPE-R metrics)</text>
  <text x="50" y="730" font-size="10" fill="#34495e">• 360° view synthesis from single image</text>
  <text x="50" y="745" font-size="10" fill="#34495e">• Compatible with Wan 2.1, SVD, and other VDMs</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It achieves control without requiring any model retraining or fine-tuning">
                        <div class="quiz-question">1. What is the main innovation of WorldForge compared to previous approaches in trajectory-controlled video generation?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a completely new video diffusion architecture">It uses a completely new video diffusion architecture</div><div class="quiz-choice" data-value="It achieves control without requiring any model retraining or fine-tuning">It achieves control without requiring any model retraining or fine-tuning</div><div class="quiz-choice" data-value="It generates higher resolution videos than other methods">It generates higher resolution videos than other methods</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Flow-Gated Latent Fusion (FLF)">
                        <div class="quiz-question">2. Which component of WorldForge is responsible for separating motion-related features from appearance-related features in the latent space?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Dual-Path Self-Corrective Guidance (DSG)">Dual-Path Self-Corrective Guidance (DSG)</div><div class="quiz-choice" data-value="Intra-Step Recursive Refinement (IRR)">Intra-Step Recursive Refinement (IRR)</div><div class="quiz-choice" data-value="Flow-Gated Latent Fusion (FLF)">Flow-Gated Latent Fusion (FLF)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Real-time face animation and lip syncing">
                        <div class="quiz-question">3. What practical application is NOT mentioned as a use case for WorldForge in the paper?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Video stabilization and camera path smoothing">Video stabilization and camera path smoothing</div><div class="quiz-choice" data-value="Real-time face animation and lip syncing">Real-time face animation and lip syncing</div><div class="quiz-choice" data-value="Object removal and replacement in videos">Object removal and replacement in videos</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/use-your-illusion.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>BaseReward: A Strong Baseline for Multimodal Reward Model</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-19</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.16127" target="_blank">http://arxiv.org/pdf/2509.16127</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> The paper focuses on developing high-performance Multimodal Reward Models (MRMs) for aligning Multimodal Large Language Models with human preferences in the domain of AI alignment and multimodal machine learning.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on existing reward modeling approaches for text-only LLMs, the paper proposes a systematic guide for building MRMs by investigating every crucial component in the development pipeline, introducing BaseReward as a simple yet effective architecture.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> The paper addresses the lack of a systematic guide for building state-of-the-art Multimodal Reward Models, which are crucial for aligning MLLMs with human preferences.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> The authors conducted comprehensive experimental analyses of reward modeling paradigms, reward head architecture, training strategies, data curation, backbone model selection, and ensemble methods, ultimately developing BaseReward using a Qwen2.5-VL backbone with an optimized two-layer reward head.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> BaseReward established new state-of-the-art performance on major benchmarks, including MM-RLHF-Reward Bench (11% improvement), VL-Reward Bench (18% improvement), and showed consistent performance gains when integrated into reinforcement learning pipelines across various tasks.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>BaseReward: A Strong Baseline for Multimodal Reward Model</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">
    BaseReward: Multimodal Reward Model Development Pipeline
  </text>
  
  <!-- Phase 1: Experimental Analysis -->
  <rect x="50" y="70" width="900" height="180" fill="#e8f4fd" stroke="#3498db" stroke-width="2" rx="10"/>
  <text x="500" y="90" text-anchor="middle" font-size="18" font-weight="bold" fill="#2980b9">
    Phase 1: Systematic Experimental Analysis
  </text>
  
  <!-- Reward Modeling Approaches -->
  <rect x="70" y="110" width="120" height="60" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2" rx="5"/>
  <text x="130" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Approaches</text>
  <text x="130" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Naive-RM</text>
  <text x="130" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Critic-RM</text>
  <text x="130" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Generative-RM</text>
  
  <!-- Architecture Design -->
  <rect x="210" y="110" width="120" height="60" fill="#fab1a0" stroke="#e17055" stroke-width="2" rx="5"/>
  <text x="270" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Architecture</text>
  <text x="270" y="145" text-anchor="middle" font-size="9" fill="#2d3436">2-layer MLP</text>
  <text x="270" y="155" text-anchor="middle" font-size="9" fill="#2d3436">SiLU activation</text>
  <text x="270" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Reward head</text>
  
  <!-- Training Strategies -->
  <rect x="350" y="110" width="120" height="60" fill="#fd79a8" stroke="#e84393" stroke-width="2" rx="5"/>
  <text x="410" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Training</text>
  <text x="410" y="145" text-anchor="middle" font-size="9" fill="#2d3436">No regularization</text>
  <text x="410" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Standard loss</text>
  <text x="410" y="165" text-anchor="middle" font-size="9" fill="#2d3436">3e-6 LR</text>
  
  <!-- Data Curation -->
  <rect x="490" y="110" width="120" height="60" fill="#a29bfe" stroke="#6c5ce7" stroke-width="2" rx="5"/>
  <text x="550" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Data</text>
  <text x="550" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Multimodal +</text>
  <text x="550" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Text-only</text>
  <text x="550" y="165" text-anchor="middle" font-size="9" fill="#2d3436">2.8M pairs</text>
  
  <!-- Backbone Selection -->
  <rect x="630" y="110" width="120" height="60" fill="#55efc4" stroke="#00b894" stroke-width="2" rx="5"/>
  <text x="690" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Backbone</text>
  <text x="690" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Qwen2.5-VL</text>
  <text x="690" y="155" text-anchor="middle" font-size="9" fill="#2d3436">7B parameters</text>
  <text x="690" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Scale analysis</text>
  
  <!-- Ensemble Methods -->
  <rect x="770" y="110" width="120" height="60" fill="#ff7675" stroke="#d63031" stroke-width="2" rx="5"/>
  <text x="830" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Ensemble</text>
  <text x="830" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Multiple models</text>
  <text x="830" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Averaging</text>
  <text x="830" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Diversity boost</text>
  
  <!-- Key Findings Box -->
  <rect x="70" y="190" width="820" height="50" fill="#dff0d8" stroke="#5cb85c" stroke-width="2" rx="5"/>
  <text x="480" y="210" text-anchor="middle" font-size="12" font-weight="bold" fill="#3c763d">Key Finding:</text>
  <text x="480" y="225" text-anchor="middle" font-size="11" fill="#3c763d">Text-only data significantly enhances multimodal reward modeling performance</text>
  
  <!-- Phase 2: BaseReward Implementation -->
  <rect x="50" y="280" width="900" height="150" fill="#fff3cd" stroke="#ffc107" stroke-width="2" rx="10"/>
  <text x="500" y="300" text-anchor="middle" font-size="18" font-weight="bold" fill="#856404">
    Phase 2: BaseReward Implementation
  </text>
  
  <!-- Model Architecture -->
  <rect x="100" y="320" width="200" height="80" fill="#e1f5fe" stroke="#0288d1" stroke-width="2" rx="5"/>
  <text x="200" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#01579b">Model Architecture</text>
  <text x="200" y="355" text-anchor="middle" font-size="10" fill="#01579b">Qwen2.5-VL-7B backbone</text>
  <text x="200" y="370" text-anchor="middle" font-size="10" fill="#01579b">2-layer MLP reward head</text>
  <text x="200" y="385" text-anchor="middle" font-size="10" fill="#01579b">SiLU activation function</text>
  
  <!-- Training Data -->
  <rect x="320" y="320" width="200" height="80" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2" rx="5"/>
  <text x="420" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#4a148c">Training Data</text>
  <text x="420" y="355" text-anchor="middle" font-size="10" fill="#4a148c">7 curated datasets</text>
  <text x="420" y="370" text-anchor="middle" font-size="10" fill="#4a148c">2.8M preference pairs</text>
  <text x="420" y="385" text-anchor="middle" font-size="10" fill="#4a148c">Multimodal + Text-only</text>
  
  <!-- Training Strategy -->
  <rect x="540" y="320" width="200" height="80" fill="#e8f5e8" stroke="#388e3c" stroke-width="2" rx="5"/>
  <text x="640" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#1b5e20">Training Strategy</text>
  <text x="640" y="355" text-anchor="middle" font-size="10" fill="#1b5e20">Learning rate: 3e-6</text>
  <text x="640" y="370" text-anchor="middle" font-size="10" fill="#1b5e20">Batch size: 128</text>
  <text x="640" y="385" text-anchor="middle" font-size="10" fill="#1b5e20">64 H100 GPUs</text>
  
  <!-- Ensemble Version -->
  <rect x="760" y="320" width="140" height="80" fill="#fff8e1" stroke="#f57c00" stroke-width="2" rx="5"/>
  <text x="830" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#e65100">Ensemble</text>
  <text x="830" y="355" text-anchor="middle" font-size="10" fill="#e65100">Qwen2.5-VL +</text>
  <text x="830" y="370" text-anchor="middle" font-size="10" fill="#e65100">Qwen2-VL</text>
  <text x="830" y="385" text-anchor="middle" font-size="10" fill="#e65100">Simple averaging</text>
  
  <!-- Phase 3: Evaluation & Results -->
  <rect x="50" y="460" width="900" height="120" fill="#e8f8f5" stroke="#16a085" stroke-width="2" rx="10"/>
  <text x="500" y="480" text-anchor="middle" font-size="18" font-weight="bold" fill="#0e6b5d">
    Phase 3: Evaluation & Results
  </text>
  
  <!-- Benchmark Results -->
  <rect x="100" y="500" width="250" height="60" fill="#fef9e7" stroke="#f39c12" stroke-width="2" rx="5"/>
  <text x="225" y="520" text-anchor="middle" font-size="12" font-weight="bold" fill="#b7950b">Benchmark Results</text>
  <text x="225" y="535" text-anchor="middle" font-size="10" fill="#b7950b">MM-RLHF: +11.9% improvement</text>
  <text x="225" y="550" text-anchor="middle" font-size="10" fill="#b7950b">VL-Reward: +18% improvement</text>
  
  <!-- SOTA Achievement -->
  <rect x="370" y="500" width="250" height="60" fill="#ebf5fb" stroke="#2980b9" stroke-width="2" rx="5"/>
  <text x="495" y="520" text-anchor="middle" font-size="12" font-weight="bold" fill="#1f4e79">SOTA Achievement</text>
  <text x="495" y="535" text-anchor="middle" font-size="10" fill="#1f4e79">Outperforms Claude 3.7 Sonnet</text>
  <text x="495" y="550" text-anchor="middle" font-size="10" fill="#1f4e79">Best open-source MRM</text>
  
  <!-- RL Validation -->
  <rect x="640" y="500" width="250" height="60" fill="#fdf2e9" stroke="#e67e22" stroke-width="2" rx="5"/>
  <text x="765" y="520" text-anchor="middle" font-size="12" font-weight="bold" fill="#a04000">RL Validation</text>
  <text x="765" y="535" text-anchor="middle" font-size="10" fill="#a04000">GRPO algorithm</text>
  <text x="765" y="550" text-anchor="middle" font-size="10" fill="#a04000">Consistent improvements</text>
  
  <!-- Phase 4: Practical Application -->
  <rect x="50" y="610" width="900" height="120" fill="#fdf2e9" stroke="#e67e22" stroke-width="2" rx="10"/>
  <text x="500" y="630" text-anchor="middle" font-size="18" font-weight="bold" fill="#a04000">
    Phase 4: Practical Application & Deployment
  </text>
  
  <!-- RL Pipeline -->
  <rect x="100" y="650" width="200" height="60" fill="#e8f6f3" stroke="#17a2b8" stroke-width="2" rx="5"/>
  <text x="200" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#0c5460">RL Pipeline</text>
  <text x="200" y="685" text-anchor="middle" font-size="10" fill="#0c5460">GRPO optimization</text>
  <text x="200" y="700" text-anchor="middle" font-size="10" fill="#0c5460">8 rollouts per prompt</text>
  
  <!-- Hybrid Reward -->
  <rect x="320" y="650" width="200" height="60" fill="#f8d7da" stroke="#dc3545" stroke-width="2" rx="5"/>
  <text x="420" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#721c24">Hybrid Reward</text>
  <text x="420" y="685" text-anchor="middle" font-size="10" fill="#721c24">Rule-based + BaseReward</text>
  <text x="420" y="700" text-anchor="middle" font-size="10" fill="#721c24">Best performance</text>
  
  <!-- Task Performance -->
  <rect x="540" y="650" width="200" height="60" fill="#d1ecf1" stroke="#0c5460" stroke-width="2" rx="5"/>
  <text x="640" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#0c5460">Task Performance</text>
  <text x="640" y="685" text-anchor="middle" font-size="10" fill="#0c5460">Perception, Reasoning</text>
  <text x="640" y="700" text-anchor="middle" font-size="10" fill="#0c5460">Conversational tasks</text>
  
  <!-- Efficiency -->
  <rect x="760" y="650" width="140" height="60" fill="#d4edda" stroke="#28a745" stroke-width="2" rx="5"/>
  <text x="830" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#155724">Efficiency</text>
  <text x="830" y="685" text-anchor="middle" font-size="10" fill="#155724">Fast inference</text>
  <text x="830" y="700" text-anchor="middle" font-size="10" fill="#155724">Low overhead</text>
  
  <!-- Final Output -->
  <ellipse cx="500" cy="760" rx="150" ry="25" fill="#28a745" stroke="#1e7e34" stroke-width="3"/>
  <text x="500" y="768" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    BaseReward: SOTA Multimodal Reward Model
  </text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Text-only data significantly enhanced multimodal judgment, especially in safety and mathematics">
                        <div class="quiz-question">1. What surprising finding did the researchers discover about text-only data in multimodal reward modeling?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Text-only data was completely ineffective for multimodal tasks">Text-only data was completely ineffective for multimodal tasks</div><div class="quiz-choice" data-value="Text-only data significantly enhanced multimodal judgment, especially in safety and mathematics">Text-only data significantly enhanced multimodal judgment, especially in safety and mathematics</div><div class="quiz-choice" data-value="Text-only data only worked when combined with video data">Text-only data only worked when combined with video data</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="A two-layer MLP with SiLU activation">
                        <div class="quiz-question">2. Which reward head configuration proved most effective in the BaseReward model?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A single-layer linear head with ReLU activation">A single-layer linear head with ReLU activation</div><div class="quiz-choice" data-value="A five-layer deep network with Tanh activation">A five-layer deep network with Tanh activation</div><div class="quiz-choice" data-value="A two-layer MLP with SiLU activation">A two-layer MLP with SiLU activation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Hybrid approach combining rule-based checks with BaseReward scoring">
                        <div class="quiz-question">3. When integrating BaseReward into reinforcement learning, which reward scheme showed the best overall performance?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Pure rule-based reward system">Pure rule-based reward system</div><div class="quiz-choice" data-value="BaseReward-only scoring">BaseReward-only scoring</div><div class="quiz-choice" data-value="Hybrid approach combining rule-based checks with BaseReward scoring">Hybrid approach combining rule-based checks with BaseReward scoring</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // 创建遮罩层
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // 获取所有问题标签
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // 设置点击事件处理
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // 点击标签切换问题卡的显示状态
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // 阻止事件冒泡
                    
                    // 如果当前问题卡已经显示，则隐藏它
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // 先隐藏所有其他问题卡
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // 将弹窗内容复制到页面最外层的弹窗中
                        document.body.appendChild(popup);
                        
                        // 显示当前问题卡和背景遮罩
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // 确保点击问题卡内部时不会关闭问题卡
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // 点击遮罩层或页面任何其他位置时隐藏所有问题卡
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // 为每个选项添加点击事件
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // 重置所有选项
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // 标记当前选项为已选
                    this.classList.add('selected');
                    
                    // 检查是否正确
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '✔️ Correct！';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '❌ Wrong！';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // 卡片轮播功能 - 新增
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // 更新计数器显示
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // 显示指定索引的卡片
                function showCard(index) {
                    // 处理循环
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // 更新当前索引
                    currentIndex = index;
                    
                    // 更新卡片显示
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // 更新计数器
                    updateCounter();
                }
                
                // 下一张卡片
                function nextCard(e) {
                    e.stopPropagation(); // 防止事件冒泡导致问题卡关闭
                    showCard(currentIndex + 1);
                }
                
                // 为卡片容器添加点击事件
                cardDeck.addEventListener('click', function(e) {
                    // 检查点击是否发生在流程图卡片内部的滚动区域
                    // 如果是在滚动条上点击，不切换卡片
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // 计算点击位置是否在滚动条区域
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // 键盘导航
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
