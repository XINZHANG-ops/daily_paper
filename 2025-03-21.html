
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-21 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042; /* Set the page background color */
            background-image: url('bg.png'); /* Set the page background to bg.png */
            background-size: auto; /* Keep the original size of the background image */
            background-repeat: repeat; /* Repeat the image to fill the page */
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9; /* Fallback background color */
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
            background-size: auto; /* Keep the original size of the background image */
            background-repeat: repeat; /* Allow the image to repeat to fill the card */
            background-position: center; /* Center the background image */
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url(''); /* Add a semi-transparent white overlay */
            background-blend-mode: overlay; /* Blend the overlay with the background image */
        }
        .paper-card:hover {
            transform: translateY(-5px); /* Lift effect on hover */
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2); /* Shadow on hover */
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
        }
        .category-chunk:hover {
            transform: translateY(-3px); /* Slightly smaller lift for categories */
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15); /* Slightly smaller shadow for categories */
        }
        .category-chunk:nth-child(1) { /* 1. Topic and Domain */
            background-color: #d3e3fd; /* Blue */
        }
        .category-chunk:nth-child(2) { /* 2. Previous Research and New Ideas */
            background-color: #e6d6fa; /* Purple */
        }
        .category-chunk:nth-child(3) { /* 3. Problem */
            background-color: #d4f8d9; /* Green */
        }
        .category-chunk:nth-child(4) { /* 4. Methods */
            background-color: #ffd7d5; /* Pink */
        }
        .category-chunk:nth-child(5) { /* 5. Results and Evaluation */
            background-color: #d3e3fd; /* Reuse Blue */
        }
    </style>
</head>
<body>
    <h1>2025-03-21 Papers</h1>
    
        <div class="paper-card" style="background-image: url('bg/robots.png');">
            <h2>Paper: 1</h2>
            <p><strong>Survey on Evaluation of LLM-based Agents</strong></p>
            <p><strong>Published: </strong>2025-03-20</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.16416" target="_blank">http://arxiv.org/pdf/2503.16416</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper is a survey on the evaluation methodologies for LLM-based agents, covering the AI domain, specifically focusing on autonomous systems that can plan, reason, and interact with environments.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing research in LLM evaluation and proposes a comprehensive analysis of evaluation benchmarks and frameworks, categorizing them across agent capabilities, application-specific tasks, generalist agent abilities, and development frameworks.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of how to reliably and comprehensively evaluate the increasingly complex capabilities of LLM-based agents in various domains.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors used a systematic literature review and analysis of existing benchmarks, frameworks, and evaluation methodologies for LLM-based agents.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The results are a structured overview of the current state of agent evaluation, identification of trends (like a shift towards realistic and challenging evaluations), and gaps in current research (such as the need for assessing cost-efficiency, safety, and robustness).</div></div>
        </div>
        
        <div class="paper-card" style="background-image: url('bg/black-linen-2.png');">
            <h2>Paper: 2</h2>
            <p><strong>Unleashing Vecset Diffusion Model for Fast Shape Generation</strong></p>
            <p><strong>Published: </strong>2025-03-20</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.16302" target="_blank">http://arxiv.org/pdf/2503.16302</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on fast 3D shape generation within the domain of computer graphics and generative AI.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on the Vecset Diffusion Model (VDM) and diffusion distillation techniques, proposing "FlashVDM" with Progressive Flow Distillation and a lightning vecset decoder for acceleration.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the slow generation speed of high-resolution 3D shapes using the Vecset Diffusion Model (VDM).</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors used Progressive Flow Distillation (guidance distillation, step distillation, adversarial finetuning) for diffusion acceleration and a lightning vecset decoder (Hierarchical Volume Decoding, Adaptive KV Selection, Efficient Decoder Design) for VAE acceleration.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The proposed FlashVDM achieved a 45√ó speedup in VAE decoding and a 32√ó overall speedup, generating high-resolution 3D shapes within 1 second, outperforming existing fast 3D generation methods while maintaining comparable quality to state-of-the-art, slower methods, as evaluated by Volume/Surface IoU, ULIP-I, Uni3D-I, and user studies.</div></div>
        </div>
        
        <div class="paper-card" style="background-image: url('bg/shley-tree-2.png');">
            <h2>Paper: 3</h2>
            <p><strong>Scale-wise Distillation of Diffusion Models</strong></p>
            <p><strong>Published: </strong>2025-03-20</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.16397" target="_blank">http://arxiv.org/pdf/2503.16397</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces Scale-wise Distillation (SWD), a method for accelerating diffusion models in the domain of text-to-image generation.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing diffusion distillation methods and next-scale prediction models, proposing a novel scale-wise distillation framework that progressively increases spatial resolution during sampling.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the computational bottleneck of high-resolution image generation with diffusion models by reducing inference time while maintaining or improving image quality.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a scale-wise distillation approach integrated with distribution matching methods (DMD2), and introduce a novel patch distribution matching (PDM) loss.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> SWD achieves significant speedups compared to full-resolution distilled models, outperforming or competing with state-of-the-art text-to-image models in terms of automated metrics and human preference studies, while being 2.5x-10x faster.</div></div>
        </div>
        
</body>
</html>
