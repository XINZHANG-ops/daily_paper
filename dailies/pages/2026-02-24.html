<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2026-02-24 Papers</title>
    <!-- AI Assistant Styles -->
    <link rel="stylesheet" href="../../css/ai-assistant.css">
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */
            /* cursor removed - only cards should show pointer */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
            cursor: pointer; /* Show pointer on cards to indicate they're clickable */
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }

        .paper-card p {
            margin: 5px 0;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
            word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        /* ÁßªÂä®ËÆæÂ§áÂíåÂ∞èÂ±èÂπï */
        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                min-height: 400px; /* ÁßªÂä®ËÆæÂ§á‰∏ä‰ΩøÁî®Êõ¥Â∞èÁöÑÊúÄÂ∞èÈ´òÂ∫¶ */
                height: auto; /* Ëá™ÈÄÇÂ∫îÈ´òÂ∫¶ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }

            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
                width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-02-24 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/argyle.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>A Very Big Video Reasoning Suite</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-23</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.20159" target="_blank">http://arxiv.org/pdf/2602.20159</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper presents a large-scale video reasoning dataset and benchmark for evaluating video generation models' reasoning capabilities across cognitive tasks.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Building on existing video reasoning benchmarks that are limited in scale (12.8K samples combined), the paper proposes VBVR with 2M+ samples and introduces a principled cognitive architecture framework organizing tasks into five faculties: perception, transformation, spatiality, abstraction, and knowledge.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Current video generation models focus primarily on visual quality while their reasoning capabilities remain underexplored, hindered by the lack of large-scale training data and verifiable evaluation frameworks for video reasoning.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors created 200 parameterized task generators based on cognitive theory, generated 1M training and 7.5K test samples via distributed cloud infrastructure, and developed rule-based scorers for reproducible evaluation instead of model-based judging.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Fine-tuning Wan2.2 on VBVR improved its performance from 0.371 to 0.685 (84.6% gain), surpassing all evaluated models including Sora 2 (0.546) and Veo 3.1 (0.480), while scaling studies showed emergent generalization to out-of-domain tasks but persistent gaps to human performance (0.974).</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>A Very Big Video Reasoning Suite</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f0f4f8"/>
  
  <!-- Title -->
  <text x="500" y="40" font-size="28" font-weight="bold" text-anchor="middle" fill="#2c3e50">VBVR: A Very Big Video Reasoning Suite</text>
  
  <!-- Main Flow -->
  
  <!-- Cognitive Architecture Box -->
  <rect x="50" y="80" width="200" height="120" rx="10" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="150" y="115" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Cognitive Architecture</text>
  <text x="150" y="140" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Abstraction</text>
  <text x="150" y="155" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Knowledge</text>
  <text x="150" y="170" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Spatiality</text>
  <text x="150" y="185" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Perception</text>
  
  <!-- Arrow 1 -->
  <path d="M 250 140 L 320 140" stroke="#34495e" stroke-width="3" fill="none" marker-end="url(#arrow)"/>
  
  <!-- Task Design Box -->
  <rect x="320" y="80" width="180" height="120" rx="10" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="410" y="115" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Task Design</text>
  <text x="410" y="140" font-size="12" text-anchor="middle" fill="white">200+ Tasks</text>
  <text x="410" y="160" font-size="12" text-anchor="middle" fill="white">6 Quality Criteria</text>
  <text x="410" y="180" font-size="12" text-anchor="middle" fill="white">Peer Review</text>
  
  <!-- Arrow 2 -->
  <path d="M 500 140 L 570 140" stroke="#34495e" stroke-width="3" fill="none" marker-end="url(#arrow)"/>
  
  <!-- Data Generation Box -->
  <rect x="570" y="80" width="200" height="120" rx="10" fill="#f39c12" stroke="#d68910" stroke-width="2"/>
  <text x="670" y="115" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Data Generation</text>
  <text x="670" y="140" font-size="12" text-anchor="middle" fill="white">Cloud-based Pipeline</text>
  <text x="670" y="160" font-size="12" text-anchor="middle" fill="white">AWS Lambda Workers</text>
  <text x="670" y="180" font-size="12" text-anchor="middle" fill="white">S3 Storage</text>
  
  <!-- Arrow 3 -->
  <path d="M 670 200 L 670 270" stroke="#34495e" stroke-width="3" fill="none" marker-end="url(#arrow)"/>
  
  <!-- VBVR-Dataset Box -->
  <rect x="520" y="270" width="300" height="140" rx="15" fill="#27ae60" stroke="#229954" stroke-width="3"/>
  <text x="670" y="310" font-size="20" font-weight="bold" text-anchor="middle" fill="white">VBVR-Dataset</text>
  <text x="670" y="340" font-size="14" text-anchor="middle" fill="white">2,015,000 Images</text>
  <text x="670" y="360" font-size="14" text-anchor="middle" fill="white">1,007,500 Videos</text>
  <text x="670" y="380" font-size="14" text-anchor="middle" fill="white">1,000,000 Training Samples</text>
  <text x="670" y="400" font-size="14" text-anchor="middle" fill="white">7,500 Test Samples</text>
  
  <!-- Arrow 4 -->
  <path d="M 520 340 L 450 340" stroke="#34495e" stroke-width="3" fill="none" marker-end="url(#arrow)"/>
  
  <!-- VBVR-Bench Box -->
  <rect x="200" y="270" width="250" height="140" rx="15" fill="#9b59b6" stroke="#8e44ad" stroke-width="3"/>
  <text x="325" y="310" font-size="20" font-weight="bold" text-anchor="middle" fill="white">VBVR-Bench</text>
  <text x="325" y="340" font-size="14" text-anchor="middle" fill="white">Rule-based Evaluation</text>
  <text x="325" y="360" font-size="14" text-anchor="middle" fill="white">100 Test Tasks</text>
  <text x="325" y="380" font-size="14" text-anchor="middle" fill="white">Human-aligned Scoring</text>
  <text x="325" y="400" font-size="14" text-anchor="middle" fill="white">Reproducible Results</text>
  
  <!-- Two-way arrow between Dataset and Bench -->
  <path d="M 450 340 L 520 340" stroke="#34495e" stroke-width="2" fill="none" stroke-dasharray="5,5"/>
  
  <!-- Model Evaluation Section -->
  <rect x="50" y="450" width="400" height="100" rx="10" fill="#16a085" stroke="#138d75" stroke-width="2"/>
  <text x="250" y="480" font-size="18" font-weight="bold" text-anchor="middle" fill="white">Model Evaluation</text>
  <text x="150" y="510" font-size="12" text-anchor="middle" fill="white">‚Ä¢ CogVideoX</text>
  <text x="250" y="510" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Wan2.2</text>
  <text x="350" y="510" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Sora 2</text>
  <text x="150" y="530" font-size="12" text-anchor="middle" fill="white">‚Ä¢ HunyuanVideo</text>
  <text x="250" y="530" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Veo 3.1</text>
  <text x="350" y="530" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Kling 2.6</text>
  
  <!-- Scaling Study Box -->
  <rect x="520" y="450" width="300" height="100" rx="10" fill="#e67e22" stroke="#d35400" stroke-width="2"/>
  <text x="670" y="480" font-size="18" font-weight="bold" text-anchor="middle" fill="white">Scaling Study</text>
  <text x="670" y="510" font-size="12" text-anchor="middle" fill="white">‚Ä¢ VBVR-Wan2.2 Training</text>
  <text x="670" y="530" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Emergent Generalization</text>
  
  <!-- Arrows from Bench and Dataset to Model sections -->
  <path d="M 325 410 L 250 450" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrow)"/>
  <path d="M 670 410 L 670 450" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrow)"/>
  
  <!-- Results Box -->
  <rect x="200" y="600" width="600" height="120" rx="15" fill="#2c3e50" stroke="#1a252f" stroke-width="3"/>
  <text x="500" y="640" font-size="20" font-weight="bold" text-anchor="middle" fill="white">Key Findings</text>
  <text x="500" y="670" font-size="14" text-anchor="middle" fill="white">‚Ä¢ VBVR-Wan2.2 achieves 0.685 overall score (84.6% improvement)</text>
  <text x="500" y="690" font-size="14" text-anchor="middle" fill="white">‚Ä¢ Early signs of emergent generalization with scale</text>
  <text x="500" y="710" font-size="14" text-anchor="middle" fill="white">‚Ä¢ Significant gap remains to human performance (0.974)</text>
  
  <!-- Arrows to Results -->
  <path d="M 250 550 L 400 600" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrow)"/>
  <path d="M 670 550 L 600 600" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrow)"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrow" markerWidth="10" markerHeight="10" refX="8" refY="3" orient="auto" markerUnits="strokeWidth">
      <path d="M0,0 L0,6 L9,3 z" fill="#34495e"/>
    </marker>
  </defs>
  
  <!-- Decorative elements -->
  <circle cx="150" cy="140" r="40" fill="none" stroke="#3498db" stroke-width="1" opacity="0.3"/>
  <circle cx="410" cy="140" r="40" fill="none" stroke="#e74c3c" stroke-width="1" opacity="0.3"/>
  <circle cx="670" cy="140" r="40" fill="none" stroke="#f39c12" stroke-width="1" opacity="0.3"/>
  
  <!-- Scale comparison visualization -->
  <g transform="translate(850, 300)">
    <circle cx="0" cy="0" r="80" fill="#27ae60" opacity="0.8"/>
    <text x="0" y="0" font-size="14" font-weight="bold" text-anchor="middle" fill="white">VBVR</text>
    <text x="0" y="20" font-size="12" text-anchor="middle" fill="white">2.015M</text>
    <circle cx="0" cy="100" r="8" fill="#95a5a6" opacity="0.8"/>
    <text x="0" y="130" font-size="10" text-anchor="middle" fill="#34495e">Others: 12.8K</text>
  </g>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Aristotle's cognitive hierarchy, ascending from 'aisthesis' (perception) through 'phantasia' to 'nous' (understanding)">
                        <div class="quiz-question">1. What philosophical foundation does VBVR use to organize its cognitive architecture, and which philosopher's concept of 'dunameis' (cognitive faculties) inspired the framework?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Kant's categories of understanding, with faculties organized around his concept of 'Vernunft'">Kant's categories of understanding, with faculties organized around his concept of 'Vernunft'</div><div class="quiz-choice long-text" data-value="Aristotle's cognitive hierarchy, ascending from 'aisthesis' (perception) through 'phantasia' to 'nous' (understanding)">Aristotle's cognitive hierarchy, ascending from 'aisthesis' (perception) through 'phantasia' to 'nous' (understanding)</div><div class="quiz-choice" data-value="Plato's theory of forms, with tasks designed around the concept of ideal representations">Plato's theory of forms, with tasks designed around the concept of ideal representations</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Knowledge and Spatiality - supported by hippocampal place cells and grid cells that enable both spatial navigation and concept learning">
                        <div class="quiz-question">2. In the capability correlation analysis, which two cognitive faculties showed a strong positive correlation (œÅ=0.461), and what neuroscience evidence supports this connection?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="Knowledge and Spatiality - supported by hippocampal place cells and grid cells that enable both spatial navigation and concept learning">Knowledge and Spatiality - supported by hippocampal place cells and grid cells that enable both spatial navigation and concept learning</div><div class="quiz-choice long-text" data-value="Perception and Transformation - supported by visual cortex regions that handle both recognition and mental rotation">Perception and Transformation - supported by visual cortex regions that handle both recognition and mental rotation</div><div class="quiz-choice long-text" data-value="Abstraction and Knowledge - supported by prefrontal cortex regions that manage both rule extraction and memory formation">Abstraction and Knowledge - supported by prefrontal cortex regions that manage both rule extraction and memory formation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Controllability is the bedrock of verifiable reasoning - models must maintain stable scenes and precise object manipulation rather than freely rewriting content">
                        <div class="quiz-question">3. What key insight emerged from VBVR-Wan2.2's qualitative analysis regarding the relationship between controllability and reasoning in video generation?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Models need to generate photorealistic videos first before attempting reasoning tasks">Models need to generate photorealistic videos first before attempting reasoning tasks</div><div class="quiz-choice long-text" data-value="Controllability is the bedrock of verifiable reasoning - models must maintain stable scenes and precise object manipulation rather than freely rewriting content">Controllability is the bedrock of verifiable reasoning - models must maintain stable scenes and precise object manipulation rather than freely rewriting content</div><div class="quiz-choice long-text" data-value="Reasoning emerges naturally from larger model scale without requiring specific controllability constraints">Reasoning emerges naturally from larger model scale without requiring specific controllability constraints</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-linen-2.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-23</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.20093" target="_blank">http://arxiv.org/pdf/2602.20093</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on sequential recommendation systems, specifically addressing latent multi-step reasoning with adaptive test-time computation.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing latent reasoning methods for sequential recommendation (like ReaRec, PLR, LARES) but introduces manifold-constrained reasoning that restricts latent states to evolve within graph-induced collaborative neighborhoods rather than unconstrained latent space.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the "latent drift" problem where unconstrained latent reasoning trajectories in existing methods deviate into implausible regions, degrading model robustness and generalization.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> ManCAR uses a variational framework with graph-conditioned teacher priors to constrain reasoning trajectories, employs progressive teacher scheduling during training, and implements adaptive test-time termination based on KL-divergence convergence between consecutive reasoning steps.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> ManCAR achieves up to 46.88% relative improvement in NDCG@10 over state-of-the-art baselines across seven Amazon datasets, with adaptive reasoning achieving near-ceiling performance while reducing unnecessary computation steps.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>ManCAR: Manifold-Constrained Latent Reasoning with Adaptive Test-Time Computation for Sequential Recommendation</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2C3E50">ManCAR: Manifold-Constrained Latent Reasoning Workflow</text>
  
  <!-- Input Section -->
  <rect x="50" y="60" width="200" height="80" rx="10" fill="#3498DB" stroke="#2980B9" stroke-width="2"/>
  <text x="150" y="90" text-anchor="middle" font-size="14" font-weight="bold" fill="white">User Interaction</text>
  <text x="150" y="110" text-anchor="middle" font-size="14" font-weight="bold" fill="white">History (H)</text>
  <text x="150" y="125" text-anchor="middle" font-size="12" fill="white">h = (h‚ÇÅ, h‚ÇÇ, ..., h‚Çô‚Çã‚ÇÅ)</text>
  
  <!-- Graph Construction -->
  <rect x="300" y="60" width="200" height="80" rx="10" fill="#E74C3C" stroke="#C0392B" stroke-width="2"/>
  <text x="400" y="90" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Item Interaction</text>
  <text x="400" y="110" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Graph G=(I,E)</text>
  <text x="400" y="125" text-anchor="middle" font-size="12" fill="white">Swing Algorithm</text>
  
  <!-- Sequential Encoder -->
  <rect x="50" y="180" width="200" height="80" rx="10" fill="#9B59B6" stroke="#8E44AD" stroke-width="2"/>
  <text x="150" y="210" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Sequential Encoder</text>
  <text x="150" y="230" text-anchor="middle" font-size="14" font-weight="bold" fill="white">f_Œ∏(¬∑)</text>
  <text x="150" y="245" text-anchor="middle" font-size="12" fill="white">h_{n-1} = f_Œ∏(h)</text>
  
  <!-- Candidate Set Construction -->
  <rect x="300" y="180" width="200" height="80" rx="10" fill="#16A085" stroke="#138871" stroke-width="2"/>
  <text x="400" y="205" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Candidate Set</text>
  <text x="400" y="225" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Construction</text>
  <text x="400" y="245" text-anchor="middle" font-size="12" fill="white">C(h_R) = {y*} ‚à™ N(h_R;G;k)</text>
  
  <!-- Multi-Step Reasoning Loop -->
  <rect x="175" y="300" width="650" height="320" rx="15" fill="#F8F9FA" stroke="#95A5A6" stroke-width="2" stroke-dasharray="5,5"/>
  <text x="500" y="325" text-anchor="middle" font-size="16" font-weight="bold" fill="#34495E">Multi-Step Latent Reasoning (t' = 1, ..., T')</text>
  
  <!-- Reasoning Module -->
  <rect x="200" y="350" width="180" height="70" rx="10" fill="#F39C12" stroke="#D68910" stroke-width="2"/>
  <text x="290" y="375" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Reasoning Module</text>
  <text x="290" y="395" text-anchor="middle" font-size="12" fill="white">r_{t'} = œÅ_Œ∏(h; r_{1:t'-1})</text>
  <text x="290" y="410" text-anchor="middle" font-size="11" fill="white">r_1 = h_{n-1}</text>
  
  <!-- Teacher Prior -->
  <rect x="420" y="350" width="180" height="70" rx="10" fill="#E67E22" stroke="#CA6F1E" stroke-width="2"/>
  <text x="510" y="375" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Teacher Prior</text>
  <text x="510" y="395" text-anchor="middle" font-size="12" fill="white">q(c|h_R,G)</text>
  <text x="510" y="410" text-anchor="middle" font-size="11" fill="white">RDMA Strategy</text>
  
  <!-- Predictive Distribution -->
  <rect x="640" y="350" width="160" height="70" rx="10" fill="#1ABC9C" stroke="#16A085" stroke-width="2"/>
  <text x="720" y="375" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Predictive Dist.</text>
  <text x="720" y="395" text-anchor="middle" font-size="12" fill="white">p_Œ∏^{(t')}(i|h)</text>
  <text x="720" y="410" text-anchor="middle" font-size="11" fill="white">z_{t'} = r_{t'}^T E</text>
  
  <!-- Loss Components -->
  <rect x="200" y="460" width="180" height="60" rx="10" fill="#8E44AD" stroke="#7D3C98" stroke-width="2"/>
  <text x="290" y="480" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Target Loss</text>
  <text x="290" y="500" text-anchor="middle" font-size="12" fill="white">L_{main}^{(t')}</text>
  
  <rect x="420" y="460" width="180" height="60" rx="10" fill="#2980B9" stroke="#21618C" stroke-width="2"/>
  <text x="510" y="480" text-anchor="middle" font-size="14" font-weight="bold" fill="white">KL Regularization</text>
  <text x="510" y="500" text-anchor="middle" font-size="12" fill="white">L_{reg}^{(t')} = D_{KL}(q||p_Œ∏^{(t')})</text>
  
  <!-- Norm Rescaling -->
  <rect x="640" y="460" width="160" height="60" rx="10" fill="#27AE60" stroke="#229954" stroke-width="2"/>
  <text x="720" y="480" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Norm Rescaling</text>
  <text x="720" y="500" text-anchor="middle" font-size="12" fill="white">h ‚Üê Œ±¬∑h/||h||¬∑avg(E)</text>
  
  <!-- Convergence Check -->
  <rect x="350" y="550" width="300" height="50" rx="10" fill="#34495E" stroke="#2C3E50" stroke-width="2"/>
  <text x="500" y="570" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Convergence Check</text>
  <text x="500" y="590" text-anchor="middle" font-size="12" fill="white">D_{KL}(p_Œ∏^{(t'-1)}||p_Œ∏^{(t')}) < Œµ ?</text>
  
  <!-- Output -->
  <rect x="375" y="660" width="250" height="80" rx="10" fill="#2ECC71" stroke="#27AE60" stroke-width="2"/>
  <text x="500" y="690" text-anchor="middle" font-size="16" font-weight="bold" fill="white">Final Recommendation</text>
  <text x="500" y="710" text-anchor="middle" font-size="14" fill="white">Top-k Items</text>
  <text x="500" y="725" text-anchor="middle" font-size="12" fill="white">Based on p_Œ∏^{(t')}(i|h)</text>
  
  <!-- Arrows -->
  <path d="M 150 140 L 150 180" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 400 140 L 400 180" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 250 220 L 290 220 L 290 350" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 400 260 L 400 290 L 510 290 L 510 350" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 380 385 L 420 385" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 600 385 L 640 385" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 290 420 L 290 460" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 510 420 L 510 460" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 720 420 L 720 460" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 500 600 L 500 660" stroke="#34495E" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  
  <!-- Loop Arrow -->
  <path d="M 800 385 Q 850 385 850 480 Q 850 575 500 575" stroke="#E74C3C" stroke-width="2" fill="none" stroke-dasharray="3,3" marker-end="url(#arrowhead2)"/>
  <text x="860" y="480" font-size="12" fill="#E74C3C">Continue</text>
  
  <!-- Arrow Markers -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#34495E"/>
    </marker>
    <marker id="arrowhead2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#E74C3C"/>
    </marker>
  </defs>
  
  <!-- Legend -->
  <rect x="50" y="760" width="900" height="30" rx="5" fill="#ECF0F1" stroke="#BDC3C7" stroke-width="1"/>
  <text x="60" y="780" font-size="12" fill="#34495E">Key: </text>
  <circle cx="120" cy="775" r="5" fill="#3498DB"/>
  <text x="130" y="780" font-size="11" fill="#34495E">Input</text>
  <circle cx="200" cy="775" r="5" fill="#E74C3C"/>
  <text x="210" y="780" font-size="11" fill="#34495E">Graph</text>
  <circle cx="280" cy="775" r="5" fill="#F39C12"/>
  <text x="290" y="780" font-size="11" fill="#34495E">Reasoning</text>
  <circle cx="380" cy="775" r="5" fill="#8E44AD"/>
  <text x="390" y="780" font-size="11" fill="#34495E">Loss</text>
  <circle cx="460" cy="775" r="5" fill="#2ECC71"/>
  <text x="470" y="780" font-size="11" fill="#34495E">Output</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A collaborative manifold defined by graph-induced neighborhoods on the item probability simplex">
                        <div class="quiz-question">1. What geometric concept does ManCAR use to prevent latent drift during multi-step reasoning?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A collaborative manifold defined by graph-induced neighborhoods on the item probability simplex">A collaborative manifold defined by graph-induced neighborhoods on the item probability simplex</div><div class="quiz-choice" data-value="A hyperbolic embedding space that captures hierarchical item relationships">A hyperbolic embedding space that captures hierarchical item relationships</div><div class="quiz-choice" data-value="A Euclidean distance metric between consecutive reasoning states">A Euclidean distance metric between consecutive reasoning states</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="When the KL divergence between consecutive reasoning states falls below a threshold">
                        <div class="quiz-question">2. How does ManCAR determine when to stop reasoning at test time?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By using a fixed number of reasoning steps determined during training">By using a fixed number of reasoning steps determined during training</div><div class="quiz-choice" data-value="When the KL divergence between consecutive reasoning states falls below a threshold">When the KL divergence between consecutive reasoning states falls below a threshold</div><div class="quiz-choice" data-value="By measuring the cosine similarity between the final state and item embeddings">By measuring the cosine similarity between the final state and item embeddings</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="ManCAR uses an increasing temperature schedule while ReaRec uses a decreasing one">
                        <div class="quiz-question">3. What is the key difference between ManCAR's teacher scheduling and ReaRec's PRL mechanism?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="ManCAR uses a decreasing temperature schedule while ReaRec uses an increasing one">ManCAR uses a decreasing temperature schedule while ReaRec uses an increasing one</div><div class="quiz-choice" data-value="ManCAR employs parallel reasoning streams while ReaRec uses sequential refinement">ManCAR employs parallel reasoning streams while ReaRec uses sequential refinement</div><div class="quiz-choice" data-value="ManCAR uses an increasing temperature schedule while ReaRec uses a decreasing one">ManCAR uses an increasing temperature schedule while ReaRec uses a decreasing one</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>Mobile-O: Unified Multimodal Understanding and Generation on Mobile Device</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-23</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.20161" target="_blank">http://arxiv.org/pdf/2602.20161</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper presents Mobile-O, a unified multimodal model for both visual understanding and image generation optimized for deployment on mobile devices.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Building on existing unified models like BLIP-3o and Show-O, the paper introduces a Mobile Conditioning Projector (MCP) for efficient cross-modal fusion and a novel quadruplet training format (generation prompt, image, question, answer) for simultaneous improvement of both tasks.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge that existing unified multimodal models are too computationally expensive and memory-intensive for deployment on edge devices like smartphones.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a lightweight architecture combining FastVLM for understanding and SANA for generation, connected via the MCP module using depthwise-separable convolutions, and employ a three-stage training scheme with unified post-training on 105k quadruplet samples.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Mobile-O achieves 74% on GenEval (5-11% better than Show-O and JanusFlow) while running 6-11√ó faster, and attains 62.1% average accuracy across seven visual understanding benchmarks, all while maintaining under 2GB memory footprint and 3-second generation time on iPhone.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Mobile-O: Unified Multimodal Understanding and Generation on Mobile Device</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background gradient -->
  <defs>
    <linearGradient id="bgGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f4ff;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e8f1ff;stop-opacity:1" />
    </linearGradient>
    
    <!-- Component gradients -->
    <linearGradient id="stageGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#4361ee;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#3f37c9;stop-opacity:1" />
    </linearGradient>
    
    <linearGradient id="moduleGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#f72585;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#b5179e;stop-opacity:1" />
    </linearGradient>
    
    <linearGradient id="mcpGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#7209b7;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#560bad;stop-opacity:1" />
    </linearGradient>
    
    <linearGradient id="dataGrad" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" style="stop-color:#4cc9f0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#4361ee;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Background -->
  <rect width="1000" height="800" fill="url(#bgGrad)"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="28" font-weight="bold" fill="#2b2d42">
    Mobile-O: Unified Multimodal Understanding and Generation Workflow
  </text>
  
  <!-- Stage 1: Cross-Modal Alignment -->
  <rect x="50" y="80" width="280" height="160" rx="15" fill="url(#stageGrad)"/>
  <text x="190" y="110" text-anchor="middle" font-size="18" font-weight="bold" fill="white">
    Stage 1: Cross-Modal Alignment
  </text>
  <text x="190" y="135" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ JourneyDB (4M samples)
  </text>
  <text x="190" y="155" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ BLIP3o-Short (5M samples)
  </text>
  <text x="190" y="175" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Pre-train DiT + MCP
  </text>
  <text x="190" y="195" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Freeze VE + LLM
  </text>
  <text x="190" y="215" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ ~3 days training
  </text>
  
  <!-- Stage 2: Supervised Fine-tuning -->
  <rect x="360" y="80" width="280" height="160" rx="15" fill="url(#stageGrad)"/>
  <text x="500" y="110" text-anchor="middle" font-size="18" font-weight="bold" fill="white">
    Stage 2: Supervised Fine-tuning
  </text>
  <text x="500" y="135" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ BLIP3o-60K
  </text>
  <text x="500" y="155" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ ShareGPT-4o (45K)
  </text>
  <text x="500" y="175" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Target complex gestures
  </text>
  <text x="500" y="195" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Maintain frozen config
  </text>
  <text x="500" y="215" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ ~15 hours training
  </text>
  
  <!-- Stage 3: Unified Post-Training -->
  <rect x="670" y="80" width="280" height="160" rx="15" fill="url(#stageGrad)"/>
  <text x="810" y="110" text-anchor="middle" font-size="18" font-weight="bold" fill="white">
    Stage 3: Unified Post-Training
  </text>
  <text x="810" y="135" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Quadruplet format
  </text>
  <text x="810" y="155" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ (prompt, image, Q, A)
  </text>
  <text x="810" y="175" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Joint I2T + T2I loss
  </text>
  <text x="810" y="195" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ LoRA on LLM + VE
  </text>
  <text x="810" y="215" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ ~5 hours training
  </text>
  
  <!-- Mobile Conditioning Projector (MCP) -->
  <rect x="350" y="280" width="300" height="200" rx="20" fill="url(#mcpGrad)"/>
  <text x="500" y="310" text-anchor="middle" font-size="20" font-weight="bold" fill="white">
    Mobile Conditioning Projector
  </text>
  <text x="500" y="335" text-anchor="middle" font-size="14" fill="white">
    Key Innovation
  </text>
  <circle cx="400" cy="380" r="30" fill="#ffd60a"/>
  <text x="400" y="385" text-anchor="middle" font-size="12" fill="#003566">Layer</text>
  <text x="400" y="395" text-anchor="middle" font-size="12" fill="#003566">Fusion</text>
  
  <circle cx="500" cy="380" r="30" fill="#ffd60a"/>
  <text x="500" y="385" text-anchor="middle" font-size="12" fill="#003566">Depthwise</text>
  <text x="500" y="395" text-anchor="middle" font-size="12" fill="#003566">Conv</text>
  
  <circle cx="600" cy="380" r="30" fill="#ffd60a"/>
  <text x="600" y="385" text-anchor="middle" font-size="12" fill="#003566">Channel</text>
  <text x="600" y="395" text-anchor="middle" font-size="12" fill="#003566">Attention</text>
  
  <text x="500" y="440" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Bridges VLM ‚Üí Diffusion
  </text>
  <text x="500" y="460" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ Only 2.4M parameters
  </text>
  
  <!-- Model Components -->
  <rect x="50" y="520" width="200" height="120" rx="15" fill="url(#moduleGrad)"/>
  <text x="150" y="550" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Understanding Module
  </text>
  <text x="150" y="575" text-anchor="middle" font-size="13" fill="white">
    ‚Ä¢ FastVLM-0.5B
  </text>
  <text x="150" y="595" text-anchor="middle" font-size="13" fill="white">
    ‚Ä¢ Image Encoder
  </text>
  <text x="150" y="615" text-anchor="middle" font-size="13" fill="white">
    ‚Ä¢ Qwen2-0.5B LLM
  </text>
  
  <rect x="280" y="520" width="200" height="120" rx="15" fill="url(#moduleGrad)"/>
  <text x="380" y="550" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Generation Module
  </text>
  <text x="380" y="575" text-anchor="middle" font-size="13" fill="white">
    ‚Ä¢ SANA-600M DiT
  </text>
  <text x="380" y="595" text-anchor="middle" font-size="13" fill="white">
    ‚Ä¢ VAE Encoder/Decoder
  </text>
  <text x="380" y="615" text-anchor="middle" font-size="13" fill="white">
    ‚Ä¢ 512√ó512 images
  </text>
  
  <!-- Unified Data Format -->
  <rect x="520" y="520" width="430" height="120" rx="15" fill="url(#dataGrad)"/>
  <text x="735" y="550" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Unified Quadruplet Data Format
  </text>
  <rect x="540" y="565" width="90" height="60" rx="10" fill="white" opacity="0.9"/>
  <text x="585" y="590" text-anchor="middle" font-size="12" fill="#003566">Generation</text>
  <text x="585" y="605" text-anchor="middle" font-size="12" fill="#003566">Prompt</text>
  
  <rect x="640" y="565" width="90" height="60" rx="10" fill="white" opacity="0.9"/>
  <text x="685" y="590" text-anchor="middle" font-size="12" fill="#003566">Image</text>
  
  <rect x="740" y="565" width="90" height="60" rx="10" fill="white" opacity="0.9"/>
  <text x="785" y="590" text-anchor="middle" font-size="12" fill="#003566">Question</text>
  
  <rect x="840" y="565" width="90" height="60" rx="10" fill="white" opacity="0.9"/>
  <text x="885" y="590" text-anchor="middle" font-size="12" fill="#003566">Answer</text>
  
  <!-- Performance Metrics -->
  <rect x="50" y="670" width="420" height="100" rx="15" fill="#06ffa5" opacity="0.8"/>
  <text x="260" y="700" text-anchor="middle" font-size="18" font-weight="bold" fill="#003566">
    Performance Highlights
  </text>
  <text x="260" y="725" text-anchor="middle" font-size="14" fill="#003566">
    ‚Ä¢ 74% on GenEval (5% better than Show-O)
  </text>
  <text x="260" y="745" text-anchor="middle" font-size="14" fill="#003566">
    ‚Ä¢ 62.1% average on 7 understanding benchmarks
  </text>
  
  <!-- Deployment Stats -->
  <rect x="530" y="670" width="420" height="100" rx="15" fill="#ff006e" opacity="0.8"/>
  <text x="740" y="700" text-anchor="middle" font-size="18" font-weight="bold" fill="white">
    Mobile Deployment
  </text>
  <text x="740" y="725" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ ~3 seconds on iPhone 17 Pro
  </text>
  <text x="740" y="745" text-anchor="middle" font-size="14" fill="white">
    ‚Ä¢ <2GB memory footprint
  </text>
  
  <!-- Flow connections -->
  <path d="M 330 160 Q 345 160 345 160 T 360 160" stroke="#003566" stroke-width="3" fill="none"/>
  <path d="M 640 160 Q 655 160 655 160 T 670 160" stroke="#003566" stroke-width="3" fill="none"/>
  <path d="M 500 240 L 500 280" stroke="#003566" stroke-width="3" fill="none"/>
  <path d="M 150 480 L 150 520" stroke="#003566" stroke-width="3" fill="none"/>
  <path d="M 380 480 L 380 520" stroke="#003566" stroke-width="3" fill="none"/>
  <path d="M 500 480 L 735 520" stroke="#003566" stroke-width="3" fill="none"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A Mobile Conditioning Projector (MCP) using depthwise-separable convolutions and layerwise alignment">
                        <div class="quiz-question">1. What is the key architectural innovation in Mobile-O that enables efficient cross-modal fusion between understanding and generation tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A Mobile Conditioning Projector (MCP) using depthwise-separable convolutions and layerwise alignment">A Mobile Conditioning Projector (MCP) using depthwise-separable convolutions and layerwise alignment</div><div class="quiz-choice" data-value="A 2.6B-parameter UNet combined with learnable query tokens">A 2.6B-parameter UNet combined with learnable query tokens</div><div class="quiz-choice" data-value="A transformer-based adapter with full 2D convolutions">A transformer-based adapter with full 2D convolutions</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Mobile-O achieves strong performance with only a few million pre-training samples (about 5√ó less than BLIP-3o)">
                        <div class="quiz-question">2. How does Mobile-O's training data requirement compare to existing unified models like BLIP-3o?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Mobile-O requires 50-100M samples, similar to other unified models">Mobile-O requires 50-100M samples, similar to other unified models</div><div class="quiz-choice long-text" data-value="Mobile-O achieves strong performance with only a few million pre-training samples (about 5√ó less than BLIP-3o)">Mobile-O achieves strong performance with only a few million pre-training samples (about 5√ó less than BLIP-3o)</div><div class="quiz-choice" data-value="Mobile-O needs at least 1B samples for effective cross-modal alignment">Mobile-O needs at least 1B samples for effective cross-modal alignment</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Quadruplet format (generation prompt, image, question, answer) where each sample supports both tasks">
                        <div class="quiz-question">3. What unique training format does Mobile-O introduce in its unified multimodal post-training stage?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Sequential training where understanding is frozen while training generation">Sequential training where understanding is frozen while training generation</div><div class="quiz-choice" data-value="Joint training on disjoint understanding and generation datasets">Joint training on disjoint understanding and generation datasets</div><div class="quiz-choice" data-value="Quadruplet format (generation prompt, image, question, answer) where each sample supports both tasks">Quadruplet format (generation prompt, image, question, answer) where each sample supports both tasks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');

                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫ÊØè‰∏™Âç°ÁâáÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂ÔºàËÄå‰∏çÊòØÊï¥‰∏™ÂÆπÂô®Ôºâ
                cards.forEach(card => {
                    card.addEventListener('click', function(e) {
                        // Âè™ÊúâÁÇπÂáªÂú®Âç°ÁâáÂÜÖÈÉ®Êó∂ÊâçÂàáÊç¢
                        // Ê£ÄÊü•ÊòØÂê¶ÊòØÊµÅÁ®ãÂõæÂç°ÁâáÁöÑÊªöÂä®Êù°Âå∫Âüü
                        if (this.classList.contains('flowchart-card')) {
                            const rect = this.getBoundingClientRect();
                            const isScrollbarClick =
                                (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                                (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);

                            if (!isScrollbarClick) {
                                nextCard(e);
                            }
                        } else {
                            nextCard(e);
                        }
                    });
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>

    <!-- AI Assistant Scripts - Load in correct order (relative paths for subpages) -->
    <script src="../../js/ai-assistant-constants.js"></script>
    <script src="../../js/ai-assistant-storage.js"></script>
    <script src="../../js/ai-assistant-positioning.js"></script>
    <script src="../../js/ai-assistant-templates.js"></script>
    <script src="../../js/ai-assistant-dom-utils.js"></script>
    <script src="../../js/ai-assistant-config.js"></script>
    <script src="../../js/ai-assistant.js"></script>
</body>
</html>
