
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-04-11 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-04-11 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>VisualCloze: A Universal Image Generation Framework via Visual
  In-Context Learning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-10</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.07960" target="_blank">http://arxiv.org/pdf/2504.07960</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> Universal image generation framework called VisualCloze that leverages visual in-context learning to handle diverse image generation tasks within a single model.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on diffusion models and task-specific image generation approaches, proposing visual in-context learning where models learn tasks from visual demonstrations rather than relying solely on language instructions.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Addressing limitations of current image generation approaches that either require task-specific models or face challenges with task ambiguity, sparse task distributions, and lack of generalization to unseen tasks.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Creating a graph-structured dataset (Graph200K) with interrelated tasks, formulating image generation as an image infilling problem, and fine-tuning FLUX.1-Fill-dev to support visual in-context learning where tasks are demonstrated through examples.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The model successfully handles various in-domain tasks with reduced ambiguity, generalizes to unseen tasks, enables task unification, and supports reverse generation, outperforming comparable methods in conditional generation, style transfer, and subject-driven image generation tasks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>VisualCloze: A Universal Image Generation Framework via Visual
  In-Context Learning</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg" font-family="Arial, sans-serif">

  <!-- Define styles and gradients -->
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,200,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(200,220,255);stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,220,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,240,200);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(160,255,160);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(210,255,210);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,180,180);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,220,220);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad5" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(200, 180, 255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(230, 220, 255);stop-opacity:1" />
    </linearGradient>
    <style>
      .title { font-size: 28px; font-weight: bold; text-anchor: middle; fill: #333; }
      .subtitle { font-size: 18px; font-weight: bold; fill: #555; }
      .text-main { font-size: 14px; fill: #444; }
      .text-detail { font-size: 12px; fill: #666; }
      .box { stroke: #aaa; stroke-width: 1; rx: 10; ry: 10; filter: drop-shadow(3px 3px 2px rgba(0,0,0,0.1)); }
      .box-problem { fill: #ffebee; stroke: #e57373; }
      .box-solution { fill: url(#grad1); stroke: #64b5f6; }
      .box-paradigm { fill: url(#grad2); stroke: #ffb74d; }
      .box-formulation { fill: url(#grad3); stroke: #81c784; }
      .box-data { fill: url(#grad4); stroke: #ff8a65; }
      .box-model { fill: url(#grad5); stroke: #9575cd; }
      .box-outcome { fill: #e0f7fa; stroke: #4dd0e1; }
    </style>
  </defs>

  <!-- Title -->
  <text x="500" y="40" class="title">VisualCloze Methodology Flowchart</text>

  <!-- Problem Statement -->
  <rect x="250" y="70" width="500" height="60" class="box box-problem" />
  <text x="500" y="95" class="subtitle" text-anchor="middle">Problem</text>
  <text x="500" y="115" class="text-main" text-anchor="middle">Task-specific models lack efficiency; Universal models face instruction, distribution, & architecture issues.</text>

  <!-- Central Solution Block -->
  <rect x="50" y="150" width="900" height="450" class="box box-solution" />
  <text x="500" y="180" class="subtitle" text-anchor="middle">Solution: VisualCloze Framework</text>

  <!-- Core Components within Solution -->
  <g transform="translate(70, 210)">
    <!-- 1. Visual In-Context Learning Paradigm -->
    <rect x="0" y="0" width="420" height="180" class="box box-paradigm" />
    <text x="210" y="25" class="subtitle" text-anchor="middle">1. Visual In-Context Learning (VICL)</text>
    <text x="10" y="55" class="text-main">Input Format:</text>
    <text x="20" y="75" class="text-detail">‚Ä¢ C In-Context Examples (Demos)</text>
    <text x="20" y="95" class="text-detail">  - Each: L images (Conditions + Target)</text>
    <text x="20" y="115" class="text-detail">‚Ä¢ 1 Query</text>
    <text x="20" y="135" class="text-detail">  - L-1 Condition Images + 1 Blank Target</text>
    <text x="10" y="165" class="text-main">Goal: Learn task from visual examples, not just text.</text>
  </g>

  <g transform="translate(510, 210)">
    <!-- 2. Unified Task Formulation -->
    <rect x="0" y="0" width="420" height="180" class="box box-formulation" />
    <text x="210" y="25" class="subtitle" text-anchor="middle">2. Unified Task as Infilling</text>
    <text x="10" y="55" class="text-main">Process:</text>
    <text x="20" y="75" class="text-detail">‚Ä¢ Concatenate all input images into a grid.</text>
    <text x="20" y="95" class="text-detail">‚Ä¢ Mask the target image region (M).</text>
    <text x="20" y="115" class="text-detail">‚Ä¢ Use Infilling Model: Generate masked region.</text>
    <text x="20" y="135" class="text-detail">‚Ä¢ Objective: `X_hat = f(X_grid | T_layout, M)`</text>
    <text x="10" y="165" class="text-main">Benefit: Aligns with pre-trained infilling models.</text>
  </g>

  <g transform="translate(70, 410)">
    <!-- 3. Graph200K Dataset -->
    <rect x="0" y="0" width="420" height="180" class="box box-data" />
    <text x="210" y="25" class="subtitle" text-anchor="middle">3. Graph200K Dataset</text>
    <text x="10" y="55" class="text-main">Structure & Purpose:</text>
    <text x="20" y="75" class="text-detail">‚Ä¢ Built on Subjects200K.</text>
    <text x="20" y="95" class="text-detail">‚Ä¢ Graph: Images (nodes) + Annotations (edges).</text>
    <text x="20" y="115" class="text-detail">‚Ä¢ 5 Meta-Tasks (CondGen, Edit, Restore, Style, IP).</text>
    <text x="20" y="135" class="text-detail">‚Ä¢ Increases task density & overlap.</text>
    <text x="10" y="165" class="text-main">Benefit: Promotes learning transferable knowledge.</text>
  </g>

  <g transform="translate(510, 410)">
    <!-- 4. Model & Training -->
    <rect x="0" y="0" width="420" height="180" class="box box-model" />
    <text x="210" y="25" class="subtitle" text-anchor="middle">4. Model & Training</text>
    <text x="10" y="55" class="text-main">Implementation:</text>
    <text x="20" y="75" class="text-detail">‚Ä¢ Base Model: FLUX.1-Fill-dev (Infilling).</text>
    <text x="20" y="95" class="text-detail">‚Ä¢ Fine-tuning: LoRA (Rank 256, minimal changes).</text>
    <text x="20" y="115" class="text-detail">‚Ä¢ Training Data: Graph200K + others (VITON, etc.).</text>
    <text x="20" y="135" class="text-detail">‚Ä¢ Positional Embedding: 3D-RoPE for aspect ratios.</text>
    <text x="10" y="165" class="text-main">Benefit: Leverages strong priors with low cost.</text>
  </g>

  <!-- Outcomes/Capabilities -->
  <text x="500" y="630" class="subtitle" text-anchor="middle">Key Capabilities Enabled by VisualCloze</text>
  <g transform="translate(50, 650)">
     <rect x="0" y="0" width="210" height="100" class="box box-outcome"/>
     <text x="105" y="30" class="text-main" text-anchor="middle">Improved Seen Tasks</text>
     <text x="105" y="55" class="text-detail" text-anchor="middle">Reduced ambiguity,</text>
     <text x="105" y="70" class="text-detail" text-anchor="middle">better performance.</text>
  </g>
   <g transform="translate(275, 650)">
     <rect x="0" y="0" width="210" height="100" class="box box-outcome"/>
     <text x="105" y="30" class="text-main" text-anchor="middle">Unseen Task Generalization</text>
     <text x="105" y="55" class="text-detail" text-anchor="middle">Adapts to new tasks</text>
      <text x="105" y="70" class="text-detail" text-anchor="middle">via VICL examples.</text>
  </g>
   <g transform="translate(500, 650)">
     <rect x="0" y="0" width="210" height="100" class="box box-outcome"/>
     <text x="105" y="30" class="text-main" text-anchor="middle">Task Unification</text>
     <text x="105" y="55" class="text-detail" text-anchor="middle">Combines multiple sub-tasks</text>
     <text x="105" y="70" class="text-detail" text-anchor="middle">into a single step.</text>
  </g>
  <g transform="translate(725, 650)">
     <rect x="0" y="0" width="210" height="100" class="box box-outcome"/>
     <text x="105" y="30" class="text-main" text-anchor="middle">Reverse Generation</text>
     <text x="105" y="55" class="text-detail" text-anchor="middle">Infers conditions</text>
     <text x="105" y="70" class="text-detail" text-anchor="middle">from target image.</text>
  </g>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Visual in-context learning instead of relying on language instructions">
                        <div class="quiz-question">1. What is the main innovation of VisualCloze compared to previous universal image generation approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using a larger and more diverse training dataset">Using a larger and more diverse training dataset</div><div class="quiz-choice" data-value="Visual in-context learning instead of relying on language instructions">Visual in-context learning instead of relying on language instructions</div><div class="quiz-choice" data-value="Developing a completely new diffusion model architecture">Developing a completely new diffusion model architecture</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="The sparsity and isolation of visual tasks that limits knowledge transfer">
                        <div class="quiz-question">2. What problem does the Graph200K dataset address in the context of visual tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="The lack of high-quality training images">The lack of high-quality training images</div><div class="quiz-choice" data-value="The sparsity and isolation of visual tasks that limits knowledge transfer">The sparsity and isolation of visual tasks that limits knowledge transfer</div><div class="quiz-choice" data-value="The computational complexity of training large generative models">The computational complexity of training large generative models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Real-time video generation with temporal consistency">
                        <div class="quiz-question">3. Which of the following capabilities was NOT demonstrated by VisualCloze?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Generating frontal faces from side-view images (unseen task)">Generating frontal faces from side-view images (unseen task)</div><div class="quiz-choice" data-value="Reverse generation (inferring conditions from target images)">Reverse generation (inferring conditions from target images)</div><div class="quiz-choice" data-value="Real-time video generation with temporal consistency">Real-time video generation with temporal consistency</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/broken-noise.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>MM-IFEngine: Towards Multimodal Instruction Following</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-10</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.07957" target="_blank">http://arxiv.org/pdf/2504.07957</a></p>
                        <div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>MM-IFEngine: Towards Multimodal Instruction Following</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">

  <!-- Define styles and gradients -->
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,200,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(200,230,255);stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,200,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,230,200);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,255,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(200,255,200);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(220,180,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(240,220,255);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad5" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,255,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,255,200);stop-opacity:1" />
    </linearGradient>
    <style>
      .title { font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; fill: #333; }
      .subtitle { font-family: Arial, sans-serif; font-size: 16px; font-weight: bold; fill: #555; }
      .text { font-family: Arial, sans-serif; font-size: 12px; fill: #444; }
      .box { stroke: #666; stroke-width: 1; filter: drop-shadow( 3px 3px 2px rgba(0,0,0,0.2)); }
      .process-box { fill: url(#grad1); rx: 10; ry: 10; }
      .input-output { fill: url(#grad2); } /* Parallelogram shape for I/O */
      .dataset-box { fill: url(#grad3); rx: 5; ry: 5; }
      .benchmark-box { fill: url(#grad4); rx: 5; ry: 5; }
      .eval-box { fill: url(#grad5); rx: 5; ry: 5; }
      .connector { stroke: #555; stroke-width: 1.5; fill: none; marker-end: url(#arrowhead); }
      .dashed-connector { stroke: #777; stroke-width: 1.5; stroke-dasharray: 4, 2; fill: none; marker-end: url(#arrowhead); }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#555" />
    </marker>
  </defs>

  <!-- Title -->
  <text x="500" y="40" class="title" text-anchor="middle">MM-IFEngine Workflow</text>

  <!-- Section 1: MM-IFEngine Pipeline -->
  <rect x="50" y="70" width="900" height="280" fill="#f0f8ff" rx="15" ry="15" stroke="#cce0ff" stroke-width="1"/>
  <text x="500" y="95" class="subtitle" text-anchor="middle">MM-IFEngine: Image-Instruction Pair Generation</text>

  <!-- Input Images -->
  <path d="M 60 120 l 20 -20 h 150 l -20 20 h -150 z" class="box input-output"/>
  <text x="145" y="118" class="text" text-anchor="middle">Diverse Image Sources</text>
  <text x="145" y="133" class="text" text-anchor="middle">(CC3M, ALLaVA, UI, Geo, Chart)</text>

  <!-- Step 1: Image Filtering -->
  <rect x="270" y="110" width="160" height="50" class="box process-box"/>
  <text x="350" y="130" class="text" text-anchor="middle">Step 1: Image Filter</text>
  <text x="350" y="145" class="text" text-anchor="middle">(Resolution, Semantics)</text>
  <path d="M 230 120 h 40" class="connector"/>

  <!-- Step 2: Task Generation -->
  <rect x="470" y="110" width="160" height="50" class="box process-box"/>
  <text x="550" y="130" class="text" text-anchor="middle">Step 2: Task Generation</text>
  <text x="550" y="145" class="text" text-anchor="middle">(GPT-4o/Refine Existing)</text>
  <path d="M 430 135 h 40" class="connector"/>

  <!-- Step 3: Constraints Integration -->
  <rect x="670" y="110" width="160" height="50" class="box process-box"/>
  <text x="750" y="130" class="text" text-anchor="middle">Step 3: Constraints Integration</text>
  <text x="750" y="145" class="text" text-anchor="middle">(LLM Generate & Validate)</text>
  <path d="M 630 135 h 40" class="connector"/>

  <!-- Constraint Pool -->
  <rect x="670" y="175" width="160" height="50" fill="#ffe0b3" rx="5" ry="5" class="box"/>
  <text x="750" y="195" class="text" text-anchor="middle">Constraint Pool</text>
  <text x="750" y="210" class="text" text-anchor="middle">(32 Types, 6 Categories)</text>
  <path d="M 750 160 v 15" class="dashed-connector"/>

  <!-- Output: Image-Instruction Pairs -->
  <path d="M 850 250 l 20 -20 h 100 l -20 20 h -100 z" class="box input-output"/>
  <text x="915" y="248" class="text" text-anchor="middle">High-Quality</text>
  <text x="915" y="263" class="text" text-anchor="middle">Image-Instruction Pairs</text>
  <path d="M 750 160 c 0 40, 100 60, 180 85" class="connector"/>


  <!-- Section 2: Dataset Generation -->
  <rect x="50" y="360" width="430" height="200" fill="#f0fff0" rx="15" ry="15" stroke="#cce0cc" stroke-width="1"/>
  <text x="265" y="385" class="subtitle" text-anchor="middle">Dataset Generation</text>

  <!-- Path from Image-Instruction Pairs -->
  <path d="M 915 275 c 0 50, -200 75, -550 75 L 265 350 v 10" class="dashed-connector"/>

  <!-- MM-IFInstruct-23k (SFT) -->
  <rect x="70" y="400" width="180" height="80" class="box dataset-box"/>
  <text x="160" y="420" class="text" text-anchor="middle">Generate Responses</text>
  <text x="160" y="435" class="text" text-anchor="middle">(InternVL2.5-78B)</text>
  <text x="160" y="450" class="text" text-anchor="middle">Post-Process (Filter)</text>
  <text x="160" y="465" class="text" text-anchor="middle">-> MM-IFInstruct-23k (SFT)</text>
  <path d="M 265 400 h -15" class="connector"/>

  <!-- MM-IFDPO-23k (DPO) -->
  <rect x="280" y="400" width="180" height="100" class="box dataset-box"/>
  <text x="370" y="420" class="text" text-anchor="middle">Generate Rejected Responses</text>
  <text x="370" y="435" class="text" text-anchor="middle">(Qwen2-VL-7B)</text>
  <text x="370" y="450" class="text" text-anchor="middle">Settings:</text>
  <text x="370" y="465" class="text" text-anchor="middle">-Remove Constraints (33/66/100%)</text>
  <text x="370" y="480" class="text" text-anchor="middle">-Remove Image</text>
  <text x="370" y="495" class="text" text-anchor="middle">-> MM-IFDPO-23k (DPO)</text>
   <path d="M 265 450 h 15" class="connector"/>


  <!-- Section 3: Benchmark Creation -->
  <rect x="500" y="360" width="450" height="120" fill="#f8f0ff" rx="15" ry="15" stroke="#e0ccee" stroke-width="1"/>
  <text x="725" y="385" class="subtitle" text-anchor="middle">MM-IFEval Benchmark Creation</text>

  <!-- Path from Image-Instruction Pairs -->
  <path d="M 915 275 c 0 50, -50 75, -150 75 L 725 350 v 10" class="dashed-connector"/>

  <rect x="520" y="400" width="180" height="60" class="box benchmark-box"/>
  <text x="610" y="420" class="text" text-anchor="middle">Human Annotation &</text>
  <text x="610" y="435" class="text" text-anchor="middle">LLM Conflict Check</text>
  <text x="610" y="450" class="text" text-anchor="middle">(400 Qs: 300C + 100P)</text>
   <path d="M 725 400 h -15" class="connector"/>

  <path d="M 700 430 h 20" class="connector"/>
  <path d="M 720 430 l 20 -20 h 180 l -20 20 h -180 z" class="box input-output" fill="#e6e6fa"/>
  <text x="830" y="428" class="text" text-anchor="middle">MM-IFEval Benchmark</text>


  <!-- Section 4: Hybrid Evaluation (for MM-IFEval) -->
   <rect x="500" y="490" width="450" height="160" fill="#fffacd" rx="15" ry="15" stroke="#eedd82" stroke-width="1"/>
   <text x="725" y="515" class="subtitle" text-anchor="middle">MM-IFEval Hybrid Evaluation Method</text>

   <!-- Link from Benchmark -->
   <path d="M 830 440 v 50 " class="dashed-connector"/>

   <!-- Evaluation Methods -->
   <rect x="520" y="535" width="130" height="100" class="box eval-box"/>
   <text x="585" y="555" class="text" text-anchor="middle">Rule-based</text>
   <text x="585" y="570" class="text" text-anchor="middle">Verification</text>
   <text x="585" y="585" class="text" text-anchor="middle">(Objective Constraints)</text>
   <text x="585" y="600" class="text" text-anchor="middle">e.g., word count,</text>
   <text x="585" y="615" class="text" text-anchor="middle">format, numbers</text>

   <rect x="665" y="535" width="130" height="100" class="box eval-box"/>
   <text x="730" y="555" class="text" text-anchor="middle">LLM-based</text>
   <text x="730" y="570" class="text" text-anchor="middle">Direct Judgment</text>
    <text x="730" y="585" class="text" text-anchor="middle">(Clear Constraints)</text>
   <text x="730" y="600" class="text" text-anchor="middle">e.g., keyword</text>
    <text x="730" y="615" class="text" text-anchor="middle">mention</text>

   <rect x="810" y="535" width="130" height="100" class="box eval-box"/>
   <text x="875" y="555" class="text" text-anchor="middle">LLM-based</text>
   <text x="875" y="570" class="text" text-anchor="middle">Comparative Judgment</text>
   <text x="875" y="585" class="text" text-anchor="middle">(Subjective Constraints)</text>
   <text x="875" y="600" class="text" text-anchor="middle">e.g., tone, style,</text>
   <text x="875" y="615" class="text" text-anchor="middle">role-play</text>

   <!-- Linking Evaluation methods -->
   <path d="M 830 490 c 10 -20 -50 -20 -100 -10 L 585 535" class="dashed-connector"/>
   <path d="M 830 490 c 0 -20 -10 -20 -10 -10 L 730 535" class="dashed-connector"/>
   <path d="M 830 490 c 10 -20 50 -20 50 -10 L 875 535" class="dashed-connector"/>


  <!-- Section 5: Model Training & Evaluation -->
  <rect x="50" y="580" width="430" height="180" fill="#e0f2f7" rx="15" ry="15" stroke="#b3dfea" stroke-width="1"/>
  <text x="265" y="605" class="subtitle" text-anchor="middle">Model Training & Evaluation</text>

  <!-- Input Base Models -->
  <path d="M 60 620 l 20 -20 h 100 l -20 20 h -100 z" class="box input-output"/>
  <text x="125" y="618" class="text" text-anchor="middle">Base MLLMs</text>
  <text x="125" y="633" class="text" text-anchor="middle">(e.g., LLaVA, Qwen2)</text>

  <!-- Links from Datasets -->
  <path d="M 160 480 v 120 c 0 10 0 10 60 10 l 10 0 " class="dashed-connector"/>
  <path d="M 370 505 v 75 c 0 10 -10 10 -10 10 l -110 0" class="dashed-connector"/>

  <!-- Training Processes -->
  <rect x="200" y="650" width="100" height="40" class="box process-box" fill="#cceeff"/>
  <text x="250" y="670" class="text" text-anchor="middle">SFT Training</text>
  <text x="250" y="685" class="text" text-anchor="middle">(on Instruct-23k)</text>

  <rect x="320" y="650" width="100" height="40" class="box process-box" fill="#cceeff"/>
  <text x="370" y="670" class="text" text-anchor="middle">DPO Training</text>
  <text x="370" y="685" class="text" text-anchor="middle">(on DPO-23k)</text>

  <path d="M 180 620 h 20" class="connector"/>
  <path d="M 180 620 c 10 0, 50 30, 70 30" class="connector"/> <!-- to SFT -->
  <path d="M 180 620 c 30 0, 100 30, 190 30" class="connector"/> <!-- to DPO -->

  <!-- Output Fine-tuned Models -->
  <path d="M 250 690 v 10" class="connector"/>
  <path d="M 370 690 v 10" class="connector"/>

  <path d="M 230 700 l 20 -20 h 140 l -20 20 h -140 z" class="box input-output"/>
  <text x="300" y="698" class="text" text-anchor="middle">Fine-tuned MLLMs</text>

  <!-- Evaluation -->
  <path d="M 300 720 v 10" class="connector"/>
  <rect x="200" y="730" width="200" height="40" class="box process-box" fill="#e0ffff"/>
  <text x="300" y="750" class="text" text-anchor="middle">Evaluate on Benchmarks</text>
  <text x="300" y="765" class="text" text-anchor="middle">(MM-IFEval, MIA, IFEval, VQA)</text>

   <!-- Link Evaluation to MM-IFEval Benchmark -->
   <path d="M 400 750 h 100 c 100 0 200 -150 200 -250 L 700 450" class="dashed-connector"/>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It incorporates both compose-level and perception-level constraints with strong visual correlations">
                        <div class="quiz-question">1. What is the primary innovation of MM-IFEngine compared to existing instruction following benchmarks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses only proprietary models for evaluation">It uses only proprietary models for evaluation</div><div class="quiz-choice" data-value="It focuses exclusively on text-based constraints">It focuses exclusively on text-based constraints</div><div class="quiz-choice" data-value="It incorporates both compose-level and perception-level constraints with strong visual correlations">It incorporates both compose-level and perception-level constraints with strong visual correlations</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="32 categories with an average of 5.1 constraints per question">
                        <div class="quiz-question">2. How many distinct constraint categories are included in MM-IFEval?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="8 categories with an average of 2.6 constraints per question">8 categories with an average of 2.6 constraints per question</div><div class="quiz-choice" data-value="32 categories with an average of 5.1 constraints per question">32 categories with an average of 5.1 constraints per question</div><div class="quiz-choice" data-value="16 categories with an average of 3.5 constraints per question">16 categories with an average of 3.5 constraints per question</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="A hybrid approach combining rule-based verification and judge models">
                        <div class="quiz-question">3. What evaluation strategy does MM-IFEval use that makes it more precise than previous benchmarks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It relies exclusively on GPT-4o for all evaluations">It relies exclusively on GPT-4o for all evaluations</div><div class="quiz-choice" data-value="A hybrid approach combining rule-based verification and judge models">A hybrid approach combining rule-based verification and judge models</div><div class="quiz-choice" data-value="It uses only human evaluators to ensure accuracy">It uses only human evaluators to ensure accuracy</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/diagmonds.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>HoloPart: Generative 3D Part Amodal Segmentation</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-10</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.07943" target="_blank">http://arxiv.org/pdf/2504.07943</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces "3D part amodal segmentation," a novel task in 3D computer vision that decomposes 3D shapes into complete semantic parts, even when parts are occluded.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing 3D part segmentation techniques but extends beyond them by proposing a diffusion-based model (HoloPart) that can complete partial segments into full 3D parts, similar to how 2D amodal segmentation has evolved for images.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper solves the challenge of generating complete 3D parts from incomplete surface segments, addressing key difficulties in inferring occluded geometry, maintaining global shape consistency, and handling diverse shapes with limited training data.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a two-stage approach: first applying existing 3D part segmentation to obtain initial surface patches, then using their novel HoloPart diffusion model with local attention and context-aware attention mechanisms to complete these segments into full 3D parts.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> HoloPart significantly outperforms state-of-the-art shape completion methods on new benchmarks based on ABO and PartObjaverse-Tiny datasets, demonstrating superior performance in Chamfer Distance, IoU, and F-Score metrics, while enabling applications in geometry editing, animation, and material assignment.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>HoloPart: Generative 3D Part Amodal Segmentation</h2>
                        <svg width="100%" viewBox="0 0 1000 800">

  <!-- Define styles and gradients -->
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,200,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(100,150,220);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,220,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,180,100);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(180,255,180);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(120,220,120);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(220,180,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(180,140,220);stop-opacity:1" />
    </linearGradient>
    <filter id="shadow" x="-20%" y="-20%" width="140%" height="140%">
      <feGaussianBlur in="SourceAlpha" stdDeviation="3"/>
      <feOffset dx="2" dy="2" result="offsetblur"/>
      <feComponentTransfer>
        <feFuncA type="linear" slope="0.5"/>
      </feComponentTransfer>
      <feMerge>
        <feMergeNode/>
        <feMergeNode in="SourceGraphic"/>
      </feMerge>
    </filter>
    <style>
      .title { font-family: 'Arial', sans-serif; font-size: 28px; font-weight: bold; fill: #333; text-anchor: middle; }
      .stage-title { font-family: 'Arial', sans-serif; font-size: 18px; font-weight: bold; fill: #444; text-anchor: middle; }
      .process-text { font-family: 'Arial', sans-serif; font-size: 14px; fill: #555; text-anchor: middle; }
      .io-text { font-family: 'Consolas', monospace; font-size: 13px; fill: #222; text-anchor: middle; }
      .note-text { font-family: 'Arial', sans-serif; font-size: 12px; fill: #666; }
      .arrow-head { fill: #555; }
      .arrow-line { stroke: #555; stroke-width: 2; }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" class="arrow-head" />
    </marker>
  </defs>

  <!-- Background -->
  <rect width="1000" height="800" fill="#f9f9f9"/>

  <!-- Title -->
  <text x="500" y="40" class="title">HoloPart Methodology: 3D Part Amodal Segmentation</text>

  <!-- Input Shape -->
  <g filter="url(#shadow)">
    <rect x="380" y="70" width="240" height="50" rx="10" ry="10" fill="url(#grad3)" stroke="#aaa" stroke-width="1"/>
    <text x="500" y="100" class="io-text">Input: 3D Shape (Mesh/Point Cloud)</text>
  </g>

  <!-- Arrow -->
  <line x1="500" y1="120" x2="500" y2="150" class="arrow-line" marker-end="url(#arrowhead)"/>

  <!-- Stage 1: Part Segmentation -->
  <g filter="url(#shadow)">
    <rect x="300" y="150" width="400" height="100" rx="15" ry="15" fill="url(#grad1)" stroke="#88aacc" stroke-width="1.5"/>
    <text x="500" y="180" class="stage-title">Stage 1: Initial Part Segmentation</text>
    <text x="500" y="205" class="process-text">Apply existing method (e.g., SAMPart3D)</text>
    <text x="500" y="230" class="io-text">Output: Incomplete Segments {si}, Whole Shape (X), Mask (M)</text>
  </g>

  <!-- Arrow -->
  <line x1="500" y1="250" x2="500" y2="280" class="arrow-line" marker-end="url(#arrowhead)"/>

  <!-- Stage 2: HoloPart Completion -->
  <g filter="url(#shadow)">
    <rect x="150" y="280" width="700" height="360" rx="15" ry="15" fill="url(#grad2)" stroke="#ccaa88" stroke-width="1.5"/>
    <text x="500" y="310" class="stage-title">Stage 2: HoloPart - Part Completion (for each segment si)</text>

    <!-- Input to Stage 2 -->
    <text x="500" y="335" class="io-text">Input: Segment (si -> S), Whole Shape (X), Mask (M)</text>

    <!-- Sub-Process 1: Attention Encoding -->
    <rect x="180" y="360" width="640" height="80" rx="10" ry="10" fill="#fff8e8" stroke="#e0c8a0" stroke-width="1"/>
    <text x="500" y="385" class="process-text" font-weight="bold">1. Attention Encoding</text>
    <text x="340" y="415" class="io-text">Context-Aware Attn (S0, X, M) -> co</text>
    <text x="660" y="415" class="io-text">Local Attn (S0, S) -> cl</text>
    <line x1="500" y1="395" x2="500" y2="430" stroke="#aaa" stroke-width="1" stroke-dasharray="4 2"/>


    <!-- Arrow -->
    <line x1="500" y1="440" x2="500" y2="460" class="arrow-line" marker-end="url(#arrowhead)"/>

    <!-- Sub-Process 2: Part Diffusion Model -->
    <rect x="180" y="460" width="640" height="90" rx="10" ry="10" fill="#fff8e8" stroke="#e0c8a0" stroke-width="1"/>
    <text x="500" y="485" class="process-text" font-weight="bold">2. Part Diffusion Model (vŒ∏)</text>
    <text x="500" y="505" class="process-text" font-size="12px">(Pretrained on Objects, Finetuned on Parts)</text>
    <text x="500" y="525" class="io-text">Inputs: Noise (Œµ), Time (t), co, cl</text>
    <text x="500" y="540" class="io-text">Process: Iterative Denoising (CFG) -> Complete Part Latent (z_part)</text>

    <!-- Arrow -->
    <line x1="500" y1="550" x2="500" y2="570" class="arrow-line" marker-end="url(#arrowhead)"/>

    <!-- Sub-Process 3: Decoding -->
    <rect x="180" y="570" width="640" height="60" rx="10" ry="10" fill="#fff8e8" stroke="#e0c8a0" stroke-width="1"/>
    <text x="500" y="590" class="process-text" font-weight="bold">3. Decoding &amp; Mesh Extraction</text>
    <text x="500" y="610" class="io-text">VAE Decoder (D) -> Occupancy -> Marching Cubes -> Complete Part (pi)</text>

  </g>

   <!-- Arrow -->
  <line x1="500" y1="640" x2="500" y2="670" class="arrow-line" marker-end="url(#arrowhead)"/>

   <!-- Final Output -->
  <g filter="url(#shadow)">
    <rect x="300" y="670" width="400" height="60" rx="10" ry="10" fill="url(#grad3)" stroke="#aaa" stroke-width="1"/>
    <text x="500" y="695" class="io-text">Output: Set of Complete Parts {p1, ..., pn}</text>
    <text x="500" y="715" class="io-text">(3D Part Amodal Segmentation)</text>
  </g>

  <!-- Supporting Notes -->
   <g>
    <rect x="20" y="300" width="120" height="120" rx="10" ry="10" fill="#e8e8f8" stroke="#b0b0d0" stroke-width="1" filter="url(#shadow)"/>
    <text x="80" y="320" class="note-text" font-weight="bold" text-anchor="middle">Pretraining</text>
    <text x="30" y="340" class="note-text">VAE + Diffusion</text>
    <text x="30" y="355" class="note-text">trained on large</text>
    <text x="30" y="370" class="note-text">dataset of WHOLE</text>
    <text x="30" y="385" class="note-text">shapes to learn</text>
    <text x="30" y="400" class="note-text">general 3D priors.</text>
   </g>

   <g>
    <rect x="860" y="300" width="120" height="120" rx="10" ry="10" fill="#e8f8e8" stroke="#b0d0b0" stroke-width="1" filter="url(#shadow)"/>
    <text x="920" y="320" class="note-text" font-weight="bold" text-anchor="middle">Data Curation</text>
    <text x="870" y="340" class="note-text">Process ABO &amp;</text>
    <text x="870" y="355" class="note-text">Objaverse (filtered).</text>
     <text x="870" y="370" class="note-text">Create Whole-Part</text>
    <text x="870" y="385" class="note-text">pairs ({si}, {K}) for</text>
    <text x="870" y="400" class="note-text">finetuning HoloPart.</text>
   </g>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It completes the geometry of occluded parts rather than just identifying visible surface patches">
                        <div class="quiz-question">1. What is the key innovation that distinguishes HoloPart from traditional 3D part segmentation methods?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a larger training dataset with more diverse 3D shapes">It uses a larger training dataset with more diverse 3D shapes</div><div class="quiz-choice" data-value="It completes the geometry of occluded parts rather than just identifying visible surface patches">It completes the geometry of occluded parts rather than just identifying visible surface patches</div><div class="quiz-choice" data-value="It performs segmentation in a single end-to-end process instead of using a two-stage approach">It performs segmentation in a single end-to-end process instead of using a two-stage approach</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Local attention and shape context-aware attention">
                        <div class="quiz-question">2. Which two key attention mechanisms does HoloPart incorporate to balance local details and global context?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Temporal attention and spatial attention">Temporal attention and spatial attention</div><div class="quiz-choice" data-value="Cross-modal attention and self-supervised attention">Cross-modal attention and self-supervised attention</div><div class="quiz-choice" data-value="Local attention and shape context-aware attention">Local attention and shape context-aware attention</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Facial recognition and biometric authentication">
                        <div class="quiz-question">3. What practical downstream application is NOT mentioned as a benefit of 3D part amodal segmentation in the paper?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Geometry editing and material assignment">Geometry editing and material assignment</div><div class="quiz-choice" data-value="Animation of individual parts">Animation of individual parts</div><div class="quiz-choice" data-value="Facial recognition and biometric authentication">Facial recognition and biometric authentication</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
