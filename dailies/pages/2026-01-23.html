<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- AI Assistant Styles -->
    <link rel="stylesheet" href="../../css/ai-assistant.css">
    <title>2026-01-23 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */
            /* cursor removed - only cards should show pointer */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
            cursor: pointer; /* Show pointer on cards to indicate they're clickable */
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }

        .paper-card p {
            margin: 5px 0;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
            word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        /* ÁßªÂä®ËÆæÂ§áÂíåÂ∞èÂ±èÂπï */
        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                min-height: 400px; /* ÁßªÂä®ËÆæÂ§á‰∏ä‰ΩøÁî®Êõ¥Â∞èÁöÑÊúÄÂ∞èÈ´òÂ∫¶ */
                height: auto; /* Ëá™ÈÄÇÂ∫îÈ´òÂ∫¶ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }

            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
                width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-01-23 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/buried.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Toward Efficient Agents: Memory, Tool learning, and Planning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-20</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.14192" target="_blank">http://arxiv.org/pdf/2601.14192</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper surveys efficient agents in the domain of Large Language Model (LLM)-based autonomous systems, focusing on memory, tool learning, and planning components.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing LLM agent research but identifies that while effectiveness has improved, efficiency (latency, token consumption, computational cost) has been overlooked; it proposes a comprehensive framework analyzing efficiency across memory, tool learning, and planning components.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the critical efficiency bottleneck in LLM-based agents, where recursive multi-step execution leads to exponentially growing resource consumption through token accumulation, context window saturation, and excessive computational costs.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors conduct a systematic literature review categorizing efficiency techniques into three core components: efficient memory (construction, management, access), efficient tool learning (selection, calling, reasoning), and efficient planning (single-agent and multi-agent strategies).</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The survey synthesizes efficiency metrics across benchmarks and methods, revealing common principles like context compression, reinforcement learning for minimizing tool invocation, and controlled search mechanisms, while identifying gaps in standardized efficiency evaluation frameworks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Toward Efficient Agents: Memory, Tool learning, and Planning</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background gradient -->
  <defs>
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f4ff;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e6f0ff;stop-opacity:1" />
    </linearGradient>
    
    <!-- Arrow markers -->
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#4a5568" />
    </marker>
  </defs>
  
  <rect width="1000" height="800" fill="url(#bgGradient)"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="28" font-weight="bold" fill="#2d3748">Efficient Agents: Memory, Tool Learning & Planning</text>
  
  <!-- Main components -->
  <!-- Memory Section -->
  <g transform="translate(100, 100)">
    <rect x="0" y="0" width="250" height="150" rx="15" fill="#4299e1" opacity="0.9"/>
    <text x="125" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="white">Memory</text>
    
    <!-- Memory subsections -->
    <rect x="10" y="50" width="230" height="30" rx="5" fill="#bee3f8"/>
    <text x="125" y="70" text-anchor="middle" font-size="14" fill="#2b6cb0">Construction</text>
    
    <rect x="10" y="85" width="230" height="30" rx="5" fill="#bee3f8"/>
    <text x="125" y="105" text-anchor="middle" font-size="14" fill="#2b6cb0">Management</text>
    
    <rect x="10" y="120" width="230" height="25" rx="5" fill="#bee3f8"/>
    <text x="125" y="137" text-anchor="middle" font-size="14" fill="#2b6cb0">Access</text>
  </g>
  
  <!-- Tool Learning Section -->
  <g transform="translate(375, 100)">
    <rect x="0" y="0" width="250" height="150" rx="15" fill="#48bb78" opacity="0.9"/>
    <text x="125" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="white">Tool Learning</text>
    
    <!-- Tool Learning subsections -->
    <rect x="10" y="50" width="230" height="30" rx="5" fill="#c6f6d5"/>
    <text x="125" y="70" text-anchor="middle" font-size="14" fill="#276749">Selection</text>
    
    <rect x="10" y="85" width="230" height="30" rx="5" fill="#c6f6d5"/>
    <text x="125" y="105" text-anchor="middle" font-size="14" fill="#276749">Calling</text>
    
    <rect x="10" y="120" width="230" height="25" rx="5" fill="#c6f6d5"/>
    <text x="125" y="137" text-anchor="middle" font-size="14" fill="#276749">Tool-Integrated Reasoning</text>
  </g>
  
  <!-- Planning Section -->
  <g transform="translate(650, 100)">
    <rect x="0" y="0" width="250" height="150" rx="15" fill="#ed8936" opacity="0.9"/>
    <text x="125" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="white">Planning</text>
    
    <!-- Planning subsections -->
    <rect x="10" y="50" width="230" height="30" rx="5" fill="#feebc8"/>
    <text x="125" y="70" text-anchor="middle" font-size="14" fill="#7b341e">Single-Agent Planning</text>
    
    <rect x="10" y="85" width="230" height="30" rx="5" fill="#feebc8"/>
    <text x="125" y="105" text-anchor="middle" font-size="14" fill="#7b341e">Multi-Agent Collaboration</text>
    
    <rect x="10" y="120" width="230" height="25" rx="5" fill="#feebc8"/>
    <text x="125" y="137" text-anchor="middle" font-size="14" fill="#7b341e">Efficiency Trade-offs</text>
  </g>
  
  <!-- Central Agent Node -->
  <g transform="translate(400, 350)">
    <circle cx="100" cy="50" r="60" fill="#805ad5" opacity="0.9"/>
    <text x="100" y="55" text-anchor="middle" font-size="18" font-weight="bold" fill="white">LLM Agent</text>
  </g>
  
  <!-- Efficiency Metrics -->
  <g transform="translate(150, 500)">
    <rect x="0" y="0" width="700" height="100" rx="10" fill="#f7fafc" stroke="#cbd5e0" stroke-width="2"/>
    <text x="350" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#2d3748">Efficiency Metrics</text>
    
    <!-- Metric boxes -->
    <rect x="20" y="45" width="100" height="40" rx="5" fill="#fbb6ce"/>
    <text x="70" y="70" text-anchor="middle" font-size="14" fill="#702459">Token Usage</text>
    
    <rect x="140" y="45" width="100" height="40" rx="5" fill="#fed7aa"/>
    <text x="190" y="70" text-anchor="middle" font-size="14" fill="#7c2d12">Latency</text>
    
    <rect x="260" y="45" width="100" height="40" rx="5" fill="#c6f6d5"/>
    <text x="310" y="70" text-anchor="middle" font-size="14" fill="#22543d">API Cost</text>
    
    <rect x="380" y="45" width="100" height="40" rx="5" fill="#bee3f8"/>
    <text x="430" y="70" text-anchor="middle" font-size="14" fill="#2a4e7c">Memory Usage</text>
    
    <rect x="500" y="45" width="180" height="40" rx="5" fill="#e9d8fd"/>
    <text x="590" y="70" text-anchor="middle" font-size="14" fill="#44337a">Interaction Steps</text>
  </g>
  
  <!-- Arrows connecting components -->
  <line x1="225" y1="250" x2="450" y2="360" stroke="#4a5568" stroke-width="3" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="250" x2="490" y2="360" stroke="#4a5568" stroke-width="3" marker-end="url(#arrowhead)"/>
  <line x1="775" y1="250" x2="550" y2="360" stroke="#4a5568" stroke-width="3" marker-end="url(#arrowhead)"/>
  
  <!-- Benchmarks section -->
  <g transform="translate(200, 650)">
    <rect x="0" y="0" width="600" height="100" rx="10" fill="#e6fffa" stroke="#38b2ac" stroke-width="2"/>
    <text x="300" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#234e52">Benchmarks</text>
    
    <text x="50" y="60" font-size="14" fill="#2c5282">‚Ä¢ MemBench, StoryBench (Memory)</text>
    <text x="50" y="80" font-size="14" fill="#2c5282">‚Ä¢ ToolBench, T-Eval (Tool Learning)</text>
    <text x="350" y="60" font-size="14" fill="#2c5282">‚Ä¢ TPS-Bench, CostBench (Planning)</text>
    <text x="350" y="80" font-size="14" fill="#2c5282">‚Ä¢ Cost-of-Pass Metrics</text>
  </g>
  
  <!-- Key Insights -->
  <g transform="translate(50, 300)">
    <rect x="0" y="0" width="200" height="120" rx="10" fill="#fef5e7" stroke="#f39c12" stroke-width="2"/>
    <text x="100" y="25" text-anchor="middle" font-size="16" font-weight="bold" fill="#7e5109">Key Insights</text>
    <text x="10" y="50" font-size="12" fill="#7e5109">‚Ä¢ Compression vs Performance</text>
    <text x="10" y="70" font-size="12" fill="#7e5109">‚Ä¢ Online vs Offline Processing</text>
    <text x="10" y="90" font-size="12" fill="#7e5109">‚Ä¢ Cost-aware Optimization</text>
    <text x="10" y="110" font-size="12" fill="#7e5109">‚Ä¢ Multi-agent Coordination</text>
  </g>
  
  <!-- Future Directions -->
  <g transform="translate(750, 300)">
    <rect x="0" y="0" width="200" height="120" rx="10" fill="#f0fff4" stroke="#48bb78" stroke-width="2"/>
    <text x="100" y="25" text-anchor="middle" font-size="16" font-weight="bold" fill="#22543d">Future Directions</text>
    <text x="10" y="50" font-size="12" fill="#22543d">‚Ä¢ Unified Evaluation</text>
    <text x="10" y="70" font-size="12" fill="#22543d">‚Ä¢ Latent Reasoning</text>
    <text x="10" y="90" font-size="12" fill="#22543d">‚Ä¢ MLLM Efficiency</text>
    <text x="10" y="110" font-size="12" fill="#22543d">‚Ä¢ Deployment-aware Design</text>
  </g>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Agents incur additional overhead from tools, memory access, and retries beyond just token generation">
                        <div class="quiz-question">1. According to the paper, what is the fundamental difference in cost structure between pure LLMs and LLM-based agents?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Agents only differ in having higher token generation costs due to longer contexts">Agents only differ in having higher token generation costs due to longer contexts</div><div class="quiz-choice" data-value="Agents incur additional overhead from tools, memory access, and retries beyond just token generation">Agents incur additional overhead from tools, memory access, and retries beyond just token generation</div><div class="quiz-choice" data-value="Agents are actually more cost-efficient because they can cache previous computations">Agents are actually more cost-efficient because they can cache previous computations</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Implementing structured topologies like chains or DAGs to achieve near-linear complexity">
                        <div class="quiz-question">2. What does the paper identify as a key efficiency strategy in multi-agent systems to avoid quadratic communication costs?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using larger language models that can process more information simultaneously">Using larger language models that can process more information simultaneously</div><div class="quiz-choice" data-value="Implementing structured topologies like chains or DAGs to achieve near-linear complexity">Implementing structured topologies like chains or DAGs to achieve near-linear complexity</div><div class="quiz-choice" data-value="Forcing all agents to communicate through a centralized database">Forcing all agents to communicate through a centralized database</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Continuous signals like KV caches or hidden states that influence computation without being represented as tokens">
                        <div class="quiz-question">3. How does the paper define 'latent memory' in the context of efficient agent memory systems?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Memory that is stored in external databases and retrieved on-demand">Memory that is stored in external databases and retrieved on-demand</div><div class="quiz-choice" data-value="Textual summaries that are hidden from the user but visible to the agent">Textual summaries that are hidden from the user but visible to the agent</div><div class="quiz-choice long-text" data-value="Continuous signals like KV caches or hidden states that influence computation without being represented as tokens">Continuous signals like KV caches or hidden states that influence computation without being represented as tokens</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/use-your-illusion.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>GutenOCR: A Grounded Vision-Language Front-End for Documents</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-20</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.14490" target="_blank">http://arxiv.org/pdf/2601.14490</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper presents GutenOCR, a grounded vision-language model for optical character recognition (OCR) in documents, focusing on unified text reading, detection, and localization through a single checkpoint.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on Qwen2.5-VL models and classical OCR pipelines, proposing a new approach that combines VLM flexibility with traditional OCR's explicit grounding capabilities through prompt-based interfaces for reading, detection, and conditional localization.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the lack of grounded OCR front-ends that provide both high-quality text extraction and fine-grained control over how documents are read, including explicit links between tokens and pixels for production systems.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors fine-tune Qwen2.5-VL-3B/7B models using a curriculum-based training approach on business documents, scientific articles, and synthetic data, exposing multiple OCR tasks through unified prompt-based schemas without modifying the architecture.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> GutenOCR-7B more than doubles the composite grounded OCR score of its backbone (0.40‚Üí0.82) on held-out pages, substantially improves region and line-level OCR on Fox benchmark, but shows trade-offs in formula recognition and color-guided tasks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>GutenOCR: A Grounded Vision-Language Front-End for Documents</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Title -->
  <text x="500" y="30" font-size="24" font-weight="bold" text-anchor="middle" fill="#2C3E50">GutenOCR: Grounded Vision-Language OCR Pipeline</text>
  
  <!-- Data Sources Section -->
  <rect x="50" y="70" width="200" height="120" rx="10" fill="#3498DB" stroke="#2980B9" stroke-width="2"/>
  <text x="150" y="100" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Data Sources</text>
  <text x="150" y="125" font-size="12" text-anchor="middle" fill="white">‚Ä¢ OCR-IDL (26M pages)</text>
  <text x="150" y="145" font-size="12" text-anchor="middle" fill="white">‚Ä¢ TabMe++ (122K pages)</text>
  <text x="150" y="165" font-size="12" text-anchor="middle" fill="white">‚Ä¢ PubMed-OCR (1.5M pages)</text>
  
  <!-- Synthetic Data Section -->
  <rect x="50" y="210" width="200" height="100" rx="10" fill="#9B59B6" stroke="#8E44AD" stroke-width="2"/>
  <text x="150" y="240" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Synthetic Data</text>
  <text x="150" y="265" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Grounded LaTeX (3M)</text>
  <text x="150" y="285" font-size="12" text-anchor="middle" fill="white">‚Ä¢ SynthDoG (1.2M)</text>
  
  <!-- Base Model -->
  <rect x="350" y="120" width="180" height="80" rx="10" fill="#E74C3C" stroke="#C0392B" stroke-width="2"/>
  <text x="440" y="150" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Base Models</text>
  <text x="440" y="175" font-size="12" text-anchor="middle" fill="white">Qwen2.5-VL-3B/7B</text>
  
  <!-- Training Stages -->
  <rect x="300" y="250" width="280" height="200" rx="10" fill="#16A085" stroke="#138D75" stroke-width="2"/>
  <text x="440" y="280" font-size="16" font-weight="bold" text-anchor="middle" fill="white">4-Stage Training Curriculum</text>
  
  <rect x="320" y="300" width="240" height="35" rx="5" fill="#1ABC9C" stroke="#16A085" stroke-width="1"/>
  <text x="440" y="325" font-size="12" text-anchor="middle" fill="white">Stage 1: Core (&lt;2k tokens)</text>
  
  <rect x="320" y="345" width="240" height="35" rx="5" fill="#1ABC9C" stroke="#16A085" stroke-width="1"/>
  <text x="440" y="370" font-size="12" text-anchor="middle" fill="white">Stage 2: Real spec. (2k-8k)</text>
  
  <rect x="320" y="390" width="240" height="35" rx="5" fill="#1ABC9C" stroke="#16A085" stroke-width="1"/>
  <text x="440" y="415" font-size="12" text-anchor="middle" fill="white">Stage 3a/3b: PMD (8k-16k)</text>
  
  <!-- Task Families -->
  <rect x="650" y="80" width="300" height="320" rx="10" fill="#F39C12" stroke="#E67E22" stroke-width="2"/>
  <text x="800" y="110" font-size="18" font-weight="bold" text-anchor="middle" fill="white">Task Families</text>
  
  <rect x="670" y="130" width="260" height="60" rx="5" fill="#F1C40F" stroke="#F39C12" stroke-width="1"/>
  <text x="800" y="155" font-size="14" font-weight="bold" text-anchor="middle" fill="#2C3E50">Full-page Reading</text>
  <text x="800" y="175" font-size="11" text-anchor="middle" fill="#2C3E50">text, text2d, lines, paragraphs</text>
  
  <rect x="670" y="200" width="260" height="60" rx="5" fill="#F1C40F" stroke="#F39C12" stroke-width="1"/>
  <text x="800" y="225" font-size="14" font-weight="bold" text-anchor="middle" fill="#2C3E50">Detection</text>
  <text x="800" y="245" font-size="11" text-anchor="middle" fill="#2C3E50">lines, paragraphs, math regions</text>
  
  <rect x="670" y="270" width="260" height="60" rx="5" fill="#F1C40F" stroke="#F39C12" stroke-width="1"/>
  <text x="800" y="295" font-size="14" font-weight="bold" text-anchor="middle" fill="#2C3E50">Conditional Detection</text>
  <text x="800" y="315" font-size="11" text-anchor="middle" fill="#2C3E50">Image + query ‚Üí BOX(q)</text>
  
  <rect x="670" y="340" width="260" height="60" rx="5" fill="#F1C40F" stroke="#F39C12" stroke-width="1"/>
  <text x="800" y="365" font-size="14" font-weight="bold" text-anchor="middle" fill="#2C3E50">Localized Reading</text>
  <text x="800" y="385" font-size="11" text-anchor="middle" fill="#2C3E50">Image + box ‚Üí text</text>
  
  <!-- Output -->
  <rect x="350" y="500" width="300" height="100" rx="10" fill="#27AE60" stroke="#229954" stroke-width="2"/>
  <text x="500" y="530" font-size="18" font-weight="bold" text-anchor="middle" fill="white">GutenOCR Models</text>
  <text x="500" y="555" font-size="14" text-anchor="middle" fill="white">Unified grounded OCR front-end</text>
  <text x="500" y="575" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Prompt-based interface</text>
  <text x="500" y="590" font-size="12" text-anchor="middle" fill="white">‚Ä¢ Text + bounding boxes</text>
  
  <!-- Evaluation -->
  <rect x="200" y="650" width="600" height="100" rx="10" fill="#34495E" stroke="#2C3E50" stroke-width="2"/>
  <text x="500" y="680" font-size="18" font-weight="bold" text-anchor="middle" fill="white">Evaluation Protocol</text>
  <text x="300" y="710" font-size="12" text-anchor="middle" fill="white">Text Metrics: CER, WER</text>
  <text x="500" y="710" font-size="12" text-anchor="middle" fill="white">Detection: F1@0.5, Recall</text>
  <text x="700" y="710" font-size="12" text-anchor="middle" fill="white">End-to-end: CERe2e, mCER</text>
  <text x="500" y="730" font-size="12" text-anchor="middle" fill="white">Benchmarks: In-domain, Fox, OmniDocBench v1.5</text>
  
  <!-- Arrows -->
  <path d="M 250 130 L 350 160" stroke="#2C3E50" stroke-width="3" fill="none"/>
  <path d="M 250 260 L 350 160" stroke="#2C3E50" stroke-width="3" fill="none"/>
  <path d="M 530 160 L 650 240" stroke="#2C3E50" stroke-width="3" fill="none"/>
  <path d="M 440 200 L 440 250" stroke="#2C3E50" stroke-width="3" fill="none"/>
  <path d="M 440 450 L 440 500" stroke="#2C3E50" stroke-width="3" fill="none"/>
  <path d="M 500 600 L 500 650" stroke="#2C3E50" stroke-width="3" fill="none"/>
  <path d="M 650 350 L 580 350" stroke="#2C3E50" stroke-width="3" fill="none"/>
  
  <!-- Arrow heads -->
  <polygon points="350,160 345,155 345,165" fill="#2C3E50"/>
  <polygon points="350,160 345,155 345,165" fill="#2C3E50"/>
  <polygon points="650,240 645,235 645,245" fill="#2C3E50"/>
  <polygon points="440,250 435,245 445,245" fill="#2C3E50"/>
  <polygon points="440,500 435,495 445,495" fill="#2C3E50"/>
  <polygon points="500,650 495,645 505,645" fill="#2C3E50"/>
  <polygon points="580,350 585,345 585,355" fill="#2C3E50"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It provides a unified checkpoint that supports reading, detection, and grounding through prompt-based interfaces">
                        <div class="quiz-question">1. What is the primary innovation of GutenOCR compared to existing OCR approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It achieves 100% accuracy on all document types by using a larger model size">It achieves 100% accuracy on all document types by using a larger model size</div><div class="quiz-choice long-text" data-value="It provides a unified checkpoint that supports reading, detection, and grounding through prompt-based interfaces">It provides a unified checkpoint that supports reading, detection, and grounding through prompt-based interfaces</div><div class="quiz-choice" data-value="It completely replaces traditional OCR with pure vision transformers without any text output">It completely replaces traditional OCR with pure vision transformers without any text output</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="It performs poorly on color-guided OCR tasks due to catastrophic forgetting">
                        <div class="quiz-question">2. What critical limitation does GutenOCR exhibit according to the evaluation results?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It cannot process documents longer than one page">It cannot process documents longer than one page</div><div class="quiz-choice" data-value="It performs poorly on color-guided OCR tasks due to catastrophic forgetting">It performs poorly on color-guided OCR tasks due to catastrophic forgetting</div><div class="quiz-choice" data-value="It only works with English text and fails on all other languages">It only works with English text and fails on all other languages</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It reads the correct content but follows a layout-driven order that differs from Fox's canonical linearization">
                        <div class="quiz-question">3. Why does GutenOCR achieve high Page F1 but poor Page CER on the Fox benchmark?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="The model hallucinates extra text that doesn't exist in the original document">The model hallucinates extra text that doesn't exist in the original document</div><div class="quiz-choice long-text" data-value="It reads the correct content but follows a layout-driven order that differs from Fox's canonical linearization">It reads the correct content but follows a layout-driven order that differs from Fox's canonical linearization</div><div class="quiz-choice" data-value="The evaluation metrics are broken and produce inconsistent results">The evaluation metrics are broken and produce inconsistent results</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-linen-2.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-20</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.14251" target="_blank">http://arxiv.org/pdf/2601.14251</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper presents LightOnOCR-2-1B, a compact end-to-end multilingual vision-language model for state-of-the-art optical character recognition (OCR) in document understanding.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on traditional OCR pipelines and recent vision-language models like Nougat, olmOCR, and Qwen-VL, proposing a unified 1B-parameter model that eliminates brittle multi-stage pipelines and adds image bounding box localization capabilities.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the complexity and brittleness of traditional multi-stage OCR pipelines that require coordinated changes across components when adapting to new document distributions.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use supervised pretraining on 43M document pages with a stronger teacher model (Qwen3-VL-235B), higher resolution training (1540px), reinforcement learning with verifiable rewards (RLVR), and weight-space techniques like checkpoint averaging and task-arithmetic merging.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> LightOnOCR-2-1B achieves state-of-the-art performance on OlmOCR-Bench (83.2% overall score) while being 9√ó smaller than prior best models, with 5.7√ó higher inference throughput and successful image localization (F1@0.5: 0.78-0.83) on their new LightOnOCR-bbox-bench.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Title -->
  <text x="500" y="30" font-size="24" font-weight="bold" text-anchor="middle" fill="#1a237e">LightOnOCR-2-1B Training Workflow</text>
  
  <!-- Data Collection & Preprocessing -->
  <rect x="50" y="60" width="200" height="80" rx="10" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="150" y="85" font-size="14" font-weight="bold" text-anchor="middle" fill="#1976d2">Data Collection</text>
  <text x="150" y="105" font-size="11" text-anchor="middle" fill="#424242">43M pages (2.5x scale)</text>
  <text x="150" y="120" font-size="11" text-anchor="middle" fill="#424242">PDFA, scans, arXiv</text>
  
  <!-- Teacher Distillation -->
  <rect x="300" y="60" width="200" height="80" rx="10" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="400" y="85" font-size="14" font-weight="bold" text-anchor="middle" fill="#7b1fa2">Teacher Distillation</text>
  <text x="400" y="105" font-size="11" text-anchor="middle" fill="#424242">Qwen3-VL-235B</text>
  <text x="400" y="120" font-size="11" text-anchor="middle" fill="#424242">Markdown + LaTeX</text>
  
  <!-- nvpdftex Pipeline -->
  <rect x="550" y="60" width="200" height="80" rx="10" fill="#e8f5e9" stroke="#388e3c" stroke-width="2"/>
  <text x="650" y="85" font-size="14" font-weight="bold" text-anchor="middle" fill="#388e3c">nvpdftex Pipeline</text>
  <text x="650" y="105" font-size="11" text-anchor="middle" fill="#424242">arXiv TEX sources</text>
  <text x="650" y="120" font-size="11" text-anchor="middle" fill="#424242">Pixel-aligned annotations</text>
  
  <!-- Normalization -->
  <rect x="300" y="180" width="200" height="80" rx="10" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="400" y="205" font-size="14" font-weight="bold" text-anchor="middle" fill="#f57c00">Normalization</text>
  <text x="400" y="225" font-size="11" text-anchor="middle" fill="#424242">Clean LaTeX, remove artifacts</text>
  <text x="400" y="240" font-size="11" text-anchor="middle" fill="#424242">Deduplication, filtering</text>
  
  <!-- Architecture -->
  <rect x="50" y="300" width="900" height="60" rx="10" fill="#fce4ec" stroke="#c2185b" stroke-width="2"/>
  <text x="500" y="325" font-size="14" font-weight="bold" text-anchor="middle" fill="#c2185b">1B Architecture: Vision Encoder (Mistral) + MLP Projector + LM Decoder (Qwen3)</text>
  <text x="500" y="345" font-size="11" text-anchor="middle" fill="#424242">Native resolution, spatial merging 2x2, max 1540px longest edge</text>
  
  <!-- Pretraining -->
  <rect x="250" y="400" width="500" height="80" rx="10" fill="#e1f5fe" stroke="#0277bd" stroke-width="2"/>
  <text x="500" y="425" font-size="16" font-weight="bold" text-anchor="middle" fill="#0277bd">Supervised Pretraining</text>
  <text x="500" y="445" font-size="12" text-anchor="middle" fill="#424242">Next-token prediction, AdamW lr=1e-4, batch=384</text>
  <text x="500" y="460" font-size="12" text-anchor="middle" fill="#424242">Data augmentations: erosion, rotation, distortion</text>
  
  <!-- Checkpoint Averaging -->
  <rect x="350" y="510" width="300" height="50" rx="10" fill="#f1f8e9" stroke="#689f38" stroke-width="2"/>
  <text x="500" y="535" font-size="13" font-weight="bold" text-anchor="middle" fill="#689f38">Checkpoint Averaging (last 5)</text>
  <text x="500" y="550" font-size="11" text-anchor="middle" fill="#424242">‚Üí LightOnOCR-2-1B-base</text>
  
  <!-- RLVR branches -->
  <rect x="100" y="600" width="350" height="80" rx="10" fill="#ede7f6" stroke="#512da8" stroke-width="2"/>
  <text x="275" y="625" font-size="14" font-weight="bold" text-anchor="middle" fill="#512da8">OCR RLVR</text>
  <text x="275" y="645" font-size="11" text-anchor="middle" fill="#424242">Unit tests, repetition penalty, KaTeX validation</text>
  <text x="275" y="660" font-size="11" text-anchor="middle" fill="#424242">GRPO, lr=4e-5, Œ≤=0.01</text>
  
  <rect x="550" y="600" width="350" height="80" rx="10" fill="#fff9c4" stroke="#f9a825" stroke-width="2"/>
  <text x="725" y="625" font-size="14" font-weight="bold" text-anchor="middle" fill="#f9a825">Bbox RLVR</text>
  <text x="725" y="645" font-size="11" text-anchor="middle" fill="#424242">Resume with coord supervision</text>
  <text x="725" y="660" font-size="11" text-anchor="middle" fill="#424242">IoU-based rewards</text>
  
  <!-- Final models -->
  <rect x="50" y="720" width="180" height="50" rx="10" fill="#c8e6c9" stroke="#2e7d32" stroke-width="2"/>
  <text x="140" y="745" font-size="12" font-weight="bold" text-anchor="middle" fill="#2e7d32">LightOnOCR-2-1B</text>
  <text x="140" y="760" font-size="10" text-anchor="middle" fill="#424242">(Best OCR)</text>
  
  <rect x="280" y="720" width="180" height="50" rx="10" fill="#ffccbc" stroke="#d84315" stroke-width="2"/>
  <text x="370" y="745" font-size="12" font-weight="bold" text-anchor="middle" fill="#d84315">LightOnOCR-2-1B-bbox</text>
  <text x="370" y="760" font-size="10" text-anchor="middle" fill="#424242">(With localization)</text>
  
  <rect x="510" y="720" width="220" height="50" rx="10" fill="#d1c4e9" stroke="#5e35b1" stroke-width="2"/>
  <text x="620" y="745" font-size="12" font-weight="bold" text-anchor="middle" fill="#5e35b1">Task Arithmetic Merging</text>
  <text x="620" y="760" font-size="10" text-anchor="middle" fill="#424242">(OCR-bbox trade-off)</text>
  
  <rect x="770" y="720" width="180" height="50" rx="10" fill="#b2dfdb" stroke="#00695c" stroke-width="2"/>
  <text x="860" y="745" font-size="12" font-weight="bold" text-anchor="middle" fill="#00695c">LightOnOCR-2-1B-soup</text>
  <text x="860" y="760" font-size="10" text-anchor="middle" fill="#424242">(Merged variants)</text>
  
  <!-- Flow lines -->
  <path d="M 150 140 L 150 170 L 300 170 L 300 180" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 400 140 L 400 180" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 650 140 L 650 170 L 500 170 L 500 180" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 400 260 L 400 300" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 500 360 L 500 400" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 500 480 L 500 510" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 500 560 L 275 560 L 275 600" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 500 560 L 725 560 L 725 600" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 275 680 L 140 680 L 140 720" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 725 680 L 370 680 L 370 720" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 140 720 L 620 720" stroke="#666" stroke-width="2" fill="none" stroke-dasharray="5,5"/>
  <path d="M 370 720 L 620 720" stroke="#666" stroke-width="2" fill="none" stroke-dasharray="5,5"/>
  <path d="M 620 720 L 860 720" stroke="#666" stroke-width="2" fill="none"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Introducing coordinate supervision during pretraining via a resume strategy, then refining with RLVR using IoU-based rewards">
                        <div class="quiz-question">1. What unique training strategy does LightOnOCR-2 employ to add image localization capabilities without degrading OCR quality?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Training separate models for OCR and localization, then ensemble them at inference">Training separate models for OCR and localization, then ensemble them at inference</div><div class="quiz-choice long-text" data-value="Introducing coordinate supervision during pretraining via a resume strategy, then refining with RLVR using IoU-based rewards">Introducing coordinate supervision during pretraining via a resume strategy, then refining with RLVR using IoU-based rewards</div><div class="quiz-choice" data-value="Fine-tuning on synthetic data with artificially generated bounding boxes">Fine-tuning on synthetic data with artificially generated bounding boxes</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="It achieves 83.2% overall score while being 9√ó smaller than prior best-performing models">
                        <div class="quiz-question">2. How does LightOnOCR-2's performance compare to larger models on OlmOCR-Bench?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It achieves 83.2% overall score while being 9√ó smaller than prior best-performing models">It achieves 83.2% overall score while being 9√ó smaller than prior best-performing models</div><div class="quiz-choice" data-value="It performs 20% worse but compensates with 50√ó faster inference speed">It performs 20% worse but compensates with 50√ó faster inference speed</div><div class="quiz-choice" data-value="It matches performance only on English documents but fails on multilingual content">It matches performance only on English documents but fails on multilingual content</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Implementing an nvpdftex-based pipeline that hooks into the pdfLaTeX engine to produce pixel-aligned annotations">
                        <div class="quiz-question">3. What innovative data curation technique does the paper introduce for obtaining high-quality supervision from scientific documents?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using GPT-4 to manually annotate each arXiv paper with ground truth labels">Using GPT-4 to manually annotate each arXiv paper with ground truth labels</div><div class="quiz-choice long-text" data-value="Implementing an nvpdftex-based pipeline that hooks into the pdfLaTeX engine to produce pixel-aligned annotations">Implementing an nvpdftex-based pipeline that hooks into the pdfLaTeX engine to produce pixel-aligned annotations</div><div class="quiz-choice" data-value="Converting all scientific PDFs to HTML first, then extracting text using web scraping tools">Converting all scientific PDFs to HTML first, then extracting text using web scraping tools</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');

                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫ÊØè‰∏™Âç°ÁâáÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂ÔºàËÄå‰∏çÊòØÊï¥‰∏™ÂÆπÂô®Ôºâ
                cards.forEach(card => {
                    card.addEventListener('click', function(e) {
                        // Âè™ÊúâÁÇπÂáªÂú®Âç°ÁâáÂÜÖÈÉ®Êó∂ÊâçÂàáÊç¢
                        // Ê£ÄÊü•ÊòØÂê¶ÊòØÊµÅÁ®ãÂõæÂç°ÁâáÁöÑÊªöÂä®Êù°Âå∫Âüü
                        if (this.classList.contains('flowchart-card')) {
                            const rect = this.getBoundingClientRect();
                            const isScrollbarClick =
                                (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                                (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);

                            if (!isScrollbarClick) {
                                nextCard(e);
                            }
                        } else {
                            nextCard(e);
                        }
                    });
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>

    <!-- AI Assistant Scripts - Load in correct order (relative paths for subpages) -->
    <script src="../../js/ai-assistant-constants.js"></script>
    <script src="../../js/ai-assistant-storage.js"></script>
    <script src="../../js/ai-assistant-positioning.js"></script>
    <script src="../../js/ai-assistant-templates.js"></script>
    <script src="../../js/ai-assistant-dom-utils.js"></script>
    <script src="../../js/ai-assistant-config.js"></script>
    <script src="../../js/ai-assistant.js"></script>
</body>
</html>
