
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- AI Assistant Styles -->
    <link rel="stylesheet" href="../../css/ai-assistant.css">
    <title>2026-01-13 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */
            /* cursor removed - only cards should show pointer */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
            cursor: pointer; /* Show pointer on cards to indicate they're clickable */
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }

        .paper-card p {
            margin: 5px 0;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
            word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        /* ÁßªÂä®ËÆæÂ§áÂíåÂ∞èÂ±èÂπï */
        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                min-height: 400px; /* ÁßªÂä®ËÆæÂ§á‰∏ä‰ΩøÁî®Êõ¥Â∞èÁöÑÊúÄÂ∞èÈ´òÂ∫¶ */
                height: auto; /* Ëá™ÈÄÇÂ∫îÈ´òÂ∫¶ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }

            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
                width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-01-13 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/dark-geometric.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-11</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.06943" target="_blank">http://arxiv.org/pdf/2601.06943</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> A benchmark for video-based deep research that evaluates AI models' ability to answer questions by combining video understanding with web searching and reasoning.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on existing deep research benchmarks that focus on text-only queries and closed-video understanding tasks, this paper introduces a novel paradigm requiring models to connect video cues with open web search.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Existing benchmarks don't evaluate how AI models can use video content as clues to search and verify information across the open web, which is important for real-world video question answering.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Created VideoDR benchmark through rigorous human annotation process with strict quality control, testing models under two paradigms (Workflow and Agentic) across difficulty levels, video durations, and semantic domains.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Leading models like Gemini-3-pro-preview achieved 76% accuracy under Agentic setting, while results showed that Agentic is not consistently superior to Workflow - success depends on models' ability to maintain initial video anchors during long search chains.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <defs>
    <linearGradient id="blueGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4A90E2;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#2E5C8A;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="greenGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#7ED321;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#5A9A16;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="orangeGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#F5A623;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#D1871B;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="purpleGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#BD10E0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#8B0AA3;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-family="Arial" font-size="20" font-weight="bold" fill="#2C3E50">VideoDR: Video Deep Research Benchmark Workflow</text>
  
  <!-- Data Construction Pipeline -->
  <rect x="50" y="60" width="900" height="140" fill="url(#blueGrad)" rx="10" opacity="0.2"/>
  <text x="70" y="85" font-family="Arial" font-size="16" font-weight="bold" fill="#2C3E50">Data Construction Pipeline</text>
  
  <!-- Step 1: Video Pool -->
  <rect x="80" y="100" width="160" height="80" fill="url(#blueGrad)" rx="8"/>
  <text x="160" y="125" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Candidate Video Pool</text>
  <text x="160" y="140" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Stratified Sampling:</text>
  <text x="160" y="155" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Source, Domain, Duration</text>
  <text x="160" y="170" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Negative Filtering</text>
  
  <!-- Step 2: Initial Filtering -->
  <rect x="270" y="100" width="160" height="80" fill="url(#greenGrad)" rx="8"/>
  <text x="350" y="125" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Initial Filtering</text>
  <text x="350" y="140" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Remove clips lacking</text>
  <text x="350" y="155" text-anchor="middle" font-family="Arial" font-size="10" fill="white">prominent visual anchors</text>
  <text x="350" y="170" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Multi-frame coherence</text>
  
  <!-- Step 3: Question Design -->
  <rect x="460" y="100" width="160" height="80" fill="url(#orangeGrad)" rx="8"/>
  <text x="540" y="125" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Question Design</text>
  <text x="540" y="140" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Multi-frame reasoning</text>
  <text x="540" y="155" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Multi-hop reasoning</text>
  <text x="540" y="170" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Verifiable answers</text>
  
  <!-- Quality Control -->
  <rect x="680" y="100" width="240" height="80" fill="url(#purpleGrad)" rx="8"/>
  <text x="800" y="115" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Quality Control</text>
  <text x="720" y="135" font-family="Arial" font-size="10" fill="white">Web-only Test</text>
  <text x="720" y="150" font-family="Arial" font-size="10" fill="white">Video-only Test</text>
  <text x="720" y="165" font-family="Arial" font-size="10" fill="white">Human Testing (5 subjects)</text>
  
  <!-- Task Definition -->
  <rect x="50" y="220" width="900" height="100" fill="#E8F4F8" rx="10"/>
  <text x="70" y="245" font-family="Arial" font-size="16" font-weight="bold" fill="#2C3E50">Task Definition: f(V, Q; S) ‚Üí A</text>
  <text x="70" y="265" font-family="Arial" font-size="12" fill="#34495E">Given Video V and Question Q, use Search tool S to produce Answer A</text>
  <text x="70" y="280" font-family="Arial" font-size="12" fill="#34495E">‚Ä¢ Multi-frame visual anchor extraction</text>
  <text x="70" y="295" font-family="Arial" font-size="12" fill="#34495E">‚Ä¢ Interactive web retrieval</text>
  <text x="70" y="310" font-family="Arial" font-size="12" fill="#34495E">‚Ä¢ Multi-hop reasoning over joint video-web evidence</text>
  
  <!-- Evaluation Paradigms -->
  <rect x="50" y="340" width="900" height="160" fill="#FFF8E1" rx="10"/>
  <text x="70" y="365" font-family="Arial" font-size="16" font-weight="bold" fill="#2C3E50">Evaluation Paradigms</text>
  
  <!-- Workflow Paradigm -->
  <rect x="80" y="380" width="400" height="100" fill="url(#greenGrad)" rx="8" opacity="0.8"/>
  <text x="280" y="400" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Workflow Paradigm</text>
  <text x="100" y="420" font-family="Arial" font-size="11" fill="white">1. Extract visual cues ‚Üí structured text</text>
  <text x="100" y="435" font-family="Arial" font-size="11" fill="white">2. Use text + question for search</text>
  <text x="100" y="450" font-family="Arial" font-size="11" fill="white">3. Multi-round retrieval & reasoning</text>
  <text x="100" y="465" font-family="Arial" font-size="11" fill="white">‚úì Stable anchors, controllable</text>
  
  <!-- Agentic Paradigm -->
  <rect x="520" y="380" width="400" height="100" fill="url(#orangeGrad)" rx="8" opacity="0.8"/>
  <text x="720" y="400" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Agentic Paradigm</text>
  <text x="540" y="420" font-family="Arial" font-size="11" fill="white">1. End-to-end single agent</text>
  <text x="540" y="435" font-family="Arial" font-size="11" fill="white">2. Direct video + question input</text>
  <text x="540" y="450" font-family="Arial" font-size="11" fill="white">3. Autonomous search & reasoning</text>
  <text x="540" y="465" font-family="Arial" font-size="11" fill="white">‚úì Preserves details, requires consistency</text>
  
  <!-- Models Evaluated -->
  <rect x="50" y="520" width="900" height="80" fill="#F0F8FF" rx="10"/>
  <text x="70" y="545" font-family="Arial" font-size="16" font-weight="bold" fill="#2C3E50">Models Evaluated</text>
  <text x="70" y="565" font-family="Arial" font-size="12" fill="#34495E">Closed-source: GPT-4o, GPT-5.2, Gemini-3-pro-preview</text>
  <text x="70" y="580" font-family="Arial" font-size="12" fill="#34495E">Open-source: MiniCPM-V 4.5, InternVL3.5-14B, Qwen3-Omni-30B-A3B</text>
  
  <!-- Key Findings -->
  <rect x="50" y="620" width="900" height="140" fill="#FFF0F5" rx="10"/>
  <text x="70" y="645" font-family="Arial" font-size="16" font-weight="bold" fill="#2C3E50">Key Findings</text>
  
  <!-- Finding boxes -->
  <rect x="80" y="660" width="260" height="80" fill="#FF6B6B" rx="6" opacity="0.7"/>
  <text x="210" y="680" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Agentic ‚â† Always Better</text>
  <text x="90" y="695" font-family="Arial" font-size="10" fill="white">Depends on model's ability to</text>
  <text x="90" y="710" font-family="Arial" font-size="10" fill="white">maintain initial video anchors</text>
  <text x="90" y="725" font-family="Arial" font-size="10" fill="white">over long retrieval chains</text>
  
  <rect x="360" y="660" width="260" height="80" fill="#4ECDC4" rx="6" opacity="0.7"/>
  <text x="490" y="680" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Core Bottlenecks</text>
  <text x="370" y="700" font-family="Arial" font-size="11" fill="white">‚Ä¢ Goal Drift</text>
  <text x="370" y="715" font-family="Arial" font-size="11" fill="white">‚Ä¢ Long-horizon Consistency</text>
  <text x="370" y="730" font-family="Arial" font-size="11" fill="white">‚Ä¢ Numerical Error Persistence</text>
  
  <rect x="640" y="660" width="260" height="80" fill="#45B7D1" rx="6" opacity="0.7"/>
  <text x="770" y="680" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Performance Leaders</text>
  <text x="650" y="695" font-family="Arial" font-size="10" fill="white">Gemini-3-pro: 69% ‚Üí 76%</text>
  <text x="650" y="710" font-family="Arial" font-size="10" fill="white">GPT-5.2: 69% ‚Üí 69%</text>
  <text x="650" y="725" font-family="Arial" font-size="10" fill="white">Human baseline: 50.4%</text>
  
  <!-- Data Statistics -->
  <circle cx="100" cy="770" r="15" fill="#9B59B6"/>
  <text x="100" y="775" text-anchor="middle" font-family="Arial" font-size="10" fill="white">100</text>
  <text x="125" y="775" font-family="Arial" font-size="12" fill="#2C3E50">samples across 6 domains</text>
  
  <circle cx="350" cy="770" r="15" fill="#E67E22"/>
  <text x="350" y="775" text-anchor="middle" font-family="Arial" font-size="10" fill="white">25.5</text>
  <text x="375" y="775" font-family="Arial" font-size="12" fill="#2C3E50">avg question tokens</text>
  
  <circle cx="600" cy="770" r="15" fill="#27AE60"/>
  <text x="600" y="775" text-anchor="middle" font-family="Arial" font-size="10" fill="white">3</text>
  <text x="625" y="775" font-family="Arial" font-size="12" fill="#2C3E50">difficulty levels</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It combines video understanding with open web search and reasoning">
                        <div class="quiz-question">1. What is the main innovation of VideoDR compared to existing benchmarks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It only focuses on video understanding without web search">It only focuses on video understanding without web search</div><div class="quiz-choice" data-value="It combines video understanding with open web search and reasoning">It combines video understanding with open web search and reasoning</div><div class="quiz-choice" data-value="It evaluates text-only queries on web search">It evaluates text-only queries on web search</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Agentic's success depends on the model's ability to maintain initial video anchors during search">
                        <div class="quiz-question">2. Which of the following best describes the relationship between Workflow and Agentic paradigms based on the paper's findings?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Agentic is consistently superior to Workflow in all scenarios">Agentic is consistently superior to Workflow in all scenarios</div><div class="quiz-choice" data-value="Workflow always performs better than Agentic">Workflow always performs better than Agentic</div><div class="quiz-choice" data-value="Agentic's success depends on the model's ability to maintain initial video anchors during search">Agentic's success depends on the model's ability to maintain initial video anchors during search</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It converted additional retrieval and reflection into more reliable evidence integration">
                        <div class="quiz-question">3. What was Gemini-3-pro-preview's key strength in tool usage according to the paper?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It used the most number of tool calls among all models">It used the most number of tool calls among all models</div><div class="quiz-choice" data-value="It converted additional retrieval and reflection into more reliable evidence integration">It converted additional retrieval and reflection into more reliable evidence integration</div><div class="quiz-choice" data-value="It had the fastest runtime among all models">It had the fastest runtime among all models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/broken-noise.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>BabyVision: Visual Reasoning Beyond Language</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-10</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.06521" target="_blank">http://arxiv.org/pdf/2601.06521</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces BabyVision, a benchmark for evaluating fundamental visual reasoning abilities in multimodal large language models (MLLMs), focusing on basic visual skills that humans develop before language acquisition.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on developmental psychology research showing humans acquire core visual skills before language, the paper proposes a new evaluation approach focused on pre-linguistic visual abilities, rather than existing benchmarks that test high-level semantic reasoning.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the gap between MLLMs' strong performance on knowledge-intensive tasks versus their weakness in basic visual tasks that even young children can solve effortlessly.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors created a benchmark with 388 questions across 22 subtypes in 4 categories (fine-grained discrimination, visual tracking, spatial perception, pattern recognition), evaluated leading MLLMs against human performance, and introduced BABYVISION-GEN for testing visual generation capabilities.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The best model (Gemini3-Pro-Preview) achieved only 49.7% accuracy compared to human performance of 94.1%, with consistent deficits across all categories, revealing significant gaps in MLLMs' fundamental visual understanding abilities.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>BabyVision: Visual Reasoning Beyond Language</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#ff6b6b;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ffd93d;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4ecdc4;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#44a08d;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#667eea;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#764ba2;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f093fb;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#f5576c;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" style="font-size:24px;font-weight:bold;fill:#2c3e50">BabyVision Research Methodology Flow</text>
  
  <!-- Data Curation Pipeline -->
  <rect x="50" y="60" width="900" height="120" fill="url(#grad1)" rx="10" opacity="0.8"/>
  <text x="500" y="85" text-anchor="middle" style="font-size:16px;font-weight:bold;fill:white">Data Curation Pipeline</text>
  
  <rect x="80" y="100" width="250" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="205" y="120" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">1. Taxonomy & Seed Collection</text>
  <text x="205" y="135" text-anchor="middle" style="font-size:10px;fill:#2c3e50">Define 4 categories, 22 subtypes</text>
  <text x="205" y="148" text-anchor="middle" style="font-size:10px;fill:#2c3e50">~50 seed images</text>
  
  <rect x="375" y="100" width="250" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="500" y="120" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">2. Data Collection & Filtering</text>
  <text x="500" y="135" text-anchor="middle" style="font-size:10px;fill:#2c3e50">Reverse image search</text>
  <text x="500" y="148" text-anchor="middle" style="font-size:10px;fill:#2c3e50">~4000 candidates</text>
  
  <rect x="670" y="100" width="250" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="795" y="120" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">3. Annotation & QA</text>
  <text x="795" y="135" text-anchor="middle" style="font-size:10px;fill:#2c3e50">Double blind expert review</text>
  <text x="795" y="148" text-anchor="middle" style="font-size:10px;fill:#2c3e50">388 questions final</text>
  
  <!-- Four Core Categories -->
  <text x="500" y="220" text-anchor="middle" style="font-size:18px;font-weight:bold;fill:#2c3e50">Four Core Visual Categories</text>
  
  <rect x="50" y="240" width="200" height="120" fill="url(#grad2)" rx="10" opacity="0.8"/>
  <text x="150" y="265" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Fine-grained</text>
  <text x="150" y="280" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Discrimination</text>
  <text x="150" y="300" text-anchor="middle" style="font-size:11px;fill:white">163 questions, 8 subtypes</text>
  <text x="150" y="315" text-anchor="middle" style="font-size:10px;fill:white">Find different, shadows,</text>
  <text x="150" y="330" text-anchor="middle" style="font-size:10px;fill:white">pattern completion</text>
  <text x="150" y="345" text-anchor="middle" style="font-size:10px;fill:white">reconstruction</text>
  
  <rect x="270" y="240" width="200" height="120" fill="url(#grad3)" rx="10" opacity="0.8"/>
  <text x="370" y="265" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Visual</text>
  <text x="370" y="280" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Tracking</text>
  <text x="370" y="300" text-anchor="middle" style="font-size:11px;fill:white">83 questions, 5 subtypes</text>
  <text x="370" y="315" text-anchor="middle" style="font-size:10px;fill:white">Maze navigation,</text>
  <text x="370" y="330" text-anchor="middle" style="font-size:10px;fill:white">line observation,</text>
  <text x="370" y="345" text-anchor="middle" style="font-size:10px;fill:white">connect lines</text>
  
  <rect x="490" y="240" width="200" height="120" fill="url(#grad4)" rx="10" opacity="0.8"/>
  <text x="590" y="265" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Spatial</text>
  <text x="590" y="280" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Perception</text>
  <text x="590" y="300" text-anchor="middle" style="font-size:11px;fill:white">91 questions, 5 subtypes</text>
  <text x="590" y="315" text-anchor="middle" style="font-size:10px;fill:white">3D views, cube unfold,</text>
  <text x="590" y="330" text-anchor="middle" style="font-size:10px;fill:white">paper folding,</text>
  <text x="590" y="345" text-anchor="middle" style="font-size:10px;fill:white">count 3D blocks</text>
  
  <rect x="710" y="240" width="200" height="120" fill="url(#grad1)" rx="10" opacity="0.8"/>
  <text x="810" y="265" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Visual Pattern</text>
  <text x="810" y="280" text-anchor="middle" style="font-size:14px;font-weight:bold;fill:white">Recognition</text>
  <text x="810" y="300" text-anchor="middle" style="font-size:11px;fill:white">51 questions, 4 subtypes</text>
  <text x="810" y="315" text-anchor="middle" style="font-size:10px;fill:white">Logic patterns,</text>
  <text x="810" y="330" text-anchor="middle" style="font-size:10px;fill:white">rotation, mirroring,</text>
  <text x="810" y="345" text-anchor="middle" style="font-size:10px;fill:white">overlay patterns</text>
  
  <!-- Two Evaluation Approaches -->
  <text x="500" y="410" text-anchor="middle" style="font-size:18px;font-weight:bold;fill:#2c3e50">Evaluation Methodologies</text>
  
  <rect x="100" y="440" width="350" height="160" fill="url(#grad2)" rx="10" opacity="0.8"/>
  <text x="275" y="465" text-anchor="middle" style="font-size:16px;font-weight:bold;fill:white">BabyVision</text>
  <text x="275" y="485" text-anchor="middle" style="font-size:12px;fill:white">Language-based Evaluation</text>
  <text x="275" y="505" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ 388 questions across 22 subtypes</text>
  <text x="275" y="520" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Multiple choice & fill-in-blank</text>
  <text x="275" y="535" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ LLM-as-judge evaluation</text>
  <text x="275" y="550" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Human baseline: 94.1%</text>
  <text x="275" y="565" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Best model: 49.7% (Gemini3)</text>
  <text x="275" y="580" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Tested 11 frontier models</text>
  
  <rect x="550" y="440" width="350" height="160" fill="url(#grad3)" rx="10" opacity="0.8"/>
  <text x="725" y="465" text-anchor="middle" style="font-size:16px;font-weight:bold;fill:white">BabyVision-Gen</text>
  <text x="725" y="485" text-anchor="middle" style="font-size:12px;fill:white">Visual Generation Evaluation</text>
  <text x="725" y="505" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ 280 questions across 21 subtypes</text>
  <text x="725" y="520" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Visual output assessment</text>
  <text x="725" y="535" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Automatic evaluation toolkit</text>
  <text x="725" y="550" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ 96% agreement with humans</text>
  <text x="725" y="565" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Best: 18.3% (NanoBanana-Pro)</text>
  <text x="725" y="580" text-anchor="middle" style="font-size:11px;fill:white">‚Ä¢ Tests visual reasoning via generation</text>
  
  <!-- Analysis and Insights -->
  <rect x="50" y="630" width="900" height="120" fill="url(#grad4)" rx="10" opacity="0.8"/>
  <text x="500" y="655" text-anchor="middle" style="font-size:16px;font-weight:bold;fill:white">Key Research Insights</text>
  
  <rect x="80" y="670" width="200" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="180" y="690" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">Verbalization Bottleneck</text>
  <text x="180" y="705" text-anchor="middle" style="font-size:10px;fill:#2c3e50">Models compress visual info</text>
  <text x="180" y="718" text-anchor="middle" style="font-size:10px;fill:#2c3e50">into language tokens</text>
  
  <rect x="300" y="670" width="200" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="400" y="690" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">RLVR Training Benefits</text>
  <text x="400" y="705" text-anchor="middle" style="font-size:10px;fill:#2c3e50">+4.8% improvement with</text>
  <text x="400" y="718" text-anchor="middle" style="font-size:10px;fill:#2c3e50">reinforcement learning</text>
  
  <rect x="520" y="670" width="200" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="620" y="690" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">Four Failure Modes</text>
  <text x="620" y="705" text-anchor="middle" style="font-size:10px;fill:#2c3e50">Detail loss, tracking,</text>
  <text x="620" y="718" text-anchor="middle" style="font-size:10px;fill:#2c3e50">spatial, pattern failures</text>
  
  <rect x="740" y="670" width="200" height="60" fill="white" rx="5" opacity="0.9"/>
  <text x="840" y="690" text-anchor="middle" style="font-size:12px;font-weight:bold;fill:#2c3e50">Visual Externalization</text>
  <text x="840" y="705" text-anchor="middle" style="font-size:10px;fill:#2c3e50">Generation models show</text>
  <text x="840" y="718" text-anchor="middle" style="font-size:10px;fill:#2c3e50">promising visual reasoning</text>
  
  <!-- Connecting lines with subtle styling -->
  <line x1="330" y1="130" x2="375" y2="130" stroke="#34495e" stroke-width="2" opacity="0.6"/>
  <line x1="625" y1="130" x2="670" y2="130" stroke="#34495e" stroke-width="2" opacity="0.6"/>
  
  <line x1="500" y1="180" x2="500" y2="220" stroke="#34495e" stroke-width="2" opacity="0.6"/>
  
  <line x1="275" y1="370" x2="275" y2="440" stroke="#34495e" stroke-width="2" opacity="0.6"/>
  <line x1="725" y1="370" x2="725" y2="440" stroke="#34495e" stroke-width="2" opacity="0.6"/>
  
  <line x1="500" y1="610" x2="500" y2="630" stroke="#34495e" stroke-width="2" opacity="0.6"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="The verbalization bottleneck">
                        <div class="quiz-question">1. What is identified as the fundamental limitation preventing MLLMs from performing well on BabyVision tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Insufficient training data">Insufficient training data</div><div class="quiz-choice" data-value="The verbalization bottleneck">The verbalization bottleneck</div><div class="quiz-choice" data-value="Limited computational resources">Limited computational resources</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Performed between 3-year-olds and 6-year-olds">
                        <div class="quiz-question">2. How did Gemini3-Pro-Preview's performance on BabyVision compare to human age groups?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Performed better than 12-year-olds">Performed better than 12-year-olds</div><div class="quiz-choice" data-value="Performed between 3-year-olds and 6-year-olds">Performed between 3-year-olds and 6-year-olds</div><div class="quiz-choice" data-value="Performed worse than 3-year-olds">Performed worse than 3-year-olds</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Visual generation outputs like drawing lines or marking regions">
                        <div class="quiz-question">3. What unique aspect does BABYVISION-GEN introduce to evaluate visual reasoning?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Text-based explanations of visual reasoning">Text-based explanations of visual reasoning</div><div class="quiz-choice" data-value="Multiple choice selection format">Multiple choice selection format</div><div class="quiz-choice" data-value="Visual generation outputs like drawing lines or marking regions">Visual generation outputs like drawing lines or marking regions</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/woven.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-12</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.07832" target="_blank">http://arxiv.org/pdf/2601.07832</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> A novel linear attention mechanism called MHLA (Multi-Head Linear Attention) for transformer architectures in computer vision and natural language processing tasks.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on linear attention mechanisms that reduce computational complexity but suffer from performance degradation; proposes token-level multi-head attention to restore expressivity while maintaining efficiency.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Addresses the "global context collapse" problem in linear attention where models lose representational diversity and performance degrades due to using a single global key-value summary.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Divides tokens into non-overlapping blocks ("heads") along spatial dimensions, computes local key-value summaries, and uses learnable mixing coefficients to create query-specific context while maintaining linear complexity.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Achieved significant improvements across multiple domains: 3.6% on ImageNet classification, 6.3% on NLP tasks, 12.6% on image generation, and 41% on video generation while maintaining the same time complexity as linear attention.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head</text>
  
  <!-- Problem Analysis Section -->
  <rect x="50" y="60" width="280" height="120" fill="#e74c3c" rx="10" opacity="0.2"/>
  <text x="190" y="80" text-anchor="middle" font-size="16" font-weight="bold" fill="#e74c3c">Problem Analysis</text>
  <text x="60" y="100" font-size="12" fill="#2c3e50">‚Ä¢ Linear Attention has O(N) complexity</text>
  <text x="60" y="115" font-size="12" fill="#2c3e50">‚Ä¢ But suffers from Global Context Collapse</text>
  <text x="60" y="130" font-size="12" fill="#2c3e50">‚Ä¢ Rank limited by dimension d</text>
  <text x="60" y="145" font-size="12" fill="#2c3e50">‚Ä¢ Loss of query-conditioned selectivity</text>
  <text x="60" y="160" font-size="12" fill="#2c3e50">‚Ä¢ Uniform attention distribution</text>
  
  <!-- Root Cause Analysis -->
  <rect x="370" y="60" width="280" height="120" fill="#f39c12" rx="10" opacity="0.2"/>
  <text x="510" y="80" text-anchor="middle" font-size="16" font-weight="bold" fill="#f39c12">Root Cause Analysis</text>
  <text x="380" y="100" font-size="12" fill="#2c3e50">‚Ä¢ Single global KV summary shared by all queries</text>
  <text x="380" y="115" font-size="12" fill="#2c3e50">‚Ä¢ rank(A_lin) ‚â§ min{rank(QÃÉ), rank(KÃÉ)} ‚â§ d</text>
  <text x="380" y="130" font-size="12" fill="#2c3e50">‚Ä¢ High entropy in attention weights</text>
  <text x="380" y="145" font-size="12" fill="#2c3e50">‚Ä¢ Information bottleneck in fixed-size matrix</text>
  <text x="380" y="160" font-size="12" fill="#2c3e50">‚Ä¢ No token-level diversity</text>
  
  <!-- Solution Overview -->
  <rect x="690" y="60" width="260" height="120" fill="#27ae60" rx="10" opacity="0.2"/>
  <text x="820" y="80" text-anchor="middle" font-size="16" font-weight="bold" fill="#27ae60">Solution Overview</text>
  <text x="700" y="100" font-size="12" fill="#2c3e50">‚Ä¢ Multi-Head Linear Attention (MHLA)</text>
  <text x="700" y="115" font-size="12" fill="#2c3e50">‚Ä¢ Partition tokens into M blocks</text>
  <text x="700" y="130" font-size="12" fill="#2c3e50">‚Ä¢ Local KV summaries per block</text>
  <text x="700" y="145" font-size="12" fill="#2c3e50">‚Ä¢ Query-conditioned mixing</text>
  <text x="700" y="160" font-size="12" fill="#2c3e50">‚Ä¢ Restore token-level diversity</text>
  
  <!-- MHLA Architecture -->
  <rect x="100" y="220" width="800" height="180" fill="#3498db" rx="15" opacity="0.1" stroke="#3498db" stroke-width="2"/>
  <text x="500" y="245" text-anchor="middle" font-size="18" font-weight="bold" fill="#3498db">MHLA Architecture</text>
  
  <!-- Input Processing -->
  <rect x="120" y="260" width="150" height="60" fill="#9b59b6" rx="8" opacity="0.3"/>
  <text x="195" y="280" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Input Sequence</text>
  <text x="195" y="295" text-anchor="middle" font-size="12" fill="#2c3e50">X ‚àà R^(N√ód)</text>
  <text x="195" y="310" text-anchor="middle" font-size="12" fill="#2c3e50">Q, K, V projections</text>
  
  <!-- Token Partitioning -->
  <rect x="300" y="260" width="150" height="60" fill="#e67e22" rx="8" opacity="0.3"/>
  <text x="375" y="280" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Token Partitioning</text>
  <text x="375" y="295" text-anchor="middle" font-size="12" fill="#2c3e50">Split into M blocks</text>
  <text x="375" y="310" text-anchor="middle" font-size="12" fill="#2c3e50">Non-overlapping</text>
  
  <!-- Local KV Summaries -->
  <rect x="480" y="260" width="150" height="60" fill="#1abc9c" rx="8" opacity="0.3"/>
  <text x="555" y="275" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Local KV Summaries</text>
  <text x="555" y="290" text-anchor="middle" font-size="11" fill="#2c3e50">S_b = Œ£_{j‚ààb} KÃÉ_j V_j^T</text>
  <text x="555" y="305" text-anchor="middle" font-size="11" fill="#2c3e50">z_b = Œ£_{j‚ààb} KÃÉ_j</text>
  
  <!-- Multi-Head Mixing -->
  <rect x="660" y="260" width="150" height="60" fill="#f1c40f" rx="8" opacity="0.3"/>
  <text x="735" y="280" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Multi-Head Mixing</text>
  <text x="735" y="295" text-anchor="middle" font-size="11" fill="#2c3e50">SÃÉ_i = Œ£_{b=1}^M m_{i,b} S_b</text>
  <text x="735" y="310" text-anchor="middle" font-size="11" fill="#2c3e50">Learnable coefficients</text>
  
  <!-- Output Computation -->
  <rect x="350" y="340" width="200" height="50" fill="#95a5a6" rx="8" opacity="0.3"/>
  <text x="450" y="360" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Output Computation</text>
  <text x="450" y="375" text-anchor="middle" font-size="11" fill="#2c3e50">o = qÃÉ^T SÃÉ_i / qÃÉ^T zÃÉ_i</text>
  
  <!-- Key Properties -->
  <rect x="80" y="430" width="840" height="100" fill="#34495e" rx="10" opacity="0.1"/>
  <text x="500" y="450" text-anchor="middle" font-size="16" font-weight="bold" fill="#34495e">Key Properties & Advantages</text>
  
  <rect x="100" y="470" width="180" height="50" fill="#e74c3c" rx="5" opacity="0.2"/>
  <text x="190" y="490" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Complexity</text>
  <text x="190" y="505" text-anchor="middle" font-size="11" fill="#2c3e50">O(Nd¬≤ + M¬≤d¬≤) = O(Nd¬≤)</text>
  
  <rect x="300" y="470" width="180" height="50" fill="#27ae60" rx="5" opacity="0.2"/>
  <text x="390" y="485" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Rank Improvement</text>
  <text x="390" y="500" text-anchor="middle" font-size="11" fill="#2c3e50">rank ‚â§ Œ£_{b=1}^M min(n_b, d)</text>
  <text x="390" y="510" text-anchor="middle" font-size="10" fill="#2c3e50">Much higher than d</text>
  
  <rect x="500" y="470" width="180" height="50" fill="#3498db" rx="5" opacity="0.2"/>
  <text x="590" y="485" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Query Selectivity</text>
  <text x="590" y="500" text-anchor="middle" font-size="11" fill="#2c3e50">Restored via mixing</text>
  <text x="590" y="510" text-anchor="middle" font-size="10" fill="#2c3e50">Lower entropy</text>
  
  <rect x="700" y="470" width="180" height="50" fill="#9b59b6" rx="5" opacity="0.2"/>
  <text x="790" y="485" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">No Extra Modules</text>
  <text x="790" y="500" text-anchor="middle" font-size="11" fill="#2c3e50">Pure attention design</text>
  <text x="790" y="510" text-anchor="middle" font-size="10" fill="#2c3e50">Standard GEMMs</text>
  
  <!-- Experimental Results -->
  <rect x="50" y="560" width="900" height="120" fill="#2ecc71" rx="10" opacity="0.1"/>
  <text x="500" y="580" text-anchor="middle" font-size="16" font-weight="bold" fill="#27ae60">Experimental Validation</text>
  
  <rect x="80" y="600" width="180" height="60" fill="#e67e22" rx="5" opacity="0.2"/>
  <text x="170" y="620" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Image Classification</text>
  <text x="170" y="635" text-anchor="middle" font-size="11" fill="#2c3e50">ImageNet: +3.6%</text>
  <text x="170" y="650" text-anchor="middle" font-size="11" fill="#2c3e50">vs Self-Attention</text>
  
  <rect x="280" y="600" width="180" height="60" fill="#3498db" rx="5" opacity="0.2"/>
  <text x="370" y="620" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Image Generation</text>
  <text x="370" y="635" text-anchor="middle" font-size="11" fill="#2c3e50">DiT: +12.6% FID</text>
  <text x="370" y="650" text-anchor="middle" font-size="11" fill="#2c3e50">Same throughput as LA</text>
  
  <rect x="480" y="600" width="180" height="60" fill="#9b59b6" rx="5" opacity="0.2"/>
  <text x="570" y="620" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">NLP Tasks</text>
  <text x="570" y="635" text-anchor="middle" font-size="11" fill="#2c3e50">MMLU: +6.3%</text>
  <text x="570" y="650" text-anchor="middle" font-size="11" fill="#2c3e50">Long context modeling</text>
  
  <rect x="680" y="600" width="180" height="60" fill="#e74c3c" rx="5" opacity="0.2"/>
  <text x="770" y="620" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Video Generation</text>
  <text x="770" y="635" text-anchor="middle" font-size="11" fill="#2c3e50">+41% improvement</text>
  <text x="770" y="650" text-anchor="middle" font-size="11" fill="#2c3e50">Ultra-long sequences</text>
  
  <!-- Key Innovation -->
  <rect x="250" y="720" width="500" height="50" fill="#f39c12" rx="10" opacity="0.2"/>
  <text x="500" y="740" text-anchor="middle" font-size="14" font-weight="bold" fill="#d35400">Core Innovation: Token-level diversity via query-conditioned block mixing</text>
  <text x="500" y="755" text-anchor="middle" font-size="12" fill="#d35400">Maintains linear complexity while restoring expressivity</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Global context collapse and loss of representational diversity">
                        <div class="quiz-question">1. What is the key problem that MHLA aims to solve in linear attention mechanisms?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="High computational complexity">High computational complexity</div><div class="quiz-choice" data-value="Global context collapse and loss of representational diversity">Global context collapse and loss of representational diversity</div><div class="quiz-choice" data-value="Inability to process long sequences">Inability to process long sequences</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By dividing tokens into spatial blocks and using learnable mixing coefficients">
                        <div class="quiz-question">2. How does MHLA achieve better performance while maintaining linear complexity?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By using multiple attention heads in parallel">By using multiple attention heads in parallel</div><div class="quiz-choice" data-value="By adding convolutional layers and gating modules">By adding convolutional layers and gating modules</div><div class="quiz-choice" data-value="By dividing tokens into spatial blocks and using learnable mixing coefficients">By dividing tokens into spatial blocks and using learnable mixing coefficients</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Video generation (41% gain)">
                        <div class="quiz-question">3. On which task did MHLA achieve the most significant performance improvement?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Image classification (3.6% gain)">Image classification (3.6% gain)</div><div class="quiz-choice" data-value="Image generation (12.6% gain)">Image generation (12.6% gain)</div><div class="quiz-choice" data-value="Video generation (41% gain)">Video generation (41% gain)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');

                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫ÊØè‰∏™Âç°ÁâáÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂ÔºàËÄå‰∏çÊòØÊï¥‰∏™ÂÆπÂô®Ôºâ
                cards.forEach(card => {
                    card.addEventListener('click', function(e) {
                        // Âè™ÊúâÁÇπÂáªÂú®Âç°ÁâáÂÜÖÈÉ®Êó∂ÊâçÂàáÊç¢
                        // Ê£ÄÊü•ÊòØÂê¶ÊòØÊµÅÁ®ãÂõæÂç°ÁâáÁöÑÊªöÂä®Êù°Âå∫Âüü
                        if (this.classList.contains('flowchart-card')) {
                            const rect = this.getBoundingClientRect();
                            const isScrollbarClick =
                                (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                                (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);

                            if (!isScrollbarClick) {
                                nextCard(e);
                            }
                        } else {
                            nextCard(e);
                        }
                    });
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>

    <!-- AI Assistant Scripts - Load in correct order (relative paths for subpages) -->
    <script src="../../js/ai-assistant-constants.js"></script>
    <script src="../../js/ai-assistant-storage.js"></script>
    <script src="../../js/ai-assistant-positioning.js"></script>
    <script src="../../js/ai-assistant-templates.js"></script>
    <script src="../../js/ai-assistant-dom-utils.js"></script>
    <script src="../../js/ai-assistant-config.js"></script>
    <script src="../../js/ai-assistant.js"></script>
</body>
</html>
