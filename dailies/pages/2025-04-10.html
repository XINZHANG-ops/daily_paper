
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-04-10 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-04-10 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-orchid.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>GenDoP: Auto-regressive Camera Trajectory Generation as a Director of
  Photography</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.07083" target="_blank">http://arxiv.org/pdf/2504.07083</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on auto-regressive camera trajectory generation for cinematography, operating in the domain of computer vision and video production.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on previous trajectory generation methods that used geometric optimization, procedural systems, or diffusion models, but proposes a novel auto-regressive approach to generate more artistic and expressive camera movements.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitation of existing camera trajectory generation methods that lack artistic expression, directorial intent, and fine-grained textual alignment for creative video production.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors introduce GenDoP, an auto-regressive model that treats camera parameters as discrete tokens and leverages a decoder-only Transformer architecture, conditioned on text descriptions and optional RGBD information.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> GenDoP outperforms state-of-the-art methods across fine-grained textual controllability, motion stability, and complexity metrics, with extensive human validation confirming its superior performance in generating artistic, expressive camera trajectories.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>GenDoP: Auto-regressive Camera Trajectory Generation as a Director of
  Photography</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg" font-family="Arial, sans-serif">

  <!-- Definitions for markers and gradients -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#555" />
    </marker>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,200,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(100,150,220);stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,255,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(100,220,100);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,220,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,180,100);stop-opacity:1" />
    </linearGradient>
    <filter id="dropshadow" height="130%">
      <feGaussianBlur in="SourceAlpha" stdDeviation="3"/>
      <feOffset dx="2" dy="2" result="offsetblur"/>
      <feComponentTransfer>
        <feFuncA type="linear" slope="0.5"/>
      </feComponentTransfer>
      <feMerge>
        <feMergeNode/>
        <feMergeNode in="SourceGraphic"/>
      </feMerge>
    </filter>
  </defs>

  <!-- Title -->
  <text x="500" y="40" font-size="28" font-weight="bold" text-anchor="middle" fill="#333">GenDoP Methodology Flowchart</text>

  <!-- Section 1: DataDoP Dataset Construction -->
  <rect x="50" y="80" width="400" height="650" rx="15" ry="15" fill="url(#grad1)" stroke="#888" stroke-width="1" filter="url(#dropshadow)"/>
  <text x="250" y="110" font-size="20" font-weight="bold" text-anchor="middle" fill="#114">1. DataDoP Dataset Construction</text>

  <!-- DataDoP Steps -->
  <g transform="translate(70, 140)">
    <!-- Input -->
    <rect x="0" y="0" width="360" height="40" rx="5" ry="5" fill="#e0f0ff" stroke="#a0c0e0"/>
    <text x="180" y="25" text-anchor="middle" font-size="14" fill="#114">Input: Raw Videos (Movies, Documentaries)</text>

    <!-- Pre-processing -->
    <rect x="0" y="60" width="360" height="80" rx="5" ry="5" fill="#d0e8ff" stroke="#90b8d8"/>
    <text x="10" y="80" font-size="14" fill="#114" font-weight="bold">Pre-processing:</text>
    <text x="20" y="100" font-size="13" fill="#114">- Shot Segmentation (PySceneDetect)</text>
    <text x="20" y="115" font-size="13" fill="#114">- Quality/Semantic Filtering (Length, Light, GPT-4o Motion Type)</text>

    <!-- Trajectory Extraction -->
    <rect x="0" y="160" width="360" height="80" rx="5" ry="5" fill="#c0e0ff" stroke="#80b0d0"/>
    <text x="10" y="180" font-size="14" fill="#114" font-weight="bold">Trajectory Extraction & Refinement:</text>
    <text x="20" y="200" font-size="13" fill="#114">- Extract Pose & Depth (MonST3R)</text>
    <text x="20" y="215" font-size="13" fill="#114">- Clean, Smooth (Kalman), Interpolate Trajectories</text>

    <!-- Motion Tagging -->
    <rect x="0" y="260" width="360" height="100" rx="5" ry="5" fill="#b0d8ff" stroke="#70a8c8"/>
    <text x="10" y="280" font-size="14" fill="#114" font-weight="bold">Motion Tagging:</text>
    <text x="20" y="300" font-size="13" fill="#114">- Segment Trajectories</text>
    <text x="20" y="315" font-size="13" fill="#114">- Assign Tags: Translation (27 types) + Rotation (7 types)</text>
    <text x="20" y="330" font-size="13" fill="#114">- Combine & Smooth Tags</text>

    <!-- Caption Generation -->
    <rect x="0" y="380" width="360" height="100" rx="5" ry="5" fill="#a0d0ff" stroke="#60a0c0"/>
    <text x="10" y="400" font-size="14" fill="#114" font-weight="bold">Caption Generation (GPT-4o):</text>
    <text x="20" y="420" font-size="13" fill="#114">- Motion Captions (from Motion Tags)</text>
    <text x="20" y="435" font-size="13" fill="#114">- Directorial Captions (Tags + Scene Grid + Intent)</text>

    <!-- Output -->
    <rect x="0" y="500" width="360" height="60" rx="5" ry="5" fill="#90c8ff" stroke="#5098b8"/>
    <text x="180" y="525" text-anchor="middle" font-size="14" fill="#114" font-weight="bold">Output: DataDoP Dataset</text>
    <text x="180" y="545" text-anchor="middle" font-size="13" fill="#114">(Trajectories, RGBD Frames, Captions)</text>

    <!-- Arrows -->
    <line x1="180" y1="40" x2="180" y2="60" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/>
    <line x1="180" y1="140" x2="180" y2="160" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/>
    <line x1="180" y1="240" x2="180" y2="260" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/>
    <line x1="180" y1="360" x2="180" y2="380" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/>
    <line x1="180" y1="480" x2="180" y2="500" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/>
  </g>

  <!-- Section 2: GenDoP Trajectory Generation -->
  <rect x="500" y="80" width="450" height="650" rx="15" ry="15" fill="url(#grad2)" stroke="#888" stroke-width="1" filter="url(#dropshadow)"/>
  <text x="725" y="110" font-size="20" font-weight="bold" text-anchor="middle" fill="#141">2. GenDoP Trajectory Generation</text>

  <!-- GenDoP Steps -->
  <g transform="translate(520, 140)">
    <!-- Input -->
    <rect x="0" y="0" width="410" height="60" rx="5" ry="5" fill="#e0ffe0" stroke="#a0e0a0"/>
    <text x="205" y="25" text-anchor="middle" font-size="14" fill="#141">Input: Text Caption (Motion/Directorial)</text>
    <text x="205" y="45" text-anchor="middle" font-size="14" fill="#141">[Optional: Initial Frame RGBD]</text>

    <!-- Encoding -->
    <rect x="0" y="80" width="410" height="80" rx="5" ry="5" fill="#d0ffd0" stroke="#90d090"/>
    <text x="10" y="100" font-size="14" fill="#141" font-weight="bold">Multi-modal Encoding:</text>
    <text x="20" y="120" font-size="13" fill="#141">- Text Encoder (SD2.1 based)</text>
    <text x="20" y="135" font-size="13" fill="#141">- RGBD Encoders (CLIP Vision based)</text>
    <text x="205" y="155" text-anchor="middle" font-size="13" fill="#141">-> Concatenated Latent Code Z</text>

    <!-- Tokenization (Side block) -->
    <rect x="250" y="180" width="160" height="130" rx="5" ry="5" fill="#c0ffc0" stroke="#80c080"/>
    <text x="330" y="200" text-anchor="middle" font-size="14" fill="#141" font-weight="bold">Trajectory Tokenization</text>
    <text x="260" y="225" font-size="12" fill="#141">- Canonical Norm.</text>
    <text x="260" y="240" font-size="12" fill="#141">- Param Conversion</text>
    <text x="260" y="255" font-size="12" fill="#141">  (Quat, Trans, Intr, Scale)</text>
    <text x="260" y="270" font-size="12" fill="#141">- Discretization (Bins)</text>
    <text x="260" y="285" font-size="12" fill="#141">- Codebook Lookup</text>
    <text x="330" y="305" text-anchor="middle" font-size="12" fill="#141">-> Pose Tokens</text>

    <!-- Auto-regressive Decoder -->
    <rect x="0" y="180" width="230" height="130" rx="5" ry="5" fill="#b0ffb0" stroke="#70b070"/>
    <text x="115" y="200" text-anchor="middle" font-size="14" fill="#141" font-weight="bold">Auto-regressive Decoding</text>
    <text x="115" y="220" text-anchor="middle" font-size="13" fill="#141">(OPT Transformer)</text>
    <text x="10" y="245" font-size="12" fill="#141">- Input: Latent Code Z +</text>
    <text x="30" y="260" font-size="12" fill="#141">Previous Pose Tokens</text>
    <text x="10" y="280" font-size="12" fill="#141">- Predicts Next Pose Token</text>
    <text x="10" y="295" font-size="12" fill="#141">  Sequentially</text>

    <!-- Output -->
    <rect x="0" y="330" width="410" height="60" rx="5" ry="5" fill="#a0ffa0" stroke="#60a060"/>
    <text x="205" y="355" text-anchor="middle" font-size="14" fill="#141" font-weight="bold">Output: Generated Pose Token Sequence</text>
    <text x="205" y="375" text-anchor="middle" font-size="13" fill="#141">-> De-tokenize -> Generated Camera Trajectory</text>

    <!-- Evaluation & Application -->
    <rect x="0" y="410" width="410" height="150" rx="15" ry="15" fill="url(#grad3)" stroke="#d8b080" filter="url(#dropshadow)"/>
    <text x="205" y="435" text-anchor="middle" font-size="16" fill="#531" font-weight="bold">Evaluation & Application</text>

    <rect x="20" y="455" width="180" height="80" rx="5" ry="5" fill="#fff0d0" stroke="#e8c090"/>
    <text x="110" y="475" text-anchor="middle" font-size="14" fill="#531" font-weight="bold">Evaluation</text>
    <text x="30" y="495" font-size="13" fill="#531">- Metrics (CLaTr, F1)</text>
    <text x="30" y="510" font-size="13" fill="#531">- User Study (AUR)</text>
    <text x="30" y="525" font-size="13" fill="#531">- Ablation Studies</text>

    <rect x="210" y="455" width="180" height="80" rx="5" ry="5" fill="#fff0d0" stroke="#e8c090"/>
    <text x="300" y="475" text-anchor="middle" font-size="14" fill="#531" font-weight="bold">Application</text>
    <text x="220" y="495" font-size="13" fill="#531">- Camera Control for</text>
    <text x="230" y="510" font-size="13" fill="#531">Text/Image-to-Video</text>
    <text x="230" y="525" font-size="13" fill="#531">Generation</text>


    <!-- Arrows -->
    <line x1="205" y1="60" x2="205" y2="80" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/>
    <line x1="205" y1="160" x2="115" y2="180" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/> <!-- Encoding to Decoder -->
    <line x1="115" y1="310" x2="205" y2="330" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/> <!-- Decoder to Output -->
    <line x1="205" y1="390" x2="205" y2="410" stroke="#555" stroke-width="1.5" marker-end="url(#arrowhead)"/> <!-- Output to Eval/App -->

    <!-- Connection: Decoder <> Tokenization -->
    <path d="M 230 245 Q 240 245 250 245" stroke="#555" stroke-width="1.5" fill="none" marker-end="url(#arrowhead)"/>
    <path d="M 250 265 Q 240 265 230 265" stroke="#555" stroke-width="1.5" fill="none" marker-end="url(#arrowhead)"/>
    <text x="240" y="260" font-size="10" fill="#555" text-anchor="middle">Uses/Produces</text>

  </g>

  <!-- Connecting Arrow between sections -->
   <path d="M 450 405 Q 475 405 500 405" stroke="#555" stroke-width="2" stroke-dasharray="5,5" fill="none" marker-end="url(#arrowhead)"/>
   <text x="475" y="395" font-size="12" fill="#555" text-anchor="middle">Provides Training Data</text>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It employs an auto-regressive model treating camera parameters as discrete tokens">
                        <div class="quiz-question">1. What is the primary innovation of GenDoP compared to previous camera trajectory generation methods?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a reinforcement learning approach to optimize camera movements">It uses a reinforcement learning approach to optimize camera movements</div><div class="quiz-choice" data-value="It employs an auto-regressive model treating camera parameters as discrete tokens">It employs an auto-regressive model treating camera parameters as discrete tokens</div><div class="quiz-choice" data-value="It introduces a diffusion-based framework with human-centric tracking">It introduces a diffusion-based framework with human-centric tracking</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Free-moving trajectories that enable unrestricted 3D camera motion">
                        <div class="quiz-question">2. What type of camera trajectories does the DataDoP dataset focus on?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Object/Scene-centric trajectories that focus on specific objects">Object/Scene-centric trajectories that focus on specific objects</div><div class="quiz-choice" data-value="Tracking trajectories that follow moving subjects">Tracking trajectories that follow moving subjects</div><div class="quiz-choice" data-value="Free-moving trajectories that enable unrestricted 3D camera motion">Free-moving trajectories that enable unrestricted 3D camera motion</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Two types: Motion captions and Directorial captions">
                        <div class="quiz-question">3. How many types of captions are generated for each trajectory in the DataDoP dataset?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="One type: Technical captions describing camera parameters">One type: Technical captions describing camera parameters</div><div class="quiz-choice" data-value="Two types: Motion captions and Directorial captions">Two types: Motion captions and Directorial captions</div><div class="quiz-choice" data-value="Three types: Translation, Rotation, and Intent captions">Three types: Translation, Rotation, and Intent captions</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training
  Tokens</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.07096" target="_blank">http://arxiv.org/pdf/2504.07096</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces OLMoTrace, a system for tracing language model outputs back to their training data in real-time.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on infini-gram (a text search engine) and extends it with a novel parallel algorithm to efficiently trace language model outputs to their training data, which was previously computationally intractable at trillion-token scale.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of understanding why language models generate certain responses by tracing their outputs back to training data, which was previously impossible at scale due to computational constraints.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a five-step inference pipeline that finds maximal matching spans in LM outputs, filters for long and unique spans, retrieves enclosing documents, merges spans and documents, and ranks documents by relevance using BM25 scoring.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The system achieves an average inference latency of 4.46 seconds per query on responses averaging 458 tokens, with document relevance evaluations showing the top documents displayed having an average relevance score of 1.82 (on a 0-3 scale) according to LLM-as-a-Judge evaluation.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>OLMoTrace: Tracing Language Model Outputs Back to Trillions of Training
  Tokens</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">

  <!-- Background -->
  <defs>
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f4f8;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#d9e2ec;stop-opacity:1" />
    </linearGradient>
  </defs>
  <rect width="100%" height="100%" fill="url(#bgGradient)" />

  <!-- Title -->
  <text x="500" y="50" font-family="Arial, sans-serif" font-size="32" font-weight="bold" text-anchor="middle" fill="#1a237e">
    OLMoTrace Inference Pipeline
  </text>
  <text x="500" y="80" font-family="Arial, sans-serif" font-size="16" text-anchor="middle" fill="#546e7a">
    Tracing LM Outputs to Training Data (Focus on Method)
  </text>

  <!-- Input -->
  <rect x="350" y="120" width="300" height="50" rx="10" ry="10" fill="#ffecb3" stroke="#ffa000" stroke-width="1.5"/>
  <text x="500" y="150" font-family="Arial, sans-serif" font-size="16" text-anchor="middle" fill="#4e342e">
    Input: LM Response & User Prompt
  </text>

  <!-- Arrow -->
  <line x1="500" y1="170" x2="500" y2="190" stroke="#546e7a" stroke-width="2"/>
  <polygon points="495,190 505,190 500,195" fill="#546e7a"/>

  <!-- Step 1: Find Maximal Matching Spans -->
  <rect x="150" y="200" width="700" height="120" rx="15" ry="15" fill="#c5cae9" stroke="#3f51b5" stroke-width="2"/>
  <text x="500" y="225" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="#1a237e">
    Step 1: Find Maximal Matching Spans
  </text>
  <text x="170" y="255" font-family="Arial, sans-serif" font-size="14" fill="#303f9f">
    - Tokenize LM output (Llama-2).
  </text>
  <text x="170" y="275" font-family="Arial, sans-serif" font-size="14" fill="#303f9f">
    - Identify verbatim spans in training data meeting:
  </text>
  <text x="190" y="295" font-family="Arial, sans-serif" font-size="13" fill="#303f9f" font-style="italic">
      Existence, Self-contained, Maximality.
  </text>
  <text x="500" y="255" font-family="Arial, sans-serif" font-size="14" fill="#303f9f">
    - Key Tech: Parallel algorithm using <tspan font-weight="bold">infini-gram</tspan>
  </text>
  <text x="500" y="275" font-family="Arial, sans-serif" font-size="14" fill="#303f9f">
      (Suffix Array index on Trillion+ tokens).
  </text>
   <text x="500" y="295" font-family="Arial, sans-serif" font-size="14" fill="#303f9f">
     - Fast lookup: O(1) FIND query per suffix (parallelized).
  </text>

  <!-- Arrow -->
  <line x1="500" y1="320" x2="500" y2="340" stroke="#546e7a" stroke-width="2"/>
  <polygon points="495,340 505,340 500,345" fill="#546e7a"/>

  <!-- Step 2: Filter Spans -->
  <rect x="250" y="350" width="500" height="60" rx="10" ry="10" fill="#b2dfdb" stroke="#00796b" stroke-width="1.5"/>
  <text x="500" y="375" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="#004d40">
    Step 2: Filter for Long & Unique Spans
  </text>
  <text x="500" y="400" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#00695c">
    Keep top K spans with lowest <tspan font-style="italic">span unigram probability</tspan>.
  </text>

  <!-- Arrow -->
  <line x1="500" y1="410" x2="500" y2="430" stroke="#546e7a" stroke-width="2"/>
  <polygon points="495,430 505,430 500,435" fill="#546e7a"/>

  <!-- Step 3: Retrieve Documents -->
  <rect x="250" y="440" width="500" height="60" rx="10" ry="10" fill="#b2dfdb" stroke="#00796b" stroke-width="1.5"/>
  <text x="500" y="465" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="#004d40">
    Step 3: Retrieve Enclosing Documents
  </text>
  <text x="500" y="490" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#00695c">
    Retrieve up to 10 document snippets per kept span (sample if >10).
  </text>

  <!-- Arrow -->
  <line x1="500" y1="500" x2="500" y2="520" stroke="#546e7a" stroke-width="2"/>
  <polygon points="495,520 505,520 500,525" fill="#546e7a"/>

  <!-- Step 4: Merge -->
  <rect x="250" y="530" width="500" height="60" rx="10" ry="10" fill="#b2dfdb" stroke="#00796b" stroke-width="1.5"/>
  <text x="500" y="555" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="#004d40">
    Step 4: Merge Spans & Documents
  </text>
  <text x="500" y="580" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#00695c">
    Merge overlapping spans for UI; merge snippets from same source doc.
  </text>

  <!-- Arrow -->
  <line x1="500" y1="590" x2="500" y2="610" stroke="#546e7a" stroke-width="2"/>
  <polygon points="495,610 505,610 500,615" fill="#546e7a"/>

  <!-- Step 5: Rerank & Color -->
  <rect x="200" y="620" width="600" height="80" rx="10" ry="10" fill="#e1bee7" stroke="#8e24aa" stroke-width="1.5"/>
  <text x="500" y="645" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="#4a148c">
    Step 5: Rerank & Color by Relevance
  </text>
  <text x="500" y="670" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#6a1b9a">
    - Rerank documents using <tspan font-weight="bold">BM25</tspan> (Query: Prompt+Response, Corpus: Retrieved Docs).
  </text>
  <text x="500" y="690" font-family="Arial, sans-serif" font-size="14" text-anchor="middle" fill="#6a1b9a">
    - Color document sidebars & span highlights based on relevance score (High/Med/Low).
  </text>

  <!-- Arrow -->
  <line x1="500" y1="700" x2="500" y2="720" stroke="#546e7a" stroke-width="2"/>
  <polygon points="495,720 505,720 500,725" fill="#546e7a"/>

  <!-- Output -->
  <rect x="300" y="730" width="400" height="50" rx="10" ry="10" fill="#ffccbc" stroke="#d84315" stroke-width="1.5"/>
  <text x="500" y="760" font-family="Arial, sans-serif" font-size="16" text-anchor="middle" fill="#bf360c">
    Output: Highlighted Spans & Ranked Source Docs
  </text>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A parallel algorithm built on infini-gram that processes suffixes simultaneously">
                        <div class="quiz-question">1. What is the primary innovation that allows OLMoTrace to efficiently trace language model outputs back to training data?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A novel tokenization algorithm that reduces the size of training data">A novel tokenization algorithm that reduces the size of training data</div><div class="quiz-choice" data-value="A parallel algorithm built on infini-gram that processes suffixes simultaneously">A parallel algorithm built on infini-gram that processes suffixes simultaneously</div><div class="quiz-choice" data-value="A reinforcement learning approach that predicts likely training sources">A reinforcement learning approach that predicts likely training sources</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Using color saturation levels to indicate the relevance of source documents">
                        <div class="quiz-question">2. How does OLMoTrace highlight spans in language model responses?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using a single color for all matching spans regardless of document relevance">Using a single color for all matching spans regardless of document relevance</div><div class="quiz-choice" data-value="Using different colors based on the length of the matching span">Using different colors based on the length of the matching span</div><div class="quiz-choice" data-value="Using color saturation levels to indicate the relevance of source documents">Using color saturation levels to indicate the relevance of source documents</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Approximately 4.6 trillion tokens">
                        <div class="quiz-question">3. What is the total size of the training data that OLMoTrace indexes and searches for OLMo-2-32B-Instruct?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Approximately 460 billion tokens">Approximately 460 billion tokens</div><div class="quiz-choice" data-value="Approximately 4.6 trillion tokens">Approximately 4.6 trillion tokens</div><div class="quiz-choice" data-value="Approximately 46 trillion tokens">Approximately 46 trillion tokens</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tasky.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>A Unified Agentic Framework for Evaluating Conditional Image Generation</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.07046" target="_blank">http://arxiv.org/pdf/2504.07046</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces CIGEVAL, a unified agentic framework for evaluating conditional image generation across various tasks such as text-guided image generation, subject-driven image editing, and control-guided image generation.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon previous image evaluation metrics like CLIP-Score, LPIPS, and VIESCORE, but proposes a novel approach that integrates large multimodal models (LMMs) with specialized tools to overcome limitations in task specificity, explainability, and human alignment.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of developing task-agnostic, reliable, and explainable evaluation metrics for conditional image generation that can align with human judgment across diverse generation tasks.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors implement an agentic framework that combines LMMs (like GPT-4o or open-source models) with a multi-functional toolbox (including Grounding, Highlight, Difference, and Scene Graph tools) and fine-grained evaluation through task decomposition, tool selection, and analysis.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> CIGEVAL with GPT-4o achieves a Spearman correlation of 0.4625 with human assessments across seven tasks, closely matching the human-to-human correlation of 0.47, and when implemented with fine-tuned 7B open-source LMMs using only 2.3K training trajectories, it surpasses previous GPT-4o-based state-of-the-art methods.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>A Unified Agentic Framework for Evaluating Conditional Image Generation</h2>
                        <svg width="100%" viewBox="0 0 1000 1000" xmlns="http://www.w3.org/2000/svg">

  <!-- Define styles -->
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,200,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(200,230,255);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,220,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,240,200);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(160,255,160);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(210,255,210);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,180,180);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,220,220);stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad5" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(200, 180, 255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(230, 220, 255);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad6" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(180, 180, 180);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(220, 220, 220);stop-opacity:1" />
    </linearGradient>
    <style>
      .box { stroke: #333; stroke-width: 1.5; rx: 10; ry: 10; filter: drop-shadow( 3px 3px 2px rgba(0,0,0,0.2) ); }
      .title { font-family: 'Arial', sans-serif; font-size: 24px; font-weight: bold; fill: #222; }
      .subtitle { font-family: 'Arial', sans-serif; font-size: 16px; font-weight: bold; fill: #444; }
      .text { font-family: 'Arial', sans-serif; font-size: 13px; fill: #333; }
      .arrow { stroke: #555; stroke-width: 2; marker-end: url(#arrowhead); }
      .dashed-arrow { stroke: #777; stroke-width: 1.5; stroke-dasharray: 5, 5; marker-end: url(#arrowhead-dashed); }
      .tool-box { fill: #f0f0f0; stroke: #aaa; stroke-width: 1; rx: 5; ry: 5; }
      .tool-text { font-family: 'Arial', sans-serif; font-size: 12px; fill: #555; }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#555" />
    </marker>
     <marker id="arrowhead-dashed" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#777" />
    </marker>
  </defs>

  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" class="title">CIGEVAL: Methodology Flowchart</text>

  <!-- Input -->
  <rect x="350" y="70" width="300" height="70" class="box" fill="url(#grad1)"/>
  <text x="500" y="95" text-anchor="middle" class="subtitle">Input: Conditional Image Generation Task</text>
  <text x="500" y="120" text-anchor="middle" class="text">Generated Image (O), Conditions (C*), Instruction (I)</text>

  <!-- Agent Core -->
  <rect x="375" y="170" width="250" height="60" class="box" fill="url(#grad2)"/>
  <text x="500" y="195" text-anchor="middle" class="subtitle">CIGEVAL Agent Core</text>
  <text x="500" y="215" text-anchor="middle" class="text">Large Multimodal Model (LMM)</text>
  <line x1="500" y1="140" x2="500" y2="170" class="arrow" />

  <!-- Toolbox -->
  <rect x="700" y="170" width="200" height="170" class="box" fill="#f9f9f9" stroke="#ccc"/>
  <text x="800" y="195" text-anchor="middle" class="subtitle">Multi-functional Toolbox</text>
  <rect x="720" y="215" width="160" height="25" class="tool-box"/>
  <text x="800" y="230" text-anchor="middle" class="tool-text">Grounding</text>
  <rect x="720" y="245" width="160" height="25" class="tool-box"/>
  <text x="800" y="260" text-anchor="middle" class="tool-text">Highlight</text>
  <rect x="720" y="275" width="160" height="25" class="tool-box"/>
  <text x="800" y="290" text-anchor="middle" class="tool-text">Difference</text>
  <rect x="720" y="305" width="160" height="25" class="tool-box"/>
  <text x="800" y="320" text-anchor="middle" class="tool-text">Scene Graph</text>
  <line x1="625" y1="200" x2="700" y2="255" class="dashed-arrow" />
  <text x="665" y="220" text-anchor="middle" class="tool-text" transform="rotate(-20 665,220)">Uses</text>

  <!-- Evaluation Framework -->
  <rect x="300" y="260" width="400" height="300" class="box" fill="url(#grad3)"/>
  <text x="500" y="285" text-anchor="middle" class="subtitle">Fine-grained Evaluation Framework</text>
  <line x1="500" y1="230" x2="500" y2="260" class="arrow" />

  <!-- Steps within Framework -->
  <rect x="320" y="300" width="360" height="50" class="box" fill="#ffffff" stroke="#aaddaa"/>
  <text x="500" y="325" text-anchor="middle" class="text">(1) Task Decomposition (based on C* & I)</text>
  <line x1="500" y1="350" x2="500" y2="370" class="arrow" />

  <rect x="320" y="370" width="360" height="50" class="box" fill="#ffffff" stroke="#aaddaa"/>
  <text x="500" y="395" text-anchor="middle" class="text">(2) Tool Selection (Agent decides, uses Toolbox if needed)</text>
  <line x1="500" y1="420" x2="500" y2="440" class="arrow" />

  <rect x="320" y="440" width="360" height="50" class="box" fill="#ffffff" stroke="#aaddaa"/>
  <text x="500" y="458" text-anchor="middle" class="text">(3) Analysis (ReAct Style: Observation, Thought, Action)</text>
   <text x="500" y="475" text-anchor="middle" class="text">(Analyzes inputs & tool outputs)</text>
  <line x1="500" y1="490" x2="500" y2="510" class="arrow" />

  <rect x="320" y="510" width="170" height="40" class="box" fill="#ffffff" stroke="#aaddaa"/>
  <text x="405" y="530" text-anchor="middle" class="text">(4) Fine-grained Scoring</text>
  <line x1="490" y1="530" x2="510" y2="530" class="arrow" />

  <rect x="510" y="510" width="170" height="40" class="box" fill="#ffffff" stroke="#aaddaa"/>
  <text x="595" y="530" text-anchor="middle" class="text">(5) Score Aggregation (min)</text>

  <!-- Output -->
  <rect x="350" y="590" width="300" height="60" class="box" fill="url(#grad4)"/>
  <text x="500" y="615" text-anchor="middle" class="subtitle">Output</text>
  <text x="500" y="635" text-anchor="middle" class="text">Rationale & Final Score (0.0 - 1.0)</text>
  <line x1="500" y1="560" x2="500" y2="590" class="arrow" />

  <!-- Agent Tuning Flow -->
  <rect x="50" y="700" width="900" height="250" class="box" fill="url(#grad5)" stroke="#aaaacc"/>
  <text x="500" y="725" text-anchor="middle" class="subtitle">Agent Tuning (for Open-Source LMMs)</text>

  <rect x="100" y="750" width="200" height="80" class="box" fill="#ffffff" stroke="#aaaacc"/>
  <text x="200" y="780" text-anchor="middle" class="text">Generate Evaluation</text>
  <text x="200" y="795" text-anchor="middle" class="text">Trajectories using</text>
  <text x="200" y="810" text-anchor="middle" class="text">GPT-4o Agent</text>

  <line x1="300" y1="790" x2="350" y2="790" class="arrow" />

  <rect x="350" y="750" width="200" height="80" class="box" fill="#ffffff" stroke="#aaaacc"/>
  <text x="450" y="780" text-anchor="middle" class="text">Filter Trajectories</text>
  <text x="450" y="795" text-anchor="middle" class="text">(Keep if agent score ‚âà</text>
  <text x="450" y="810" text-anchor="middle" class="text">human score)</text>

  <line x1="550" y1="790" x2="600" y2="790" class="arrow" />

  <rect x="600" y="750" width="200" height="80" class="box" fill="#ffffff" stroke="#aaaacc"/>
  <text x="700" y="780" text-anchor="middle" class="text">Supervised Fine-Tuning</text>
  <text x="700" y="795" text-anchor="middle" class="text">(SFT) on Filtered Data</text>
  <text x="700" y="810" text-anchor="middle" class="text">(Loss on Thought & Action)</text>

  <line x1="800" y1="790" x2="850" y2="790" class="arrow" />

  <rect x="850" y="765" width="80" height="50" class="box" fill="url(#grad2)"/>
  <text x="890" y="785" text-anchor="middle" class="text">Tuned</text>
  <text x="890" y="800" text-anchor="middle" class="text">OS-LMM</text>

  <!-- Link Tuning back to Agent Core -->
   <path d="M 890 765 Q 890 700 500 700 Q 110 700 110 790" fill="none" stroke="#aaaacc" stroke-width="1.5" stroke-dasharray="5,5"/>
   <path d="M 500 230 C 500 680, 870 680, 870 765" stroke="#aaaacc" stroke-width="1.5" stroke-dasharray="5, 5" fill="none" marker-end="url(#arrowhead-dashed)"/>
   <text x="690" y="700" text-anchor="middle" class="tool-text">Resulting Tuned Agent</text>

  <!-- Evaluation (Mentioned, not detailed flow) -->
   <rect x="50" y="860" width="900" height="80" class="box" fill="url(#grad6)" stroke="#888888"/>
   <text x="500" y="885" text-anchor="middle" class="subtitle">Framework Evaluation</text>
   <text x="500" y="905" text-anchor="middle" class="text">Benchmarked on ImagenHub against baselines & human correlation.</text>
   <text x="500" y="920" text-anchor="middle" class="text">Ablation studies performed to validate tool contributions.</text>
   <line x1="500" y1="650" x2="500" y2="860" class="dashed-arrow" />

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It integrates LMMs with specialized tools in an agentic framework">
                        <div class="quiz-question">1. What is the main innovation of CIGEVAL compared to previous image evaluation metrics?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses only GPT-4o as the evaluation model">It uses only GPT-4o as the evaluation model</div><div class="quiz-choice" data-value="It integrates LMMs with specialized tools in an agentic framework">It integrates LMMs with specialized tools in an agentic framework</div><div class="quiz-choice" data-value="It focuses exclusively on text-guided image generation">It focuses exclusively on text-guided image generation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="2,300 trajectories">
                        <div class="quiz-question">2. How many training trajectories were used to fine-tune the open-source 7B LMMs in CIGEVAL?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="47,000 trajectories">47,000 trajectories</div><div class="quiz-choice" data-value="23,000 trajectories">23,000 trajectories</div><div class="quiz-choice" data-value="2,300 trajectories">2,300 trajectories</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Difference">
                        <div class="quiz-question">3. What tool in CIGEVAL's toolbox is used to detect subtle differences between two similar images?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Scene Graph">Scene Graph</div><div class="quiz-choice" data-value="Grounding">Grounding</div><div class="quiz-choice" data-value="Difference">Difference</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
