
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-05-02 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-05-02 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-linen-2.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>DeepCritic: Deliberate Critique with Large Language Models</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-01</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.00662" target="_blank">http://arxiv.org/pdf/2505.00662</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on enhancing the mathematical critique capabilities of Large Language Models (LLMs), specifically in their ability to evaluate and provide feedback on mathematical reasoning solutions.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on existing LLM critics that provide shallow critiques, the paper proposes a novel two-stage framework called DeepCritic that enables LLMs to generate more deliberate and thorough critiques of mathematical solutions.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitation of current LLM critics that provide superficial critiques of mathematical solutions, leading to low judgment accuracy and insufficient feedback for error correction.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The paper employs a two-stage approach: first using Qwen2.5-72B-Instruct to generate 4.5K long-form critiques for supervised fine-tuning, then applying reinforcement learning using either human-labeled data or automatically annotated data via Monte Carlo sampling.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The developed DeepCritic model outperformed existing LLM critics (including GPT-4o) on various error identification benchmarks and demonstrated effectiveness in helping LLM generators refine erroneous solutions through detailed feedback.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>DeepCritic: Deliberate Critique with Large Language Models</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">

  <!-- Define styles -->
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,200,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(100,150,255);stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,200,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,150,100);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(150,255,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(100,255,100);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(200,180,255);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(150,130,255);stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad5" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:rgb(255,255,150);stop-opacity:1" />
      <stop offset="100%" style="stop-color:rgb(255,255,100);stop-opacity:1" />
    </linearGradient>
    <style>
      .stage-title { font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; fill: #333; }
      .step-box { fill: url(#grad1); stroke: #666; stroke-width: 1.5; rx: 10; ry: 10; }
      .step-text { font-family: Arial, sans-serif; font-size: 14px; fill: #000; text-anchor: middle; }
      .data-box { fill: url(#grad3); stroke: #666; stroke-width: 1.5; rx: 5; ry: 5; }
      .data-text { font-family: Arial, sans-serif; font-size: 12px; fill: #000; text-anchor: middle; }
      .model-box { fill: url(#grad4); stroke: #444; stroke-width: 2; rx: 15; ry: 15; }
      .model-text { font-family: Arial, sans-serif; font-size: 16px; font-weight: bold; fill: #000; text-anchor: middle; }
      .arrow { stroke: #555; stroke-width: 2; marker-end: url(#arrowhead); }
       .connector { stroke: #888; stroke-width: 1.5; stroke-dasharray: 5, 5; }
       .llm-box { fill: url(#grad5); stroke: #888; stroke-width: 1; rx: 5; ry: 5; }
       .llm-text { font-family: Arial, sans-serif; font-size: 11px; fill: #333; text-anchor: middle; }
       .rl-box { fill: url(#grad2); stroke: #666; stroke-width: 1.5; rx: 10; ry: 10; }
       .final-model { fill: url(#grad4); stroke: #333; stroke-width: 2.5; rx: 20; ry: 20; }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#555" />
    </marker>
  </defs>

  <!-- Title -->
  <text x="500" y="40" class="stage-title" text-anchor="middle">DeepCritic: Two-Stage Training Pipeline</text>

  <!-- Stage 1: Critique Teaching (SFT) -->
  <rect x="50" y="80" width="400" height="400" fill="#eef" rx="15" ry="15" stroke="#ccc" stroke-width="1"/>
  <text x="250" y="110" class="stage-title" text-anchor="middle">Stage 1: Critique Teaching (SFT)</text>

  <!-- SFT Step 1: Initial Critique -->
  <rect x="100" y="140" width="300" height="50" class="step-box"/>
  <text x="250" y="160" class="step-text">1. Initial Critique Generation</text>
  <text x="250" y="175" class="step-text">(Critique each step si independently)</text>
  <rect x="180" y="195" width="140" height="30" class="llm-box"/>
  <text x="250" y="210" class="llm-text">using Qwen2.5-72B-Instruct</text>

  <!-- SFT Step 2: In-Depth Critique -->
  <rect x="100" y="240" width="300" height="65" class="step-box"/>
  <text x="250" y="260" class="step-text">2. In-Depth Critique Generation</text>
  <text x="250" y="275" class="step-text">(Critique initial critique or re-evaluate step si)</text>
  <text x="250" y="290" class="step-text">(Filter based on ground truth)</text>
  <rect x="180" y="310" width="140" height="30" class="llm-box"/>
  <text x="250" y="325" class="llm-text">using Qwen2.5-72B-Instruct</text>

  <!-- SFT Step 3: Synthesis -->
  <rect x="100" y="355" width="300" height="50" class="step-box"/>
  <text x="250" y="375" class="step-text">3. Final Critique Synthesis</text>
  <text x="250" y="390" class="step-text">(Merge initial & in-depth critiques)</text>
  <rect x="180" y="410" width="140" height="30" class="llm-box"/>
  <text x="250" y="425" class="llm-text">using Qwen2.5-72B-Instruct + ICL</text>

  <!-- SFT Data -->
  <rect x="175" y="455" width="150" height="40" class="data-box"/>
  <text x="250" y="470" class="data-text">4.5K Seed Critique Data</text>
  <text x="250" y="485" class="data-text">(Long-form, Deliberate)</text>

  <!-- SFT Training -->
  <rect x="100" y="510" width="300" height="50" class="step-box"/>
  <text x="250" y="535" class="step-text">4. Supervised Fine-Tuning (SFT)</text>

  <!-- SFT Output Model -->
  <rect x="150" y="580" width="200" height="50" class="model-box"/>
  <text x="250" y="605" class="model-text">DeepCritic-7B-SFT</text>

  <!-- Stage 2: Critique Incentivization (RL) -->
  <rect x="550" y="80" width="400" height="400" fill="#ffe" rx="15" ry="15" stroke="#ccc" stroke-width="1"/>
  <text x="750" y="110" class="stage-title" text-anchor="middle">Stage 2: Critique Incentivization (RL)</text>

  <!-- RL Data Source Choice -->
  <path d="M 600 150 L 900 150 L 900 350 L 600 350 Z" fill="none" stroke="#aaa" stroke-width="1.5" rx="10" ry="10"/>
  <text x="750" y="140" class="step-text" style="font-weight:bold;">RL Data Source</text>

  <!-- RL Data Source 1: Human-labeled -->
  <rect x="580" y="170" width="150" height="60" class="data-box"/>
  <text x="655" y="190" class="data-text">Human-Annotated Data</text>
  <text x="655" y="205" class="data-text">(e.g., PRM800K)</text>
  <text x="655" y="220" class="data-text">(40.7K samples)</text>

  <text x="750" y="200" class="step-text" style="font-size:16px; font-weight:bold;">OR</text>

  <!-- RL Data Source 2: Auto-labeled -->
  <rect x="770" y="170" width="150" height="160" class="data-box"/>
  <text x="845" y="190" class="data-text">Auto-Labeled Data</text>
  <text x="845" y="210" class="data-text">1. Generate Solutions</text>
  <text x="845" y="225" class="data-text">(NuminaMath-CoT)</text>
  <text x="845" y="245" class="data-text">2. Monte Carlo Sampling</text>
  <text x="845" y="260" class="data-text">based Correctness</text>
  <text x="845" y="275" class="data-text">Estimation</text>
   <text x="845" y="295" class="data-text">(using Qwen2.5-7B)</text>
  <text x="845" y="315" class="data-text">(14.2K samples)</text>

  <!-- RL Training -->
  <rect x="600" y="370" width="300" height="70" class="rl-box"/>
  <text x="750" y="395" class="step-text">Reinforcement Learning (RL)</text>
  <text x="750" y="410" class="step-text">(e.g., GRPO)</text>
  <text x="750" y="425" class="step-text">(Accuracy Reward)</text>

  <!-- RL Output Models -->
  <rect x="580" y="580" width="150" height="50" class="final-model"/>
  <text x="655" y="605" class="model-text">DeepCritic-7B</text>
  <text x="655" y="620" class="model-text" style="font-size:12px;">-RL-PRM800K</text>

  <rect x="770" y="580" width="150" height="50" class="final-model"/>
  <text x="845" y="605" class="model-text">DeepCritic-7B</text>
  <text x="845" y="620" class="model-text" style="font-size:12px;">-RL-Numina</text>

  <!-- Arrows and Connectors -->
  <path d="M 250 190 V 240" class="arrow"/>
  <path d="M 250 305 V 355" class="arrow"/>
  <path d="M 250 405 V 455" class="arrow"/>
  <path d="M 250 495 V 510" class="arrow"/>
  <path d="M 250 560 V 580" class="arrow"/>

  <!-- Connector from SFT model to RL stage -->
   <path d="M 350 605 H 450 C 500 605, 500 405, 550 405 H 600" class="connector" fill="none" marker-end="url(#arrowhead)"/>
   <text x="480" y="500" class="step-text" style="font-size:12px;">Input Model for RL</text>

  <!-- Arrows in RL Stage -->
   <path d="M 655 230 V 370" class="arrow"/>
   <path d="M 845 330 V 370" class="arrow"/>
   <path d="M 655 440 V 580" class="arrow"/>
   <path d="M 845 440 V 580" class="arrow"/>

   <!-- Final Goal/Output -->
   <rect x="350" y="680" width="300" height="60" fill="#f0fff0" stroke="#0a0" stroke-width="1.5" rx="10" ry="10"/>
   <text x="500" y="705" class="model-text" style="font-size:16px;">Final DeepCritic Models</text>
   <text x="500" y="725" class="step-text">(Enhanced Math Critique Ability)</text>

   <path d="M 250 630 V 680" class="arrow"/>
   <path d="M 655 630 V 680" class="arrow"/>
   <path d="M 845 630 V 680" class="arrow"/>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="They provide critiques that are superficial and lack in-depth analysis on each step.">
                        <div class="quiz-question">1. What is the main problem with existing LLM critics in the math domain that the DeepCritic framework aims to solve?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They are too computationally expensive to run.">They are too computationally expensive to run.</div><div class="quiz-choice" data-value="They provide critiques that are superficial and lack in-depth analysis on each step.">They provide critiques that are superficial and lack in-depth analysis on each step.</div><div class="quiz-choice" data-value="They can only critique correct solutions, not incorrect ones.">They can only critique correct solutions, not incorrect ones.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL).">
                        <div class="quiz-question">2. The DeepCritic framework employs a two-stage training pipeline. What are these two stages in order?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL).">Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL).</div><div class="quiz-choice" data-value="Reinforcement Learning (RL) followed by Supervised Fine-Tuning (SFT).">Reinforcement Learning (RL) followed by Supervised Fine-Tuning (SFT).</div><div class="quiz-choice" data-value="Generating initial critiques followed by generating final answers.">Generating initial critiques followed by generating final answers.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It significantly outperformed them on various benchmarks.">
                        <div class="quiz-question">3. How did the DeepCritic model perform compared to existing LLM critics (including GPT-4o and DeepSeek-R1-Distill models) on various error identification benchmarks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It performed significantly worse across all benchmarks.">It performed significantly worse across all benchmarks.</div><div class="quiz-choice" data-value="It performed comparably, showing similar accuracy.">It performed comparably, showing similar accuracy.</div><div class="quiz-choice" data-value="It significantly outperformed them on various benchmarks.">It significantly outperformed them on various benchmarks.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-paper.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level
  and Token-level CoT</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-01</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.00703" target="_blank">http://arxiv.org/pdf/2505.00703</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on enhancing text-to-image generation through reasoning capabilities using chain-of-thought (CoT) approaches in computer vision and artificial intelligence.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous work in language model reasoning and visual generation, the paper introduces a novel bi-level CoT approach combining semantic-level planning and token-level generation, which is new to image generation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of incorporating reasoning capabilities into text-to-image generation models to improve their understanding of complex prompts and generation quality.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors develop BiCoT-GRPO, a reinforcement learning framework that jointly optimizes both semantic-level and token-level CoT, using an ensemble of vision experts as reward models.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The resulting model T2I-R1 achieved 13% improvement on T2I-CompBench and 19% improvement on WISE benchmark, surpassing state-of-the-art model FLUX.1.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level
  and Token-level CoT</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">

  <!-- Define styles and markers -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#333" />
    </marker>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#bbdefb;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e3f2fd;stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#c5cae9;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ede7f6;stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#f8bbd0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#fce4ec;stop-opacity:1" />
    </linearGradient>
     <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#d1c4e9;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ede7f6;stop-opacity:1" />
    </linearGradient>
    <style>
      .process-box { fill: url(#grad1); stroke: #1e88e5; stroke-width: 1.5; rx: 10; ry: 10; }
      .input-box { fill: #fff3e0; stroke: #f57c00; stroke-width: 1.5; rx: 10; ry: 10; }
      .output-box { fill: #e8f5e9; stroke: #388e3c; stroke-width: 1.5; rx: 10; ry: 10; }
      .reward-box { fill: url(#grad3); stroke: #d81b60; stroke-width: 1.5; rx: 15; ry: 15; }
      .rl-box { fill: url(#grad4); stroke: #5e35b1; stroke-width: 1.5; rx: 10; ry: 10; }
      .cot-box { fill: #e0f7fa; stroke: #00acc1; stroke-width: 1; rx: 5; ry: 5; }
      .text-main { font-family: 'Arial', sans-serif; font-size: 14px; fill: #333; text-anchor: middle; }
      .text-title { font-family: 'Georgia', serif; font-size: 22px; font-weight: bold; fill: #1a237e; text-anchor: middle; }
      .text-subtitle { font-family: 'Arial', sans-serif; font-size: 16px; font-weight: bold; fill: #0d47a1; text-anchor: middle; }
      .text-small { font-family: 'Arial', sans-serif; font-size: 11px; fill: #555; text-anchor: middle; }
      .text-code { font-family: 'Courier New', monospace; font-size: 12px; fill: #333; text-anchor: middle; }
      .arrow { stroke: #555; stroke-width: 1.5; marker-end: url(#arrowhead); fill: none; }
      .dashed-arrow { stroke: #777; stroke-width: 1.5; stroke-dasharray: 5, 5; marker-end: url(#arrowhead); fill: none; }
      .group-box { fill: none; stroke: #78909c; stroke-width: 1.5; stroke-dasharray: 6, 4; rx: 15; ry: 15; }
      .reward-item { fill: #fff; stroke: #ec407a; stroke-width: 1; rx: 5; ry: 5; }
    </style>
  </defs>

  <!-- Title -->
  <text x="500" y="45" class="text-title">T2I-R1 Method: Reinforcing Generation via Bi-Level CoT & GRPO</text>

  <!-- Base Model -->
   <rect x="30" y="70" width="200" height="50" class="rl-box" fill="#e8eaf6" stroke="#3f51b5"/>
   <text x="130" y="100" class="text-main">Base Model: ULM</text>
   <text x="130" y="115" class="text-small">(e.g., Janus-Pro)</text>

  <!-- Input Prompt -->
  <rect x="350" y="70" width="300" height="50" class="input-box" />
  <text x="500" y="95" class="text-main" font-weight="bold">Input: Image Prompt (p)</text>
  <text x="500" y="110" class="text-small">+ Reasoning Instruction</text>

  <!-- Generation Process Container -->
  <rect x="20" y="140" width="960" height="250" class="process-box" rx="15" ry="15"/>
  <text x="500" y="165" class="text-subtitle">Bi-Level CoT Generation (Using ULM œÄŒ∏old)</text>

  <!-- Step 1: Semantic-level CoT -->
  <g transform="translate(50, 190)">
    <rect x="0" y="0" width="400" height="100" class="cot-box" />
    <text x="200" y="25" class="text-main" font-weight="bold">1. Semantic-level CoT (s)</text>
    <text x="200" y="50" class="text-small">ULM generates textual reasoning/planning</text>
    <text x="200" y="65" class="text-small">"How does the whole image look like?"</text>
    <text x="200" y="85" class="text-code">s = {s1, s2, ..., s|s|}</text>
  </g>

  <!-- Step 2: Token-level CoT -->
   <g transform="translate(550, 190)">
     <rect x="0" y="0" width="400" height="150" class="cot-box" />
     <text x="200" y="25" class="text-main" font-weight="bold">2. Token-level CoT (t)</text>
     <text x="200" y="50" class="text-small">Conditioned on Prompt (p) + Semantic CoT (s)</text>
     <text x="200" y="65" class="text-small">ULM generates image tokens patch-by-patch</text>
     <text x="200" y="80" class="text-small">"How does the next patch look like?"</text>
     <text x="200" y="100" class="text-code">t = {t1, t2, ..., tM}</text>
     <rect x="100" y="110" width="200" height="30" class="output-box" />
     <text x="200" y="130" class="text-main">Image Decoder (D)</text>
   </g>

  <!-- Arrows within Generation -->
  <path d="M 500 120 V 140" class="arrow" />
  <path d="M 450 240 H 550" class="arrow" />
  <text x="500" y="245" class="text-small">(Pass s)</text>
  <path d="M 750 305 V 340" class="arrow" /> <!-- Token CoT to Decoder -->

  <!-- Group Generation Box -->
   <rect x="20" y="400" width="960" height="210" class="group-box" />
   <text x="500" y="420" class="text-main" font-style="italic">Generate G responses {oi = (si, ti)} ‚Üí {Ii} per prompt for Group Computation</text>

   <!-- Generated Image Output -->
   <rect x="400" y="440" width="200" height="50" class="output-box" />
   <text x="500" y="470" class="text-main">Generated Image (Ii)</text>

  <!-- Reward Ensemble -->
  <rect x="50" y="500" width="900" height="100" class="reward-box" />
  <text x="500" y="520" class="text-subtitle" fill="#c2185b">Ensemble of Vision Expert Rewards</text>
  <g transform="translate(70, 540)">
      <rect x="0" y="0" width="190" height="45" class="reward-item"/>
      <text x="95" y="20" class="text-main">HPM</text>
      <text x="95" y="35" class="text-small">(Aesthetics, Alignment)</text>
  </g>
  <g transform="translate(280, 540)">
      <rect x="0" y="0" width="190" height="45" class="reward-item"/>
      <text x="95" y="20" class="text-main">Object Detector</text>
      <text x="95" y="35" class="text-small">(Existence, Relations)</text>
  </g>
   <g transform="translate(490, 540)">
      <rect x="0" y="0" width="190" height="45" class="reward-item"/>
      <text x="95" y="20" class="text-main">VQA Model</text>
      <text x="95" y="35" class="text-small">(Attributes)</text>
  </g>
   <g transform="translate(700, 540)">
      <rect x="0" y="0" width="190" height="45" class="reward-item"/>
      <text x="95" y="20" class="text-main">ORM</text>
      <text x="95" y="35" class="text-small">(Prompt Alignment)</text>
  </g>
  <text x="500" y="590" class="text-main">Output: Averaged Rewards (R1, R2, ..., RG)</text>

  <!-- RL Optimization -->
  <rect x="150" y="620" width="700" height="160" class="rl-box" />
  <text x="500" y="640" class="text-subtitle" fill="#5e35b1">BiCoT-GRPO Optimization Step</text>
  <text x="500" y="665" class="text-main">1. Compute Group-Relative Advantages (Ai)</text>
  <text x="500" y="680" class="text-small">Normalize rewards within the group G</text>
  <text x="500" y="700" class="text-main">2. Calculate Policy Ratio ri,j(Œ∏) for oi=(si, ti)</text>
  <text x="500" y="715" class="text-small">Ratio = œÄŒ∏(oi,j | ...) / œÄŒ∏old(oi,j | ...)</text>
  <text x="500" y="735" class="text-main">3. Update ULM (œÄŒ∏) via GRPO Objective (Eq. 2)</text>
  <text x="500" y="750" class="text-small">Maximize: Clipped Advantage Term - Œ≤ * DKL(œÄŒ∏ || œÄref)</text>

  <!-- Arrows for RL loop -->
   <path d="M 750 340 Q 800 370, 500 435" class="dashed-arrow"/> <!-- Image to Group -->
   <path d="M 500 490 V 500" class="arrow"/> <!-- Image to Reward -->
   <path d="M 500 600 V 620" class="arrow"/> <!-- Reward to RL -->
   <!-- Feedback loop -->
    <path d="M 150 690 H 80 Q 30 690, 30 360 V 120" fill="none" class="dashed-arrow"/>
    <text x="60" y="450" class="text-small" transform="rotate(-90 60 450)">Update ULM (Œ∏)</text>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Semantic-level CoT and Token-level CoT">
                        <div class="quiz-question">1. According to the paper, what are the two distinct levels of Chain-of-Thought (CoT) reasoning identified for enhancing text-to-image generation?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Global-level CoT and Local-level CoT">Global-level CoT and Local-level CoT</div><div class="quiz-choice" data-value="Semantic-level CoT and Token-level CoT">Semantic-level CoT and Token-level CoT</div><div class="quiz-choice" data-value="Textual CoT and Visual CoT">Textual CoT and Visual CoT</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="BiCoT-GRPO">
                        <div class="quiz-question">2. What is the name of the reinforcement learning framework introduced in the paper to jointly optimize both levels of CoT?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="DualCoT-PPO">DualCoT-PPO</div><div class="quiz-choice" data-value="BiCoT-GRPO">BiCoT-GRPO</div><div class="quiz-choice" data-value="Ensemble-RL">Ensemble-RL</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="T2I-CompBench and WISE">
                        <div class="quiz-question">3. Which benchmarks did T2I-R1 achieve significant performance improvements on compared to baseline and state-of-the-art models?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="MS COCO and Visual Genome">MS COCO and Visual Genome</div><div class="quiz-choice" data-value="T2I-CompBench and WISE">T2I-CompBench and WISE</div><div class="quiz-choice" data-value="CLEVR and VQA">CLEVR and VQA</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-04-30</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2504.21850" target="_blank">http://arxiv.org/pdf/2504.21850</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on improving multimodal large language models' ability to handle complex visual-language tasks through a novel compositional training approach.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on previous visual instruction tuning research but proposes a new approach called COMPACT that explicitly controls for compositional complexity in training data rather than just scaling data volume.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses how current multimodal models struggle with complex tasks requiring multiple capabilities simultaneously (like recognizing objects, counting them, and understanding spatial relationships together).</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors develop a data generation pipeline that creates training examples combining 10 atomic visual capabilities into progressively more complex tasks (k=1,2,3 capabilities), using Gemini for generation and verification.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Using only 10% of standard training data, COMPACT achieved comparable or better performance than full-scale visual instruction tuning, with particularly strong improvements on complex tasks (83.3% improvement on MMStar and 94.0% on MM-Vet for tasks requiring 4+ capabilities).</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>COMPACT: COMPositional Atomic-to-Complex Visual Capability Tuning</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">

  <!-- Define styles -->
  <style>
    .title { font-family: Arial, sans-serif; font-size: 24px; font-weight: bold; text-anchor: middle; fill: #2c3e50; }
    .step-box { fill: #e0f2f7; stroke: #0277bd; stroke-width: 1.5; rx: 8; ry: 8; }
    .step-text { font-family: Arial, sans-serif; font-size: 14px; text-anchor: middle; fill: #333; }
    .sub-step-box { fill: #ffffff; stroke: #757575; stroke-width: 1; rx: 5; ry: 5; }
    .sub-step-text { font-family: Arial, sans-serif; font-size: 12px; text-anchor: middle; fill: #555; }
    .input-box { fill: #fff9c4; stroke: #fbc02d; stroke-width: 1; rx: 5; ry: 5; }
    .output-box { fill: #c8e6c9; stroke: #388e3c; stroke-width: 1; rx: 5; ry: 5; }
    .connector-line { stroke: #90a4ae; stroke-width: 2; marker-end: url(#arrowhead); }
    .connector-line-thin { stroke: #b0bec5; stroke-width: 1; }
    .highlight-box { fill: #ffe0b2; stroke: #ef6c00; stroke-width: 1.5; rx: 8; ry: 8; }
    .highlight-text { font-family: Arial, sans-serif; font-size: 13px; font-weight: bold; text-anchor: middle; fill: #c65100; }
    .capability-box { fill: #d1c4e9; stroke: #5e35b1; stroke-width: 1; rx: 4; ry: 4; }
    .capability-text { font-family: Arial, sans-serif; font-size: 11px; text-anchor: middle; fill: #4527a0; }
    .verification-box { fill: #ffcdd2; stroke: #c62828; stroke-width: 1.5; shape-rendering: geometricPrecision; } /* Diamond-like shape */
    .verification-text { font-family: Arial, sans-serif; font-size: 12px; text-anchor: middle; fill: #b71c1c; }
    .group-box { fill: none; stroke: #0277bd; stroke-width: 2; stroke-dasharray: 5,5; rx: 15; ry: 15; }
  </style>

  <!-- Define arrowhead marker -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#90a4ae" />
    </marker>
  </defs>

  <!-- Title -->
  <text x="500" y="40" class="title">COMPACT: Workflow for Compositional Visual Capability Tuning</text>

  <!-- Group Box for Data Generation -->
  <rect x="50" y="70" width="900" height="450" class="group-box"/>
  <text x="500" y="90" class="step-text" style="font-weight:bold; fill:#0277bd;">COMPACT Data Generation Pipeline</text>

  <!-- Step 0: Define Atomic Capabilities -->
  <rect x="70" y="110" width="180" height="80" class="highlight-box"/>
  <text x="160" y="135" class="highlight-text">Define Atomic</text>
  <text x="160" y="155" class="highlight-text">Visual Capabilities (10)</text>
  <text x="160" y="175" class="step-text" style="font-size:10px;">(e.g., Color, Count, Spatial Rel.)</text>

  <!-- Step 1: Capability Sampling -->
  <rect x="300" y="110" width="180" height="140" class="step-box"/>
  <text x="390" y="130" class="step-text" style="font-weight:bold;">Step 1: Capability Sampling</text>
  <rect x="315" y="150" width="150" height="30" class="input-box"/>
  <text x="390" y="170" class="sub-step-text">Input: Image from LLaVA-665K</text>
  <rect x="315" y="190" width="150" height="45" class="sub-step-box"/>
  <text x="390" y="205" class="sub-step-text">Sample k ‚àà {1, 2, 3}</text>
  <text x="390" y="220" class="sub-step-text">atomic capabilities</text>
  <text x="390" y="235" class="sub-step-text">(ensure diversity)</text>

  <!-- Step 2: Conversation Generation -->
  <rect x="530" y="110" width="180" height="140" class="step-box"/>
  <text x="620" y="130" class="step-text" style="font-weight:bold;">Step 2: Conversation Gen.</text>
  <rect x="545" y="150" width="150" height="30" class="input-box"/>
  <text x="620" y="170" class="sub-step-text">Input: Image + Sampled k Caps</text>
  <rect x="545" y="190" width="150" height="45" class="sub-step-box"/>
  <text x="620" y="205" class="sub-step-text">Prompt Gemini-2.0-Flash</text>
  <text x="620" y="220" class="sub-step-text">Generate QA pair integrating</text>
  <text x="620" y="235" class="sub-step-text">exactly k capabilities + Confidence</text>

  <!-- Step 3: Quality Verification -->
  <rect x="760" y="110" width="180" height="140" class="step-box"/>
  <text x="850" y="130" class="step-text" style="font-weight:bold;">Step 3: Quality Verification</text>
  <rect x="775" y="150" width="150" height="30" class="input-box"/>
  <text x="850" y="170" class="sub-step-text">Input: Generated QA + Conf.</text>
    <!-- Verification Diamond -->
  <path d="M 850 190 L 910 220 L 850 250 L 790 220 Z" class="verification-box"/>
  <text x="850" y="215" class="verification-text">Filter & Verify:</text>
  <text x="850" y="230" class="verification-text">Quality, Grounding,</text>
  <text x="850" y="245" class="verification-text">Exact k Capabilities</text>

  <!-- Iteration Loop for Verification -->
  <path d="M 760 210 Q 730 210, 710 210" stroke="#c62828" stroke-width="1.5" fill="none" marker-end="url(#arrowhead-red)"/>
  <text x="735" y="200" class="verification-text" style="font-size:10px;">Reject/Retry</text>
    <marker id="arrowhead-red" markerWidth="8" markerHeight="5.6" refX="0" refY="2.8" orient="auto">
      <polygon points="0 0, 8 2.8, 0 5.6" fill="#c62828" />
    </marker>
  <path d="M 710 210 L 530 210 " stroke="#c62828" stroke-width="1.5" fill="none" />

  <!-- Output of Verification -->
  <rect x="775" y="265" width="150" height="30" class="output-box"/>
  <text x="850" y="285" class="sub-step-text">Output: Verified QA Pairs</text>

  <!-- Connecting Lines (Generation Steps) -->
  <line x1="250" y1="150" x2="300" y2="150" class="connector-line"/>
  <line x1="480" y1="180" x2="530" y2="180" class="connector-line"/>
  <line x1="710" y1="180" x2="760" y2="180" class="connector-line"/>
  <line x1="850" y1="250" x2="850" y2="265" class="connector-line" marker-end="url(#arrowhead)" /> <!-- From Verification to Output -->


  <!-- Atomic Capabilities Visualization -->
  <g transform="translate(100, 300)">
    <text x="150" y="15" class="step-text" style="font-weight:bold;">Atomic Capabilities (Examples)</text>
    <rect x="0" y="30" width="90" height="30" class="capability-box"/> <text x="45" y="50" class="capability-text">Color</text>
    <rect x="100" y="30" width="90" height="30" class="capability-box"/> <text x="145" y="50" class="capability-text">Shape</text>
    <rect x="200" y="30" width="90" height="30" class="capability-box"/> <text x="245" y="50" class="capability-text">Object Rec.</text>
    <rect x="300" y="30" width="90" height="30" class="capability-box"/> <text x="345" y="50" class="capability-text">Action Rec.</text>
    <rect x="400" y="30" width="90" height="30" class="capability-box"/> <text x="445" y="50" class="capability-text">Text Rec.</text>
    <rect x="0" y="70" width="90" height="30" class="capability-box"/> <text x="45" y="90" class="capability-text">Spatial Rec.</text>
    <rect x="100" y="70" width="90" height="30" class="capability-box"/> <text x="145" y="90" class="capability-text">Counting</text>
    <rect x="200" y="70" width="90" height="30" class="capability-box"/> <text x="245" y="90" class="capability-text">Spatial Rel.</text>
    <rect x="300" y="70" width="90" height="30" class="capability-box"/> <text x="345" y="90" class="capability-text">Obj Interaction</text>
    <rect x="400" y="70" width="90" height="30" class="capability-box"/> <text x="445" y="90" class="capability-text">Scene Underst.</text>
  </g>

  <!-- Step 4: Dataset Assembly -->
   <rect x="300" y="380" width="400" height="120" class="step-box" />
   <text x="500" y="400" class="step-text" style="font-weight:bold;">Step 4: Dataset Assembly</text>

   <rect x="320" y="420" width="170" height="60" class="output-box" />
   <text x="405" y="440" class="sub-step-text">COMPACT Generated</text>
   <text x="405" y="455" class="sub-step-text">Compositional Data</text>
   <text x="405" y="470" class="sub-step-text">(e.g., 32K, Balanced k=1,2,3)</text>

   <rect x="510" y="420" width="170" height="60" class="input-box" />
   <text x="595" y="440" class="sub-step-text">Small Subset of</text>
   <text x="595" y="455" class="sub-step-text">LLaVA-665K VIT Data</text>
   <text x="595" y="470" class="sub-step-text">(e.g., 5% for Instruction Following)</text>

   <text x="465" y="450" style="font-size: 24px; fill: #0277bd;">+</text> <!-- Plus Sign -->

   <!-- Connect Verification Output to Assembly Input -->
   <path d="M 850 295 L 850 350 L 405 350 L 405 420" class="connector-line" fill="none" />

  <!-- Output: Final COMPACT Dataset -->
  <rect x="350" y="540" width="300" height="50" class="highlight-box"/>
  <text x="500" y="570" class="highlight-text">Final COMPACT Training Dataset (e.g., 65K)</text>

  <!-- Connect Assembly to Final Dataset -->
  <line x1="500" y1="500" x2="500" y2="540" class="connector-line"/>


  <!-- Training & Evaluation Section -->
  <rect x="50" y="610" width="900" height="150" class="group-box" style="stroke:#388e3c;"/>
  <text x="500" y="630" class="step-text" style="font-weight:bold; fill:#388e3c;">Model Training & Evaluation</text>

  <!-- Training Step -->
  <rect x="150" y="650" width="300" height="90" class="step-box" style="fill: #e8f5e9; stroke:#388e3c;"/>
  <text x="300" y="670" class="step-text" style="font-weight:bold;">Training</text>
  <rect x="170" y="690" width="260" height="40" class="input-box" style="fill:#fff; stroke:#757575;"/>
  <text x="300" y="705" class="sub-step-text">Input: Pre-VIT MLLM Checkpoint</text>
  <text x="300" y="720" class="sub-step-text">(e.g., LLaVA-v1.5-7B)</text>

  <!-- Evaluation Step -->
  <rect x="550" y="650" width="300" height="90" class="step-box" style="fill: #e8f5e9; stroke:#388e3c;"/>
  <text x="700" y="670" class="step-text" style="font-weight:bold;">Evaluation</text>
  <rect x="570" y="690" width="260" height="40" class="output-box" style="fill:#fff; stroke:#757575;"/>
  <text x="700" y="705" class="sub-step-text">Evaluate on Benchmarks</text>
  <text x="700" y="720" class="sub-step-text">(MM-Vet, MMStar, etc.)</text>

  <!-- Connect Final Dataset to Training -->
  <line x1="500" y1="590" x2="300" y2="650" class="connector-line"/>

  <!-- Connect Training to Evaluation -->
  <line x1="450" y1="695" x2="550" y2="695" class="connector-line"/>

</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Their struggle with complex visual tasks that require combining multiple capabilities.">
                        <div class="quiz-question">1. According to the paper, what is a primary limitation of current MLLMs that COMPACT aims to address?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Their inability to process high-resolution images efficiently.">Their inability to process high-resolution images efficiently.</div><div class="quiz-choice" data-value="Their struggle with complex visual tasks that require combining multiple capabilities.">Their struggle with complex visual tasks that require combining multiple capabilities.</div><div class="quiz-choice" data-value="Their lack of diverse visual instruction tuning datasets for simple tasks.">Their lack of diverse visual instruction tuning datasets for simple tasks.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="It explicitly controls and balances the compositional complexity (number of combined capabilities) of training examples.">
                        <div class="quiz-question">2. What is the key distinguishing feature of COMPACT's training data generation compared to traditional Visual Instruction Tuning (VIT)?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It focuses primarily on generating a much larger volume of data.">It focuses primarily on generating a much larger volume of data.</div><div class="quiz-choice long-text" data-value="It explicitly controls and balances the compositional complexity (number of combined capabilities) of training examples.">It explicitly controls and balances the compositional complexity (number of combined capabilities) of training examples.</div><div class="quiz-choice" data-value="It relies exclusively on human annotation for data quality verification.">It relies exclusively on human annotation for data quality verification.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Less than 10%">
                        <div class="quiz-question">3. COMPACT demonstrates improved performance, particularly on complex multi-capability tasks, while using what fraction of the LLaVA-665K VIT data budget?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="More than 50%">More than 50%</div><div class="quiz-choice" data-value="Approximately 25%">Approximately 25%</div><div class="quiz-choice" data-value="Less than 10%">Less than 10%</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
