
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- AI Assistant Styles -->
    <link rel="stylesheet" href="../../css/ai-assistant.css">
    <title>2025-11-20 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-11-20 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/shattered-dark.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-11-18</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2511.14993" target="_blank">http://arxiv.org/pdf/2511.14993</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces Kandinsky 5.0, a family of foundation models for high-resolution image and video generation, consisting of three core models: Image Lite (6B parameters), Video Lite (2B parameters), and Video Pro (19B parameters).</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous diffusion models and flow matching approaches, the paper proposes new architectural optimizations including CrossDiT (Cross-Attention Diffusion Transformer) and NABLA (Neighborhood Adaptive Block-Level Attention) mechanism for efficient video generation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenges of creating high-quality, consistent, and controllable video generation while maintaining computational efficiency and reducing the complexity of attention mechanisms for long video sequences.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The paper implements a multi-stage training pipeline including pre-training, supervised fine-tuning, distillation, and RL-based post-training, along with comprehensive data processing and curation methods. It also introduces optimizations for VAE encoding, memory efficiency, and inference speed.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Through human side-by-side evaluations, the models demonstrated superior or competitive performance against leading models like Sora, Veo, and Wan across key metrics including visual quality, motion dynamics, and prompt adherence. The NABLA mechanism achieved 2.7√ó reduction in training and inference time while maintaining quality.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background gradient -->
  <defs>
    <linearGradient id="bgGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f8ff;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e6f3ff;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="dataGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#ff6b6b;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#ff8e53;stop-opacity:0.8" />
    </linearGradient>
    <linearGradient id="archGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4ecdc4;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#44a08d;stop-opacity:0.8" />
    </linearGradient>
    <linearGradient id="trainGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#6c5ce7;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#a29bfe;stop-opacity:0.8" />
    </linearGradient>
    <linearGradient id="optGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#fd79a8;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#fdcb6e;stop-opacity:0.8" />
    </linearGradient>
    <linearGradient id="evalGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#00b894;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#55a3ff;stop-opacity:0.8" />
    </linearGradient>
  </defs>
  
  <rect width="100%" height="100%" fill="url(#bgGrad)"/>
  
  <!-- Title -->
  <text x="500" y="30" font-family="Arial, sans-serif" font-size="24" font-weight="bold" text-anchor="middle" fill="#2d3436">
    Kandinsky 5.0 Model Development Pipeline
  </text>
  
  <!-- Data Processing Pipeline -->
  <rect x="50" y="60" width="180" height="120" rx="10" fill="url(#dataGrad)" stroke="#d63031" stroke-width="2"/>
  <text x="140" y="85" font-family="Arial, sans-serif" font-size="14" font-weight="bold" text-anchor="middle" fill="white">Data Processing</text>
  <text x="140" y="105" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ T2I Dataset (500M images)</text>
  <text x="140" y="120" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ T2V Dataset (250M videos)</text>
  <text x="140" y="135" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ I2I Editing Dataset</text>
  <text x="140" y="150" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ SFT Quality Dataset</text>
  <text x="140" y="165" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Russian Cultural Dataset</text>
  
  <!-- Architecture Design -->
  <rect x="280" y="60" width="180" height="120" rx="10" fill="url(#archGrad)" stroke="#00b894" stroke-width="2"/>
  <text x="370" y="85" font-family="Arial, sans-serif" font-size="14" font-weight="bold" text-anchor="middle" fill="white">Architecture</text>
  <text x="370" y="105" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ CrossDiT Backbone</text>
  <text x="370" y="120" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ NABLA Attention</text>
  <text x="370" y="135" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Flow Matching</text>
  <text x="370" y="150" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Qwen2.5-VL Encoder</text>
  <text x="370" y="165" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ HunyuanVideo VAE</text>
  
  <!-- Multi-Stage Training -->
  <rect x="510" y="60" width="200" height="120" rx="10" fill="url(#trainGrad)" stroke="#6c5ce7" stroke-width="2"/>
  <text x="610" y="85" font-family="Arial, sans-serif" font-size="14" font-weight="bold" text-anchor="middle" fill="white">Multi-Stage Training</text>
  <text x="610" y="105" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Pre-training (Multi-resolution)</text>
  <text x="610" y="120" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Supervised Fine-tuning (SFT)</text>
  <text x="610" y="135" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Model Souping</text>
  <text x="610" y="150" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Distillation (CFG + TSCD)</text>
  <text x="610" y="165" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ RL-based Post-training</text>
  
  <!-- Optimizations -->
  <rect x="750" y="60" width="180" height="120" rx="10" fill="url(#optGrad)" stroke="#fd79a8" stroke-width="2"/>
  <text x="840" y="85" font-family="Arial, sans-serif" font-size="14" font-weight="bold" text-anchor="middle" fill="white">Optimizations</text>
  <text x="840" y="105" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ VAE Acceleration (2.5x)</text>
  <text x="840" y="120" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ NABLA Sparse Attention</text>
  <text x="840" y="135" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ Memory Optimization</text>
  <text x="840" y="150" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ torch.compile</text>
  <text x="840" y="165" font-family="Arial, sans-serif" font-size="11" text-anchor="middle" fill="white">‚Ä¢ MagCache</text>
  
  <!-- Model Family -->
  <rect x="150" y="220" width="700" height="80" rx="15" fill="#74b9ff" stroke="#0984e3" stroke-width="3"/>
  <text x="500" y="245" font-family="Arial, sans-serif" font-size="18" font-weight="bold" text-anchor="middle" fill="white">Kandinsky 5.0 Model Family</text>
  
  <!-- Image Lite -->
  <rect x="80" y="330" width="160" height="100" rx="10" fill="#81ecec" stroke="#00cec9" stroke-width="2"/>
  <text x="160" y="350" font-family="Arial, sans-serif" font-size="13" font-weight="bold" text-anchor="middle" fill="#2d3436">Image Lite (6B)</text>
  <text x="160" y="370" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#2d3436">‚Ä¢ Text-to-Image</text>
  <text x="160" y="385" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#2d3436">‚Ä¢ Image Editing</text>
  <text x="160" y="400" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#2d3436">‚Ä¢ High Resolution</text>
  <text x="160" y="415" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="#2d3436">‚Ä¢ RL Post-training</text>
  
  <!-- Video Lite -->
  <rect x="270" y="330" width="160" height="100" rx="10" fill="#fd79a8" stroke="#e84393" stroke-width="2"/>
  <text x="350" y="350" font-family="Arial, sans-serif" font-size="13" font-weight="bold" text-anchor="middle" fill="white">Video Lite (2B)</text>
  <text x="350" y="370" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ Text-to-Video</text>
  <text x="350" y="385" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ Image-to-Video</text>
  <text x="350" y="400" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ 10-second clips</text>
  <text x="350" y="415" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ Flash variant</text>
  
  <!-- Video Pro -->
  <rect x="460" y="330" width="160" height="100" rx="10" fill="#a29bfe" stroke="#6c5ce7" stroke-width="2"/>
  <text x="540" y="350" font-family="Arial, sans-serif" font-size="13" font-weight="bold" text-anchor="middle" fill="white">Video Pro (19B)</text>
  <text x="540" y="370" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ High-quality T2V</text>
  <text x="540" y="385" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ Superior dynamics</text>
  <text x="540" y="400" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ Up to 1408p</text>
  <text x="540" y="415" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">‚Ä¢ Flash variant</text>
  
  <!-- Training Stages Detail -->
  <rect x="650" y="330" width="270" height="100" rx="10" fill="#00b894" stroke="#00a085" stroke-width="2"/>
  <text x="785" y="350" font-family="Arial, sans-serif" font-size="13" font-weight="bold" text-anchor="middle" fill="white">Training Stages Pipeline</text>
  <text x="785" y="370" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">1. Multi-resolution Pre-training</text>
  <text x="785" y="385" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">2. Domain-specific SFT + Model Souping</text>
  <text x="785" y="400" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">3. Distillation (CFG ‚Üí TSCD ‚Üí Adversarial)</text>
  <text x="785" y="415" font-family="Arial, sans-serif" font-size="10" text-anchor="middle" fill="white">4. RL-based Post-training (Images)</text>
  
  <!-- Evaluation Results -->
  <rect x="200" y="460" width="600" height="80" rx="15" fill="url(#evalGrad)" stroke="#00b894" stroke-width="3"/>
  <text x="500" y="485" font-family="Arial, sans-serif" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Human Evaluation Results</text>
  <text x="500" y="505" font-family="Arial, sans-serif" font-size="12" text-anchor="middle" fill="white">Superior Visual Quality & Motion Dynamics vs Sora, Veo, Wan models</text>
  <text x="500" y="520" font-family="Arial, sans-serif" font-size="12" text-anchor="middle" fill="white">Competitive Prompt Following ‚Ä¢ State-of-the-art Open Source Performance</text>
  
  <!-- Key Innovations -->
  <rect x="100" y="570" width="800" height="120" rx="15" fill="#636e72" stroke="#2d3436" stroke-width="2"/>
  <text x="500" y="595" font-family="Arial, sans-serif" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Key Technical Innovations</text>
  
  <circle cx="200" cy="620" r="8" fill="#00b894"/>
  <text x="220" y="625" font-family="Arial, sans-serif" font-size="11" fill="white">NABLA: 2.7x speedup with 90% sparsity</text>
  
  <circle cx="500" cy="620" r="8" fill="#fd79a8"/>
  <text x="520" y="625" font-family="Arial, sans-serif" font-size="11" fill="white">Flow Matching + CrossDiT Architecture</text>
  
  <circle cx="200" cy="645" r="8" fill="#fdcb6e"/>
  <text x="220" y="650" font-family="Arial, sans-serif" font-size="11" fill="white">Model Souping for domain expertise</text>
  
  <circle cx="500" cy="645" r="8" fill="#a29bfe"/>
  <text x="520" y="650" font-family="Arial, sans-serif" font-size="11" fill="white">Multi-stage distillation (100‚Üí16 NFEs)</text>
  
  <circle cx="200" cy="670" r="8" fill="#81ecec"/>
  <text x="220" y="675" font-family="Arial, sans-serif" font-size="11" fill="white">Reward-based RL fine-tuning</text>
  
  <circle cx="500" cy="670" r="8" fill="#e17055"/>
  <text x="520" y="675" font-family="Arial, sans-serif" font-size="11" fill="white">Comprehensive data curation pipeline</text>
  
  <!-- Output -->
  <rect x="300" y="720" width="400" height="50" rx="25" fill="#2d3436" stroke="#636e72" stroke-width="2"/>
  <text x="500" y="740" font-family="Arial, sans-serif" font-size="14" font-weight="bold" text-anchor="middle" fill="white">Open Source Release</text>
  <text x="500" y="755" font-family="Arial, sans-serif" font-size="12" text-anchor="middle" fill="white">MIT License ‚Ä¢ Code, Weights & Training Checkpoints</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It dynamically constructs content-aware sparse attention masks for efficient video processing">
                        <div class="quiz-question">1. What is the main innovation of the NABLA mechanism introduced in Kandinsky 5.0?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It reduces training time by compressing video data before processing">It reduces training time by compressing video data before processing</div><div class="quiz-choice" data-value="It dynamically constructs content-aware sparse attention masks for efficient video processing">It dynamically constructs content-aware sparse attention masks for efficient video processing</div><div class="quiz-choice" data-value="It eliminates the need for attention mechanisms entirely in video generation">It eliminates the need for attention mechanisms entirely in video generation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="They conducted human side-by-side evaluations comparing with other models like Sora and Veo">
                        <div class="quiz-question">2. How did the researchers handle the challenge of evaluating video generation quality?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They relied solely on automated metrics like FID scores">They relied solely on automated metrics like FID scores</div><div class="quiz-choice" data-value="They used only internal testing by the development team">They used only internal testing by the development team</div><div class="quiz-choice" data-value="They conducted human side-by-side evaluations comparing with other models like Sora and Veo">They conducted human side-by-side evaluations comparing with other models like Sora and Veo</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It employed a multi-stage approach including pre-training, SFT, distillation, and RL-based post-training">
                        <div class="quiz-question">3. What unique approach did Kandinsky 5.0 take in its training pipeline?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It used only pre-training on a single large dataset">It used only pre-training on a single large dataset</div><div class="quiz-choice long-text" data-value="It employed a multi-stage approach including pre-training, SFT, distillation, and RL-based post-training">It employed a multi-stage approach including pre-training, SFT, distillation, and RL-based post-training</div><div class="quiz-choice" data-value="It focused exclusively on adversarial training methods">It focused exclusively on adversarial training methods</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-paper.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-11-18</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2511.15065" target="_blank">http://arxiv.org/pdf/2511.15065</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> Evaluation of video models' spatial reasoning abilities through maze-solving tasks in the computer vision and artificial intelligence domain.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous research in text-based reasoning (Chain-of-Thought) and video generation models, proposes a novel "reasoning via video" paradigm where reasoning emerges through video frame generation rather than text generation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Addresses the lack of comprehensive benchmarks for evaluating video models' reasoning capabilities and investigates whether video models can perform complex spatial reasoning tasks.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Created VR-Bench, a benchmark with 7,920 procedurally generated maze videos across five maze types, evaluated models through path matching metrics and rule compliance, and used supervised fine-tuning on video models.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Fine-tuned video models outperformed vision-language models, showing 10-20% performance improvement through test-time scaling, strong generalization across different maze types and textures, and superior spatial reasoning capabilities.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <defs>
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f8ff;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e6f3ff;stop-opacity:1" />
    </linearGradient>
    
    <linearGradient id="dataGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4CAF50;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#45a049;stop-opacity:0.8" />
    </linearGradient>
    
    <linearGradient id="methodGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#2196F3;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#1976D2;stop-opacity:0.8" />
    </linearGradient>
    
    <linearGradient id="evalGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#FF9800;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#F57C00;stop-opacity:0.8" />
    </linearGradient>
    
    <linearGradient id="resultGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#9C27B0;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#7B1FA2;stop-opacity:0.8" />
    </linearGradient>
  </defs>
  
  <rect width="100%" height="100%" fill="url(#bgGradient)"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-family="Arial, sans-serif" font-size="24" font-weight="bold" fill="#2c3e50">
    VR-Bench: Video Model Reasoning Evaluation Workflow
  </text>
  
  <!-- Phase 1: Dataset Construction -->
  <rect x="50" y="60" width="200" height="140" rx="10" fill="url(#dataGradient)" stroke="#2e7d32" stroke-width="2"/>
  <text x="150" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="white">
    Dataset Construction
  </text>
  
  <!-- Maze Generation -->
  <rect x="60" y="100" width="180" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#2e7d32" stroke-width="1"/>
  <text x="150" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2e7d32">
    Maze Generation (5 Types)
  </text>
  
  <!-- Video Generation -->
  <rect x="60" y="140" width="180" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#2e7d32" stroke-width="1"/>
  <text x="150" y="160" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2e7d32">
    Video Generation (7,920 videos)
  </text>
  
  <!-- Phase 2: Model Training -->
  <rect x="300" y="60" width="200" height="140" rx="10" fill="url(#methodGradient)" stroke="#1565C0" stroke-width="2"/>
  <text x="400" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="white">
    Model Training
  </text>
  
  <!-- SFT Training -->
  <rect x="310" y="100" width="180" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#1565C0" stroke-width="1"/>
  <text x="400" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#1565C0">
    Supervised Fine-Tuning (SFT)
  </text>
  
  <!-- Base Model -->
  <rect x="310" y="140" width="180" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#1565C0" stroke-width="1"/>
  <text x="400" y="160" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#1565C0">
    Wan2.2-TI2V-5B ‚Üí Wan-R1
  </text>
  
  <!-- Phase 3: Evaluation Framework -->
  <rect x="550" y="60" width="200" height="140" rx="10" fill="url(#evalGradient)" stroke="#E65100" stroke-width="2"/>
  <text x="650" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="white">
    Evaluation Framework
  </text>
  
  <!-- Path Matching -->
  <rect x="560" y="100" width="85" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#E65100" stroke-width="1"/>
  <text x="602" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#E65100">
    Path Matching
  </text>
  
  <!-- Rule Compliance -->
  <rect x="655" y="100" width="85" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#E65100" stroke-width="1"/>
  <text x="697" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#E65100">
    Rule Compliance
  </text>
  
  <!-- Metrics -->
  <rect x="560" y="140" width="180" height="35" rx="5" fill="rgba(255,255,255,0.9)" stroke="#E65100" stroke-width="1"/>
  <text x="650" y="160" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#E65100">
    EM, SR, PR, SD, VLM-Score, MF
  </text>
  
  <!-- Phase 4: Experimental Analysis -->
  <rect x="800" y="60" width="180" height="140" rx="10" fill="url(#resultGradient)" stroke="#6A1B9A" stroke-width="2"/>
  <text x="890" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="16" font-weight="bold" fill="white">
    Experimental Analysis
  </text>
  
  <!-- Baseline Comparison -->
  <rect x="810" y="100" width="160" height="25" rx="5" fill="rgba(255,255,255,0.9)" stroke="#6A1B9A" stroke-width="1"/>
  <text x="890" y="115" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#6A1B9A">
    Baseline Comparison
  </text>
  
  <!-- Test-Time Scaling -->
  <rect x="810" y="130" width="160" height="25" rx="5" fill="rgba(255,255,255,0.9)" stroke="#6A1B9A" stroke-width="1"/>
  <text x="890" y="145" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#6A1B9A">
    Test-Time Scaling
  </text>
  
  <!-- Generalization Tests -->
  <rect x="810" y="160" width="160" height="25" rx="5" fill="rgba(255,255,255,0.9)" stroke="#6A1B9A" stroke-width="1"/>
  <text x="890" y="175" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#6A1B9A">
    Generalization Tests
  </text>
  
  <!-- Detailed Components -->
  
  <!-- Maze Types Section -->
  <rect x="50" y="230" width="450" height="120" rx="10" fill="rgba(76,175,80,0.1)" stroke="#4CAF50" stroke-width="2"/>
  <text x="275" y="255" text-anchor="middle" font-family="Arial, sans-serif" font-size="18" font-weight="bold" fill="#2e7d32">
    Five Maze Types
  </text>
  
  <circle cx="100" cy="280" r="25" fill="#4CAF50" stroke="#2e7d32" stroke-width="2"/>
  <text x="100" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Regular</text>
  
  <circle cx="180" cy="280" r="25" fill="#4CAF50" stroke="#2e7d32" stroke-width="2"/>
  <text x="180" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Irregular</text>
  
  <circle cx="260" cy="280" r="25" fill="#4CAF50" stroke="#2e7d32" stroke-width="2"/>
  <text x="260" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">3D Maze</text>
  
  <circle cx="340" cy="280" r="25" fill="#4CAF50" stroke="#2e7d32" stroke-width="2"/>
  <text x="340" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Trapfield</text>
  
  <circle cx="420" cy="280" r="25" fill="#4CAF50" stroke="#2e7d32" stroke-width="2"/>
  <text x="420" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Sokoban</text>
  
  <!-- Variations -->
  <rect x="60" y="315" width="120" height="25" rx="5" fill="#81C784" stroke="#4CAF50" stroke-width="1"/>
  <text x="120" y="330" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Difficulty Levels
  </text>
  
  <rect x="190" y="315" width="120" height="25" rx="5" fill="#81C784" stroke="#4CAF50" stroke-width="1"/>
  <text x="250" y="330" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Texture Variations
  </text>
  
  <rect x="320" y="315" width="120" height="25" rx="5" fill="#81C784" stroke="#4CAF50" stroke-width="1"/>
  <text x="380" y="330" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Visual Styles
  </text>
  
  <!-- Model Comparison Section -->
  <rect x="530" y="230" width="420" height="120" rx="10" fill="rgba(33,150,243,0.1)" stroke="#2196F3" stroke-width="2"/>
  <text x="740" y="255" text-anchor="middle" font-family="Arial, sans-serif" font-size="18" font-weight="bold" fill="#1565C0">
    Model Categories
  </text>
  
  <!-- VLMs -->
  <rect x="550" y="270" width="120" height="30" rx="5" fill="#2196F3" stroke="#1565C0" stroke-width="2"/>
  <text x="610" y="290" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    VLMs (3 models)
  </text>
  
  <!-- Closed-source Video -->
  <rect x="680" y="270" width="130" height="30" rx="5" fill="#2196F3" stroke="#1565C0" stroke-width="2"/>
  <text x="745" y="290" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Closed Video (6)
  </text>
  
  <!-- Open-source Video -->
  <rect x="820" y="270" width="120" height="30" rx="5" fill="#2196F3" stroke="#1565C0" stroke-width="2"/>
  <text x="880" y="290" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Open Video (2)
  </text>
  
  <!-- Sub-models -->
  <text x="610" y="320" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#1565C0">
    Gemini, GPT-5, Qwen
  </text>
  
  <text x="745" y="320" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#1565C0">
    Veo, Sora-2, Kling, etc.
  </text>
  
  <text x="880" y="320" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#1565C0">
    Wan2.5, Wan2.2
  </text>
  
  <!-- Key Findings Section -->
  <rect x="50" y="380" width="900" height="150" rx="10" fill="rgba(156,39,176,0.1)" stroke="#9C27B0" stroke-width="2"/>
  <text x="500" y="405" text-anchor="middle" font-family="Arial, sans-serif" font-size="18" font-weight="bold" fill="#7B1FA2">
    Key Findings & Insights
  </text>
  
  <!-- Finding 1 -->
  <rect x="70" y="420" width="200" height="45" rx="5" fill="#9C27B0" stroke="#7B1FA2" stroke-width="2"/>
  <text x="170" y="440" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Video > Text Reasoning
  </text>
  <text x="170" y="455" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Better spatial perception
  </text>
  
  <!-- Finding 2 -->
  <rect x="290" y="420" width="200" height="45" rx="5" fill="#9C27B0" stroke="#7B1FA2" stroke-width="2"/>
  <text x="390" y="440" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Test-Time Scaling
  </text>
  <text x="390" y="455" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    10-20% improvement
  </text>
  
  <!-- Finding 3 -->
  <rect x="510" y="420" width="200" height="45" rx="5" fill="#9C27B0" stroke="#7B1FA2" stroke-width="2"/>
  <text x="610" y="440" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    Strong Generalization
  </text>
  <text x="610" y="455" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Difficulty, texture, type
  </text>
  
  <!-- Finding 4 -->
  <rect x="730" y="420" width="200" height="45" rx="5" fill="#9C27B0" stroke="#7B1FA2" stroke-width="2"/>
  <text x="830" y="440" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">
    SFT Effectiveness
  </text>
  <text x="830" y="455" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Elicits reasoning ability
  </text>
  
  <!-- Generalization Analysis -->
  <rect x="70" y="480" width="860" height="40" rx="5" fill="rgba(255,152,0,0.2)" stroke="#FF9800" stroke-width="2"/>
  <text x="500" y="505" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#E65100">
    Generalization Tests: Difficulty ‚Ä¢ Texture ‚Ä¢ Maze Type ‚Ä¢ Test-Time Scaling
  </text>
  
  <!-- Evaluation Metrics Detail -->
  <rect x="50" y="550" width="900" height="100" rx="10" fill="rgba(255,152,0,0.1)" stroke="#FF9800" stroke-width="2"/>
  <text x="500" y="575" text-anchor="middle" font-family="Arial, sans-serif" font-size="18" font-weight="bold" fill="#E65100">
    Comprehensive Evaluation Metrics
  </text>
  
  <!-- Path Metrics -->
  <rect x="70" y="590" width="140" height="50" rx="5" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="140" y="610" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Path Metrics</text>
  <text x="140" y="625" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">EM, SR, PR, SD</text>
  
  <!-- Rule Metrics -->
  <rect x="230" y="590" width="140" height="50" rx="5" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="300" y="610" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Rule Compliance</text>
  <text x="300" y="625" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">VLM-Score, MF</text>
  
  <!-- Chain of Frame -->
  <rect x="390" y="590" width="140" height="50" rx="5" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="460" y="610" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Chain of Frame</text>
  <text x="460" y="625" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Temporal reasoning</text>
  
  <!-- Performance -->
  <rect x="550" y="590" width="140" height="50" rx="5" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="620" y="610" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Performance</text>
  <text x="620" y="625" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Wan-R1 SOTA</text>
  
  <!-- Scaling -->
  <rect x="710" y="590" width="140" height="50" rx="5" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="780" y="610" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Test-Time Scale</text>
  <text x="780" y="625" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">Pass@K analysis</text>
  
  <!-- Final Outcome -->
  <rect x="50" y="680" width="900" height="80" rx="10" fill="rgba(76,175,80,0.2)" stroke="#4CAF50" stroke-width="3"/>
  <text x="500" y="710" text-anchor="middle" font-family="Arial, sans-serif" font-size="20" font-weight="bold" fill="#2e7d32">
    Reasoning via Video: A New Paradigm for Spatial Reasoning
  </text>
  <text x="500" y="735" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" fill="#2e7d32">
    Video models demonstrate superior spatial reasoning through sequential frame generation
  </text>
  <text x="500" y="750" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" fill="#2e7d32">
    Outperforming text-based approaches with better scalability and generalization
  </text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Implementing reasoning through sequential video frame generation">
                        <div class="quiz-question">1. What is the key innovation in the paper's reasoning approach compared to traditional methods?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using text-based chain-of-thought reasoning">Using text-based chain-of-thought reasoning</div><div class="quiz-choice" data-value="Implementing reasoning through sequential video frame generation">Implementing reasoning through sequential video frame generation</div><div class="quiz-choice" data-value="Applying reinforcement learning to maze solving">Applying reinforcement learning to maze solving</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Diverse sampling during inference improved reasoning reliability by 10-20%">
                        <div class="quiz-question">2. What unique phenomenon did researchers discover about video models' performance during testing?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Models performed better in 3D mazes than 2D mazes">Models performed better in 3D mazes than 2D mazes</div><div class="quiz-choice" data-value="Performance decreased with larger sampling sizes">Performance decreased with larger sampling sizes</div><div class="quiz-choice" data-value="Diverse sampling during inference improved reasoning reliability by 10-20%">Diverse sampling during inference improved reasoning reliability by 10-20%</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Uses both path matching metrics and rule compliance evaluation">
                        <div class="quiz-question">3. Which of the following best describes VR-Bench's evaluation approach?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Only evaluates maze completion success rates">Only evaluates maze completion success rates</div><div class="quiz-choice" data-value="Focuses exclusively on visual quality metrics">Focuses exclusively on visual quality metrics</div><div class="quiz-choice" data-value="Uses both path matching metrics and rule compliance evaluation">Uses both path matching metrics and rule compliance evaluation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/diagmonds.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>VisPlay: Self-Evolving Vision-Language Models from Images</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-11-19</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2511.15661" target="_blank">http://arxiv.org/pdf/2511.15661</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper presents VisPlay, a self-evolving reinforcement learning framework for Vision-Language Models (VLMs) that improves visual reasoning capabilities using unlabeled images.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous research in self-evolving language models and reinforcement learning for VLMs, the paper proposes a novel framework that enables VLMs to autonomously improve without human-annotated data through self-play between two roles.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitation of current VLM training approaches that rely heavily on costly human-annotated labels and task-specific heuristics for defining rewards.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The paper implements a self-play framework where a single base VLM alternates between two roles - an Image-Conditioned Questioner that generates challenging questions and a Multimodal Reasoner that produces answers, jointly trained using Group Relative Policy Optimization (GRPO).</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The framework achieved consistent improvements in visual reasoning, compositional generalization, and hallucination reduction across eight benchmarks when tested on three models (Qwen2.5-VL and MiMo-VL), showing effectiveness in enhancing VLM capabilities without human supervision.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>VisPlay: Self-Evolving Vision-Language Models from Images</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <defs>
    <linearGradient id="bg" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f8f9fa;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e9ecef;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="questioner" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4fc3f7;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#29b6f6;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="reasoner" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#81c784;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#66bb6a;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grpo" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#ffb74d;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ffa726;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <rect width="100%" height="100%" fill="url(#bg)"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-family="Arial, sans-serif" font-size="28" font-weight="bold" fill="#2c3e50">
    VisPlay: Self-Evolving Vision-Language Models
  </text>
  
  <!-- Input: Raw Images -->
  <rect x="50" y="80" width="120" height="60" rx="10" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="110" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Raw Images
  </text>
  <text x="110" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    (No Labels)
  </text>
  
  <!-- Base VLM -->
  <rect x="220" y="80" width="140" height="60" rx="10" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
  <text x="290" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Base VLM
  </text>
  <text x="290" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    (Single Model)
  </text>
  
  <!-- Two Roles Split -->
  <rect x="150" y="180" width="180" height="80" rx="15" fill="url(#questioner)" stroke="#1976d2" stroke-width="3"/>
  <text x="240" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Image-Conditioned
  </text>
  <text x="240" y="225" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Questioner
  </text>
  <text x="240" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Generates challenging questions
  </text>
  
  <rect x="450" y="180" width="180" height="80" rx="15" fill="url(#reasoner)" stroke="#388e3c" stroke-width="3"/>
  <text x="540" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Multimodal
  </text>
  <text x="540" y="225" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Reasoner
  </text>
  <text x="540" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Produces silver responses
  </text>
  
  <!-- Question Generation Process -->
  <rect x="100" y="300" width="280" height="60" rx="10" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="240" y="325" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Question Generation with Rewards:
  </text>
  <text x="240" y="345" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    ‚Ä¢ Uncertainty Reward ‚Ä¢ Diversity Regularization ‚Ä¢ Format Constraint
  </text>
  
  <!-- GRPO Training -->
  <rect x="400" y="400" width="200" height="80" rx="15" fill="url(#grpo)" stroke="#e67e22" stroke-width="3"/>
  <text x="500" y="425" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Group Relative Policy
  </text>
  <text x="500" y="445" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Optimization (GRPO)
  </text>
  <text x="500" y="465" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Joint training of both roles
  </text>
  
  <!-- Pseudo-Label Generation -->
  <rect x="650" y="300" width="280" height="60" rx="10" fill="#27ae60" stroke="#229954" stroke-width="2"/>
  <text x="790" y="325" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Pseudo-Label Generation:
  </text>
  <text x="790" y="345" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    ‚Ä¢ Majority Voting ‚Ä¢ Confidence Scoring ‚Ä¢ Informative Filtering
  </text>
  
  <!-- Self-Evolution Loop -->
  <ellipse cx="200" cy="550" rx="120" ry="50" fill="#f39c12" stroke="#d68910" stroke-width="3"/>
  <text x="200" y="540" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Iterative
  </text>
  <text x="200" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Self-Evolution
  </text>
  <text x="200" y="570" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Co-evolution Loop
  </text>
  
  <!-- Evaluation Results -->
  <rect x="450" y="520" width="300" height="80" rx="10" fill="#8e44ad" stroke="#7d3c98" stroke-width="2"/>
  <text x="600" y="545" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Performance Improvements
  </text>
  <text x="600" y="565" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="white">
    ‚Ä¢ Visual Reasoning ‚Ä¢ Compositional Generalization
  </text>
  <text x="600" y="580" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="white">
    ‚Ä¢ Hallucination Reduction ‚Ä¢ Cross-domain Adaptation
  </text>
  
  <!-- Algorithm Steps -->
  <rect x="750" y="450" width="220" height="120" rx="10" fill="#34495e" stroke="#2c3e50" stroke-width="2"/>
  <text x="860" y="470" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Algorithm Steps:
  </text>
  <text x="760" y="490" font-family="Arial, sans-serif" font-size="10" fill="white">
    1. Sample question groups
  </text>
  <text x="760" y="505" font-family="Arial, sans-serif" font-size="10" fill="white">
    2. Compute confidence scores
  </text>
  <text x="760" y="520" font-family="Arial, sans-serif" font-size="10" fill="white">
    3. Calculate rewards
  </text>
  <text x="760" y="535" font-family="Arial, sans-serif" font-size="10" fill="white">
    4. Update via GRPO
  </text>
  <text x="760" y="550" font-family="Arial, sans-serif" font-size="10" fill="white">
    5. Generate curated dataset
  </text>
  
  <!-- Key Innovation Box -->
  <rect x="50" y="650" width="900" height="60" rx="15" fill="#e8f5e8" stroke="#4caf50" stroke-width="3"/>
  <text x="500" y="670" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2e7d32">
    Key Innovation: Self-evolving framework using only raw images without human supervision
  </text>
  <text x="500" y="690" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#388e3c">
    Achieves competitive performance through autonomous question generation and reasoning improvement
  </text>
  
  <!-- Connection Lines -->
  <path d="M 170 110 Q 200 150 240 180" stroke="#34495e" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 320 110 Q 380 150 540 180" stroke="#34495e" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 240 260 Q 240 280 240 300" stroke="#34495e" stroke-width="2" fill="none"/>
  <path d="M 540 260 Q 650 280 790 300" stroke="#34495e" stroke-width="2" fill="none"/>
  <path d="M 380 330 Q 440 360 500 400" stroke="#34495e" stroke-width="2" fill="none"/>
  <path d="M 790 360 Q 650 380 500 400" stroke="#34495e" stroke-width="2" fill="none"/>
  <path d="M 450 440 Q 320 480 200 520" stroke="#34495e" stroke-width="2" fill="none"/>
  <path d="M 600 440 Q 600 480 600 520" stroke="#34495e" stroke-width="2" fill="none"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#34495e"/>
    </marker>
  </defs>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It enables self-improvement without human-annotated data through role-based self-play">
                        <div class="quiz-question">1. What is the main innovation of VisPlay compared to traditional VLM training approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses pre-trained language models to generate questions">It uses pre-trained language models to generate questions</div><div class="quiz-choice" data-value="It enables self-improvement without human-annotated data through role-based self-play">It enables self-improvement without human-annotated data through role-based self-play</div><div class="quiz-choice" data-value="It combines multiple existing VLMs to enhance performance">It combines multiple existing VLMs to enhance performance</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By analyzing the uncertainty in the Multimodal Reasoner's responses">
                        <div class="quiz-question">2. How does the Image-Conditioned Questioner evaluate the difficulty of generated questions?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By comparing with human-rated difficulty scores">By comparing with human-rated difficulty scores</div><div class="quiz-choice" data-value="By measuring the length and complexity of questions">By measuring the length and complexity of questions</div><div class="quiz-choice" data-value="By analyzing the uncertainty in the Multimodal Reasoner's responses">By analyzing the uncertainty in the Multimodal Reasoner's responses</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="A single base model switches between questioning and reasoning roles while progressively improving both capabilities">
                        <div class="quiz-question">3. Which of the following best describes the co-evolution process in VisPlay?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="The model alternates between generating easier and harder questions randomly">The model alternates between generating easier and harder questions randomly</div><div class="quiz-choice" data-value="Two separate models compete against each other to improve performance">Two separate models compete against each other to improve performance</div><div class="quiz-choice long-text" data-value="A single base model switches between questioning and reasoning roles while progressively improving both capabilities">A single base model switches between questioning and reasoning roles while progressively improving both capabilities</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>


    <!-- AI Assistant Scripts - Load in correct order (relative paths for subpages) -->
    <script src="../../js/ai-assistant-constants.js"></script>
    <script src="../../js/ai-assistant-storage.js"></script>
    <script src="../../js/ai-assistant-positioning.js"></script>
    <script src="../../js/ai-assistant-templates.js"></script>
    <script src="../../js/ai-assistant-dom-utils.js"></script>
    <script src="../../js/ai-assistant-config.js"></script>
    <script src="../../js/ai-assistant.js"></script>
</body>
</html>
