
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-21 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042; /* Set the page background color */
            background-image: url('bg.png'); /* Set the page background to bg.png */
            background-size: auto; /* Keep the original size of the background image */
            background-repeat: repeat; /* Repeat the image to fill the page */
        }
        h1 {
            color: #333;
        }
        .paper-card {
            background-color: #f9f9f9; /* Fallback background color */
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
            background-size: auto; /* Keep the original size of the background image */
            background-repeat: repeat; /* Allow the image to repeat to fill the card */
            background-position: center; /* Center the background image */
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url(''); /* Add a semi-transparent white overlay */
            background-blend-mode: overlay; /* Blend the overlay with the background image */
        }
        .paper-card:hover {
            transform: translateY(-5px); /* Lift effect on hover */
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2); /* Shadow on hover */
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s; /* Smooth transition for hover effect */
        }
        .category-chunk:hover {
            transform: translateY(-3px); /* Slightly smaller lift for categories */
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15); /* Slightly smaller shadow for categories */
        }
        .category-chunk:nth-child(1) { /* 1. Topic and Domain */
            background-color: #d3e3fd; /* Blue */
        }
        .category-chunk:nth-child(2) { /* 2. Previous Research and New Ideas */
            background-color: #e6d6fa; /* Purple */
        }
        .category-chunk:nth-child(3) { /* 3. Problem */
            background-color: #d4f8d9; /* Green */
        }
        .category-chunk:nth-child(4) { /* 4. Methods */
            background-color: #ffd7d5; /* Pink */
        }
        .category-chunk:nth-child(5) { /* 5. Results and Evaluation */
            background-color: #d3e3fd; /* Reuse Blue */
        }
    
        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-03-21 Papers</h1>
    
        <div class="paper-card" style="background-image: url('bg/robots.png');">
            <h2>Paper: 1</h2>
            <p><strong>Survey on Evaluation of LLM-based Agents</strong></p>
            <p><strong>Published: </strong>2025-03-20</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.16416" target="_blank">http://arxiv.org/pdf/2503.16416</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper is a survey on the evaluation methodologies for LLM-based agents, covering the AI domain, specifically focusing on autonomous systems that can plan, reason, and interact with environments.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds upon existing research in LLM evaluation and proposes a comprehensive analysis of evaluation benchmarks and frameworks, categorizing them across agent capabilities, application-specific tasks, generalist agent abilities, and development frameworks.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the problem of how to reliably and comprehensively evaluate the increasingly complex capabilities of LLM-based agents in various domains.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors used a systematic literature review and analysis of existing benchmarks, frameworks, and evaluation methodologies for LLM-based agents.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The results are a structured overview of the current state of agent evaluation, identification of trends (like a shift towards realistic and challenging evaluations), and gaps in current research (such as the need for assessing cost-efficiency, safety, and robustness).</div></div>
        </div>
        
        <div class="paper-card" style="background-image: url('bg/black-linen-2.png');">
            <h2>Paper: 2</h2>
            <p><strong>Unleashing Vecset Diffusion Model for Fast Shape Generation</strong></p>
            <p><strong>Published: </strong>2025-03-20</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.16302" target="_blank">http://arxiv.org/pdf/2503.16302</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on fast 3D shape generation within the domain of computer graphics and generative AI.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on the Vecset Diffusion Model (VDM) and diffusion distillation techniques, proposing "FlashVDM" with Progressive Flow Distillation and a lightning vecset decoder for acceleration.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the slow generation speed of high-resolution 3D shapes using the Vecset Diffusion Model (VDM).</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors used Progressive Flow Distillation (guidance distillation, step distillation, adversarial finetuning) for diffusion acceleration and a lightning vecset decoder (Hierarchical Volume Decoding, Adaptive KV Selection, Efficient Decoder Design) for VAE acceleration.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The proposed FlashVDM achieved a 45√ó speedup in VAE decoding and a 32√ó overall speedup, generating high-resolution 3D shapes within 1 second, outperforming existing fast 3D generation methods while maintaining comparable quality to state-of-the-art, slower methods, as evaluated by Volume/Surface IoU, ULIP-I, Uni3D-I, and user studies.</div></div>
        </div>
        
        <div class="paper-card" style="background-image: url('bg/shley-tree-2.png');">
            <h2>Paper: 3</h2>
            <p><strong>Scale-wise Distillation of Diffusion Models</strong></p>
            <p><strong>Published: </strong>2025-03-20</p>
            <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.16397" target="_blank">http://arxiv.org/pdf/2503.16397</a></p>
            <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces Scale-wise Distillation (SWD), a method for accelerating diffusion models in the domain of text-to-image generation.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing diffusion distillation methods and next-scale prediction models, proposing a novel scale-wise distillation framework that progressively increases spatial resolution during sampling.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the computational bottleneck of high-resolution image generation with diffusion models by reducing inference time while maintaining or improving image quality.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a scale-wise distillation approach integrated with distribution matching methods (DMD2), and introduce a novel patch distribution matching (PDM) loss.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> SWD achieves significant speedups compared to full-resolution distilled models, outperforming or competing with state-of-the-art text-to-image models in terms of automated metrics and human preference studies, while being 2.5x-10x faster.</div></div>
        </div>
        

    <!-- Personal Takeaways Section -->
        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <div id="takeaways-container"></div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
