
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-09-10 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            height: 600px; /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%;
            transition: transform 0.5s ease, opacity 0.5s ease;
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow: auto !important;
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖ */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-height: none; /* ÁßªÈô§‰ªª‰ΩïÈ´òÂ∫¶ÈôêÂà∂ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        
        .paper-card p {
            margin: 5px 0;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        @media (max-width: 768px) {
            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }
            
            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            }
        }
    
        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-09-10 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/shley-tree-1.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Parallel-R1: Towards Parallel Thinking via Reinforcement Learning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.07980" target="_blank">http://arxiv.org/pdf/2509.07980</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on developing parallel thinking capabilities in large language models through reinforcement learning for mathematical reasoning tasks.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Previous research relied on supervised fine-tuning with synthetic data, while this paper introduces the first reinforcement learning framework for parallel thinking that can explore multiple reasoning paths simultaneously.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of effectively training language models to use parallel thinking for complex reasoning tasks, as existing methods struggle with exploration and generalization.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors implement a progressive curriculum combining supervised fine-tuning on simple tasks followed by reinforcement learning on harder problems, using specialized reward schemes and both causal and structured model variants.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The approach achieved 8.4% accuracy improvements over sequential thinking models on math benchmarks like MATH, AMC23, and AIME, with a notable 42.9% improvement on AIME25 when using parallel thinking as a mid-training exploration scaffold.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Parallel-R1: Towards Parallel Thinking via Reinforcement Learning</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="#2c3e50">
    Parallel-R1: Reinforcement Learning Framework for Parallel Thinking
  </text>
  
  <!-- Stage 1: Cold Start -->
  <rect x="50" y="80" width="200" height="120" rx="10" fill="#e8f4fd" stroke="#3498db" stroke-width="2"/>
  <text x="150" y="100" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Stage 1: Cold Start</text>
  <text x="150" y="120" text-anchor="middle" font-size="12" fill="#34495e">SFT on Easy Math</text>
  <text x="150" y="135" text-anchor="middle" font-size="12" fill="#34495e">(Parallel-GSM8K)</text>
  <text x="150" y="150" text-anchor="middle" font-size="11" fill="#7f8c8d">Format Learning</text>
  <text x="150" y="165" text-anchor="middle" font-size="11" fill="#7f8c8d">Control Tags Training</text>
  <text x="150" y="180" text-anchor="middle" font-size="11" fill="#7f8c8d">&lt;Parallel&gt; &lt;Path&gt; &lt;Summary&gt;</text>
  
  <!-- Stage 2: RL on Easy Math (Optional) -->
  <rect x="300" y="80" width="180" height="120" rx="10" fill="#fff2e8" stroke="#e67e22" stroke-width="2"/>
  <text x="390" y="100" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Stage 2 (Optional)</text>
  <text x="390" y="120" text-anchor="middle" font-size="12" fill="#34495e">Small-Scale RL</text>
  <text x="390" y="135" text-anchor="middle" font-size="12" fill="#34495e">on GSM8K</text>
  <text x="390" y="150" text-anchor="middle" font-size="11" fill="#7f8c8d">Reward: R_parallel √ó R_acc</text>
  <text x="390" y="165" text-anchor="middle" font-size="11" fill="#7f8c8d">Stabilize Format</text>
  <text x="390" y="180" text-anchor="middle" font-size="11" fill="#7f8c8d">GRPO Algorithm</text>
  
  <!-- Stage 3: RL on General Math -->
  <rect x="530" y="80" width="200" height="120" rx="10" fill="#e8f5e8" stroke="#27ae60" stroke-width="2"/>
  <text x="630" y="100" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Stage 3: Main RL</text>
  <text x="630" y="120" text-anchor="middle" font-size="12" fill="#34495e">Large-Scale RL</text>
  <text x="630" y="135" text-anchor="middle" font-size="12" fill="#34495e">on DAPO Dataset</text>
  <text x="630" y="150" text-anchor="middle" font-size="11" fill="#7f8c8d">Reward: R_accuracy</text>
  <text x="630" y="165" text-anchor="middle" font-size="11" fill="#7f8c8d">Generalize to Hard Tasks</text>
  <text x="630" y="180" text-anchor="middle" font-size="11" fill="#7f8c8d">300 Update Steps</text>
  
  <!-- Data Pipeline -->
  <rect x="50" y="240" width="280" height="100" rx="10" fill="#fdf2e9" stroke="#d35400" stroke-width="2"/>
  <text x="190" y="260" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Simple Data Pipeline</text>
  <text x="190" y="280" text-anchor="middle" font-size="12" fill="#34495e">Zero-shot Prompting on Easy Tasks</text>
  <text x="190" y="295" text-anchor="middle" font-size="11" fill="#7f8c8d">83.6% success on GSM8K vs 0% on DAPO</text>
  <text x="190" y="310" text-anchor="middle" font-size="11" fill="#7f8c8d">Format Check Algorithm</text>
  <text x="190" y="325" text-anchor="middle" font-size="11" fill="#7f8c8d">High-quality Parallel-GSM8K Dataset</text>
  
  <!-- Model Variants -->
  <rect x="380" y="240" width="160" height="100" rx="10" fill="#f4e6ff" stroke="#8e44ad" stroke-width="2"/>
  <text x="460" y="260" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Model Variants</text>
  <text x="460" y="280" text-anchor="middle" font-size="12" fill="#34495e">Parallel-R1-Seen</text>
  <text x="460" y="295" text-anchor="middle" font-size="11" fill="#7f8c8d">(Causal Architecture)</text>
  <text x="460" y="315" text-anchor="middle" font-size="12" fill="#34495e">Parallel-R1-Unseen</text>
  <text x="460" y="330" text-anchor="middle" font-size="11" fill="#7f8c8d">(Structured Architecture)</text>
  
  <!-- Reward Design -->
  <rect x="570" y="240" width="180" height="100" rx="10" fill="#e8f8f5" stroke="#16a085" stroke-width="2"/>
  <text x="660" y="260" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Reward Design</text>
  <text x="660" y="280" text-anchor="middle" font-size="12" fill="#34495e">Accuracy Only (S1)</text>
  <text x="660" y="295" text-anchor="middle" font-size="12" fill="#34495e">Alternating Acc/Parallel (S2)</text>
  <text x="660" y="310" text-anchor="middle" font-size="11" fill="#7f8c8d">80% Accuracy + 20% Parallel</text>
  <text x="660" y="325" text-anchor="middle" font-size="11" fill="#7f8c8d">10-step Windows</text>
  
  <!-- Parallel Thinking Behavior -->
  <rect x="50" y="380" width="300" height="120" rx="10" fill="#fff5f5" stroke="#e74c3c" stroke-width="2"/>
  <text x="200" y="400" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Parallel Thinking Behavior</text>
  <text x="200" y="420" text-anchor="middle" font-size="12" fill="#34495e">1. Exploration Phase</text>
  <text x="200" y="435" text-anchor="middle" font-size="11" fill="#7f8c8d">Generate N independent trajectories</text>
  <text x="200" y="450" text-anchor="middle" font-size="11" fill="#7f8c8d">Multiple reasoning paths</text>
  <text x="200" y="470" text-anchor="middle" font-size="12" fill="#34495e">2. Summary Phase</text>
  <text x="200" y="485" text-anchor="middle" font-size="11" fill="#7f8c8d">Aggregate outcomes and insights</text>
  
  <!-- Learning Dynamics -->
  <rect x="380" y="380" width="240" height="120" rx="10" fill="#f0f8ff" stroke="#3498db" stroke-width="2"/>
  <text x="500" y="400" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Learning Dynamics Evolution</text>
  <text x="500" y="420" text-anchor="middle" font-size="12" fill="#34495e">Early Stage: Computational Exploration</text>
  <text x="500" y="435" text-anchor="middle" font-size="11" fill="#7f8c8d">High-variance strategy to discover solutions</text>
  <text x="500" y="455" text-anchor="middle" font-size="12" fill="#34495e">Late Stage: Multi-perspective Verification</text>
  <text x="500" y="470" text-anchor="middle" font-size="11" fill="#7f8c8d">Risk-averse confirmation of answers</text>
  <text x="500" y="485" text-anchor="middle" font-size="11" fill="#7f8c8d">Relative position increases over training</text>
  
  <!-- Mid-Training Scaffold -->
  <rect x="650" y="380" width="200" height="120" rx="10" fill="#f9f2ff" stroke="#9b59b6" stroke-width="2"/>
  <text x="750" y="400" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Mid-Training Scaffold</text>
  <text x="750" y="420" text-anchor="middle" font-size="12" fill="#34495e">Two-Stage Training</text>
  <text x="750" y="435" text-anchor="middle" font-size="11" fill="#7f8c8d">Stage 1: Forced Exploration</text>
  <text x="750" y="450" text-anchor="middle" font-size="11" fill="#7f8c8d">Stage 2: Exploitation</text>
  <text x="750" y="465" text-anchor="middle" font-size="12" fill="#34495e">Peak: 25.6% on AIME25</text>
  <text x="750" y="480" text-anchor="middle" font-size="11" fill="#7f8c8d">42.9% improvement over baseline</text>
  
  <!-- Evaluation Results -->
  <rect x="200" y="540" width="300" height="100" rx="10" fill="#f0fff0" stroke="#2ecc71" stroke-width="2"/>
  <text x="350" y="560" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Evaluation Results</text>
  <text x="350" y="580" text-anchor="middle" font-size="12" fill="#34495e">8.4% accuracy improvement over sequential</text>
  <text x="350" y="595" text-anchor="middle" font-size="12" fill="#34495e">Benchmarks: MATH, AMC23, AIME24/25</text>
  <text x="350" y="610" text-anchor="middle" font-size="11" fill="#7f8c8d">Parallel-R1-Seen: 48.9 average score</text>
  <text x="350" y="625" text-anchor="middle" font-size="11" fill="#7f8c8d">Consistent gains across benchmarks</text>
  
  <!-- Key Contributions -->
  <rect x="50" y="680" width="900" height="80" rx="10" fill="#fffbf0" stroke="#f39c12" stroke-width="2"/>
  <text x="500" y="700" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Key Contributions</text>
  <text x="200" y="720" text-anchor="middle" font-size="11" fill="#34495e">First RL Framework for Parallel Thinking</text>
  <text x="500" y="720" text-anchor="middle" font-size="11" fill="#34495e">Progressive Curriculum Design</text>
  <text x="800" y="720" text-anchor="middle" font-size="11" fill="#34495e">Learning Dynamics Analysis</text>
  <text x="200" y="735" text-anchor="middle" font-size="11" fill="#7f8c8d">From scratch on general math tasks</text>
  <text x="500" y="735" text-anchor="middle" font-size="11" fill="#7f8c8d">Cold-start ‚Üí Easy ‚Üí Hard progression</text>
  <text x="800" y="735" text-anchor="middle" font-size="11" fill="#7f8c8d">Exploration ‚Üí Verification evolution</text>
  <text x="350" y="750" text-anchor="middle" font-size="11" fill="#34495e">Mid-Training Exploration Scaffold</text>
  <text x="650" y="750" text-anchor="middle" font-size="11" fill="#34495e">Architectural Design Insights</text>
  <text x="350" y="765" text-anchor="middle" font-size="11" fill="#7f8c8d">Temporary exploration unlocks higher ceiling</text>
  <text x="650" y="765" text-anchor="middle" font-size="11" fill="#7f8c8d">Causal vs Structured model comparison</text>
  
  <!-- Flow connections with curved lines -->
  <path d="M 250 140 Q 275 140 300 140" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 480 140 Q 505 140 530 140" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 150 200 Q 150 220 190 240" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 390 200 Q 390 220 460 240" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 630 200 Q 630 220 660 240" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 200 360 Q 200 370 200 380" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 500 360 Q 500 370 500 380" stroke="#666" stroke-width="2" fill="none"/>
  <path d="M 350 520 Q 350 530 350 540" stroke="#666" stroke-width="2" fill="none"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="From exploration to verification">
                        <div class="quiz-question">1. How does the model's parallel thinking strategy evolve throughout the training process according to the paper?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="From verification to exploration">From verification to exploration</div><div class="quiz-choice" data-value="From exploration to verification">From exploration to verification</div><div class="quiz-choice" data-value="Remains constant throughout training">Remains constant throughout training</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Used simple prompting on easier math problems as cold-start data">
                        <div class="quiz-question">2. What unique approach did the authors take to generate training data compared to previous methods?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Used human annotators to create parallel thinking examples">Used human annotators to create parallel thinking examples</div><div class="quiz-choice" data-value="Generated synthetic data using complex multi-stage pipelines">Generated synthetic data using complex multi-stage pipelines</div><div class="quiz-choice" data-value="Used simple prompting on easier math problems as cold-start data">Used simple prompting on easier math problems as cold-start data</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="42.9% improvement on AIME25">
                        <div class="quiz-question">3. What was the most significant improvement achieved when using parallel thinking as a mid-training exploration scaffold?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="42.9% improvement on AIME25">42.9% improvement on AIME25</div><div class="quiz-choice" data-value="8.4% improvement on MATH benchmark">8.4% improvement on MATH benchmark</div><div class="quiz-choice" data-value="25.6% improvement on AMC23">25.6% improvement on AMC23</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>Visual Representation Alignment for Multimodal Large Language Models</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.07979" target="_blank">http://arxiv.org/pdf/2509.07979</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> Visual representation alignment in multimodal large language models (MLLMs) to improve their visual understanding capabilities.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous MLLMs like LLaVA that use text-only supervision, proposes new idea of aligning internal visual representations with pre-trained vision foundation models.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> MLLMs trained with text-only supervision often discard important visual details, leading to poor performance in vision-centric tasks like object counting and spatial reasoning.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Introduces VIRAL (VIsual Representation ALignment), which aligns the internal visual representations of MLLMs with those of pre-trained vision foundation models using cosine similarity-based loss.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Achieved consistent improvements across multiple benchmarks, with significant gains in vision-centric tasks, and demonstrated better training efficiency and robustness in spatial reasoning tasks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Visual Representation Alignment for Multimodal Large Language Models</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="#2c3e50">VIRAL: Visual Representation Alignment for MLLMs</text>
  
  <!-- Problem Identification Section -->
  <rect x="50" y="60" width="200" height="80" rx="10" fill="#e74c3c" opacity="0.8"/>
  <text x="150" y="85" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Problem</text>
  <text x="150" y="105" text-anchor="middle" font-size="10" fill="white">Text-only supervision</text>
  <text x="150" y="120" text-anchor="middle" font-size="10" fill="white">causes visual info loss</text>
  
  <!-- Hypothesis Section -->
  <rect x="300" y="60" width="200" height="80" rx="10" fill="#f39c12" opacity="0.8"/>
  <text x="400" y="85" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Hypothesis</text>
  <text x="400" y="105" text-anchor="middle" font-size="10" fill="white">Visual representations</text>
  <text x="400" y="120" text-anchor="middle" font-size="10" fill="white">misalign during training</text>
  
  <!-- Validation Section -->
  <rect x="550" y="60" width="200" height="80" rx="10" fill="#9b59b6" opacity="0.8"/>
  <text x="650" y="85" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Validation</text>
  <text x="650" y="105" text-anchor="middle" font-size="10" fill="white">CKNNA similarity</text>
  <text x="650" y="120" text-anchor="middle" font-size="10" fill="white">measurement</text>
  
  <!-- Baseline Method -->
  <rect x="50" y="180" width="180" height="100" rx="10" fill="#34495e" opacity="0.8"/>
  <text x="140" y="205" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Baseline MLLM</text>
  <text x="140" y="225" text-anchor="middle" font-size="10" fill="white">Vision Encoder</text>
  <text x="140" y="240" text-anchor="middle" font-size="10" fill="white">‚Üì</text>
  <text x="140" y="255" text-anchor="middle" font-size="10" fill="white">Projector</text>
  <text x="140" y="270" text-anchor="middle" font-size="10" fill="white">‚Üì</text>
  
  <!-- Residual Connection Experiments -->
  <rect x="280" y="180" width="180" height="100" rx="10" fill="#3498db" opacity="0.8"/>
  <text x="370" y="205" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Residual Connection</text>
  <text x="370" y="225" text-anchor="middle" font-size="10" fill="white">Post-projection: ‚úì</text>
  <text x="370" y="240" text-anchor="middle" font-size="10" fill="white">Pre-projection: ‚úó</text>
  <text x="370" y="255" text-anchor="middle" font-size="10" fill="white">Need better design</text>
  
  <!-- VIRAL Core Method -->
  <rect x="510" y="180" width="220" height="100" rx="10" fill="#27ae60" opacity="0.9"/>
  <text x="620" y="205" text-anchor="middle" font-size="14" font-weight="bold" fill="white">VIRAL Method</text>
  <text x="620" y="225" text-anchor="middle" font-size="11" fill="white">Visual Representation</text>
  <text x="620" y="240" text-anchor="middle" font-size="11" fill="white">Alignment Loss</text>
  <text x="620" y="255" text-anchor="middle" font-size="10" fill="white">L_VRA = -1/N Œ£ sim(P_œÄ(e^img_‚Ñì), y_i)</text>
  
  <!-- VFM Selection -->
  <rect x="780" y="180" width="180" height="100" rx="10" fill="#e67e22" opacity="0.8"/>
  <text x="870" y="205" text-anchor="middle" font-size="12" font-weight="bold" fill="white">VFM Teachers</text>
  <text x="870" y="225" text-anchor="middle" font-size="10" fill="white">DINOv2 (Best)</text>
  <text x="870" y="240" text-anchor="middle" font-size="10" fill="white">SAM, DAv2</text>
  <text x="870" y="255" text-anchor="middle" font-size="10" fill="white">RADIO, CLIP</text>
  
  <!-- Architecture Details -->
  <rect x="50" y="320" width="280" height="120" rx="10" fill="#8e44ad" opacity="0.7"/>
  <text x="190" y="345" text-anchor="middle" font-size="12" font-weight="bold" fill="white">VIRAL Architecture</text>
  <text x="190" y="365" text-anchor="middle" font-size="10" fill="white">Input Image ‚Üí Vision Encoder</text>
  <text x="190" y="380" text-anchor="middle" font-size="10" fill="white">‚Üì</text>
  <text x="190" y="395" text-anchor="middle" font-size="10" fill="white">Projector ‚Üí LLM Layer ‚Ñì</text>
  <text x="190" y="410" text-anchor="middle" font-size="10" fill="white">‚Üì</text>
  <text x="190" y="425" text-anchor="middle" font-size="10" fill="white">Align with VFM features</text>
  
  <!-- Layer Analysis -->
  <rect x="370" y="320" width="200" height="120" rx="10" fill="#16a085" opacity="0.7"/>
  <text x="470" y="345" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Layer Analysis</text>
  <text x="470" y="365" text-anchor="middle" font-size="10" fill="white">Target: Layer 16/32</text>
  <text x="470" y="380" text-anchor="middle" font-size="10" fill="white">Middle layers crucial</text>
  <text x="470" y="395" text-anchor="middle" font-size="10" fill="white">for visual understanding</text>
  <text x="470" y="410" text-anchor="middle" font-size="10" fill="white">Single layer > Multi-layer</text>
  
  <!-- Training Setup -->
  <rect x="610" y="320" width="200" height="120" rx="10" fill="#c0392b" opacity="0.7"/>
  <text x="710" y="345" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Training Setup</text>
  <text x="710" y="365" text-anchor="middle" font-size="10" fill="white">Total Loss:</text>
  <text x="710" y="380" text-anchor="middle" font-size="10" fill="white">L_total = L_LM + ŒªL_VRA</text>
  <text x="710" y="395" text-anchor="middle" font-size="10" fill="white">Œª = 0.5</text>
  <text x="710" y="410" text-anchor="middle" font-size="10" fill="white">Cosine similarity objective</text>
  
  <!-- Evaluation -->
  <rect x="50" y="480" width="280" height="100" rx="10" fill="#2980b9" opacity="0.8"/>
  <text x="190" y="505" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Evaluation Benchmarks</text>
  <text x="190" y="525" text-anchor="middle" font-size="10" fill="white">Vision-centric: CV-Bench2D, MMVP</text>
  <text x="190" y="540" text-anchor="middle" font-size="10" fill="white">Hallucination: POPE</text>
  <text x="190" y="555" text-anchor="middle" font-size="10" fill="white">General: MME, MMStar</text>
  
  <!-- Results -->
  <rect x="370" y="480" width="280" height="100" rx="10" fill="#27ae60" opacity="0.8"/>
  <text x="510" y="505" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Key Results</text>
  <text x="510" y="525" text-anchor="middle" font-size="10" fill="white">Consistent improvements across tasks</text>
  <text x="510" y="540" text-anchor="middle" font-size="10" fill="white">Better spatial reasoning</text>
  <text x="510" y="555" text-anchor="middle" font-size="10" fill="white">Faster convergence</text>
  
  <!-- Analysis -->
  <rect x="690" y="480" width="260" height="100" rx="10" fill="#f39c12" opacity="0.8"/>
  <text x="820" y="505" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Analysis</text>
  <text x="820" y="525" text-anchor="middle" font-size="10" fill="white">Attention maps more focused</text>
  <text x="820" y="540" text-anchor="middle" font-size="10" fill="white">Better token permutation sensitivity</text>
  <text x="820" y="555" text-anchor="middle" font-size="10" fill="white">Structured visual representations</text>
  
  <!-- Key Contributions -->
  <rect x="200" y="620" width="600" height="120" rx="15" fill="#8e44ad" opacity="0.9"/>
  <text x="500" y="645" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Key Contributions</text>
  <text x="500" y="670" text-anchor="middle" font-size="11" fill="white">1. Identified visual representation misalignment in MLLMs</text>
  <text x="500" y="690" text-anchor="middle" font-size="11" fill="white">2. Proposed VIRAL: Simple yet effective regularization strategy</text>
  <text x="500" y="710" text-anchor="middle" font-size="11" fill="white">3. Demonstrated consistent improvements across benchmarks</text>
  <text x="500" y="730" text-anchor="middle" font-size="11" fill="white">4. Comprehensive ablation studies validating design choices</text>
  
  <!-- Flow indicators -->
  <circle cx="150" cy="150" r="3" fill="#2c3e50"/>
  <circle cx="400" cy="150" r="3" fill="#2c3e50"/>
  <circle cx="650" cy="150" r="3" fill="#2c3e50"/>
  
  <circle cx="250" cy="230" r="3" fill="#2c3e50"/>
  <circle cx="480" cy="230" r="3" fill="#2c3e50"/>
  <circle cx="750" cy="230" r="3" fill="#2c3e50"/>
  
  <circle cx="350" cy="380" r="3" fill="#2c3e50"/>
  <circle cx="590" cy="380" r="3" fill="#2c3e50"/>
  
  <circle cx="350" cy="530" r="3" fill="#2c3e50"/>
  <circle cx="670" cy="530" r="3" fill="#2c3e50"/>
  
  <circle cx="500" cy="600" r="3" fill="#2c3e50"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Loss of fine-grained visual details during text-only supervision">
                        <div class="quiz-question">1. What is the main limitation of current multimodal large language models that VIRAL aims to address?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Slow processing speed of visual inputs">Slow processing speed of visual inputs</div><div class="quiz-choice" data-value="Loss of fine-grained visual details during text-only supervision">Loss of fine-grained visual details during text-only supervision</div><div class="quiz-choice" data-value="High computational requirements for training">High computational requirements for training</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By aligning internal representations with pre-trained vision foundation models">
                        <div class="quiz-question">2. How does VIRAL improve visual representation in MLLMs?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By increasing the size of the vision encoder">By increasing the size of the vision encoder</div><div class="quiz-choice" data-value="By adding more visual training data">By adding more visual training data</div><div class="quiz-choice" data-value="By aligning internal representations with pre-trained vision foundation models">By aligning internal representations with pre-trained vision foundation models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Middle layers (around layer 16)">
                        <div class="quiz-question">3. At which layer of the MLLM did the VIRAL alignment show the best performance?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Early layers (1-8)">Early layers (1-8)</div><div class="quiz-choice" data-value="Middle layers (around layer 16)">Middle layers (around layer 16)</div><div class="quiz-choice" data-value="Final layers (24-32)">Final layers (24-32)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/broken-noise.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual
  Search</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.07969" target="_blank">http://arxiv.org/pdf/2509.07969</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on developing a visual language model called Mini-o3 for multi-turn visual search tasks through reinforcement learning and tool-based interactions.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous research in tool-based visual language models like DeepEyes and Chain-of-Focus, it proposes new techniques for scaling up reasoning patterns and interaction turns beyond existing limitations.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitation of existing open-source visual language models that exhibit monotonous reasoning patterns and allow only limited interaction turns, making them inadequate for difficult visual search tasks.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a three-component approach: constructing a Visual Probe Dataset, developing an iterative data collection pipeline for cold-start trajectories, and implementing an over-turn masking strategy in reinforcement learning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Mini-o3 achieved state-of-the-art performance on multiple visual search benchmarks, demonstrating the ability to scale to tens of interaction turns and showing improved accuracy as the number of turns increased, despite being trained with only a 6-turn limit.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual
  Search</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">Mini-o3: Visual Search Workflow</text>
  
  <!-- Phase 1: Data Construction -->
  <rect x="50" y="60" width="280" height="120" rx="10" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="190" y="85" text-anchor="middle" font-size="16" font-weight="bold" fill="#1976d2">Phase 1: Data Construction</text>
  <text x="190" y="105" text-anchor="middle" font-size="12" fill="#424242">Visual Probe Dataset</text>
  <text x="190" y="120" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Small targets</text>
  <text x="190" y="135" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Distractor objects</text>
  <text x="190" y="150" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ High-resolution images</text>
  <text x="190" y="165" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ 4,000 training + 500 test</text>
  
  <!-- Phase 2: Cold-start Data Collection -->
  <rect x="360" y="60" width="280" height="120" rx="10" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="500" y="85" text-anchor="middle" font-size="16" font-weight="bold" fill="#7b1fa2">Phase 2: Cold-start Data</text>
  <text x="500" y="105" text-anchor="middle" font-size="12" fill="#424242">Iterative Data Collection</text>
  <text x="500" y="120" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Few-shot prompting</text>
  <text x="500" y="135" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Diverse reasoning patterns</text>
  <text x="500" y="150" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Multi-turn trajectories</text>
  <text x="500" y="165" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ ~6,000 trajectories</text>
  
  <!-- Phase 3: Base Model -->
  <rect x="670" y="60" width="280" height="120" rx="10" fill="#e8f5e8" stroke="#388e3c" stroke-width="2"/>
  <text x="810" y="85" text-anchor="middle" font-size="16" font-weight="bold" fill="#388e3c">Base Model</text>
  <text x="810" y="105" text-anchor="middle" font-size="12" fill="#424242">Qwen2.5-VL-7B-Instruct</text>
  <text x="810" y="120" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Vision-Language Model</text>
  <text x="810" y="135" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Multi-modal capabilities</text>
  <text x="810" y="150" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Image tool integration</text>
  
  <!-- Training Phase 1: SFT -->
  <rect x="150" y="220" width="250" height="100" rx="10" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="275" y="245" text-anchor="middle" font-size="16" font-weight="bold" fill="#f57c00">Supervised Fine-Tuning</text>
  <text x="275" y="265" text-anchor="middle" font-size="12" fill="#424242">Cold-start Initialization</text>
  <text x="275" y="280" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Multi-turn tool use</text>
  <text x="275" y="295" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ 3 epochs training</text>
  <text x="275" y="310" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Learning rate: 1e-5</text>
  
  <!-- Training Phase 2: RLVR -->
  <rect x="450" y="220" width="250" height="100" rx="10" fill="#fce4ec" stroke="#c2185b" stroke-width="2"/>
  <text x="575" y="245" text-anchor="middle" font-size="16" font-weight="bold" fill="#c2185b">Reinforcement Learning</text>
  <text x="575" y="265" text-anchor="middle" font-size="12" fill="#424242">GRPO + Over-turn Masking</text>
  <text x="575" y="280" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Verifiable rewards</text>
  <text x="575" y="295" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ 6 turns training limit</text>
  <text x="575" y="310" text-anchor="middle" font-size="11" fill="#666">‚Ä¢ Test-time scaling</text>
  
  <!-- Core Components -->
  <rect x="100" y="360" width="180" height="80" rx="8" fill="#e1f5fe" stroke="#0277bd" stroke-width="2"/>
  <text x="190" y="385" text-anchor="middle" font-size="14" font-weight="bold" fill="#0277bd">Thought Generation</text>
  <text x="190" y="405" text-anchor="middle" font-size="11" fill="#666">Internal reasoning</text>
  <text x="190" y="420" text-anchor="middle" font-size="11" fill="#666">Trial-and-error patterns</text>
  
  <rect x="310" y="360" width="180" height="80" rx="8" fill="#f1f8e9" stroke="#689f38" stroke-width="2"/>
  <text x="400" y="385" text-anchor="middle" font-size="14" font-weight="bold" fill="#689f38">Action Space</text>
  <text x="400" y="405" text-anchor="middle" font-size="11" fill="#666">Grounding + Answer</text>
  <text x="400" y="420" text-anchor="middle" font-size="11" fill="#666">bbox_2d parameters</text>
  
  <rect x="520" y="360" width="180" height="80" rx="8" fill="#fff8e1" stroke="#ffa000" stroke-width="2"/>
  <text x="610" y="385" text-anchor="middle" font-size="14" font-weight="bold" fill="#ffa000">Observation</text>
  <text x="610" y="405" text-anchor="middle" font-size="11" fill="#666">Cropped image patches</text>
  <text x="610" y="420" text-anchor="middle" font-size="11" fill="#666">Environmental feedback</text>
  
  <!-- Key Innovation -->
  <rect x="750" y="360" width="200" height="80" rx="8" fill="#ffebee" stroke="#d32f2f" stroke-width="2"/>
  <text x="850" y="385" text-anchor="middle" font-size="14" font-weight="bold" fill="#d32f2f">Over-turn Masking</text>
  <text x="850" y="405" text-anchor="middle" font-size="11" fill="#666">Prevents early stopping</text>
  <text x="850" y="420" text-anchor="middle" font-size="11" fill="#666">Enables test-time scaling</text>
  
  <!-- Inference Process -->
  <rect x="200" y="480" width="600" height="120" rx="10" fill="#f5f5f5" stroke="#424242" stroke-width="2"/>
  <text x="500" y="505" text-anchor="middle" font-size="16" font-weight="bold" fill="#424242">Multi-turn Inference Loop</text>
  
  <circle cx="280" cy="540" r="25" fill="#4fc3f7" stroke="#0277bd" stroke-width="2"/>
  <text x="280" y="545" text-anchor="middle" font-size="11" fill="#fff">Think</text>
  
  <circle cx="400" cy="540" r="25" fill="#81c784" stroke="#388e3c" stroke-width="2"/>
  <text x="400" y="545" text-anchor="middle" font-size="11" fill="#fff">Act</text>
  
  <circle cx="520" cy="540" r="25" fill="#ffb74d" stroke="#f57c00" stroke-width="2"/>
  <text x="520" y="545" text-anchor="middle" font-size="11" fill="#fff">Observe</text>
  
  <circle cx="640" cy="540" r="25" fill="#f06292" stroke="#c2185b" stroke-width="2"/>
  <text x="640" y="545" text-anchor="middle" font-size="11" fill="#fff">Loop</text>
  
  <text x="500" y="580" text-anchor="middle" font-size="12" fill="#666">Iterative until answer or turn limit (up to 32 turns at test time)</text>
  
  <!-- Results -->
  <rect x="150" y="640" width="300" height="100" rx="10" fill="#e8f5e8" stroke="#4caf50" stroke-width="2"/>
  <text x="300" y="665" text-anchor="middle" font-size="16" font-weight="bold" fill="#4caf50">Performance Results</text>
  <text x="300" y="685" text-anchor="middle" font-size="12" fill="#424242">VisualProbe-Hard: 48.0%</text>
  <text x="300" y="700" text-anchor="middle" font-size="11" fill="#666">State-of-the-art on visual search</text>
  <text x="300" y="715" text-anchor="middle" font-size="11" fill="#666">Deep reasoning trajectories</text>
  <text x="300" y="730" text-anchor="middle" font-size="11" fill="#666">Test-time turn scaling</text>
  
  <!-- Key Features -->
  <rect x="500" y="640" width="300" height="100" rx="10" fill="#f3e5f5" stroke="#9c27b0" stroke-width="2"/>
  <text x="650" y="665" text-anchor="middle" font-size="16" font-weight="bold" fill="#9c27b0">Key Capabilities</text>
  <text x="650" y="685" text-anchor="middle" font-size="12" fill="#424242">Multi-turn Visual Search</text>
  <text x="650" y="700" text-anchor="middle" font-size="11" fill="#666">Depth-first search patterns</text>
  <text x="650" y="715" text-anchor="middle" font-size="11" fill="#666">Trial-and-error exploration</text>
  <text x="650" y="730" text-anchor="middle" font-size="11" fill="#666">Goal maintenance strategies</text>
  
  <!-- Flow connections -->
  <line x1="190" y1="180" x2="275" y2="220" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="500" y1="180" x2="275" y2="220" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="810" y1="180" x2="575" y2="220" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="275" y1="320" x2="575" y2="320" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="400" y1="320" x2="400" y2="360" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="500" y1="440" x2="500" y2="480" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="500" y1="600" x2="300" y2="640" stroke="#666" stroke-width="2" opacity="0.6"/>
  <line x1="500" y1="600" x2="650" y2="640" stroke="#666" stroke-width="2" opacity="0.6"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Over-turn masking strategy in reinforcement learning">
                        <div class="quiz-question">1. What is the main innovation of Mini-o3's training approach that enables it to scale to many interaction turns at test time despite limited training turns?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using a larger dataset for training">Using a larger dataset for training</div><div class="quiz-choice" data-value="Over-turn masking strategy in reinforcement learning">Over-turn masking strategy in reinforcement learning</div><div class="quiz-choice" data-value="Increasing the model size to 7B parameters">Increasing the model size to 7B parameters</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Trained with 6 turns, scaled to 32 turns">
                        <div class="quiz-question">2. How many interaction turns was Mini-o3 trained with, yet it could scale to during testing?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Trained with 32 turns, scaled to 6 turns">Trained with 32 turns, scaled to 6 turns</div><div class="quiz-choice" data-value="Trained with 12 turns, scaled to 24 turns">Trained with 12 turns, scaled to 24 turns</div><div class="quiz-choice" data-value="Trained with 6 turns, scaled to 32 turns">Trained with 6 turns, scaled to 32 turns</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It featured small targets with many distractor objects">
                        <div class="quiz-question">3. What was a key characteristic of the Visual Probe Dataset that made it especially challenging?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It only contained black and white images">It only contained black and white images</div><div class="quiz-choice" data-value="It had very low resolution images">It had very low resolution images</div><div class="quiz-choice" data-value="It featured small targets with many distractor objects">It featured small targets with many distractor objects</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
