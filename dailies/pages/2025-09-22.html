
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-09-22 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-09-22 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/office.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid
  Vision Tokenizer</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-19</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.16197" target="_blank">http://arxiv.org/pdf/2509.16197</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> A unified multimodal large language model called MANZANO that can both understand and generate visual content, operating in the domain of computer vision and natural language processing.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous unified multimodal models that struggled with performance trade-offs between understanding and generation capabilities, this paper proposes a novel hybrid vision tokenizer that uses a single shared encoder with specialized adapters for both tasks.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the conflict between visual tokenization methods in existing unified models, where discrete tokens work better for generation but continuous embeddings are superior for understanding tasks.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Implements a three-component architecture: a hybrid vision tokenizer (producing both continuous and discrete tokens), a unified LLM decoder (for text/image token prediction), and a diffusion-based image decoder (for pixel generation), trained through a three-stage process of pre-training, continued pre-training, and supervised fine-tuning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Achieves state-of-the-art performance among unified models, with their 3B model matching or exceeding larger models' performance on understanding tasks while maintaining strong generation capabilities, and shows consistent improvements when scaled up to 30B parameters.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid
  Vision Tokenizer</h2>
                        <svg width="100%" viewBox="0 0 1200 900">
  <!-- Background -->
  <rect width="1200" height="900" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="600" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">MANZANO: Unified Multimodal Model Workflow</text>
  
  <!-- Stage 1: Hybrid Image Tokenizer Training -->
  <rect x="50" y="80" width="300" height="200" fill="#e8f4f8" stroke="#3498db" stroke-width="2" rx="10"/>
  <text x="200" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Stage 1: Hybrid Tokenizer Training</text>
  
  <!-- Vision Encoder -->
  <rect x="70" y="120" width="80" height="40" fill="#3498db" rx="5"/>
  <text x="110" y="143" text-anchor="middle" font-size="12" fill="white">Vision Encoder (ViT)</text>
  
  <!-- Continuous Adapter -->
  <rect x="170" y="120" width="70" height="40" fill="#27ae60" rx="5"/>
  <text x="205" y="135" text-anchor="middle" font-size="10" fill="white">Continuous</text>
  <text x="205" y="150" text-anchor="middle" font-size="10" fill="white">Adapter</text>
  
  <!-- Discrete Adapter -->
  <rect x="260" y="120" width="70" height="40" fill="#e74c3c" rx="5"/>
  <text x="295" y="135" text-anchor="middle" font-size="10" fill="white">Discrete</text>
  <text x="295" y="150" text-anchor="middle" font-size="10" fill="white">Adapter</text>
  
  <!-- Small LLM -->
  <rect x="170" y="180" width="100" height="40" fill="#9b59b6" rx="5"/>
  <text x="220" y="203" text-anchor="middle" font-size="12" fill="white">300M LLM Decoder</text>
  
  <!-- Random Sampling -->
  <circle cx="220" cy="240" r="15" fill="#f39c12"/>
  <text x="220" y="245" text-anchor="middle" font-size="10" fill="white">Random</text>
  
  <!-- Stage 2: Unified LLM Training -->
  <rect x="400" y="80" width="350" height="300" fill="#fff3cd" stroke="#f39c12" stroke-width="2" rx="10"/>
  <text x="575" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Stage 2: Unified LLM Training</text>
  
  <!-- Data Types -->
  <rect x="420" y="120" width="90" height="30" fill="#17a2b8" rx="5"/>
  <text x="465" y="138" text-anchor="middle" font-size="10" fill="white">Understanding Data</text>
  
  <rect x="520" y="120" width="90" height="30" fill="#dc3545" rx="5"/>
  <text x="565" y="138" text-anchor="middle" font-size="10" fill="white">Generation Data</text>
  
  <rect x="620" y="120" width="90" height="30" fill="#6c757d" rx="5"/>
  <text x="665" y="138" text-anchor="middle" font-size="10" fill="white">Text-only Data</text>
  
  <!-- Training Phases -->
  <rect x="420" y="170" width="310" height="30" fill="#28a745" rx="5"/>
  <text x="575" y="188" text-anchor="middle" font-size="12" fill="white">Pre-training (1.6T tokens)</text>
  
  <rect x="420" y="210" width="310" height="30" fill="#ffc107" rx="5"/>
  <text x="575" y="228" text-anchor="middle" font-size="12" fill="#2c3e50">Continued Pre-training (83B tokens)</text>
  
  <rect x="420" y="250" width="310" height="30" fill="#fd7e14" rx="5"/>
  <text x="575" y="268" text-anchor="middle" font-size="12" fill="white">Supervised Fine-tuning</text>
  
  <!-- Unified LLM -->
  <rect x="450" y="300" width="250" height="60" fill="#6f42c1" rx="10"/>
  <text x="575" y="325" text-anchor="middle" font-size="14" fill="white">Unified LLM Decoder</text>
  <text x="575" y="345" text-anchor="middle" font-size="12" fill="white">(300M - 30B parameters)</text>
  
  <!-- Stage 3: Image Decoder Training -->
  <rect x="800" y="80" width="300" height="200" fill="#d1ecf1" stroke="#17a2b8" stroke-width="2" rx="10"/>
  <text x="950" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Stage 3: Image Decoder Training</text>
  
  <!-- Progressive Training -->
  <rect x="820" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="850" y="145" text-anchor="middle" font-size="10" fill="white">256x256</text>
  
  <rect x="890" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="920" y="145" text-anchor="middle" font-size="10" fill="white">512x512</text>
  
  <rect x="960" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="990" y="145" text-anchor="middle" font-size="10" fill="white">1024x1024</text>
  
  <rect x="1030" y="130" width="60" height="25" fill="#007bff" rx="3"/>
  <text x="1060" y="145" text-anchor="middle" font-size="10" fill="white">2048x2048</text>
  
  <!-- DiT Architecture -->
  <rect x="850" y="180" width="200" height="40" fill="#20c997" rx="5"/>
  <text x="950" y="203" text-anchor="middle" font-size="12" fill="white">DiT-Air Architecture (0.9B-3.5B)</text>
  
  <!-- Flow Matching -->
  <rect x="850" y="230" width="200" height="30" fill="#6610f2" rx="5"/>
  <text x="950" y="248" text-anchor="middle" font-size="12" fill="white">Flow Matching Pipeline</text>
  
  <!-- Inference Pipeline -->
  <rect x="100" y="420" width="1000" height="200" fill="#f8f9fa" stroke="#6c757d" stroke-width="2" rx="10"/>
  <text x="600" y="445" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Inference Pipeline</text>
  
  <!-- Understanding Task -->
  <rect x="150" y="470" width="350" height="120" fill="#e8f5e8" stroke="#28a745" stroke-width="2" rx="8"/>
  <text x="325" y="490" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Understanding Task</text>
  
  <rect x="170" y="510" width="80" height="30" fill="#28a745" rx="5"/>
  <text x="210" y="528" text-anchor="middle" font-size="10" fill="white">Image Input</text>
  
  <rect x="270" y="510" width="100" height="30" fill="#17a2b8" rx="5"/>
  <text x="320" y="528" text-anchor="middle" font-size="10" fill="white">Continuous Tokens</text>
  
  <rect x="390" y="510" width="80" height="30" fill="#6f42c1" rx="5"/>
  <text x="430" y="528" text-anchor="middle" font-size="10" fill="white">LLM Output</text>
  
  <rect x="250" y="560" width="100" height="20" fill="#ffc107" rx="3"/>
  <text x="300" y="572" text-anchor="middle" font-size="10" fill="#2c3e50">Text Answer</text>
  
  <!-- Generation Task -->
  <rect x="650" y="470" width="350" height="120" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2" rx="8"/>
  <text x="825" y="490" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Generation Task</text>
  
  <rect x="670" y="510" width="80" height="30" fill="#fd7e14" rx="5"/>
  <text x="710" y="528" text-anchor="middle" font-size="10" fill="white">Text Input</text>
  
  <rect x="770" y="510" width="100" height="30" fill="#e74c3c" rx="5"/>
  <text x="820" y="528" text-anchor="middle" font-size="10" fill="white">Discrete Tokens</text>
  
  <rect x="890" y="510" width="80" height="30" fill="#20c997" rx="5"/>
  <text x="930" y="528" text-anchor="middle" font-size="10" fill="white">Image Output</text>
  
  <!-- Key Features -->
  <rect x="200" y="660" width="800" height="180" fill="#f1f3f4" stroke="#495057" stroke-width="2" rx="10"/>
  <text x="600" y="685" text-anchor="middle" font-size="16" font-weight="bold" fill="#2c3e50">Key Design Principles</text>
  
  <!-- Feature boxes -->
  <rect x="220" y="710" width="180" height="60" fill="#e3f2fd" stroke="#1976d2" stroke-width="1" rx="5"/>
  <text x="310" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#1976d2">Unified Semantic Space</text>
  <text x="310" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">Both adapters share</text>
  <text x="310" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">same encoder backbone</text>
  
  <rect x="420" y="710" width="180" height="60" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="1" rx="5"/>
  <text x="510" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#7b1fa2">Simple & Scalable</text>
  <text x="510" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">Standard AR objective</text>
  <text x="510" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">Decoupled components</text>
  
  <rect x="620" y="710" width="180" height="60" fill="#e8f5e8" stroke="#388e3c" stroke-width="1" rx="5"/>
  <text x="710" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#388e3c">Minimal Task Conflict</text>
  <text x="710" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">Hybrid tokenizer reduces</text>
  <text x="710" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">understanding-generation gap</text>
  
  <rect x="820" y="710" width="160" height="60" fill="#fff3e0" stroke="#f57c00" stroke-width="1" rx="5"/>
  <text x="900" y="730" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">Progressive Scaling</text>
  <text x="900" y="750" text-anchor="middle" font-size="10" fill="#2c3e50">300M to 30B LLM</text>
  <text x="900" y="762" text-anchor="middle" font-size="10" fill="#2c3e50">0.9B to 3.5B decoder</text>
  
  <!-- Evaluation Results -->
  <rect x="250" y="790" width="700" height="40" fill="#d4edda" stroke="#155724" stroke-width="2" rx="8"/>
  <text x="600" y="810" text-anchor="middle" font-size="14" font-weight="bold" fill="#155724">Results: SOTA on understanding tasks, competitive generation performance</text>
  <text x="600" y="825" text-anchor="middle" font-size="12" fill="#155724">Especially strong on text-rich benchmarks (DocVQA, ChartQA, OCRBench)</text>
  
  <!-- Connection lines -->
  <line x1="350" y1="180" x2="400" y2="180" stroke="#666" stroke-width="2"/>
  <line x1="750" y1="180" x2="800" y2="180" stroke="#666" stroke-width="2"/>
  <line x1="575" y1="380" x2="325" y2="470" stroke="#28a745" stroke-width="2"/>
  <line x1="575" y1="380" x2="825" y2="470" stroke="#fd7e14" stroke-width="2"/>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A hybrid vision tokenizer with shared encoder and specialized adapters">
                        <div class="quiz-question">1. What is the key innovation in MANZANO's architecture that helps resolve the conflict between understanding and generation tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using two completely separate vision encoders for each task">Using two completely separate vision encoders for each task</div><div class="quiz-choice" data-value="A hybrid vision tokenizer with shared encoder and specialized adapters">A hybrid vision tokenizer with shared encoder and specialized adapters</div><div class="quiz-choice" data-value="Removing the tokenizer entirely and using raw pixel values">Removing the tokenizer entirely and using raw pixel values</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Consistent improvements across both understanding and generation tasks">
                        <div class="quiz-question">2. When scaling up MANZANO from 3B to 30B parameters, what was observed?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Performance decreased due to overfitting">Performance decreased due to overfitting</div><div class="quiz-choice" data-value="Only generation capabilities improved while understanding stayed the same">Only generation capabilities improved while understanding stayed the same</div><div class="quiz-choice" data-value="Consistent improvements across both understanding and generation tasks">Consistent improvements across both understanding and generation tasks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It employs a three-stage process: pre-training, continued pre-training, and supervised fine-tuning">
                        <div class="quiz-question">3. How does MANZANO's training process differ from conventional approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a single-stage training process focused only on generation">It uses a single-stage training process focused only on generation</div><div class="quiz-choice" data-value="It requires no pre-training and starts directly with fine-tuning">It requires no pre-training and starts directly with fine-tuning</div><div class="quiz-choice" data-value="It employs a three-stage process: pre-training, continued pre-training, and supervised fine-tuning">It employs a three-stage process: pre-training, continued pre-training, and supervised fine-tuning</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model
  via Training-Free Guidance</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-18</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.15130" target="_blank">http://arxiv.org/pdf/2509.15130</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on trajectory-controlled video generation using pre-trained video diffusion models, specifically in the domain of 3D/4D computer vision and generative AI.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous work in video diffusion models and trajectory control methods that required model retraining, this paper proposes a novel training-free approach that leverages existing model knowledge.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of achieving precise camera trajectory control in video generation while maintaining high visual quality, without requiring expensive model retraining or fine-tuning.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors develop a three-part framework called WorldForge that includes: Intra-Step Recursive Refinement (IRR) for step-wise trajectory guidance, Flow-Gated Latent Fusion (FLF) for separating motion from appearance features, and Dual-Path Self-Corrective Guidance (DSG) for maintaining visual quality.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The method achieves state-of-the-art performance in both static 3D scene generation and dynamic 4D trajectory control, outperforming existing approaches in terms of FID, CLIP similarity, and trajectory accuracy metrics while requiring no additional training.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model
  via Training-Free Guidance</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="18" font-weight="bold" fill="#2c3e50">WorldForge: Training-Free 3D/4D Video Generation Framework</text>
  
  <!-- Input Section -->
  <rect x="50" y="60" width="120" height="80" rx="10" fill="#e8f4fd" stroke="#3498db" stroke-width="2"/>
  <text x="110" y="90" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Input</text>
  <text x="110" y="110" text-anchor="middle" font-size="10" fill="#34495e">Single Image/</text>
  <text x="110" y="125" text-anchor="middle" font-size="10" fill="#34495e">Video Frame</text>
  
  <!-- 3D Vision Foundation Model -->
  <rect x="220" y="60" width="140" height="80" rx="10" fill="#fff2e8" stroke="#e67e22" stroke-width="2"/>
  <text x="290" y="85" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">3D Vision</text>
  <text x="290" y="100" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">Foundation Model</text>
  <text x="290" y="120" text-anchor="middle" font-size="9" fill="#34495e">Depth + Camera Poses</text>
  
  <!-- Point Cloud Generation -->
  <rect x="410" y="40" width="100" height="50" rx="8" fill="#e8f8f5" stroke="#27ae60" stroke-width="2"/>
  <text x="460" y="60" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Static Point</text>
  <text x="460" y="75" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Cloud</text>
  
  <rect x="410" y="110" width="100" height="50" rx="8" fill="#fdf2e9" stroke="#f39c12" stroke-width="2"/>
  <text x="460" y="130" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Dynamic Point</text>
  <text x="460" y="145" text-anchor="middle" font-size="10" font-weight="bold" fill="#2c3e50">Cloud</text>
  
  <!-- Trajectory Warping -->
  <rect x="560" y="60" width="120" height="80" rx="10" fill="#f4e8fd" stroke="#9b59b6" stroke-width="2"/>
  <text x="620" y="85" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">Trajectory</text>
  <text x="620" y="100" text-anchor="middle" font-size="11" font-weight="bold" fill="#2c3e50">Warping</text>
  <text x="620" y="120" text-anchor="middle" font-size="9" fill="#34495e">Warped Frames + Masks</text>
  
  <!-- Video Diffusion Model -->
  <rect x="50" y="200" width="200" height="100" rx="15" fill="#e8f6f3" stroke="#16a085" stroke-width="3"/>
  <text x="150" y="230" text-anchor="middle" font-size="14" font-weight="bold" fill="#2c3e50">Video Diffusion Model</text>
  <text x="150" y="250" text-anchor="middle" font-size="12" fill="#34495e">(Frozen Weights)</text>
  <text x="150" y="270" text-anchor="middle" font-size="10" fill="#7f8c8d">Wan 2.1 / SVD</text>
  
  <!-- Three Core Components -->
  <g id="components">
    <!-- IRR -->
    <rect x="320" y="180" width="180" height="60" rx="10" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2"/>
    <text x="410" y="200" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Intra-Step Recursive</text>
    <text x="410" y="215" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Refinement (IRR)</text>
    <text x="410" y="230" text-anchor="middle" font-size="9" fill="#636e72">Trajectory injection at each step</text>
    
    <!-- FLF -->
    <rect x="320" y="260" width="180" height="60" rx="10" fill="#fab1a0" stroke="#e17055" stroke-width="2"/>
    <text x="410" y="280" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Flow-Gated Latent</text>
    <text x="410" y="295" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Fusion (FLF)</text>
    <text x="410" y="310" text-anchor="middle" font-size="9" fill="#636e72">Motion/appearance decoupling</text>
    
    <!-- DSG -->
    <rect x="320" y="340" width="180" height="60" rx="10" fill="#a29bfe" stroke="#6c5ce7" stroke-width="2"/>
    <text x="410" y="360" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Dual-Path Self-Corrective</text>
    <text x="410" y="375" text-anchor="middle" font-size="12" font-weight="bold" fill="#2d3436">Guidance (DSG)</text>
    <text x="410" y="390" text-anchor="middle" font-size="9" fill="#636e72">Artifact suppression</text>
  </g>
  
  <!-- Denoising Process Detail -->
  <rect x="550" y="200" width="400" height="200" rx="15" fill="#f8f9fa" stroke="#95a5a6" stroke-width="2"/>
  <text x="750" y="220" text-anchor="middle" font-size="13" font-weight="bold" fill="#2c3e50">Single-Step Denoising Process</text>
  
  <!-- Noise Input -->
  <circle cx="580" cy="250" r="20" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
  <text x="580" y="255" text-anchor="middle" font-size="10" fill="white">x‚Çú</text>
  
  <!-- Network Prediction -->
  <rect x="630" y="235" width="80" height="30" rx="5" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="670" y="255" text-anchor="middle" font-size="10" fill="white">NN Predict</text>
  
  <!-- Guided/Unguided Paths -->
  <rect x="580" y="290" width="70" height="25" rx="5" fill="#27ae60" stroke="#229954" stroke-width="2"/>
  <text x="615" y="307" text-anchor="middle" font-size="9" fill="white">Unguided</text>
  
  <rect x="670" y="290" width="70" height="25" rx="5" fill="#f39c12" stroke="#e67e22" stroke-width="2"/>
  <text x="705" y="307" text-anchor="middle" font-size="9" fill="white">Guided</text>
  
  <!-- Fusion -->
  <rect x="620" y="340" width="80" height="25" rx="5" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
  <text x="660" y="357" text-anchor="middle" font-size="10" fill="white">FLF Fusion</text>
  
  <!-- Corrected Output -->
  <rect x="750" y="290" width="80" height="40" rx="5" fill="#16a085" stroke="#138d75" stroke-width="2"/>
  <text x="790" y="305" text-anchor="middle" font-size="10" fill="white">Corrected</text>
  <text x="790" y="320" text-anchor="middle" font-size="10" fill="white">Output</text>
  
  <!-- Output Results -->
  <rect x="100" y="480" width="150" height="80" rx="10" fill="#d5f4e6" stroke="#27ae60" stroke-width="2"/>
  <text x="175" y="510" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">3D Scene</text>
  <text x="175" y="525" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Generation</text>
  <text x="175" y="545" text-anchor="middle" font-size="9" fill="#34495e">Novel view synthesis</text>
  
  <rect x="300" y="480" width="150" height="80" rx="10" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2"/>
  <text x="375" y="510" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">4D Trajectory</text>
  <text x="375" y="525" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Control</text>
  <text x="375" y="545" text-anchor="middle" font-size="9" fill="#34495e">Dynamic re-rendering</text>
  
  <rect x="500" y="480" width="150" height="80" rx="10" fill="#fab1a0" stroke="#e17055" stroke-width="2"/>
  <text x="575" y="510" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Video Effects</text>
  <text x="575" y="530" text-anchor="middle" font-size="9" fill="#34495e">Stabilization, Editing</text>
  <text x="575" y="545" text-anchor="middle" font-size="9" fill="#34495e">Object manipulation</text>
  
  <!-- Key Features -->
  <rect x="700" y="480" width="250" height="100" rx="10" fill="#e8f4fd" stroke="#3498db" stroke-width="2"/>
  <text x="825" y="500" text-anchor="middle" font-size="12" font-weight="bold" fill="#2c3e50">Key Features</text>
  <text x="720" y="520" font-size="10" fill="#34495e">‚Ä¢ Training-free inference</text>
  <text x="720" y="535" font-size="10" fill="#34495e">‚Ä¢ Plug-and-play framework</text>
  <text x="720" y="550" font-size="10" fill="#34495e">‚Ä¢ Model-agnostic design</text>
  <text x="720" y="565" font-size="10" fill="#34495e">‚Ä¢ Precise trajectory control</text>
  
  <!-- Process Flow Indicators -->
  <path d="M 170 100 L 210 100" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 360 100 L 400 100" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 510 100 L 550 100" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 150 300 L 150 470" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 410 400 L 410 470" stroke="#34495e" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#34495e"/>
    </marker>
  </defs>
  
  <!-- Training-Free Label -->
  <rect x="20" y="600" width="960" height="40" rx="20" fill="#e8f8f5" stroke="#27ae60" stroke-width="3"/>
  <text x="500" y="625" text-anchor="middle" font-size="16" font-weight="bold" fill="#27ae60">TRAINING-FREE ‚Ä¢ PLUG-AND-PLAY ‚Ä¢ MODEL-AGNOSTIC</text>
  
  <!-- Performance Metrics -->
  <text x="50" y="680" font-size="12" font-weight="bold" fill="#2c3e50">Performance Highlights:</text>
  <text x="50" y="700" font-size="10" fill="#34495e">‚Ä¢ Superior FID scores on LLFF, MipNeRF-360, Tanks-and-Temples</text>
  <text x="50" y="715" font-size="10" fill="#34495e">‚Ä¢ Best trajectory accuracy (ATE, RPE-T, RPE-R metrics)</text>
  <text x="50" y="730" font-size="10" fill="#34495e">‚Ä¢ 360¬∞ view synthesis from single image</text>
  <text x="50" y="745" font-size="10" fill="#34495e">‚Ä¢ Compatible with Wan 2.1, SVD, and other VDMs</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="It achieves control without requiring any model retraining or fine-tuning">
                        <div class="quiz-question">1. What is the main innovation of WorldForge compared to previous approaches in trajectory-controlled video generation?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses a completely new video diffusion architecture">It uses a completely new video diffusion architecture</div><div class="quiz-choice" data-value="It achieves control without requiring any model retraining or fine-tuning">It achieves control without requiring any model retraining or fine-tuning</div><div class="quiz-choice" data-value="It generates higher resolution videos than other methods">It generates higher resolution videos than other methods</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Flow-Gated Latent Fusion (FLF)">
                        <div class="quiz-question">2. Which component of WorldForge is responsible for separating motion-related features from appearance-related features in the latent space?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Dual-Path Self-Corrective Guidance (DSG)">Dual-Path Self-Corrective Guidance (DSG)</div><div class="quiz-choice" data-value="Intra-Step Recursive Refinement (IRR)">Intra-Step Recursive Refinement (IRR)</div><div class="quiz-choice" data-value="Flow-Gated Latent Fusion (FLF)">Flow-Gated Latent Fusion (FLF)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Real-time face animation and lip syncing">
                        <div class="quiz-question">3. What practical application is NOT mentioned as a use case for WorldForge in the paper?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Video stabilization and camera path smoothing">Video stabilization and camera path smoothing</div><div class="quiz-choice" data-value="Real-time face animation and lip syncing">Real-time face animation and lip syncing</div><div class="quiz-choice" data-value="Object removal and replacement in videos">Object removal and replacement in videos</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/use-your-illusion.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>BaseReward: A Strong Baseline for Multimodal Reward Model</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-09-19</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2509.16127" target="_blank">http://arxiv.org/pdf/2509.16127</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on developing high-performance Multimodal Reward Models (MRMs) for aligning Multimodal Large Language Models with human preferences in the domain of AI alignment and multimodal machine learning.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on existing reward modeling approaches for text-only LLMs, the paper proposes a systematic guide for building MRMs by investigating every crucial component in the development pipeline, introducing BaseReward as a simple yet effective architecture.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the lack of a systematic guide for building state-of-the-art Multimodal Reward Models, which are crucial for aligning MLLMs with human preferences.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors conducted comprehensive experimental analyses of reward modeling paradigms, reward head architecture, training strategies, data curation, backbone model selection, and ensemble methods, ultimately developing BaseReward using a Qwen2.5-VL backbone with an optimized two-layer reward head.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> BaseReward established new state-of-the-art performance on major benchmarks, including MM-RLHF-Reward Bench (11% improvement), VL-Reward Bench (18% improvement), and showed consistent performance gains when integrated into reinforcement learning pipelines across various tasks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>BaseReward: A Strong Baseline for Multimodal Reward Model</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">
    BaseReward: Multimodal Reward Model Development Pipeline
  </text>
  
  <!-- Phase 1: Experimental Analysis -->
  <rect x="50" y="70" width="900" height="180" fill="#e8f4fd" stroke="#3498db" stroke-width="2" rx="10"/>
  <text x="500" y="90" text-anchor="middle" font-size="18" font-weight="bold" fill="#2980b9">
    Phase 1: Systematic Experimental Analysis
  </text>
  
  <!-- Reward Modeling Approaches -->
  <rect x="70" y="110" width="120" height="60" fill="#ffeaa7" stroke="#fdcb6e" stroke-width="2" rx="5"/>
  <text x="130" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Approaches</text>
  <text x="130" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Naive-RM</text>
  <text x="130" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Critic-RM</text>
  <text x="130" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Generative-RM</text>
  
  <!-- Architecture Design -->
  <rect x="210" y="110" width="120" height="60" fill="#fab1a0" stroke="#e17055" stroke-width="2" rx="5"/>
  <text x="270" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Architecture</text>
  <text x="270" y="145" text-anchor="middle" font-size="9" fill="#2d3436">2-layer MLP</text>
  <text x="270" y="155" text-anchor="middle" font-size="9" fill="#2d3436">SiLU activation</text>
  <text x="270" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Reward head</text>
  
  <!-- Training Strategies -->
  <rect x="350" y="110" width="120" height="60" fill="#fd79a8" stroke="#e84393" stroke-width="2" rx="5"/>
  <text x="410" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Training</text>
  <text x="410" y="145" text-anchor="middle" font-size="9" fill="#2d3436">No regularization</text>
  <text x="410" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Standard loss</text>
  <text x="410" y="165" text-anchor="middle" font-size="9" fill="#2d3436">3e-6 LR</text>
  
  <!-- Data Curation -->
  <rect x="490" y="110" width="120" height="60" fill="#a29bfe" stroke="#6c5ce7" stroke-width="2" rx="5"/>
  <text x="550" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Data</text>
  <text x="550" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Multimodal +</text>
  <text x="550" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Text-only</text>
  <text x="550" y="165" text-anchor="middle" font-size="9" fill="#2d3436">2.8M pairs</text>
  
  <!-- Backbone Selection -->
  <rect x="630" y="110" width="120" height="60" fill="#55efc4" stroke="#00b894" stroke-width="2" rx="5"/>
  <text x="690" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Backbone</text>
  <text x="690" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Qwen2.5-VL</text>
  <text x="690" y="155" text-anchor="middle" font-size="9" fill="#2d3436">7B parameters</text>
  <text x="690" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Scale analysis</text>
  
  <!-- Ensemble Methods -->
  <rect x="770" y="110" width="120" height="60" fill="#ff7675" stroke="#d63031" stroke-width="2" rx="5"/>
  <text x="830" y="130" text-anchor="middle" font-size="11" font-weight="bold" fill="#2d3436">Ensemble</text>
  <text x="830" y="145" text-anchor="middle" font-size="9" fill="#2d3436">Multiple models</text>
  <text x="830" y="155" text-anchor="middle" font-size="9" fill="#2d3436">Averaging</text>
  <text x="830" y="165" text-anchor="middle" font-size="9" fill="#2d3436">Diversity boost</text>
  
  <!-- Key Findings Box -->
  <rect x="70" y="190" width="820" height="50" fill="#dff0d8" stroke="#5cb85c" stroke-width="2" rx="5"/>
  <text x="480" y="210" text-anchor="middle" font-size="12" font-weight="bold" fill="#3c763d">Key Finding:</text>
  <text x="480" y="225" text-anchor="middle" font-size="11" fill="#3c763d">Text-only data significantly enhances multimodal reward modeling performance</text>
  
  <!-- Phase 2: BaseReward Implementation -->
  <rect x="50" y="280" width="900" height="150" fill="#fff3cd" stroke="#ffc107" stroke-width="2" rx="10"/>
  <text x="500" y="300" text-anchor="middle" font-size="18" font-weight="bold" fill="#856404">
    Phase 2: BaseReward Implementation
  </text>
  
  <!-- Model Architecture -->
  <rect x="100" y="320" width="200" height="80" fill="#e1f5fe" stroke="#0288d1" stroke-width="2" rx="5"/>
  <text x="200" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#01579b">Model Architecture</text>
  <text x="200" y="355" text-anchor="middle" font-size="10" fill="#01579b">Qwen2.5-VL-7B backbone</text>
  <text x="200" y="370" text-anchor="middle" font-size="10" fill="#01579b">2-layer MLP reward head</text>
  <text x="200" y="385" text-anchor="middle" font-size="10" fill="#01579b">SiLU activation function</text>
  
  <!-- Training Data -->
  <rect x="320" y="320" width="200" height="80" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2" rx="5"/>
  <text x="420" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#4a148c">Training Data</text>
  <text x="420" y="355" text-anchor="middle" font-size="10" fill="#4a148c">7 curated datasets</text>
  <text x="420" y="370" text-anchor="middle" font-size="10" fill="#4a148c">2.8M preference pairs</text>
  <text x="420" y="385" text-anchor="middle" font-size="10" fill="#4a148c">Multimodal + Text-only</text>
  
  <!-- Training Strategy -->
  <rect x="540" y="320" width="200" height="80" fill="#e8f5e8" stroke="#388e3c" stroke-width="2" rx="5"/>
  <text x="640" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#1b5e20">Training Strategy</text>
  <text x="640" y="355" text-anchor="middle" font-size="10" fill="#1b5e20">Learning rate: 3e-6</text>
  <text x="640" y="370" text-anchor="middle" font-size="10" fill="#1b5e20">Batch size: 128</text>
  <text x="640" y="385" text-anchor="middle" font-size="10" fill="#1b5e20">64 H100 GPUs</text>
  
  <!-- Ensemble Version -->
  <rect x="760" y="320" width="140" height="80" fill="#fff8e1" stroke="#f57c00" stroke-width="2" rx="5"/>
  <text x="830" y="340" text-anchor="middle" font-size="12" font-weight="bold" fill="#e65100">Ensemble</text>
  <text x="830" y="355" text-anchor="middle" font-size="10" fill="#e65100">Qwen2.5-VL +</text>
  <text x="830" y="370" text-anchor="middle" font-size="10" fill="#e65100">Qwen2-VL</text>
  <text x="830" y="385" text-anchor="middle" font-size="10" fill="#e65100">Simple averaging</text>
  
  <!-- Phase 3: Evaluation & Results -->
  <rect x="50" y="460" width="900" height="120" fill="#e8f8f5" stroke="#16a085" stroke-width="2" rx="10"/>
  <text x="500" y="480" text-anchor="middle" font-size="18" font-weight="bold" fill="#0e6b5d">
    Phase 3: Evaluation & Results
  </text>
  
  <!-- Benchmark Results -->
  <rect x="100" y="500" width="250" height="60" fill="#fef9e7" stroke="#f39c12" stroke-width="2" rx="5"/>
  <text x="225" y="520" text-anchor="middle" font-size="12" font-weight="bold" fill="#b7950b">Benchmark Results</text>
  <text x="225" y="535" text-anchor="middle" font-size="10" fill="#b7950b">MM-RLHF: +11.9% improvement</text>
  <text x="225" y="550" text-anchor="middle" font-size="10" fill="#b7950b">VL-Reward: +18% improvement</text>
  
  <!-- SOTA Achievement -->
  <rect x="370" y="500" width="250" height="60" fill="#ebf5fb" stroke="#2980b9" stroke-width="2" rx="5"/>
  <text x="495" y="520" text-anchor="middle" font-size="12" font-weight="bold" fill="#1f4e79">SOTA Achievement</text>
  <text x="495" y="535" text-anchor="middle" font-size="10" fill="#1f4e79">Outperforms Claude 3.7 Sonnet</text>
  <text x="495" y="550" text-anchor="middle" font-size="10" fill="#1f4e79">Best open-source MRM</text>
  
  <!-- RL Validation -->
  <rect x="640" y="500" width="250" height="60" fill="#fdf2e9" stroke="#e67e22" stroke-width="2" rx="5"/>
  <text x="765" y="520" text-anchor="middle" font-size="12" font-weight="bold" fill="#a04000">RL Validation</text>
  <text x="765" y="535" text-anchor="middle" font-size="10" fill="#a04000">GRPO algorithm</text>
  <text x="765" y="550" text-anchor="middle" font-size="10" fill="#a04000">Consistent improvements</text>
  
  <!-- Phase 4: Practical Application -->
  <rect x="50" y="610" width="900" height="120" fill="#fdf2e9" stroke="#e67e22" stroke-width="2" rx="10"/>
  <text x="500" y="630" text-anchor="middle" font-size="18" font-weight="bold" fill="#a04000">
    Phase 4: Practical Application & Deployment
  </text>
  
  <!-- RL Pipeline -->
  <rect x="100" y="650" width="200" height="60" fill="#e8f6f3" stroke="#17a2b8" stroke-width="2" rx="5"/>
  <text x="200" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#0c5460">RL Pipeline</text>
  <text x="200" y="685" text-anchor="middle" font-size="10" fill="#0c5460">GRPO optimization</text>
  <text x="200" y="700" text-anchor="middle" font-size="10" fill="#0c5460">8 rollouts per prompt</text>
  
  <!-- Hybrid Reward -->
  <rect x="320" y="650" width="200" height="60" fill="#f8d7da" stroke="#dc3545" stroke-width="2" rx="5"/>
  <text x="420" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#721c24">Hybrid Reward</text>
  <text x="420" y="685" text-anchor="middle" font-size="10" fill="#721c24">Rule-based + BaseReward</text>
  <text x="420" y="700" text-anchor="middle" font-size="10" fill="#721c24">Best performance</text>
  
  <!-- Task Performance -->
  <rect x="540" y="650" width="200" height="60" fill="#d1ecf1" stroke="#0c5460" stroke-width="2" rx="5"/>
  <text x="640" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#0c5460">Task Performance</text>
  <text x="640" y="685" text-anchor="middle" font-size="10" fill="#0c5460">Perception, Reasoning</text>
  <text x="640" y="700" text-anchor="middle" font-size="10" fill="#0c5460">Conversational tasks</text>
  
  <!-- Efficiency -->
  <rect x="760" y="650" width="140" height="60" fill="#d4edda" stroke="#28a745" stroke-width="2" rx="5"/>
  <text x="830" y="670" text-anchor="middle" font-size="12" font-weight="bold" fill="#155724">Efficiency</text>
  <text x="830" y="685" text-anchor="middle" font-size="10" fill="#155724">Fast inference</text>
  <text x="830" y="700" text-anchor="middle" font-size="10" fill="#155724">Low overhead</text>
  
  <!-- Final Output -->
  <ellipse cx="500" cy="760" rx="150" ry="25" fill="#28a745" stroke="#1e7e34" stroke-width="3"/>
  <text x="500" y="768" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    BaseReward: SOTA Multimodal Reward Model
  </text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Text-only data significantly enhanced multimodal judgment, especially in safety and mathematics">
                        <div class="quiz-question">1. What surprising finding did the researchers discover about text-only data in multimodal reward modeling?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Text-only data was completely ineffective for multimodal tasks">Text-only data was completely ineffective for multimodal tasks</div><div class="quiz-choice" data-value="Text-only data significantly enhanced multimodal judgment, especially in safety and mathematics">Text-only data significantly enhanced multimodal judgment, especially in safety and mathematics</div><div class="quiz-choice" data-value="Text-only data only worked when combined with video data">Text-only data only worked when combined with video data</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="A two-layer MLP with SiLU activation">
                        <div class="quiz-question">2. Which reward head configuration proved most effective in the BaseReward model?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A single-layer linear head with ReLU activation">A single-layer linear head with ReLU activation</div><div class="quiz-choice" data-value="A five-layer deep network with Tanh activation">A five-layer deep network with Tanh activation</div><div class="quiz-choice" data-value="A two-layer MLP with SiLU activation">A two-layer MLP with SiLU activation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Hybrid approach combining rule-based checks with BaseReward scoring">
                        <div class="quiz-question">3. When integrating BaseReward into reinforcement learning, which reward scheme showed the best overall performance?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Pure rule-based reward system">Pure rule-based reward system</div><div class="quiz-choice" data-value="BaseReward-only scoring">BaseReward-only scoring</div><div class="quiz-choice" data-value="Hybrid approach combining rule-based checks with BaseReward scoring">Hybrid approach combining rule-based checks with BaseReward scoring</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
