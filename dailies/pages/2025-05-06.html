
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- AI Assistant Styles -->
    <link rel="stylesheet" href="../../css/ai-assistant.css">
    <title>2025-05-06 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-05-06 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/use-your-illusion.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Voila: Voice-Language Foundation Models for Real-Time Autonomous
  Interaction and Voice Role-Play</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-05</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.02707" target="_blank">http://arxiv.org/pdf/2505.02707</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> Voice-language foundation models for real-time autonomous interaction and voice role-play, focusing on AI-human voice communication.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on traditional pipeline systems (like Siri, Alexa) and end-to-end audio-language models, introducing new full-duplex architecture enabling simultaneous listening and speaking with voice customization capabilities.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Addressing limitations of current voice AI systems including high latency, loss of vocal nuances, and rigid turn-based interactions that prevent natural, autonomous conversations.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Implemented hierarchical Transformer architecture with streaming audio encoding, multi-scale Transformers consisting of LLM backbone and hierarchical audio generator, trained end-to-end with extensive audio-text data.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Achieved 195ms response latency (faster than human average), outperformed baselines in ASR (2.7% WER) and TTS (2.8% WER) tasks, and demonstrated superior performance on the Voila Benchmark across multiple domains.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Voila: Voice-Language Foundation Models for Real-Time Autonomous
  Interaction and Voice Role-Play</h2>
                        <svg width="100%" viewBox="0 0 1000 850" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <style>
      .title { font-family: 'Arial', sans-serif; font-size: 28px; font-weight: bold; fill: #2c3e50; text-anchor: middle; }
      .subtitle { font-family: 'Arial', sans-serif; font-size: 18px; font-weight: bold; fill: #34495e; }
      .block-text { font-family: 'Arial', sans-serif; font-size: 13px; fill: #333; text-anchor: middle; dominant-baseline: middle;}
      .small-text { font-family: 'Arial', sans-serif; font-size: 11px; fill: #555; text-anchor: middle; dominant-baseline: middle;}
      .arrow-line { stroke: #7f8c8d; stroke-width: 2; fill: none; }
      .data-flow { stroke: #3498db; stroke-width: 2.5; fill: none; marker-end: url(#arrowhead); }
      .data-flow-thin { stroke: #5dade2; stroke-width: 1.5; fill: none; marker-end: url(#arrowhead-small); }
      .dashed-line { stroke: #95a5a6; stroke-width: 1.5; stroke-dasharray: 4 4; fill: none; }
    </style>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#3498db"/>
    </marker>
    <marker id="arrowhead-small" markerWidth="8" markerHeight="5.6" refX="0" refY="2.8" orient="auto">
      <polygon points="0 0, 8 2.8, 0 5.6" fill="#5dade2"/>
    </marker>
    <linearGradient id="gradInput" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#A7F3D0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#6EE7B7;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradProc" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#BFDBFE;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#93C5FD;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradModel" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#FEF9C3;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#FDE68A;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradTokenizer" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#DDD6FE;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#C4B5FD;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradOutput" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#A7F3D0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#6EE7B7;stop-opacity:1" />
    </linearGradient>
  </defs>

  <rect x="0" y="0" width="1000" height="850" fill="#F8F9FA"/>

  <text x="500" y="40" class="title">Voila: Methodological Flow (Voila-e2e)</text>

  <!-- Inputs Section -->
  <g id="inputs">
    <rect x="50" y="80" width="180" height="60" rx="10" ry="10" fill="url(#gradInput)"/>
    <text x="140" y="110" class="block-text">User Speech</text>

    <rect x="50" y="160" width="180" height="60" rx="10" ry="10" fill="url(#gradInput)"/>
    <text x="140" y="180" class="block-text">Text Instructions</text>
    <text x="140" y="200" class="small-text">(e.g., Persona)</text>

    <rect x="50" y="240" width="180" height="60" rx="10" ry="10" fill="url(#gradInput)"/>
    <text x="140" y="260" class="block-text">Audio Sample</text>
    <text x="140" y="280" class="small-text">(Voice Reference)</text>
  </g>

  <!-- Initial Processing -->
  <g id="initial-processing">
    <rect x="280" y="80" width="180" height="60" rx="10" ry="10" fill="url(#gradProc)"/>
    <text x="370" y="110" class="block-text">Streaming Audio Encoder</text>
    <path d="M230,110 H270" class="data-flow"/>

    <rect x="280" y="240" width="180" height="60" rx="10" ry="10" fill="url(#gradProc)"/>
    <text x="370" y="260" class="block-text">Wespeaker</text>
    <text x="370" y="280" class="small-text">(Speaker Encoder)</text>
    <path d="M230,270 H270" class="data-flow"/>
  </g>

  <!-- Tokenization & Embedding -->
  <g id="tokenization-embedding">
    <rect x="500" y="80" width="200" height="100" rx="10" ry="10" fill="url(#gradTokenizer)"/>
    <text x="600" y="105" class="block-text">Voila Tokenizer (Encoder)</text>
    <text x="600" y="130" class="small-text">Audio Signal ‚Üí Discrete Tokens</text>
    <text x="600" y="150" class="small-text">L1 RVQ: Semantic</text>
    <text x="600" y="165" class="small-text">L2-L4 RVQ: Acoustic</text>
    <path d="M460,110 C480,110 480,130 500,130" class="data-flow"/>

    <ellipse cx="600" cy="270" rx="90" ry="30" fill="#E9D5FF"/>
    <text x="600" y="270" class="block-text">Voice Embedding</text>
    <path d="M460,270 H500" class="data-flow"/>

    <ellipse cx="370" cy="190" rx="90" ry="30" fill="#E9D5FF"/>
    <text x="370" y="190" class="block-text">Text Tokens</text>
    <path d="M230,190 H270" class="data-flow-thin"/>
  </g>

  <!-- Core Model Section -->
  <rect x="250" y="330" width="500" height="280" rx="15" ry="15" fill="#FFF9Db" stroke="#FDBA74" stroke-width="2"/>
  <text x="500" y="355" class="subtitle">Core Model: Hierarchical Multi-scale Transformer</text>

  <g id="core-model">
    <rect x="300" y="380" width="400" height="50" rx="8" ry="8" fill="url(#gradProc)"/>
    <text x="500" y="405" class="block-text">Input Formatting & Alignment</text>
    <text x="500" y="420" class="small-text">(Interleaved Text & Audio Tokens, Embeddings)</text>
    <!-- Arrows to Input Formatting -->
    <path d="M600,180 V370 H520" class="data-flow-thin"/> <!-- From Voila Tokenizer -->
    <path d="M370,220 V370 H480" class="data-flow-thin"/> <!-- From Text Tokens -->
    <path d="M600,300 V370 H500" class="data-flow-thin"/> <!-- From Voice Embedding -->


    <rect x="300" y="450" width="400" height="70" rx="8" ry="8" fill="url(#gradModel)"/>
    <text x="500" y="475" class="block-text">Voice-Language LLM Backbone</text>
    <text x="500" y="495" class="small-text">Processes Semantic Info</text>
    <text x="500" y="510" class="small-text">Conditioned by Persona & Voice Embedding</text>
    <path d="M500,430 V450" class="data-flow"/>

    <rect x="300" y="540" width="400" height="50" rx="8" ry="8" fill="url(#gradModel)"/>
    <text x="500" y="565" class="block-text">Audio Transformer</text>
    <text x="500" y="580" class="small-text">(Hierarchical Audio Generator)</text>
    <path d="M500,520 V540" class="data-flow"/>
  </g>

  <!-- Output Generation -->
  <g id="output-generation">
    <ellipse cx="600" cy="650" rx="100" ry="30" fill="#E9D5FF"/>
    <text x="600" y="650" class="block-text">Predicted Audio Tokens</text>
    <path d="M500,590 V620 C500,620 520,635 600,635" class="data-flow"/>


    <rect x="750" y="450" width="200" height="100" rx="10" ry="10" fill="url(#gradTokenizer)"/>
    <text x="850" y="475" class="block-text">Voila Tokenizer (Decoder)</text>
    <text x="850" y="500" class="small-text">Discrete Tokens ‚Üí Audio Signal</text>
    <text x="850" y="520" class="small-text">Reconstructs from</text>
    <text x="850" y="535" class="small-text">Semantic & Acoustic Tokens</text>
    <path d="M600,665 C650,665 700,600 750,500" class="data-flow"/>


    <rect x="750" y="80" width="180" height="60" rx="10" ry="10" fill="url(#gradOutput)"/>
    <text x="840" y="110" class="block-text">Voice Response</text>
    <path d="M850,450 V140 H840" class="data-flow"/>
  </g>

  <!-- Voila-autonomous Annotation -->
  <rect x="50" y="690" width="900" height="130" rx="15" ry="15" fill="#E0F2F7" stroke="#76D7C4" stroke-width="2"/>
  <text x="500" y="715" class="subtitle">Voila-autonomous Extension: Full-Duplex Interaction</text>

  <rect x="80" y="740" width="200" height="50" rx="8" ry="8" fill="url(#gradProc)"/>
  <text x="180" y="765" class="block-text">User Audio Stream Processing</text>
  <text x="180" y="780" class="small-text">(Tokenize & Embed)</text>

  <rect x="330" y="740" width="200" height="50" rx="8" ry="8" fill="url(#gradProc)"/>
  <text x="430" y="755" class="block-text">Voila's Own Audio Stream</text>
  <text x="430" y="770" class="block-text">Processing</text>
  <text x="430" y="785" class="small-text">(Tokenize & Embed)</text>

  <rect x="580" y="740" width="150" height="50" rx="8" ry="8" fill="#FAD7A0"/>
  <text x="655" y="765" class="block-text">Fuse Embeddings</text>
  <text x="655" y="780" class="small-text">(e.g., Averaging)</text>

  <text x="830" y="765" class="block-text">‚Üí To LLM Backbone</text>
  <text x="830" y="780" class="small-text">(Then similar flow as above)</text>

  <path d="M280,765 H320" class="data-flow-thin"/>
  <path d="M530,765 H570" class="data-flow-thin"/>
  <path d="M730,765 H780" class="data-flow-thin"/>

  <!-- Legend (Optional) -->
  <!--
  <g id="legend" transform="translate(750, 630)">
    <text x="0" y="0" class="subtitle" style="font-size:14px;">Legend</text>
    <rect x="0" y="15" width="15" height="15" fill="url(#gradInput)"/>
    <text x="20" y="27" class="small-text" text-anchor="start">Input/Output</text>
    <rect x="0
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="They suffer from high latency and lose rich vocal nuances like emotion and tone.">
                        <div class="quiz-question">1. What is one major limitation of traditional pipeline voice AI systems (like older Siri/Alexa) that Voila attempts to overcome?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They are unable to process simple voice commands.">They are unable to process simple voice commands.</div><div class="quiz-choice" data-value="They suffer from high latency and lose rich vocal nuances like emotion and tone.">They suffer from high latency and lose rich vocal nuances like emotion and tone.</div><div class="quiz-choice" data-value="They cannot be connected to the internet for information retrieval.">They cannot be connected to the internet for information retrieval.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="A structured interleaved alignment where each semantic unit of text is paired with its corresponding audio tokens.">
                        <div class="quiz-question">2. Voila introduces a method to better align text and audio during generation. What is this method called?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A rigid, sequential text-first generation process.">A rigid, sequential text-first generation process.</div><div class="quiz-choice long-text" data-value="A structured interleaved alignment where each semantic unit of text is paired with its corresponding audio tokens.">A structured interleaved alignment where each semantic unit of text is paired with its corresponding audio tokens.</div><div class="quiz-choice" data-value="Relying solely on text prediction and converting the full text to speech afterwards.">Relying solely on text prediction and converting the full text to speech afterwards.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="By allowing users to use text instructions and provide a brief audio sample to learn a voice embedding.">
                        <div class="quiz-question">3. Voila highlights its capability for voice role-play and interaction customization. How does it allow users to define speaker characteristics and voice?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By requiring users to train a new model from scratch for each voice.">By requiring users to train a new model from scratch for each voice.</div><div class="quiz-choice long-text" data-value="By allowing users to use text instructions and provide a brief audio sample to learn a voice embedding.">By allowing users to use text instructions and provide a brief audio sample to learn a voice embedding.</div><div class="quiz-choice" data-value="By limiting users to a small, predefined set of generic voices.">By limiting users to a small, predefined set of generic voices.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>RM-R1: Reward Modeling as Reasoning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-05</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.02387" target="_blank">http://arxiv.org/pdf/2505.02387</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces RM-R1, a new approach to reward modeling for large language models that frames it as a reasoning task, focusing on improving model evaluation and preference learning.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on existing scalar-based and generative reward models, it proposes a novel approach of integrating explicit reasoning capabilities into reward modeling through Chain-of-Rubrics prompting and structured evaluation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the lack of interpretability and reliability in current reward models, which either produce opaque scalar scores or generate superficial judgments without deep reasoning.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Uses a two-stage training pipeline: first distilling high-quality reasoning traces from teacher models, then applying reinforcement learning with verifiable rewards (RLVR), while implementing a Chain-of-Rubrics framework for structured evaluation.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> RM-R1 achieved state-of-the-art or near state-of-the-art performance across multiple benchmarks (RewardBench, RM-Bench, RMB), outperforming larger models like Llama3.1-405B and GPT-4o by up to 13.8% in accuracy while providing more interpretable judgments.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>RM-R1: Reward Modeling as Reasoning</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg" font-family="Arial, sans-serif">
    <defs>
        <style>
            .title-text { font-size: 24px; font-weight: bold; fill: white; }
            .stage-title-text { font-size: 18px; font-weight: bold; fill: #333; }
            .main-text { font-size: 14px; fill: #333; }
            .detail-text { font-size: 12px; fill: #444; }
            .sub-detail-text { font-size: 11px; fill: #555; }
            .box-shadow {
                filter: drop-shadow(3px 3px 2px rgba(0,0,0,0.2));
            }
        </style>
    </defs>

    <!-- Background -->
    <rect width="100%" height="100%" fill="#f4f7f9"/>

    <!-- Main Title Box -->
    <rect x="100" y="20" width="800" height="50" rx="10" ry="10" fill="#4A90E2" class="box-shadow"/>
    <text x="500" y="45" text-anchor="middle" class="title-text">RM-R1: Reward Modeling as Reasoning - Method Flowchart</text>

    <!-- Starting Models Section -->
    <rect x="50" y="90" width="430" height="110" rx="10" ry="10" fill="#F5A623" class="box-shadow"/>
    <text x="265" y="110" text-anchor="middle" class="stage-title-text">Start: Instruction-Tuned LLM</text>
    <text x="265" y="135" text-anchor="middle" class="main-text">
        <tspan x="265" dy="0em">(e.g., Qwen-2.5-Instruct)</tspan>
        <tspan x="265" dy="1.2em">Lacks specialized reward modeling</tspan>
        <tspan x="265" dy="1.2em">reasoning capabilities.</tspan>
    </text>

    <rect x="520" y="90" width="430" height="110" rx="10" ry="10" fill="#F5A623" class="box-shadow"/>
    <text x="735" y="110" text-anchor="middle" class="stage-title-text">Start: Existing Reasoning Model</text>
    <text x="735" y="135" text-anchor="middle" class="main-text">
        <tspan x="735" dy="0em">(e.g., DeepSeek-R1-distilled)</tspan>
        <tspan x="735" dy="1.2em">Already has strong reasoning</tspan>
        <tspan x="735" dy="1.2em">capabilities from prior distillation.</tspan>
    </text>

    <!-- Arrow from Instruction-Tuned to Distillation -->
    <line x1="265" y1="200" x2="265" y2="230" stroke="#333" stroke-width="2"/>
    <polygon points="260,225 270,225 265,235" fill="#333"/>

    <!-- Stage 1: Distillation (Only for Instruction-Tuned Models) -->
    <rect x="50" y="240" width="430" height="160" rx="10" ry="10" fill="#7ED321" class="box-shadow"/>
    <text x="265" y="260" text-anchor="middle" class="stage-title-text">Stage 1: Distillation of Reasoning Trace</text>
    <text x="70" y="285" class="detail-text" text-anchor="start">
        <tspan x="70" dy="0em">- Goal: Bootstrap reasoning ability for reward modeling.</tspan>
        <tspan x="70" dy="1.3em">- Subsample preference data D_sub from D.</tspan>
        <tspan x="70" dy="1.3em">- Synthesize high-quality structured reasoning traces (r)</tspan>
        <tspan x="90" dy="1.2em">using Oracle Models (e.g., Claude, O3).</tspan>
        <tspan x="70" dy="1.3em">- Construct ground truth: y_trace = r ‚äï preferred_response.</tspan>
        <tspan x="70" dy="1.3em">- Create distillation dataset D_distill.</tspan>
        <tspan x="70" dy="1.3em">- Fine-tune model via NLL loss on D_distill.</tspan>
    </text>
    <text x="265" y="385" text-anchor="middle" class="main-text" font-weight="bold">Output: Distilled REAS RM</text>

    <!-- Arrow from Distillation to RL Stage -->
    <line x1="265" y1="400" x2="265" y2="425" stroke="#333" stroke-width="2"/>
    <line x1="265" y1="425" x2="480" y2="425" stroke="#333" stroke-width="2"/>
    <polygon points="475,420 475,430 485,425" fill="#333"/>

    <!-- Arrow from Existing Reasoning Model to RL Stage -->
    <line x1="735" y1="200" x2="735" y2="425" stroke="#333" stroke-width="2"/>
    <line x1="735" y1="425" x2="515" y2="425" stroke="#333" stroke-width="2"/>
    <polygon points="520,420 520,430 510,425" fill="#333"/>

    <!-- Stage 2: Reinforcement Learning (RL) Training -->
    <rect x="100" y="440" width="800" height="240" rx="10" ry="10" fill="#BD10E0" class="box-shadow"/>
    <text x="500" y="460" text-anchor="middle" class="stage-title-text" fill="white">Stage 2: Reinforcement Learning with Verifiable Rewards (RLVR)</text>
    <text x="500" y="480" text-anchor="middle" class="detail-text" fill="white">Objective: max E[R(x,j)] - Œ≤DKL(r_Œ∏ || r_ref)</text>

    <!-- RL Sub-components -->
    <rect x="120" y="500" width="240" height="160" rx="8" ry="8" fill="#e9cffc"/>
    <text x="240" y="515" text-anchor="middle" class="main-text" font-weight="bold">1. Chain-of-Rubrics (CoR) Rollout</text>
    <text x="130" y="535" class="sub-detail-text" text-anchor="start">
        <tspan x="130" dy="0em">- System Prompts (elicit reasoning):</tspan>
        <tspan x="140" dy="1.2em">‚Ä¢ Instruct Models: Fig 3 (Detailed)</tspan>
        <tspan x="140" dy="1.2em">‚Ä¢ Reasoning Models: Fig 4 (Simpler)</tspan>
        <tspan x="130" dy="1.5em">- Task Classification (for Instruct Models):</tspan>
        <tspan x="140" dy="1.2em">‚Ä¢ Chat: Gen. Rubrics, Justify,</tspan>
        <tspan x="140" dy="1.2em">  Eval based on Rubrics, Answer.</tspan>
        <tspan x="140" dy="1.2em">‚Ä¢ Reasoning: Self-Solve (gen. </tspan>
        <tspan x="140" dy="1.2em">  &lt;solution&gt;), Eval, Answer.</tspan>
    </text>

    <rect x="380" y="500" width="240" height="160" rx="8" ry="8" fill="#e9cffc"/>
    <text x="500" y="515" text-anchor="middle" class="main-text" font-weight="bold">2. Reward Design</text>
    <text x="390" y="535" class="sub-detail-text" text-anchor="start">
        <tspan x="390" dy="0em">- Focus: Correctness-based.</tspan>
        <tspan x="390" dy="1.5em">- R(x, j | ya, yb) =</tspan>
        <tspan x="400" dy="1.2em">  +1, if predicted label (lÃÇ) = true label (l)</tspan>
        <tspan x="400" dy="1.2em">  -1, otherwise.</tspan>
        <tspan x="390" dy="1.5em">- Simplified from DeepSeek-R1,</tspan>
        <tspan x="390" dy="1.2em">  omits format reward for efficiency.</tspan>
    </text>

    <rect x="640" y="500" width="240" height="160" rx="8" ry="8" fill="#e9cffc"/>
    <text x="760" y="515" text-anchor="middle" class="main-text" font-weight="bold">3. Group Relative Policy Opt. (GRPO)</text>
    <text x="650" y="535" class="sub-detail-text" text-anchor="start">
        <tspan x="650" dy="0em">- PPO Variant.</tspan>
        <tspan x="650" dy="1.5em">- No explicit value function needed.</tspan>
        <tspan x="650" dy="1.5em">- Baseline: Average reward of multiple</tspan>
        <tspan x="650" dy="1.2em">  sampled outputs for the same prompt.</tspan>
        <tspan x="650" dy="1.5em">- Optimizes policy by maximizing</tspan>
        <tspan x="650" dy="1.2em">  GRPO objective (Eq. 7).</tspan>
    </text>

    <!-- Arrow from RL Stage to Final Output -->
    <line x1="500" y1="680" x2="500" y2="700" stroke="#333" stroke-width="2"/>
    <polygon points="495,695 505,695 500,705" fill="#333"/>

    <!-- Final Output Box -->
    <rect x="100" y="710" width="800" height="70" rx="10" ry="10" fill="#4A90E2" class="box-shadow"/>
    <text x="500" y="730" text-anchor="middle" class="stage-title-text" fill="white">Final Output: RM-R1 Model Family (7B to 32B)</text>
    <text x="500" y="755" text-anchor="middle" class="main-text" fill_opacity="0.9" fill="white">
        <tspan>Achieves SOTA performance, highly interpretable reasoning traces,</tspan>
        <tspan x="500" dy="1.2em">outperforms larger open-weight and proprietary models.</tspan>
    </text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="They often produce opaque scalar scores or superficial judgments, lacking interpretability and deep reasoning.">
                        <div class="quiz-question">1. According to the paper, what is a major limitation of existing reward models that RM-R1 aims to overcome?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They can only process text data, not multimodal inputs.">They can only process text data, not multimodal inputs.</div><div class="quiz-choice long-text" data-value="They often produce opaque scalar scores or superficial judgments, lacking interpretability and deep reasoning.">They often produce opaque scalar scores or superficial judgments, lacking interpretability and deep reasoning.</div><div class="quiz-choice" data-value="They require an excessive amount of human feedback data compared to RM-R1.">They require an excessive amount of human feedback data compared to RM-R1.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Distillation of high-quality reasoning chains followed by reinforcement learning with verifiable rewards.">
                        <div class="quiz-question">2. The training pipeline for RM-R1 involves two key stages. What are they?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Supervised fine-tuning on human preferences followed by active learning.">Supervised fine-tuning on human preferences followed by active learning.</div><div class="quiz-choice long-text" data-value="Distillation of high-quality reasoning chains followed by reinforcement learning with verifiable rewards.">Distillation of high-quality reasoning chains followed by reinforcement learning with verifiable rewards.</div><div class="quiz-choice" data-value="Pre-training on a large text corpus followed by direct preference optimization (DPO).">Pre-training on a large text corpus followed by direct preference optimization (DPO).</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Larger model sizes and increased inference-time computation budgets lead to greater performance improvements.">
                        <div class="quiz-question">3. Based on the paper's analysis (Section 5), how does scaling affect RM-R1's performance?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Scaling has minimal impact on reasoning reward models, unlike traditional LLMs.">Scaling has minimal impact on reasoning reward models, unlike traditional LLMs.</div><div class="quiz-choice long-text" data-value="Larger model sizes and increased inference-time computation budgets lead to greater performance improvements.">Larger model sizes and increased inference-time computation budgets lead to greater performance improvements.</div><div class="quiz-choice long-text" data-value="Scaling primarily benefits the model's ability to generate rubrics but not its final judgment accuracy.">Scaling primarily benefits the model's ability to generate rubrics but not its final judgment accuracy.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/type.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>Practical Efficiency of Muon for Pretraining</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-04</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.02222" target="_blank">http://arxiv.org/pdf/2505.02222</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper explores the practical efficiency of Muon, a second-order optimizer, for pretraining large language models, in the domain of machine learning optimization.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous research on AdamW optimizer and maximal update parameterization (muP), the paper proposes using Muon as a more efficient alternative and introduces a novel "telescoping" algorithm for hyperparameter tuning.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve two practical challenges in language model pretraining: finding an optimizer that delivers the best tradeoff between compute and time resources, and developing an efficient way to tune that optimizer without excessive computational cost.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors conducted extensive experiments comparing Muon and AdamW across different model sizes (100M-4B parameters), analyzed compute-time tradeoffs using Pareto frontiers, and implemented a telescoping algorithm for hyperparameter optimization.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Results showed that Muon expands AdamW's Pareto frontier on the compute-time plane, requires 10-15% fewer tokens to reach identical loss, maintains efficiency at large batch sizes, and successfully works with muP for hyperparameter transfer up to 3.7B-parameter models.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Practical Efficiency of Muon for Pretraining</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
    <defs>
        <style type="text/css">
            <![CDATA[
                .titleText { font-family: Arial, Helvetica, sans-serif; font-size: 24px; font-weight: bold; fill: #2c3e50; text-anchor: middle; }
                .sectionHeaderText { font-family: Arial, Helvetica, sans-serif; font-size: 20px; font-weight: bold; text-anchor: middle; }
                .blockTitleText { font-family: Arial, Helvetica, sans-serif; font-size: 16px; font-weight: bold; text-anchor: middle; }
                .blockBodyText { font-family: Arial, Helvetica, sans-serif; font-size: 13px; text-anchor: middle; }
                .blockBodyTextSmall { font-family: Arial, Helvetica, sans-serif; font-size: 12px; text-anchor: middle; }
            ]]>
        </style>
    </defs>

    <!-- Background -->
    <rect width="1000" height="800" fill="#f8f9fa"/>

    <!-- Main Title -->
    <text x="500" y="40" class="titleText">Paper Methodology: Practical Efficiency of Muon for Pretraining</text>

    <!-- Part 1: Muon vs. AdamW -->
    <g id="part1">
        <rect x="50" y="75" width="900" height="40" fill="#a9d6e5" rx="10" ry="10"/>
        <text x="500" y="100" class="sectionHeaderText" fill="#013a63">Part 1: Muon vs. AdamW - Compute-Time Tradeoff</text>

        <!-- Step 1.1: Define Muon -->
        <g class="step_p1_1">
            <rect x="70" y="130" width="860" height="70" fill="#e0f3f8" stroke="#61a5c2" stroke-width="2" rx="8" ry="8"/>
            <text x="500" y="150" class="blockTitleText" fill="#01497c">1. Define Muon Optimizer</text>
            <text x="500" y="170" class="blockBodyText" fill="#014f86">
                <tspan x="500" dy="0em">Core: Matrix Steepest Descent, Spectral Norm Regularization, SVD-based Update (`Ot = UV^T`)</tspan>
                <tspan x="500" dy="1.3em">Practice: Newton-Schulz iteration, Nesterov Momentum, LR Scaling, Weight Decay.</tspan>
            </text>
        </g>

        <!-- Step 1.2: Experimental Setup -->
        <g class="step_p1_2">
            <rect x="70" y="210" width="860" height="55" fill="#e0f3f8" stroke="#61a5c2" stroke-width="2" rx="8" ry="8"/>
            <text x="500" y="230" class="blockTitleText" fill="#01497c">2. Experimental Setup</text>
            <text x="500" y="250" class="blockBodyText" fill="#014f86">Models (Transformers ‚â§4B), Data (Text/Code), Optimizers (Muon/AdamW), TPU v5p.</text>
        </g>

        <!-- Step 1.3: Compute-Time Tradeoff Study -->
        <g class="step_p1_3">
            <rect x="70" y="275" width="860" height="65" fill="#e0f3f8" stroke="#61a5c2" stroke-width="2" rx="8" ry="8"/>
            <text x="500" y="295" class="blockTitleText" fill="#01497c">3. Compute-Time Tradeoff Study</text>
            <text x="500" y="315" class="blockBodyText" fill="#014f86">
                <tspan x="500" dy="0em">Method: Plot Iso-loss frontiers (Time vs. #Devices/Batch Size for 500M models).</tspan>
                <tspan x="500" dy="1.3em">Finding: Muon expands Pareto frontier over AdamW.</tspan>
            </text>
        </g>

        <!-- Step 1.4: Relative Data Efficiency -->
        <g class="step_p1_4">
            <rect x="70" y="350" width="860" height="65" fill="#e0f3f8" stroke="#61a5c2" stroke-width="2" rx="8" ry="8"/>
            <text x="500" y="370" class="blockTitleText" fill="#01497c">4. Relative Data Efficiency Analysis</text>
            <text x="500" y="390" class="blockBodyText" fill="#014f86">
                <tspan x="500" dy="0em">Metric: Token Ratio `RL(B) = TL,A(B) / TL,M(B)` for 1B model.</tspan>
                <tspan x="500" dy="1.3em">Finding: `RL(B) > 1` & non-decreasing (Muon more data-efficient at large batches).</tspan>
            </text>
        </g>
    </g>

    <!-- Part 2: Hyperparameter Tuning -->
    <g id="part2">
        <rect x="50" y="430" width="900" height="40" fill="#cce8cc" rx="10" ry="10"/>
        <text x="500" y="455" class="sectionHeaderText" fill="#1b4332">Part 2: Hyperparameter Tuning for Muon</text>

        <!-- Step 2.1: Leverage muP -->
        <g class="step_p2_1">
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Muon explicitly expands the Pareto frontier over AdamW, offering more flexible resource allocation options.">
                        <div class="quiz-question">1. According to the paper, what is the main advantage of Muon over AdamW demonstrated through the compute-time tradeoff analysis?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Muon significantly reduces the total number of FLOPs required for training compared to AdamW.">Muon significantly reduces the total number of FLOPs required for training compared to AdamW.</div><div class="quiz-choice long-text" data-value="Muon explicitly expands the Pareto frontier over AdamW, offering more flexible resource allocation options.">Muon explicitly expands the Pareto frontier over AdamW, offering more flexible resource allocation options.</div><div class="quiz-choice" data-value="Muon achieves lower training loss than AdamW but only at the cost of much longer training times.">Muon achieves lower training loss than AdamW but only at the cost of much longer training times.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Muon maintains better data efficiency than AdamW in the large batch size regime, requiring fewer tokens to reach the same loss.">
                        <div class="quiz-question">2. What is the key mechanism identified in the paper that allows Muon to outperform AdamW, especially at large batch sizes?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="Muon uses a novel method to automatically adjust the learning rate based on the gradient magnitude, unlike AdamW.">Muon uses a novel method to automatically adjust the learning rate based on the gradient magnitude, unlike AdamW.</div><div class="quiz-choice long-text" data-value="Muon maintains better data efficiency than AdamW in the large batch size regime, requiring fewer tokens to reach the same loss.">Muon maintains better data efficiency than AdamW in the large batch size regime, requiring fewer tokens to reach the same loss.</div><div class="quiz-choice long-text" data-value="Muon parallelizes gradient computation across devices more effectively than AdamW, leading to faster wall-clock time.">Muon parallelizes gradient computation across devices more effectively than AdamW, leading to faster wall-clock time.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="To efficiently manage errors and conduct hyperparameter tuning using muP across different model scales.">
                        <div class="quiz-question">3. The paper introduces a "telescoping" algorithm primarily for what purpose in the context of pretraining with Muon?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="To reduce the memory footprint of large models during training by compressing weights.">To reduce the memory footprint of large models during training by compressing weights.</div><div class="quiz-choice long-text" data-value="To efficiently manage errors and conduct hyperparameter tuning using muP across different model scales.">To efficiently manage errors and conduct hyperparameter tuning using muP across different model scales.</div><div class="quiz-choice" data-value="To automatically determine the optimal number of training steps required for convergence.">To automatically determine the optimal number of training steps required for convergence.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>


    <!-- AI Assistant Scripts - Load in correct order (relative paths for subpages) -->
    <script src="../../js/ai-assistant-constants.js"></script>
    <script src="../../js/ai-assistant-storage.js"></script>
    <script src="../../js/ai-assistant-positioning.js"></script>
    <script src="../../js/ai-assistant-templates.js"></script>
    <script src="../../js/ai-assistant-dom-utils.js"></script>
    <script src="../../js/ai-assistant-config.js"></script>
    <script src="../../js/ai-assistant.js"></script>
</body>
</html>
