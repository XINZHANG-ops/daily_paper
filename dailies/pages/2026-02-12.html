<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2026-02-12 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */
            /* cursor removed - only cards should show pointer */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
            cursor: pointer; /* Show pointer on cards to indicate they're clickable */
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }

        .paper-card p {
            margin: 5px 0;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
            word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        /* ÁßªÂä®ËÆæÂ§áÂíåÂ∞èÂ±èÂπï */
        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                min-height: 400px; /* ÁßªÂä®ËÆæÂ§á‰∏ä‰ΩøÁî®Êõ¥Â∞èÁöÑÊúÄÂ∞èÈ´òÂ∫¶ */
                height: auto; /* Ëá™ÈÄÇÂ∫îÈ´òÂ∫¶ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }

            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
                width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-02-12 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/shley-tree-2.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>GENIUS: Generative Fluid Intelligence Evaluation Suite</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-11</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.11144" target="_blank">http://arxiv.org/pdf/2602.11144</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper introduces GENIUS, a benchmark for evaluating Generative Fluid Intelligence (GFI) in unified multimodal models, focusing on their ability to perform dynamic reasoning and adaptation in visual generation tasks rather than just retrieving pre-trained knowledge.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on the Cattell-Horn-Carroll theory of intelligence that distinguishes between Crystallized Intelligence (knowledge retrieval) and Fluid Intelligence (novel problem solving), proposing the first formal definition and benchmark for Generative Fluid Intelligence with three core dimensions: Implicit Pattern Induction, Ad-hoc Constraint Execution, and Contextual Knowledge Adaptation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the gap in evaluating whether current unified multimodal models possess true general intelligence for visual generation, as existing benchmarks primarily assess memorized knowledge rather than the ability to reason, adapt, and solve novel visual generation problems on the fly.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors created a manually curated benchmark with 510 expert-designed samples across 5 tasks and 20 sub-tasks, employed hybrid evaluation using LMM-as-a-judge with three metrics (Rule Compliance, Visual Consistency, Aesthetic Quality), and proposed a training-free attention adjustment mechanism based on theoretical analysis of in-context learning as implicit fine-tuning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The systematic evaluation of 12 models revealed significant performance deficits with even the best proprietary model (Nano Banana Pro) achieving only 57.19% overall score, demonstrating that current models struggle with fluid intelligence tasks and often prioritize aesthetic quality over logical rule compliance, while the proposed attention mechanism showed consistent improvements across all tasks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>GENIUS: Generative Fluid Intelligence Evaluation Suite</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">
    GENIUS: Generative Fluid Intelligence Evaluation Suite - Methodology Flow
  </text>
  
  <!-- Main Framework Box -->
  <rect x="50" y="70" width="900" height="120" rx="10" fill="#3498db" stroke="#2980b9" stroke-width="2"/>
  <text x="500" y="100" text-anchor="middle" font-size="18" font-weight="bold" fill="white">
    Theoretical Foundation: CHC Theory
  </text>
  <text x="500" y="125" text-anchor="middle" font-size="14" fill="white">
    Crystallized Intelligence (CI) vs Generative Fluid Intelligence (GFI)
  </text>
  <text x="500" y="145" text-anchor="middle" font-size="12" fill="white">
    Three Core Primitives: Inductive Inference | Abstract Dynamic Reasoning | Adaptive Inhibition
  </text>
  <text x="500" y="165" text-anchor="middle" font-size="12" fill="white">
    Formalized into: Implicit Pattern Induction | Ad-hoc Constraint Execution | Contextual Knowledge Adaptation
  </text>
  
  <!-- Three Main Dimensions -->
  <g>
    <!-- Dimension 1: Implicit Pattern Induction -->
    <rect x="80" y="220" width="250" height="100" rx="8" fill="#e74c3c" stroke="#c0392b" stroke-width="2"/>
    <text x="205" y="245" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
      Implicit Pattern Induction
    </text>
    <text x="205" y="265" text-anchor="middle" font-size="11" fill="white">
      Task: Implicit Pattern Generation (86 samples)
    </text>
    <text x="205" y="280" text-anchor="middle" font-size="10" fill="white">
      Sub-tasks: Overall Style, Visual Feature,
    </text>
    <text x="205" y="295" text-anchor="middle" font-size="10" fill="white">
      Spatial Relationship, Palette, Entity
    </text>
    
    <!-- Dimension 2: Ad-hoc Constraint Execution -->
    <rect x="370" y="220" width="250" height="100" rx="8" fill="#f39c12" stroke="#e67e22" stroke-width="2"/>
    <text x="495" y="245" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
      Ad-hoc Constraint Execution
    </text>
    <text x="495" y="265" text-anchor="middle" font-size="11" fill="white">
      Tasks: Symbolic (153) + Visual (60) Constraints
    </text>
    <text x="495" y="280" text-anchor="middle" font-size="10" fill="white">
      Sub-tasks: Operation Implementation,
    </text>
    <text x="495" y="295" text-anchor="middle" font-size="10" fill="white">
      Visual Metaphor, Layout, Features, Binding
    </text>
    
    <!-- Dimension 3: Contextual Knowledge Adaptation -->
    <rect x="660" y="220" width="250" height="100" rx="8" fill="#27ae60" stroke="#229954" stroke-width="2"/>
    <text x="785" y="245" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
      Contextual Knowledge Adaptation
    </text>
    <text x="785" y="265" text-anchor="middle" font-size="11" fill="white">
      Tasks: Prior-Conflicting (101) + Multi-Semantic (110)
    </text>
    <text x="785" y="280" text-anchor="middle" font-size="10" fill="white">
      Sub-tasks: Biological Growth, Gravity,
    </text>
    <text x="785" y="295" text-anchor="middle" font-size="10" fill="white">
      Animal Behavior, Time Reversal, Weather
    </text>
  </g>
  
  <!-- Evaluation Framework -->
  <rect x="100" y="360" width="800" height="80" rx="8" fill="#9b59b6" stroke="#8e44ad" stroke-width="2"/>
  <text x="500" y="385" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Hybrid Evaluation Framework
  </text>
  <text x="250" y="410" text-anchor="middle" font-size="12" fill="white">
    Rule Compliance (RC)
  </text>
  <text x="500" y="410" text-anchor="middle" font-size="12" fill="white">
    Visual Consistency (VC)
  </text>
  <text x="750" y="410" text-anchor="middle" font-size="12" fill="white">
    Aesthetic Quality (AQ)
  </text>
  <text x="500" y="425" text-anchor="middle" font-size="11" fill="white">
    LMM-as-Judge (Gemini-3-Pro) + Manual Hints + 3-Point Scale (0,1,2)
  </text>
  
  <!-- Experimental Analysis -->
  <rect x="50" y="470" width="420" height="120" rx="8" fill="#34495e" stroke="#2c3e50" stroke-width="2"/>
  <text x="260" y="495" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Systematic Evaluation
  </text>
  <text x="260" y="515" text-anchor="middle" font-size="12" fill="white">
    12 Representative Models
  </text>
  <text x="260" y="535" text-anchor="middle" font-size="11" fill="white">
    Proprietary: Nano Banana Pro/Base, GPT-Image, SeeDream 4.0/4.5
  </text>
  <text x="260" y="550" text-anchor="middle" font-size="11" fill="white">
    Open-source: Qwen-Image, GLM-Image, FLUX.2, NextStep-1, Emu3.5, Bagel
  </text>
  <text x="260" y="570" text-anchor="middle" font-size="12" font-weight="bold" fill="#e74c3c">
    Key Finding: Even SOTA models fall short (Best: 57.19)
  </text>
  
  <!-- Theoretical Analysis -->
  <rect x="520" y="470" width="420" height="120" rx="8" fill="#16a085" stroke="#138d75" stroke-width="2"/>
  <text x="730" y="495" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Failure Analysis & Solution
  </text>
  <text x="730" y="515" text-anchor="middle" font-size="12" fill="white">
    Attention Visualization: Irregular noise & spikes
  </text>
  <text x="730" y="535" text-anchor="middle" font-size="11" fill="white">
    Theoretical Framework: ICL as Implicit Fine-tuning
  </text>
  <text x="730" y="550" text-anchor="middle" font-size="11" fill="white">
    Root Cause: Imbalanced attention ‚Üí noisy gradients
  </text>
  <text x="730" y="570" text-anchor="middle" font-size="12" font-weight="bold" fill="#f39c12">
    Solution: Training-free Attention Adjustment
  </text>
  
  <!-- Method Pipeline -->
  <rect x="150" y="620" width="700" height="100" rx="8" fill="#8e44ad" stroke="#7d3c98" stroke-width="2"/>
  <text x="500" y="645" text-anchor="middle" font-size="16" font-weight="bold" fill="white">
    Three-Stage Attention Adjustment Pipeline
  </text>
  
  <!-- Stage boxes -->
  <rect x="180" y="660" width="180" height="40" rx="5" fill="#e8daef" stroke="#8e44ad" stroke-width="1"/>
  <text x="270" y="680" text-anchor="middle" font-size="11" font-weight="bold" fill="#8e44ad">
    1. Keyword Distillation
  </text>
  <text x="270" y="692" text-anchor="middle" font-size="9" fill="#8e44ad">
    Extract task-critical cues
  </text>
  
  <rect x="410" y="660" width="180" height="40" rx="5" fill="#e8daef" stroke="#8e44ad" stroke-width="1"/>
  <text x="500" y="680" text-anchor="middle" font-size="11" font-weight="bold" fill="#8e44ad">
    2. Relevance Mapping
  </text>
  <text x="500" y="692" text-anchor="middle" font-size="9" fill="#8e44ad">
    Compute semantic alignment
  </text>
  
  <rect x="640" y="660" width="180" height="40" rx="5" fill="#e8daef" stroke="#8e44ad" stroke-width="1"/>
  <text x="730" y="680" text-anchor="middle" font-size="11" font-weight="bold" fill="#8e44ad">
    3. Bias Injection
  </text>
  <text x="730" y="692" text-anchor="middle" font-size="9" fill="#8e44ad">
    Modulate attention logits
  </text>
  
  <!-- Results -->
  <rect x="300" y="740" width="400" height="40" rx="8" fill="#27ae60" stroke="#229954" stroke-width="2"/>
  <text x="500" y="765" text-anchor="middle" font-size="14" font-weight="bold" fill="white">
    Result: +6.18% improvement on Bagel (Overall Score)
  </text>
  
  <!-- Connection lines -->
  <line x1="500" y1="190" x2="500" y2="220" stroke="#34495e" stroke-width="2"/>
  <line x1="500" y1="320" x2="500" y2="360" stroke="#34495e" stroke-width="2"/>
  <line x1="500" y1="440" x2="500" y2="470" stroke="#34495e" stroke-width="2"/>
  <line x1="500" y1="590" x2="500" y2="620" stroke="#34495e" stroke-width="2"/>
  <line x1="500" y1="720" x2="500" y2="740" stroke="#34495e" stroke-width="2"/>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Implicit Pattern Induction, Ad-hoc Constraint Execution, and Contextual Knowledge Adaptation">
                        <div class="quiz-question">1. What are the three core primitives that define Generative Fluid Intelligence (GFI) according to the GENIUS framework?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Visual Understanding, Text Generation, and Image Synthesis">Visual Understanding, Text Generation, and Image Synthesis</div><div class="quiz-choice" data-value="Implicit Pattern Induction, Ad-hoc Constraint Execution, and Contextual Knowledge Adaptation">Implicit Pattern Induction, Ad-hoc Constraint Execution, and Contextual Knowledge Adaptation</div><div class="quiz-choice" data-value="Rule Compliance, Visual Consistency, and Aesthetic Quality">Rule Compliance, Visual Consistency, and Aesthetic Quality</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="57.19% by Nano Banana Pro, demonstrating significant deficits in fluid intelligence even for state-of-the-art models">
                        <div class="quiz-question">2. What was the highest overall score achieved by any model on the GENIUS benchmark, and what does this reveal about current AI capabilities?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="85.3% by GPT-Image, showing models are close to human-level fluid intelligence">85.3% by GPT-Image, showing models are close to human-level fluid intelligence</div><div class="quiz-choice" data-value="72.8% by Bagel, indicating moderate success in generative reasoning tasks">72.8% by Bagel, indicating moderate success in generative reasoning tasks</div><div class="quiz-choice long-text" data-value="57.19% by Nano Banana Pro, demonstrating significant deficits in fluid intelligence even for state-of-the-art models">57.19% by Nano Banana Pro, demonstrating significant deficits in fluid intelligence even for state-of-the-art models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Imbalanced attention distribution that results in noisy implicit gradients, preventing models from overcoming pre-trained priors">
                        <div class="quiz-question">3. According to the paper's theoretical analysis, what is the primary cause of models' failure in Generative Fluid Intelligence tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Insufficient training data containing novel scenarios and constraints">Insufficient training data containing novel scenarios and constraints</div><div class="quiz-choice long-text" data-value="Imbalanced attention distribution that results in noisy implicit gradients, preventing models from overcoming pre-trained priors">Imbalanced attention distribution that results in noisy implicit gradients, preventing models from overcoming pre-trained priors</div><div class="quiz-choice" data-value="Limited computational resources during inference that restrict complex reasoning capabilities">Limited computational resources during inference that restrict complex reasoning capabilities</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-paper.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>PhyCritic: Multimodal Critic Models for Physical AI</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-11</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.11124" target="_blank">http://arxiv.org/pdf/2602.11124</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper focuses on developing multimodal critic models specifically designed for evaluating physical AI tasks involving perception, causal reasoning, and planning in embodied environments.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing multimodal reward models and reinforcement learning techniques for vision-language models, proposing a novel self-referential critic finetuning approach where the critic first generates its own prediction before evaluating candidate responses.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the lack of physics-aware multimodal critics that can reliably evaluate responses involving physical perception, causal reasoning, and action planning, as existing critics focus mainly on general visual domains.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a two-stage RLVR pipeline with GRPO optimization: Stage 1 involves physical skill warmup on question-answer pairs, followed by Stage 2 self-referential critic finetuning where the model generates its own prediction before judging candidate responses.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> PhyCritic achieved the best performance among open-source 7B/8B models on PhyCritic-Bench (68.0% accuracy), outperformed baselines on physical reasoning benchmarks (CosmosReason1-Bench, CV-Bench, EgoPlan-Bench2), and demonstrated strong generalization to general multimodal reward benchmarks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>PhyCritic: Multimodal Critic Models for Physical AI</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <defs>
    <linearGradient id="bgGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f8f9fa"/>
      <stop offset="100%" style="stop-color:#e9ecef"/>
    </linearGradient>
    <linearGradient id="stage1Grad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#e3f2fd"/>
      <stop offset="100%" style="stop-color:#bbdefb"/>
    </linearGradient>
    <linearGradient id="stage2Grad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f3e5f5"/>
      <stop offset="100%" style="stop-color:#e1bee7"/>
    </linearGradient>
    <linearGradient id="dataGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#e8f5e8"/>
      <stop offset="100%" style="stop-color:#c8e6c8"/>
    </linearGradient>
  </defs>
  
  <rect width="100%" height="100%" fill="url(#bgGrad)"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">PhyCritic: Multimodal Critic Models for Physical AI</text>
  <text x="500" y="65" text-anchor="middle" font-size="16" fill="#7f8c8d">Two-Stage RLVR Training Pipeline</text>
  
  <!-- Data Sources -->
  <rect x="50" y="100" width="200" height="120" rx="10" fill="url(#dataGrad)" stroke="#4caf50" stroke-width="2"/>
  <text x="150" y="125" text-anchor="middle" font-size="14" font-weight="bold" fill="#2e7d32">Training Data Sources</text>
  <text x="150" y="145" text-anchor="middle" font-size="11" fill="#2e7d32">‚Ä¢ RoboVQA</text>
  <text x="150" y="160" text-anchor="middle" font-size="11" fill="#2e7d32">‚Ä¢ BridgeData V2</text>
  <text x="150" y="175" text-anchor="middle" font-size="11" fill="#2e7d32">‚Ä¢ HoloAssist</text>
  <text x="150" y="190" text-anchor="middle" font-size="11" fill="#2e7d32">‚Ä¢ AgiBot World</text>
  <text x="150" y="205" text-anchor="middle" font-size="11" fill="#2e7d32">‚Ä¢ Cosmos-Reason1</text>
  
  <!-- Base Model -->
  <circle cx="150" cy="300" r="40" fill="#ff9800" stroke="#f57c00" stroke-width="3"/>
  <text x="150" y="295" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Base</text>
  <text x="150" y="308" text-anchor="middle" font-size="12" font-weight="bold" fill="white">Model</text>
  <text x="150" y="355" text-anchor="middle" font-size="10" fill="#f57c00">Qwen2.5-VL-7B</text>
  
  <!-- Stage 1: Physical Skill Warmup -->
  <rect x="300" y="240" width="280" height="160" rx="15" fill="url(#stage1Grad)" stroke="#2196f3" stroke-width="3"/>
  <text x="440" y="265" text-anchor="middle" font-size="16" font-weight="bold" fill="#1976d2">Stage 1: Physical Skill Warmup</text>
  
  <!-- GRPO Process -->
  <rect x="320" y="280" width="240" height="50" rx="8" fill="#ffffff" stroke="#2196f3" stroke-width="2"/>
  <text x="440" y="300" text-anchor="middle" font-size="12" font-weight="bold" fill="#1976d2">Vanilla GRPO Training</text>
  <text x="440" y="315" text-anchor="middle" font-size="10" fill="#1976d2">80 steps on Physical QA pairs</text>
  
  <!-- Reward Formula Stage 1 -->
  <rect x="320" y="340" width="240" height="50" rx="8" fill="#e3f2fd" stroke="#2196f3" stroke-width="1"/>
  <text x="440" y="360" text-anchor="middle" font-size="12" font-weight="bold" fill="#1976d2">Accuracy Reward</text>
  <text x="440" y="375" text-anchor="middle" font-size="10" fill="#1976d2">R = I(√Ç_pred(Q) = A^Q)</text>
  
  <!-- Stage 2: Self-Referential Critic Finetuning -->
  <rect x="650" y="180" width="320" height="280" rx="15" fill="url(#stage2Grad)" stroke="#9c27b0" stroke-width="3"/>
  <text x="810" y="205" text-anchor="middle" font-size="16" font-weight="bold" fill="#7b1fa2">Stage 2: Self-Referential Critic Finetuning</text>
  
  <!-- Self-Prediction Component -->
  <rect x="670" y="220" width="130" height="70" rx="8" fill="#ffffff" stroke="#9c27b0" stroke-width="2"/>
  <text x="735" y="240" text-anchor="middle" font-size="11" font-weight="bold" fill="#7b1fa2">Self-Prediction</text>
  <text x="735" y="255" text-anchor="middle" font-size="9" fill="#7b1fa2">&lt;pred_think&gt;</text>
  <text x="735" y="270" text-anchor="middle" font-size="9" fill="#7b1fa2">&lt;pred&gt;</text>
  <text x="735" y="285" text-anchor="middle" font-size="9" fill="#7b1fa2">Own reasoning</text>
  
  <!-- Critic Judgment Component -->
  <rect x="820" y="220" width="130" height="70" rx="8" fill="#ffffff" stroke="#9c27b0" stroke-width="2"/>
  <text x="885" y="240" text-anchor="middle" font-size="11" font-weight="bold" fill="#7b1fa2">Critic Judgment</text>
  <text x="885" y="255" text-anchor="middle" font-size="9" fill="#7b1fa2">&lt;think&gt;</text>
  <text x="885" y="270" text-anchor="middle" font-size="9" fill="#7b1fa2">\boxed{}</text>
  <text x="885" y="285" text-anchor="middle" font-size="9" fill="#7b1fa2">Preference eval</text>
  
  <!-- Reward Components Stage 2 -->
  <rect x="670" y="310" width="280" height="80" rx="8" fill="#f3e5f5" stroke="#9c27b0" stroke-width="1"/>
  <text x="810" y="330" text-anchor="middle" font-size="12" font-weight="bold" fill="#7b1fa2">Reward Components</text>
  <text x="810" y="345" text-anchor="middle" font-size="10" fill="#7b1fa2">R_total = R_acc + Œ±_form √ó R_form</text>
  <text x="810" y="360" text-anchor="middle" font-size="10" fill="#7b1fa2">R_acc = Œ±_sp √ó R_sp + Œ±_crit √ó R_crit</text>
  <text x="810" y="375" text-anchor="middle" font-size="9" fill="#7b1fa2">Self-prediction + Critic + Format rewards</text>
  
  <!-- GRPO Training Stage 2 -->
  <rect x="670" y="400" width="280" height="50" rx="8" fill="#ffffff" stroke="#9c27b0" stroke-width="2"/>
  <text x="810" y="420" text-anchor="middle" font-size="12" font-weight="bold" fill="#7b1fa2">GRPO with Multi-Reward</text>
  <text x="810" y="435" text-anchor="middle" font-size="10" fill="#7b1fa2">300 steps with preference data</text>
  
  <!-- Final Model -->
  <circle cx="810" cy="530" r="50" fill="#4caf50" stroke="#388e3c" stroke-width="3"/>
  <text x="810" y="520" text-anchor="middle" font-size="14" font-weight="bold" fill="white">PhyCritic</text>
  <text x="810" y="535" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Model</text>
  <text x="810" y="550" text-anchor="middle" font-size="14" font-weight="bold" fill="white">7B</text>
  
  <!-- Evaluation -->
  <rect x="50" y="600" width="900" height="120" rx="15" fill="#fff3e0" stroke="#ff9800" stroke-width="3"/>
  <text x="500" y="625" text-anchor="middle" font-size="16" font-weight="bold" fill="#f57c00">Evaluation Results</text>
  
  <!-- Benchmark Results -->
  <rect x="80" y="640" width="200" height="70" rx="8" fill="#ffffff" stroke="#ff9800" stroke-width="2"/>
  <text x="180" y="660" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">PhyCritic-Bench</text>
  <text x="180" y="675" text-anchor="middle" font-size="11" fill="#f57c00">68.0% accuracy</text>
  <text x="180" y="690" text-anchor="middle" font-size="10" fill="#f57c00">Best open-source 7B</text>
  
  <rect x="300" y="640" width="200" height="70" rx="8" fill="#ffffff" stroke="#ff9800" stroke-width="2"/>
  <text x="400" y="660" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">CosmosReason1</text>
  <text x="400" y="675" text-anchor="middle" font-size="11" fill="#f57c00">63.9% accuracy</text>
  <text x="400" y="690" text-anchor="middle" font-size="10" fill="#f57c00">Physical reasoning</text>
  
  <rect x="520" y="640" width="200" height="70" rx="8" fill="#ffffff" stroke="#ff9800" stroke-width="2"/>
  <text x="620" y="660" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">VL-RewardBench</text>
  <text x="620" y="675" text-anchor="middle" font-size="11" fill="#f57c00">57.3% accuracy</text>
  <text x="620" y="690" text-anchor="middle" font-size="10" fill="#f57c00">General domains</text>
  
  <rect x="740" y="640" width="200" height="70" rx="8" fill="#ffffff" stroke="#ff9800" stroke-width="2"/>
  <text x="840" y="660" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">Best-of-N</text>
  <text x="840" y="675" text-anchor="middle" font-size="11" fill="#f57c00">+6.5% improvement</text>
  <text x="840" y="690" text-anchor="middle" font-size="10" fill="#f57c00">Test-time scaling</text>
  
  <!-- Flow connections -->
  <path d="M 150 220 L 150 260" stroke="#666" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 190 300 L 300 320" stroke="#666" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 580 320 L 650 320" stroke="#666" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 810 460 L 810 480" stroke="#666" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 810 580 L 500 600" stroke="#666" stroke-width="3" fill="none" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>
  
  <!-- Key Innovation Highlight -->
  <rect x="400" y="480" width="200" height="60" rx="10" fill="#ffeb3b" stroke="#fbc02d" stroke-width="2" opacity="0.9"/>
  <text x="500" y="500" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57f17">Key Innovation</text>
  <text x="500" y="515" text-anchor="middle" font-size="11" fill="#f57f17">Self-referential</text>
  <text x="500" y="530" text-anchor="middle" font-size="11" fill="#f57f17">critic finetuning</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="The model first generates its own prediction for the question before evaluating candidate responses">
                        <div class="quiz-question">1. What is the core innovation of PhyCritic's self-referential critic finetuning approach?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="The model first generates its own prediction for the question before evaluating candidate responses">The model first generates its own prediction for the question before evaluating candidate responses</div><div class="quiz-choice" data-value="The model uses multiple vision encoders to process physical scenes from different angles">The model uses multiple vision encoders to process physical scenes from different angles</div><div class="quiz-choice long-text" data-value="The model employs adversarial training to distinguish between correct and incorrect physical reasoning">The model employs adversarial training to distinguish between correct and incorrect physical reasoning</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="ImageNet, COCO, and Visual Genome">
                        <div class="quiz-question">2. Which datasets were NOT used in constructing the PhyCritic training dataset?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="RoboVQA, BridgeData V2, and HoloAssist">RoboVQA, BridgeData V2, and HoloAssist</div><div class="quiz-choice" data-value="ImageNet, COCO, and Visual Genome">ImageNet, COCO, and Visual Genome</div><div class="quiz-choice" data-value="AgiBot World and Cosmos-Reason1">AgiBot World and Cosmos-Reason1</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="4,058 samples with 380 RL steps (80 + 300) for data-efficient training">
                        <div class="quiz-question">3. How many training samples and RL steps does PhyCritic require compared to approaches using millions of supervised traces?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="10,000+ samples with 1,000+ RL steps for comprehensive coverage">10,000+ samples with 1,000+ RL steps for comprehensive coverage</div><div class="quiz-choice" data-value="4,058 samples with 380 RL steps (80 + 300) for data-efficient training">4,058 samples with 380 RL steps (80 + 300) for data-efficient training</div><div class="quiz-choice" data-value="50,000 samples with 2,000 RL steps for robust performance">50,000 samples with 2,000 RL steps for robust performance</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-10</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.10090" target="_blank">http://arxiv.org/pdf/2602.10090</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper presents Agent World Model (AWM), a synthetic environment generation pipeline for training tool-use agents in reinforcement learning within the domain of autonomous AI agents and multi-turn tool interactions.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing work in LLM-based agents and synthetic data generation, proposing a novel code-driven pipeline that systematically generates executable environments with database-backed state consistency rather than relying on LLM simulation or limited hand-crafted environments.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the scalability limitations in training tool-use agents caused by the lack of diverse, reliable, and executable environments that can support large-scale reinforcement learning.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a five-step synthesis pipeline (scenario generation, task synthesis, database design, interface creation, and verification) combined with Group Relative Policy Optimization (GRPO) for reinforcement learning training on 1,000 generated environments.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The results show that agents trained exclusively on synthetic environments achieve strong out-of-distribution generalization across three benchmarks (BFCLv3, œÑ¬≤-bench, MCP-Universe), consistently outperforming baseline methods and demonstrating the effectiveness of the synthetic training approach.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background gradient -->
  <defs>
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f4f8;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e2e8f0;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="blueGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4299e1;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#2b77cb;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="greenGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#48bb78;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#38a169;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="purpleGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#9f7aea;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#805ad5;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="orangeGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#ed8936;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#dd6b20;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Background -->
  <rect width="100%" height="100%" fill="url(#bgGradient)"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-family="Arial, sans-serif" font-size="20" font-weight="bold" fill="#2d3748">
    Agent World Model (AWM) Workflow
  </text>
  
  <!-- Step 1: Scenario Synthesis -->
  <rect x="50" y="60" width="180" height="80" rx="10" fill="url(#blueGradient)" stroke="#2b77cb" stroke-width="2"/>
  <text x="140" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Step 1: Scenario Synthesis
  </text>
  <text x="140" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    100 seed domains ‚Üí 1,000 scenarios
  </text>
  <text x="140" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    LLM expansion + filtering
  </text>
  
  <!-- Step 2: Task Generation -->
  <rect x="270" y="60" width="180" height="80" rx="10" fill="url(#greenGradient)" stroke="#38a169" stroke-width="2"/>
  <text x="360" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Step 2: Task Generation
  </text>
  <text x="360" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    10 tasks per scenario
  </text>
  <text x="360" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    API-solvable, post-auth
  </text>
  
  <!-- Step 3: Database Design -->
  <rect x="50" y="180" width="180" height="100" rx="10" fill="url(#purpleGradient)" stroke="#805ad5" stroke-width="2"/>
  <text x="140" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Step 3: Database Design
  </text>
  <text x="140" y="225" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    SQLite schema generation
  </text>
  <text x="140" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Sample data synthesis
  </text>
  <text x="140" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Self-correction mechanism
  </text>
  
  <!-- Step 4: Interface Generation -->
  <rect x="270" y="180" width="180" height="100" rx="10" fill="url(#orangeGradient)" stroke="#dd6b20" stroke-width="2"/>
  <text x="360" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Step 4: Interface Generation
  </text>
  <text x="360" y="225" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    MCP toolset design
  </text>
  <text x="360" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Python code generation
  </text>
  <text x="360" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    35 tools per environment
  </text>
  
  <!-- Step 5: Verification -->
  <rect x="490" y="180" width="180" height="100" rx="10" fill="#e53e3e" stroke="#c53030" stroke-width="2"/>
  <text x="580" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="white">
    Step 5: Verification
  </text>
  <text x="580" y="225" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Code-augmented judge
  </text>
  <text x="580" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Database state comparison
  </text>
  <text x="580" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    Reward signal generation
  </text>
  
  <!-- Reinforcement Learning Training -->
  <rect x="720" y="60" width="220" height="220" rx="15" fill="#2d3748" stroke="#1a202c" stroke-width="3"/>
  <text x="830" y="85" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">
    Agentic Reinforcement Learning
  </text>
  
  <!-- RL Components -->
  <rect x="740" y="100" width="180" height="40" rx="5" fill="#4a5568" stroke="#718096" stroke-width="1"/>
  <text x="830" y="125" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    GRPO Algorithm
  </text>
  
  <rect x="740" y="150" width="180" height="40" rx="5" fill="#4a5568" stroke="#718096" stroke-width="1"/>
  <text x="830" y="175" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    History-Aware Training
  </text>
  
  <rect x="740" y="200" width="180" height="40" rx="5" fill="#4a5568" stroke="#718096" stroke-width="1"/>
  <text x="830" y="225" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="white">
    1,024 Parallel Instances
  </text>
  
  <rect x="740" y="250" width="180" height="20" rx="3" fill="#68d391" stroke="#48bb78" stroke-width="1"/>
  <text x="830" y="263" text-anchor="middle" font-family="Arial, sans-serif" font-size="9" fill="#1a202c">
    Trained Tool-Use Agents
  </text>
  
  <!-- Flow connections -->
  <path d="M 230 100 L 270 100" stroke="#4a5568" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 360 140 L 360 180" stroke="#4a5568" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 140 140 L 140 180" stroke="#4a5568" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 450 230 L 490 230" stroke="#4a5568" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 230 230 L 270 230" stroke="#4a5568" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 670 230 L 720 170" stroke="#4a5568" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  
  <!-- Key Statistics -->
  <rect x="50" y="320" width="900" height="120" rx="10" fill="#f7fafc" stroke="#cbd5e0" stroke-width="2"/>
  <text x="500" y="345" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2d3748">
    AWM Pipeline Results
  </text>
  
  <text x="150" y="370" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#2b77cb">
    1,000 Environments
  </text>
  <text x="150" y="390" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Diverse scenarios
  </text>
  
  <text x="350" y="370" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#38a169">
    35,062 Tools
  </text>
  <text x="350" y="390" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    MCP interfaces
  </text>
  
  <text x="550" y="370" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#805ad5">
    10,000 Tasks
  </text>
  <text x="550" y="390" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    With verification
  </text>
  
  <text x="750" y="370" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#dd6b20">
    88% Success Rate
  </text>
  <text x="750" y="390" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Self-correction
  </text>
  
  <text x="150" y="415" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    18.5 tables avg
  </text>
  <text x="350" y="415" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    2K lines code avg
  </text>
  <text x="550" y="415" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    8.5 steps avg
  </text>
  <text x="750" y="415" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    1.13 trials avg
  </text>
  
  <!-- Evaluation Results -->
  <rect x="50" y="480" width="900" height="100" rx="10" fill="#e6fffa" stroke="#4fd1c7" stroke-width="2"/>
  <text x="500" y="505" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2d3748">
    Evaluation on Out-of-Distribution Benchmarks
  </text>
  
  <text x="200" y="535" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#319795">
    BFCLv3
  </text>
  <text x="200" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    +12.11 improvement
  </text>
  
  <text x="400" y="535" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#319795">
    œÑ¬≤-bench
  </text>
  <text x="400" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Competitive results
  </text>
  
  <text x="600" y="535" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#319795">
    MCP-Universe
  </text>
  <text x="600" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Best overall
  </text>
  
  <text x="800" y="535" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#319795">
    Generalization
  </text>
  <text x="800" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Strong OOD performance
  </text>
  
  <!-- Key Features -->
  <rect x="50" y="620" width="900" height="120" rx="10" fill="#fff5f5" stroke="#feb2b2" stroke-width="2"/>
  <text x="500" y="645" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2d3748">
    Key Technical Innovations
  </text>
  
  <circle cx="150" cy="670" r="25" fill="#e53e3e" stroke="#c53030" stroke-width="2"/>
  <text x="150" y="675" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" font-weight="bold" fill="white">
    Code
  </text>
  <text x="150" y="700" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Database-backed state
  </text>
  <text x="150" y="715" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    consistency
  </text>
  
  <circle cx="350" cy="670" r="25" fill="#805ad5" stroke="#6b46c1" stroke-width="2"/>
  <text x="350" y="675" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" font-weight="bold" fill="white">
    MCP
  </text>
  <text x="350" y="700" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Unified interface
  </text>
  <text x="350" y="715" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    protocol
  </text>
  
  <circle cx="550" cy="670" r="25" fill="#38a169" stroke="#2f855a" stroke-width="2"/>
  <text x="550" y="675" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" font-weight="bold" fill="white">
    Auto
  </text>
  <text x="550" y="700" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Self-correction</text>
  <text x="550" y="715" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    mechanism
  </text>
  
  <circle cx="750" cy="670" r="25" fill="#dd6b20" stroke="#c05621" stroke-width="2"/>
  <text x="750" y="675" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" font-weight="bold" fill="white">
    Scale
  </text>
  <text x="750" y="700" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    Parallel RL training</text>
  <text x="750" y="715" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#4a5568">
    1K instances
  </text>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" 
            refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#4a5568" />
    </marker>
  </defs>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="They provide more reliable state transitions and are more cost-effective for large-scale RL training">
                        <div class="quiz-question">1. What is the key advantage of AWM's code-driven environments over LLM-simulated environments for agent training?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They provide more reliable state transitions and are more cost-effective for large-scale RL training">They provide more reliable state transitions and are more cost-effective for large-scale RL training</div><div class="quiz-choice" data-value="They generate more creative and diverse scenarios than LLM simulation">They generate more creative and diverse scenarios than LLM simulation</div><div class="quiz-choice" data-value="They require less computational resources during environment synthesis">They require less computational resources during environment synthesis</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="1,000 environments with 35,062 tools">
                        <div class="quiz-question">2. How many environments and tools did the AWM pipeline successfully generate at scale?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="500 environments with 20,000 tools">500 environments with 20,000 tools</div><div class="quiz-choice" data-value="1,000 environments with 35,062 tools">1,000 environments with 35,062 tools</div><div class="quiz-choice" data-value="2,000 environments with 50,000 tools">2,000 environments with 50,000 tools</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Code-augmented LLM-as-a-Judge that combines structured database verification with trajectory context">
                        <div class="quiz-question">3. What verification approach does AWM use to provide robust reward signals for RL training?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Pure code-based verification that strictly checks database state changes">Pure code-based verification that strictly checks database state changes</div><div class="quiz-choice" data-value="LLM-only verification that judges based solely on agent trajectories">LLM-only verification that judges based solely on agent trajectories</div><div class="quiz-choice" data-value="Code-augmented LLM-as-a-Judge that combines structured database verification with trajectory context">Code-augmented LLM-as-a-Judge that combines structured database verification with trajectory context</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');

                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫ÊØè‰∏™Âç°ÁâáÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂ÔºàËÄå‰∏çÊòØÊï¥‰∏™ÂÆπÂô®Ôºâ
                cards.forEach(card => {
                    card.addEventListener('click', function(e) {
                        // Âè™ÊúâÁÇπÂáªÂú®Âç°ÁâáÂÜÖÈÉ®Êó∂ÊâçÂàáÊç¢
                        // Ê£ÄÊü•ÊòØÂê¶ÊòØÊµÅÁ®ãÂõæÂç°ÁâáÁöÑÊªöÂä®Êù°Âå∫Âüü
                        if (this.classList.contains('flowchart-card')) {
                            const rect = this.getBoundingClientRect();
                            const isScrollbarClick =
                                (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                                (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);

                            if (!isScrollbarClick) {
                                nextCard(e);
                            }
                        } else {
                            nextCard(e);
                        }
                    });
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
