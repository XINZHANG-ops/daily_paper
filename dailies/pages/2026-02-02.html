<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2026-02-02 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */
            /* cursor removed - only cards should show pointer */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
            cursor: pointer; /* Show pointer on cards to indicate they're clickable */
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }

        .paper-card p {
            margin: 5px 0;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
            word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        /* ÁßªÂä®ËÆæÂ§áÂíåÂ∞èÂ±èÂπï */
        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                min-height: 400px; /* ÁßªÂä®ËÆæÂ§á‰∏ä‰ΩøÁî®Êõ¥Â∞èÁöÑÊúÄÂ∞èÈ´òÂ∫¶ */
                height: auto; /* Ëá™ÈÄÇÂ∫îÈ´òÂ∫¶ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }

            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
                width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-02-02 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tasky.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-28</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.20833" target="_blank">http://arxiv.org/pdf/2601.20833</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on autonomous scientific discovery using large language models (LLMs) in the domain of AI-assisted research automation.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Building on runtime-centric LLM research agents that repeatedly process literature online, the paper proposes Idea2Story, a pre-computation-driven framework that shifts literature understanding to offline knowledge graph construction.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the computational inefficiency and unreliability of existing LLM-based research agents that repeatedly read and reason over large volumes of scientific literature at runtime.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a two-stage approach: offline construction of a methodological knowledge graph from peer-reviewed papers and reviews, followed by online research generation through graph-based retrieval and composition of reusable method units.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Qualitative analyses and case studies demonstrate that Idea2Story generates more coherent, methodologically grounded, and novel research patterns compared to direct LLM generation, with external evaluation consistently favoring Idea2Story's outputs.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Title -->
  <text x="500" y="30" font-size="24" font-weight="bold" text-anchor="middle" fill="#2C3E50">Idea2Story: Research Concept to Scientific Narrative Pipeline</text>
  
  <!-- Offline Stage Container -->
  <rect x="50" y="60" width="400" height="300" fill="#E8F4F8" stroke="#3498DB" stroke-width="2" rx="10"/>
  <text x="250" y="85" font-size="18" font-weight="bold" text-anchor="middle" fill="#3498DB">Offline Knowledge Construction</text>
  
  <!-- Paper Pool -->
  <rect x="70" y="100" width="160" height="60" fill="#85C1E9" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="150" y="125" font-size="14" text-anchor="middle" fill="white">Paper Pool Construction</text>
  <text x="150" y="145" font-size="12" text-anchor="middle" fill="white">~13K papers from</text>
  <text x="150" y="155" font-size="12" text-anchor="middle" fill="white">NeurIPS & ICLR</text>
  
  <!-- Method Unit Extraction -->
  <rect x="70" y="180" width="160" height="60" fill="#F39C12" stroke="#D68910" stroke-width="2" rx="5"/>
  <text x="150" y="205" font-size="14" text-anchor="middle" fill="white">Method Unit Extraction</text>
  <text x="150" y="225" font-size="12" text-anchor="middle" fill="white">Core methodological</text>
  <text x="150" y="235" font-size="12" text-anchor="middle" fill="white">contributions</text>
  
  <!-- Knowledge Graph -->
  <rect x="70" y="260" width="160" height="60" fill="#27AE60" stroke="#229954" stroke-width="2" rx="5"/>
  <text x="150" y="285" font-size="14" text-anchor="middle" fill="white">Knowledge Graph</text>
  <text x="150" y="305" font-size="12" text-anchor="middle" fill="white">Structured method units</text>
  <text x="150" y="315" font-size="12" text-anchor="middle" fill="white">& relations</text>
  
  <!-- Offline Details -->
  <rect x="260" y="100" width="170" height="220" fill="#FFF3CD" stroke="#F0AD4E" stroke-width="1" rx="5"/>
  <text x="345" y="120" font-size="12" text-anchor="middle" fill="#856404">Key Components:</text>
  <text x="270" y="140" font-size="11" fill="#856404">‚Ä¢ Anonymization (A)</text>
  <text x="270" y="160" font-size="11" fill="#856404">‚Ä¢ Safety filtering (F)</text>
  <text x="270" y="180" font-size="11" fill="#856404">‚Ä¢ Review artifacts</text>
  <text x="270" y="200" font-size="11" fill="#856404">‚Ä¢ UMAP reduction</text>
  <text x="270" y="220" font-size="11" fill="#856404">‚Ä¢ DBSCAN clustering</text>
  <text x="270" y="240" font-size="11" fill="#856404">‚Ä¢ Meta-methods</text>
  <text x="270" y="260" font-size="11" fill="#856404">‚Ä¢ Composition relations</text>
  <text x="270" y="280" font-size="11" fill="#856404">‚Ä¢ Canonicalization</text>
  <text x="270" y="300" font-size="11" fill="#856404">‚Ä¢ Graph G=(V,E)</text>
  
  <!-- Online Stage Container -->
  <rect x="500" y="60" width="450" height="300" fill="#FFF5F5" stroke="#E74C3C" stroke-width="2" rx="10"/>
  <text x="725" y="85" font-size="18" font-weight="bold" text-anchor="middle" fill="#E74C3C">Online Research Generation</text>
  
  <!-- User Input -->
  <ellipse cx="600" cy="130" rx="80" ry="30" fill="#EC7063" stroke="#C0392B" stroke-width="2"/>
  <text x="600" y="135" font-size="14" text-anchor="middle" fill="white">User Research Idea</text>
  
  <!-- Pattern Retrieval -->
  <rect x="520" y="180" width="160" height="60" fill="#9B59B6" stroke="#7D3C98" stroke-width="2" rx="5"/>
  <text x="600" y="205" font-size="14" text-anchor="middle" fill="white">Pattern Retrieval</text>
  <text x="600" y="225" font-size="12" text-anchor="middle" fill="white">Multi-view scoring</text>
  
  <!-- Review-Guided Refinement -->
  <rect x="520" y="260" width="160" height="60" fill="#3498DB" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="600" y="285" font-size="14" text-anchor="middle" fill="white">Review-Guided</text>
  <text x="600" y="305" font-size="12" text-anchor="middle" fill="white">Refinement</text>
  
  <!-- Online Details -->
  <rect x="710" y="100" width="220" height="220" fill="#E8F8F5" stroke="#16A085" stroke-width="1" rx="5"/>
  <text x="820" y="120" font-size="12" text-anchor="middle" fill="#0E6655">Retrieval Views:</text>
  <text x="720" y="140" font-size="11" fill="#0E6655">‚Ä¢ Idea-level similarity</text>
  <text x="720" y="160" font-size="11" fill="#0E6655">‚Ä¢ Domain-level relevance</text>
  <text x="720" y="180" font-size="11" fill="#0E6655">‚Ä¢ Paper-level alignment</text>
  <text x="820" y="210" font-size="12" text-anchor="middle" fill="#0E6655">Refinement Process:</text>
  <text x="720" y="230" font-size="11" fill="#0E6655">‚Ä¢ LLM-based review</text>
  <text x="720" y="250" font-size="11" fill="#0E6655">‚Ä¢ Generate-review-revise loop</text>
  <text x="720" y="270" font-size="11" fill="#0E6655">‚Ä¢ Novelty & soundness checks</text>
  <text x="720" y="290" font-size="11" fill="#0E6655">‚Ä¢ Rollback mechanism</text>
  
  <!-- Output -->
  <rect x="300" y="400" width="400" height="80" fill="#2ECC71" stroke="#27AE60" stroke-width="3" rx="10"/>
  <text x="500" y="430" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Structured Research Pattern Output</text>
  <text x="500" y="450" font-size="14" text-anchor="middle" fill="white">Coherent, methodologically grounded research directions</text>
  <text x="500" y="470" font-size="14" text-anchor="middle" fill="white">Ready for experimentation & paper generation</text>
  
  <!-- Flow Connections -->
  <path d="M 150 160 L 150 180" stroke="#34495E" stroke-width="2" fill="none"/>
  <path d="M 150 240 L 150 260" stroke="#34495E" stroke-width="2" fill="none"/>
  <path d="M 230 290 L 450 290 L 450 210 L 520 210" stroke="#E74C3C" stroke-width="2" fill="none" stroke-dasharray="5,5"/>
  <path d="M 600 160 L 600 180" stroke="#34495E" stroke-width="2" fill="none"/>
  <path d="M 600 240 L 600 260" stroke="#34495E" stroke-width="2" fill="none"/>
  <path d="M 600 320 L 600 400" stroke="#27AE60" stroke-width="3" fill="none"/>
  
  <!-- Legend -->
  <rect x="50" y="520" width="900" height="100" fill="#F8F9FA" stroke="#BDC3C7" stroke-width="1" rx="5"/>
  <text x="500" y="540" font-size="14" font-weight="bold" text-anchor="middle" fill="#34495E">Key Innovation: Pre-computation‚ÄìDriven Framework</text>
  <rect x="100" y="560" width="20" height="20" fill="#85C1E9"/>
  <text x="130" y="575" font-size="12" fill="#34495E">Data Collection</text>
  <rect x="300" y="560" width="20" height="20" fill="#F39C12"/>
  <text x="330" y="575" font-size="12" fill="#34495E">Extraction</text>
  <rect x="500" y="560" width="20" height="20" fill="#27AE60"/>
  <text x="530" y="575" font-size="12" fill="#34495E">Knowledge Structure</text>
  <rect x="700" y="560" width="20" height="20" fill="#9B59B6"/>
  <text x="730" y="575" font-size="12" fill="#34495E">Retrieval & Composition</text>
  <text x="500" y="600" font-size="12" text-anchor="middle" fill="#7F8C8D">Shifts literature understanding from online reasoning to offline knowledge construction</text>
  
  <!-- Performance Notes -->
  <text x="500" y="680" font-size="16" font-weight="bold" text-anchor="middle" fill="#2C3E50">Benefits</text>
  <text x="250" y="710" font-size="14" text-anchor="middle" fill="#27AE60">‚úì Reduced computational cost</text>
  <text x="500" y="710" font-size="14" text-anchor="middle" fill="#27AE60">‚úì Alleviates context window bottleneck</text>
  <text x="750" y="710" font-size="14" text-anchor="middle" fill="#27AE60">‚úì Higher quality research patterns</text>
  <text x="250" y="740" font-size="14" text-anchor="middle" fill="#27AE60">‚úì Reusable methodological abstractions</text>
  <text x="500" y="740" font-size="14" text-anchor="middle" fill="#27AE60">‚úì Grounded in peer-reviewed work</text>
  <text x="750" y="740" font-size="14" text-anchor="middle" fill="#27AE60">‚úì End-to-end paper generation</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Shifting from runtime-centric execution to pre-computation-driven knowledge graph construction">
                        <div class="quiz-question">1. What is the fundamental paradigm shift that Idea2Story introduces compared to existing LLM-based research agents?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Moving from offline to online literature processing for faster runtime execution">Moving from offline to online literature processing for faster runtime execution</div><div class="quiz-choice" data-value="Shifting from runtime-centric execution to pre-computation-driven knowledge graph construction">Shifting from runtime-centric execution to pre-computation-driven knowledge graph construction</div><div class="quiz-choice" data-value="Replacing knowledge graphs with direct neural embeddings of research papers">Replacing knowledge graphs with direct neural embeddings of research papers</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Method units capturing core methodological contributions and their composition relations">
                        <div class="quiz-question">2. In the offline knowledge construction phase, what specific artifacts does Idea2Story extract from the approximately 13,000 papers in its corpus?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Author names, affiliations, and citation networks for collaboration analysis">Author names, affiliations, and citation networks for collaboration analysis</div><div class="quiz-choice" data-value="Raw experimental results and dataset specifications for reproducibility">Raw experimental results and dataset specifications for reproducibility</div><div class="quiz-choice" data-value="Method units capturing core methodological contributions and their composition relations">Method units capturing core methodological contributions and their composition relations</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Idea2Story reframed it as a dynamic structural reasoning process while LLM kept it as static classification">
                        <div class="quiz-question">3. When comparing Idea2Story's output to direct LLM generation for the e-commerce intent understanding task, what was the key difference in problem formulation?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="Idea2Story reframed it as a dynamic structural reasoning process while LLM kept it as static classification">Idea2Story reframed it as a dynamic structural reasoning process while LLM kept it as static classification</div><div class="quiz-choice" data-value="Both systems proposed identical multi-class classification approaches with different architectures">Both systems proposed identical multi-class classification approaches with different architectures</div><div class="quiz-choice" data-value="LLM introduced diffusion-based methods while Idea2Story used traditional BERT encoders">LLM introduced diffusion-based methods while Idea2Story used traditional BERT encoders</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-28</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.20354" target="_blank">http://arxiv.org/pdf/2601.20354</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on benchmarking spatial intelligence of text-to-image models, evaluating their ability to understand and generate complex spatial relationships in images.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Building on existing T2I benchmarks that use short or information-sparse prompts, this work proposes long, information-dense prompts covering 10 spatial sub-domains and introduces omni-dimensional multi-choice evaluations instead of simple yes/no questions.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Current T2I models excel at generating objects but fail at handling complex spatial relationships like positioning, orientation, occlusion, and causal interactions, which existing benchmarks fail to adequately evaluate.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors create SpatialGenEval with 1,230 information-dense prompts across 25 real-world scenes, each paired with 10 multi-choice questions targeting different spatial abilities, and construct SpatialT2I dataset with 15,400 text-image pairs for fine-tuning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Evaluation of 23 SOTA models reveals spatial reasoning as the primary bottleneck (scores often below 30%), while fine-tuning with SpatialT2I yields consistent improvements (+4.2% for SD-XL, +5.7% for UniWorld-V1, +4.4% for OmniGen2).</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Title -->
  <text x="500" y="30" font-size="24" font-weight="bold" text-anchor="middle" fill="#2C3E50">SpatialGenEval: Benchmarking Workflow</text>
  
  <!-- Main Components -->
  <!-- 1. Domain & Scene Selection -->
  <rect x="50" y="80" width="200" height="100" rx="10" fill="#3498DB" stroke="#2980B9" stroke-width="2"/>
  <text x="150" y="120" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Domain & Scene</text>
  <text x="150" y="140" font-size="14" text-anchor="middle" fill="white">Selection</text>
  <text x="150" y="160" font-size="12" text-anchor="middle" fill="white">(25 scenes, 10 domains)</text>
  
  <!-- 2. Prompt Generation -->
  <rect x="350" y="80" width="200" height="100" rx="10" fill="#E74C3C" stroke="#C0392B" stroke-width="2"/>
  <text x="450" y="120" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Prompt Generation</text>
  <text x="450" y="140" font-size="14" text-anchor="middle" fill="white">(Gemini 2.5 Pro)</text>
  <text x="450" y="160" font-size="12" text-anchor="middle" fill="white">Long & Dense</text>
  
  <!-- 3. Human Refinement -->
  <rect x="650" y="80" width="200" height="100" rx="10" fill="#9B59B6" stroke="#8E44AD" stroke-width="2"/>
  <text x="750" y="120" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Human-in-the-loop</text>
  <text x="750" y="140" font-size="14" text-anchor="middle" fill="white">Refinement</text>
  <text x="750" y="160" font-size="12" text-anchor="middle" fill="white">(1,230 prompts)</text>
  
  <!-- 4. QA Generation -->
  <rect x="200" y="250" width="200" height="100" rx="10" fill="#2ECC71" stroke="#27AE60" stroke-width="2"/>
  <text x="300" y="290" font-size="16" font-weight="bold" text-anchor="middle" fill="white">QA Generation</text>
  <text x="300" y="310" font-size="14" text-anchor="middle" fill="white">(10 Multi-choice)</text>
  <text x="300" y="330" font-size="12" text-anchor="middle" fill="white">Omni-dimensional</text>
  
  <!-- 5. Human QA Validation -->
  <rect x="500" y="250" width="200" height="100" rx="10" fill="#F39C12" stroke="#E67E22" stroke-width="2"/>
  <text x="600" y="290" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Human QA</text>
  <text x="600" y="310" font-size="14" text-anchor="middle" fill="white">Validation</text>
  <text x="600" y="330" font-size="12" text-anchor="middle" fill="white">(12,300 QAs)</text>
  
  <!-- 6. T2I Model Generation -->
  <rect x="100" y="420" width="200" height="100" rx="10" fill="#1ABC9C" stroke="#16A085" stroke-width="2"/>
  <text x="200" y="460" font-size="16" font-weight="bold" text-anchor="middle" fill="white">T2I Model</text>
  <text x="200" y="480" font-size="14" text-anchor="middle" fill="white">Generation</text>
  <text x="200" y="500" font-size="12" text-anchor="middle" fill="white">(23 SOTA models)</text>
  
  <!-- 7. MLLM Evaluation -->
  <rect x="400" y="420" width="200" height="100" rx="10" fill="#34495E" stroke="#2C3E50" stroke-width="2"/>
  <text x="500" y="460" font-size="16" font-weight="bold" text-anchor="middle" fill="white">MLLM Evaluation</text>
  <text x="500" y="480" font-size="14" text-anchor="middle" fill="white">(Qwen2.5-VL-72B)</text>
  <text x="500" y="500" font-size="12" text-anchor="middle" fill="white">5-round voting</text>
  
  <!-- 8. Results Analysis -->
  <rect x="700" y="420" width="200" height="100" rx="10" fill="#E74C3C" stroke="#C0392B" stroke-width="2"/>
  <text x="800" y="460" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Results Analysis</text>
  <text x="800" y="480" font-size="14" text-anchor="middle" fill="white">Performance Scores</text>
  <text x="800" y="500" font-size="12" text-anchor="middle" fill="white">by Sub-domains</text>
  
  <!-- 9. SpatialT2I Dataset -->
  <rect x="250" y="590" width="200" height="100" rx="10" fill="#9B59B6" stroke="#8E44AD" stroke-width="2"/>
  <text x="350" y="630" font-size="16" font-weight="bold" text-anchor="middle" fill="white">SpatialT2I Dataset</text>
  <text x="350" y="650" font-size="14" text-anchor="middle" fill="white">Construction</text>
  <text x="350" y="670" font-size="12" text-anchor="middle" fill="white">(15,400 pairs)</text>
  
  <!-- 10. Fine-tuning -->
  <rect x="550" y="590" width="200" height="100" rx="10" fill="#3498DB" stroke="#2980B9" stroke-width="2"/>
  <text x="650" y="630" font-size="16" font-weight="bold" text-anchor="middle" fill="white">Model Fine-tuning</text>
  <text x="650" y="650" font-size="14" text-anchor="middle" fill="white">(SD-XL, UniWorld,</text>
  <text x="650" y="670" font-size="12" text-anchor="middle" fill="white">OmniGen2)</text>
  
  <!-- Connecting Lines -->
  <line x1="250" y1="130" x2="350" y2="130" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="550" y1="130" x2="650" y2="130" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="750" y1="180" x2="300" y2="250" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="400" y1="300" x2="500" y2="300" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="600" y1="350" x2="200" y2="420" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="300" y1="470" x2="400" y2="470" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="600" y1="470" x2="700" y2="470" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="800" y1="520" x2="350" y2="590" stroke="#7F8C8D" stroke-width="3"/>
  <line x1="450" y1="640" x2="550" y2="640" stroke="#7F8C8D" stroke-width="3"/>
  
  <!-- Key Features -->
  <rect x="50" y="720" width="900" height="60" rx="5" fill="#ECF0F1" stroke="#BDC3C7" stroke-width="2"/>
  <text x="500" y="740" font-size="14" font-weight="bold" text-anchor="middle" fill="#2C3E50">Key Features</text>
  <text x="200" y="760" font-size="12" text-anchor="middle" fill="#34495E">‚Ä¢ Long & Dense Prompts</text>
  <text x="400" y="760" font-size="12" text-anchor="middle" fill="#34495E">‚Ä¢ 10 Spatial Sub-domains</text>
  <text x="600" y="760" font-size="12" text-anchor="middle" fill="#34495E">‚Ä¢ Multi-choice Questions</text>
  <text x="800" y="760" font-size="12" text-anchor="middle" fill="#34495E">‚Ä¢ Human Validation</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Spatial reasoning capabilities like comparison and occlusion">
                        <div class="quiz-question">1. What is the primary bottleneck identified in current text-to-image models according to SpatialGenEval?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Object generation and attribute binding">Object generation and attribute binding</div><div class="quiz-choice" data-value="Spatial reasoning capabilities like comparison and occlusion">Spatial reasoning capabilities like comparison and occlusion</div><div class="quiz-choice" data-value="Text encoding and prompt understanding">Text encoding and prompt understanding</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="It uses 10 multi-choice questions per prompt covering all spatial sub-domains instead of simple yes/no questions">
                        <div class="quiz-question">2. How does SpatialGenEval differ from existing T2I benchmarks in its evaluation approach?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="It uses 10 multi-choice questions per prompt covering all spatial sub-domains instead of simple yes/no questions">It uses 10 multi-choice questions per prompt covering all spatial sub-domains instead of simple yes/no questions</div><div class="quiz-choice" data-value="It focuses exclusively on artistic style and aesthetic quality assessment">It focuses exclusively on artistic style and aesthetic quality assessment</div><div class="quiz-choice" data-value="It only evaluates closed-source commercial models">It only evaluates closed-source commercial models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It includes an 'E: None' option when generated images don't match any given choices">
                        <div class="quiz-question">3. What unique feature does SpatialGenEval include to prevent forced guessing in evaluations?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses human annotators exclusively instead of automated evaluation">It uses human annotators exclusively instead of automated evaluation</div><div class="quiz-choice" data-value="It includes an 'E: None' option when generated images don't match any given choices">It includes an 'E: None' option when generated images don't match any given choices</div><div class="quiz-choice" data-value="It requires models to generate multiple images for each prompt">It requires models to generate multiple images for each prompt</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-paper.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-29</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.21821" target="_blank">http://arxiv.org/pdf/2601.21821</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on multimodal reasoning in vision-language models, specifically addressing the performance gap between open-source and proprietary systems through data-centric methods.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Building on existing multimodal datasets like FineVision and LLaVA-OneVision, the paper proposes MMFineReason - a large-scale dataset with high-quality Chain-of-Thought annotations distilled from Qwen3-VL-235B-A22B-Thinking, addressing data imbalance and inconsistent reasoning quality issues.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the lack of high-quality reasoning data in open-source multimodal models, particularly the scarcity of STEM diagram and visual puzzle samples with consistent, long-form reasoning annotations.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a three-stage pipeline: data collection and standardization from diverse sources, CoT rationale generation via teacher model distillation, and difficulty-aware filtering for quality verification and efficient subset creation.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> MMFineReason models (2B/4B/8B) achieve state-of-the-art results for their size class, with the 4B model surpassing Qwen3-VL-8B-Thinking and the 8B model outperforming Qwen3-VL-30B-A3B-Thinking, while using only 7% of data achieves comparable performance to the full dataset.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>MMFineReason: Closing the Multimodal Reasoning Gap via Open Data-Centric Methods</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2C3E50">MMFineReason: Data Pipeline Flow</text>
  
  <!-- Stage 1: Data Collection & Processing -->
  <rect x="50" y="80" width="900" height="120" fill="#E8F4F8" stroke="#3498DB" stroke-width="2" rx="10"/>
  <text x="500" y="110" text-anchor="middle" font-size="18" font-weight="bold" fill="#2C3E50">Stage 1: Data Collection & Processing</text>
  
  <!-- Data sources -->
  <rect x="70" y="130" width="120" height="50" fill="#85C1E9" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="130" y="160" text-anchor="middle" font-size="12" fill="white">FineVision</text>
  
  <rect x="210" y="130" width="120" height="50" fill="#85C1E9" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="270" y="160" text-anchor="middle" font-size="12" fill="white">BMMR</text>
  
  <rect x="350" y="130" width="120" height="50" fill="#85C1E9" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="410" y="160" text-anchor="middle" font-size="12" fill="white">Euclid30K</text>
  
  <rect x="490" y="130" width="120" height="50" fill="#85C1E9" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="550" y="160" text-anchor="middle" font-size="12" fill="white">GameQA-140K</text>
  
  <rect x="630" y="130" width="120" height="50" fill="#85C1E9" stroke="#2874A6" stroke-width="2" rx="5"/>
  <text x="690" y="160" text-anchor="middle" font-size="12" fill="white">Other Sources</text>
  
  <!-- Processing steps -->
  <rect x="780" y="130" width="150" height="50" fill="#F39C12" stroke="#D35400" stroke-width="2" rx="5"/>
  <text x="855" y="150" text-anchor="middle" font-size="11" fill="white">Data Cleaning</text>
  <text x="855" y="165" text-anchor="middle" font-size="11" fill="white">& Standardization</text>
  
  <!-- Stage 2: Reasoning Distillation -->
  <rect x="50" y="230" width="900" height="140" fill="#FEF5E7" stroke="#F39C12" stroke-width="2" rx="10"/>
  <text x="500" y="260" text-anchor="middle" font-size="18" font-weight="bold" fill="#2C3E50">Stage 2: Reasoning Distillation</text>
  
  <!-- Teacher model -->
  <ellipse cx="250" cy="310" rx="150" ry="40" fill="#E67E22" stroke="#D35400" stroke-width="2"/>
  <text x="250" y="305" text-anchor="middle" font-size="14" fill="white">Qwen3-VL-235B-A22B</text>
  <text x="250" y="320" text-anchor="middle" font-size="14" fill="white">Thinking (Teacher)</text>
  
  <!-- Distillation outputs -->
  <rect x="450" y="280" width="140" height="60" fill="#F8B500" stroke="#F39C12" stroke-width="2" rx="5"/>
  <text x="520" y="305" text-anchor="middle" font-size="12" fill="white">Long CoT</text>
  <text x="520" y="320" text-anchor="middle" font-size="12" fill="white">Generation</text>
  
  <rect x="620" y="280" width="140" height="60" fill="#F8B500" stroke="#F39C12" stroke-width="2" rx="5"/>
  <text x="690" y="305" text-anchor="middle" font-size="12" fill="white">Dense Caption</text>
  <text x="690" y="320" text-anchor="middle" font-size="12" fill="white">Generation</text>
  
  <rect x="790" y="280" width="140" height="60" fill="#F8B500" stroke="#F39C12" stroke-width="2" rx="5"/>
  <text x="860" y="305" text-anchor="middle" font-size="12" fill="white">Template</text>
  <text x="860" y="320" text-anchor="middle" font-size="12" fill="white">Validation</text>
  
  <!-- Stage 3: Data Selection -->
  <rect x="50" y="400" width="900" height="140" fill="#E8F8F5" stroke="#27AE60" stroke-width="2" rx="10"/>
  <text x="500" y="430" text-anchor="middle" font-size="18" font-weight="bold" fill="#2C3E50">Stage 3: Data Selection</text>
  
  <!-- Selection criteria -->
  <rect x="100" y="460" width="180" height="60" fill="#58D68D" stroke="#27AE60" stroke-width="2" rx="5"/>
  <text x="190" y="485" text-anchor="middle" font-size="12" fill="white">Quality Filtering</text>
  <text x="190" y="500" text-anchor="middle" font-size="12" fill="white">(Length & Template)</text>
  
  <rect x="310" y="460" width="180" height="60" fill="#58D68D" stroke="#27AE60" stroke-width="2" rx="5"/>
  <text x="400" y="485" text-anchor="middle" font-size="12" fill="white">Correctness</text>
  <text x="400" y="500" text-anchor="middle" font-size="12" fill="white">Verification</text>
  
  <rect x="520" y="460" width="180" height="60" fill="#58D68D" stroke="#27AE60" stroke-width="2" rx="5"/>
  <text x="610" y="485" text-anchor="middle" font-size="12" fill="white">Difficulty-aware</text>
  <text x="610" y="500" text-anchor="middle" font-size="12" fill="white">Filtering</text>
  
  <rect x="730" y="460" width="180" height="60" fill="#58D68D" stroke="#27AE60" stroke-width="2" rx="5"/>
  <text x="820" y="485" text-anchor="middle" font-size="12" fill="white">N-gram</text>
  <text x="820" y="500" text-anchor="middle" font-size="12" fill="white">De-duplication</text>
  
  <!-- Output datasets -->
  <rect x="50" y="570" width="900" height="100" fill="#F4ECF7" stroke="#8E44AD" stroke-width="2" rx="10"/>
  <text x="500" y="600" text-anchor="middle" font-size="18" font-weight="bold" fill="#2C3E50">Output Datasets</text>
  
  <ellipse cx="200" cy="630" rx="120" ry="25" fill="#9B59B6" stroke="#7D3C98" stroke-width="2"/>
  <text x="200" y="635" text-anchor="middle" font-size="14" fill="white">MMFineReason-1.8M</text>
  
  <ellipse cx="500" cy="630" rx="120" ry="25" fill="#AF7AC5" stroke="#7D3C98" stroke-width="2"/>
  <text x="500" y="635" text-anchor="middle" font-size="14" fill="white">MMFineReason-586K</text>
  
  <ellipse cx="800" cy="630" rx="120" ry="25" fill="#C39BD3" stroke="#7D3C98" stroke-width="2"/>
  <text x="800" y="635" text-anchor="middle" font-size="14" fill="white">MMFineReason-123K</text>
  
  <!-- Training stages -->
  <rect x="150" y="700" width="300" height="60" fill="#E74C3C" stroke="#C0392B" stroke-width="2" rx="5"/>
  <text x="300" y="735" text-anchor="middle" font-size="16" fill="white">SFT Training</text>
  
  <rect x="550" y="700" width="300" height="60" fill="#E74C3C" stroke="#C0392B" stroke-width="2" rx="5"/>
  <text x="700" y="735" text-anchor="middle" font-size="16" fill="white">RL Training (GSPO)</text>
  
  <!-- Flow indicators -->
  <path d="M 500 200 L 500 230" stroke="#34495E" stroke-width="3" fill="none"/>
  <path d="M 500 370 L 500 400" stroke="#34495E" stroke-width="3" fill="none"/>
  <path d="M 500 540 L 500 570" stroke="#34495E" stroke-width="3" fill="none"/>
  <path d="M 300 670 L 300 700" stroke="#34495E" stroke-width="3" fill="none"/>
  <path d="M 700 670 L 700 700" stroke="#34495E" stroke-width="3" fill="none"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Training on just 7% of the data (123K samples) achieves performance comparable to the full 1.8M dataset">
                        <div class="quiz-question">1. What surprising finding did the authors discover about data efficiency in MMFineReason?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="Training on just 7% of the data (123K samples) achieves performance comparable to the full 1.8M dataset">Training on just 7% of the data (123K samples) achieves performance comparable to the full 1.8M dataset</div><div class="quiz-choice" data-value="Larger models always require exponentially more data to achieve better performance">Larger models always require exponentially more data to achieve better performance</div><div class="quiz-choice" data-value="Natural images require 10x more samples than STEM diagrams for effective training">Natural images require 10x more samples than STEM diagrams for effective training</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Qwen3-VL-235B-A22B-Thinking, making the pipeline fully open-source without relying on closed APIs">
                        <div class="quiz-question">2. Which teacher model did MMFineReason use to distill high-quality reasoning annotations, and what made this choice significant?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="GPT-4V, because it's the most widely used proprietary model for data annotation">GPT-4V, because it's the most widely used proprietary model for data annotation</div><div class="quiz-choice" data-value="Qwen3-VL-235B-A22B-Thinking, making the pipeline fully open-source without relying on closed APIs">Qwen3-VL-235B-A22B-Thinking, making the pipeline fully open-source without relying on closed APIs</div><div class="quiz-choice" data-value="A custom ensemble of multiple smaller models to reduce computational costs">A custom ensemble of multiple smaller models to reduce computational costs</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Ultra-high resolution (2048¬≤) shows diminishing returns compared to 768¬≤ for reasoning, though it still helps with natural images">
                        <div class="quiz-question">3. What counterintuitive result did the ablation studies reveal about ultra-high resolution inputs for reasoning tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="2048√ó2048 resolution dramatically improves performance on all benchmarks by 20%">2048√ó2048 resolution dramatically improves performance on all benchmarks by 20%</div><div class="quiz-choice" data-value="Resolution has no impact on reasoning tasks whatsoever">Resolution has no impact on reasoning tasks whatsoever</div><div class="quiz-choice long-text" data-value="Ultra-high resolution (2048¬≤) shows diminishing returns compared to 768¬≤ for reasoning, though it still helps with natural images">Ultra-high resolution (2048¬≤) shows diminishing returns compared to 768¬≤ for reasoning, though it still helps with natural images</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');

                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫ÊØè‰∏™Âç°ÁâáÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂ÔºàËÄå‰∏çÊòØÊï¥‰∏™ÂÆπÂô®Ôºâ
                cards.forEach(card => {
                    card.addEventListener('click', function(e) {
                        // Âè™ÊúâÁÇπÂáªÂú®Âç°ÁâáÂÜÖÈÉ®Êó∂ÊâçÂàáÊç¢
                        // Ê£ÄÊü•ÊòØÂê¶ÊòØÊµÅÁ®ãÂõæÂç°ÁâáÁöÑÊªöÂä®Êù°Âå∫Âüü
                        if (this.classList.contains('flowchart-card')) {
                            const rect = this.getBoundingClientRect();
                            const isScrollbarClick =
                                (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                                (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);

                            if (!isScrollbarClick) {
                                nextCard(e);
                            }
                        } else {
                            nextCard(e);
                        }
                    });
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
