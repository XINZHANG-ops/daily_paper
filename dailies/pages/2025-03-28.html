
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-03-28 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            width: 100%;
            margin-right: 20px;
            overflow-wrap: break-word;
        }
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        .paper-card p {
            margin: 5px 0;
        }
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        .paper-card a:hover {
            text-decoration: underline;
        }
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* æ”¹ä¸ºå›ºå®šå®šä½ï¼Œä¸éšæ»šåŠ¨è€Œç§»åŠ¨ */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* å±…ä¸­æ˜¾ç¤º */
            width: 90%;
            max-width: 500px; /* å¢åŠ æœ€å¤§å®½åº¦ï¼Œé€‚åº”é•¿å†…å®¹ */
            max-height: 80vh; /* é™åˆ¶æœ€å¤§é«˜åº¦ */
            overflow-y: auto; /* å†…å®¹è¿‡å¤šæ—¶å¯æ»šåŠ¨ */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* ç¡®ä¿æ˜¾ç¤ºåœ¨æœ€ä¸Šå±‚ */
        }
        
        /* æ·»åŠ é®ç½©å±‚ï¼Œé˜²æ­¢é—®é¢˜å¡è¢«å…¶ä»–å†…å®¹é®æŒ¡ */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ä½¿ç”¨JavaScriptæ§åˆ¶é—®é¢˜å¡çš„æ˜¾ç¤ºå’Œéšè—ï¼Œä¸å†ä½¿ç”¨hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* ç¡®ä¿é•¿å•è¯è‡ªåŠ¨æ¢è¡Œ */
            overflow-wrap: break-word;
            hyphens: auto; /* åœ¨å¿…è¦æ—¶ä½¿ç”¨è¿å­—ç¬¦ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* ç¡®ä¿é•¿å•è¯è‡ªåŠ¨æ¢è¡Œ */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* é•¿æ–‡æœ¬å·¦å¯¹é½ */
            display: block; /* ç¡®ä¿æ˜¯å—çº§å…ƒç´  */
            white-space: normal; /* å…è®¸è‡ªåŠ¨æ¢è¡Œ */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* é•¿æ–‡æœ¬é€‰é¡¹çš„ç‰¹æ®Šæ ·å¼ */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* ç¡®ä¿å¼¹çª—ä¸­çš„æŒ‰é’®æ–‡æœ¬ä¸ä¼šæº¢å‡º */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* é€‚åº”è¶…é•¿é€‰é¡¹æ–‡æœ¬ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        @media (max-width: 768px) {
            .paper-container {
                flex-direction: column;
            }
            .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            }
            /* ç§»åŠ¨è®¾å¤‡ä¸Šå¼¹çª—å·²ç»æ˜¯å±…ä¸­æ˜¾ç¤ºï¼Œæ— éœ€é¢å¤–æ ·å¼ */
        }
    
        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-03-28 Papers</h1>
    
        <div class="paper-container">
            <div class="paper-card" style="background-image: url('bg/black-paper.png');">             
                <h2 style="color: #ffffff;">Paper 1</h2>
                <p style="color: #badb12;"><strong>Video-R1: Reinforcing Video Reasoning in MLLMs</strong></p>
                <p style="color: #ffffff;"><strong>Published: </strong>2025-03-27</p>
                <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.21776" target="_blank">http://arxiv.org/pdf/2503.21776</a></p>
                <div><div class="category-chunk">1.  <strong>ğŸ“˜ Topic and Domain:</strong> The paper focuses on enhancing video reasoning capabilities in multimodal large language models (MLLMs) through reinforcement learning techniques.</div><div class="category-chunk">2.  <strong>ğŸ’¡ Previous Research and New Ideas:</strong> Based on DeepSeek-R1's success in text reasoning through rule-based reinforcement learning, this paper extends the approach to video understanding and introduces temporal-aware reinforcement learning.</div><div class="category-chunk">3.  <strong>â“ Problem:</strong> The paper addresses two main challenges: the lack of temporal modeling in existing reinforcement learning methods for video reasoning, and the scarcity of high-quality video-reasoning training data.</div><div class="category-chunk">4.  <strong>ğŸ› ï¸ Methods:</strong> The authors propose T-GRPO (Temporal Group Relative Policy Optimization) algorithm that compares model performance on ordered vs shuffled video frames, and create two datasets (Video-R1-COT-165k and Video-R1-260k) combining both image and video reasoning tasks.</div><div class="category-chunk">5.  <strong>ğŸ“Š Results and Evaluation:</strong> Video-R1-7B achieves state-of-the-art performance across multiple benchmarks, notably reaching 35.8% accuracy on VSI-Bench (surpassing GPT-4o), while showing significant improvements in video reasoning and general video understanding tasks.</div></div>
            </div>
            <div class="quiz-tabs">
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #1">Q1
                    <div class="quiz-popup" data-answer="It compares model performance on ordered vs shuffled video frames">
                        <div class="quiz-question">1. What is the key innovation in the T-GRPO algorithm compared to traditional GRPO?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses larger batch sizes for training">It uses larger batch sizes for training</div><div class="quiz-choice" data-value="It compares model performance on ordered vs shuffled video frames">It compares model performance on ordered vs shuffled video frames</div><div class="quiz-choice" data-value="It processes videos at higher resolution">It processes videos at higher resolution</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #2">Q2
                    <div class="quiz-popup" data-answer="To teach the model general reasoning skills before tackling temporal reasoning">
                        <div class="quiz-question">2. Why did the authors include image-based data in their training dataset?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="To reduce computational costs during training">To reduce computational costs during training</div><div class="quiz-choice" data-value="To increase the total size of the dataset">To increase the total size of the dataset</div><div class="quiz-choice" data-value="To teach the model general reasoning skills before tackling temporal reasoning">To teach the model general reasoning skills before tackling temporal reasoning</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #3">Q3
                    <div class="quiz-popup" data-answer="It initially dropped, then gradually increased before stabilizing">
                        <div class="quiz-question">3. What interesting pattern was observed in the response length during RL training?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It remained constant throughout training">It remained constant throughout training</div><div class="quiz-choice" data-value="It increased steadily from start to finish">It increased steadily from start to finish</div><div class="quiz-choice" data-value="It initially dropped, then gradually increased before stabilizing">It initially dropped, then gradually increased before stabilizing</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
        </div>
        
        <div class="paper-container">
            <div class="paper-card" style="background-image: url('bg/type.png');">             
                <h2 style="color: #ffffff;">Paper 2</h2>
                <p style="color: #badb12;"><strong>UI-R1: Enhancing Action Prediction of GUI Agents by Reinforcement
  Learning</strong></p>
                <p style="color: #ffffff;"><strong>Published: </strong>2025-03-27</p>
                <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.21620" target="_blank">http://arxiv.org/pdf/2503.21620</a></p>
                <div><div class="category-chunk">1.  <strong>ğŸ“˜ Topic and Domain:</strong> The paper explores reinforcement learning to enhance action prediction capabilities of GUI agents for interacting with graphical user interfaces.</div><div class="category-chunk">2.  <strong>ğŸ’¡ Previous Research and New Ideas:</strong> Based on DeepSeek-R1's rule-based reinforcement learning approach, the paper introduces a novel application to multimodal large language models for GUI tasks, proposing a unified rule-based action reward system.</div><div class="category-chunk">3.  <strong>â“ Problem:</strong> The paper addresses the limitations of supervised fine-tuning methods which require large labeled datasets and perform poorly on out-of-domain tasks for GUI agents.</div><div class="category-chunk">4.  <strong>ğŸ› ï¸ Methods:</strong> The authors employ rule-based reinforcement learning with a three-component reward function (action type, coordinate accuracy, format) and carefully curated 136 high-quality training samples selected through a three-stage process.</div><div class="category-chunk">5.  <strong>ğŸ“Š Results and Evaluation:</strong> The model achieved significant improvements over baseline, with 15% better action type accuracy and 10.3% better grounding accuracy on in-domain tasks, while showing competitive performance with larger models on out-of-domain tasks using much less training data.</div></div>
            </div>
            <div class="quiz-tabs">
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #1">Q1
                    <div class="quiz-popup" data-answer="It employs rule-based reinforcement learning with only 136 training samples">
                        <div class="quiz-question">1. What is the main innovation in the training approach used by UI-R1 compared to previous GUI agents?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It uses supervised learning with a much larger dataset">It uses supervised learning with a much larger dataset</div><div class="quiz-choice" data-value="It employs rule-based reinforcement learning with only 136 training samples">It employs rule-based reinforcement learning with only 136 training samples</div><div class="quiz-choice" data-value="It relies on human feedback for training">It relies on human feedback for training</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #2">Q2
                    <div class="quiz-popup" data-answer="User satisfaction score">
                        <div class="quiz-question">2. Which component is NOT part of UI-R1's reward function design?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Action type reward">Action type reward</div><div class="quiz-choice" data-value="User satisfaction score">User satisfaction score</div><div class="quiz-choice" data-value="Coordinate accuracy reward">Coordinate accuracy reward</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #3">Q3
                    <div class="quiz-popup" data-answer="It matched the performance of 7B models trained on 76K samples">
                        <div class="quiz-question">3. What impressive result did UI-R1-3B achieve with minimal training data?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It performed worse than all existing models">It performed worse than all existing models</div><div class="quiz-choice" data-value="It matched the performance of 7B models trained on 76K samples">It matched the performance of 7B models trained on 76K samples</div><div class="quiz-choice" data-value="It only worked on mobile interfaces">It only worked on mobile interfaces</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
        </div>
        
        <div class="paper-container">
            <div class="paper-card" style="background-image: url('bg/my-little-plaid-dark.png');">             
                <h2 style="color: #ffffff;">Paper 3</h2>
                <p style="color: #badb12;"><strong>Challenging the Boundaries of Reasoning: An Olympiad-Level Math
  Benchmark for Large Language Models</strong></p>
                <p style="color: #ffffff;"><strong>Published: </strong>2025-03-27</p>
                <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2503.21380" target="_blank">http://arxiv.org/pdf/2503.21380</a></p>
                <div><div class="category-chunk">1.  <strong>ğŸ“˜ Topic and Domain:</strong> Mathematical reasoning evaluation of Large Language Models through a new Olympiad-level benchmark called OlymMATH.</div><div class="category-chunk">2.  <strong>ğŸ’¡ Previous Research and New Ideas:</strong> Based on existing math benchmarks like GSM8K, MATH, and AIME that have become saturated; proposes a novel bilingual benchmark with higher difficulty and more comprehensive evaluation methods.</div><div class="category-chunk">3.  <strong>â“ Problem:</strong> Addresses the lack of challenging and rigorous evaluation frameworks for testing mathematical reasoning capabilities of advanced LLMs, as existing benchmarks have become too easy.</div><div class="category-chunk">4.  <strong>ğŸ› ï¸ Methods:</strong> Created a 200-problem benchmark across four mathematical fields in two difficulty tiers (easy/hard), available in both English and Chinese, with problems manually curated from printed sources and verified by experts.</div><div class="category-chunk">5.  <strong>ğŸ“Š Results and Evaluation:</strong> Even top models like DeepSeek-R1 and OpenAI's o3-mini achieved only 21.2% and 30.3% accuracy respectively on the hard subset, demonstrating the benchmark's effectiveness in challenging current state-of-the-art models.</div></div>
            </div>
            <div class="quiz-tabs">
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #1">Q1
                    <div class="quiz-popup" data-answer="They sourced problems exclusively from printed materials">
                        <div class="quiz-question">1. What unique approach did the researchers take to prevent data contamination when creating OlymMATH?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They used only problems from online forums">They used only problems from online forums</div><div class="quiz-choice" data-value="They sourced problems exclusively from printed materials">They sourced problems exclusively from printed materials</div><div class="quiz-choice" data-value="They generated new problems using AI">They generated new problems using AI</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #2">Q2
                    <div class="quiz-popup" data-answer="Models performed better on English problems">
                        <div class="quiz-question">2. Which of these findings reveals an interesting linguistic bias in the performance of LLMs on OlymMATH?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Models performed equally well in both languages">Models performed equally well in both languages</div><div class="quiz-choice" data-value="Models performed better on Chinese problems">Models performed better on Chinese problems</div><div class="quiz-choice" data-value="Models performed better on English problems">Models performed better on English problems</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="ç‚¹å‡»æŸ¥çœ‹é—®é¢˜ #3">Q3
                    <div class="quiz-popup" data-answer="They sometimes rely on pattern matching and empirical guessing rather than rigorous reasoning">
                        <div class="quiz-question">3. What concerning behavior did the researchers discover about how LLMs sometimes solve math problems?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They sometimes rely on pattern matching and empirical guessing rather than rigorous reasoning">They sometimes rely on pattern matching and empirical guessing rather than rigorous reasoning</div><div class="quiz-choice" data-value="They always provide incomplete solutions">They always provide incomplete solutions</div><div class="quiz-choice" data-value="They consistently misinterpret geometric problems">They consistently misinterpret geometric problems</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
        </div>
        
    
    
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // åˆ›å»ºé®ç½©å±‚
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // è·å–æ‰€æœ‰é—®é¢˜æ ‡ç­¾
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // è®¾ç½®ç‚¹å‡»äº‹ä»¶å¤„ç†
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ç‚¹å‡»æ ‡ç­¾åˆ‡æ¢é—®é¢˜å¡çš„æ˜¾ç¤ºçŠ¶æ€
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // é˜»æ­¢äº‹ä»¶å†’æ³¡
                    
                    // å¦‚æœå½“å‰é—®é¢˜å¡å·²ç»æ˜¾ç¤ºï¼Œåˆ™éšè—å®ƒ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // å…ˆéšè—æ‰€æœ‰å…¶ä»–é—®é¢˜å¡
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // å°†å¼¹çª—å†…å®¹å¤åˆ¶åˆ°é¡µé¢æœ€å¤–å±‚çš„å¼¹çª—ä¸­
                        document.body.appendChild(popup);
                        
                        // æ˜¾ç¤ºå½“å‰é—®é¢˜å¡å’ŒèƒŒæ™¯é®ç½©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // ç¡®ä¿ç‚¹å‡»é—®é¢˜å¡å†…éƒ¨æ—¶ä¸ä¼šå…³é—­é—®é¢˜å¡
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ç‚¹å‡»é®ç½©å±‚æˆ–é¡µé¢ä»»ä½•å…¶ä»–ä½ç½®æ—¶éšè—æ‰€æœ‰é—®é¢˜å¡
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ä¸ºæ¯ä¸ªé€‰é¡¹æ·»åŠ ç‚¹å‡»äº‹ä»¶
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // é‡ç½®æ‰€æœ‰é€‰é¡¹
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // æ ‡è®°å½“å‰é€‰é¡¹ä¸ºå·²é€‰
                    this.classList.add('selected');
                    
                    // æ£€æŸ¥æ˜¯å¦æ­£ç¡®
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = 'âœ”ï¸ Correctï¼';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = 'âŒ Wrongï¼';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>ğŸ“ My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>

</body>
</html>
