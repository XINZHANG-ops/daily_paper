<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2026-02-10 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */
            /* cursor removed - only cards should show pointer */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
            cursor: pointer; /* Show pointer on cards to indicate they're clickable */
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }

        .paper-card p {
            margin: 5px 0;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
            word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        /* ÁßªÂä®ËÆæÂ§áÂíåÂ∞èÂ±èÂπï */
        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                min-height: 400px; /* ÁßªÂä®ËÆæÂ§á‰∏ä‰ΩøÁî®Êõ¥Â∞èÁöÑÊúÄÂ∞èÈ´òÂ∫¶ */
                height: auto; /* Ëá™ÈÄÇÂ∫îÈ´òÂ∫¶ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }

            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
                width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-02-10 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>GEBench: Benchmarking Image Generation Models as GUI Environments</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.09007" target="_blank">http://arxiv.org/pdf/2602.09007</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper introduces GEBench, a benchmark for evaluating image generation models as interactive GUI environments in the computer vision and human-computer interaction domain.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing image generation models and GUI automation research, proposing a novel evaluation framework that shifts focus from general visual fidelity to GUI-specific interaction logic and temporal coherence across discrete state transitions.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the lack of evaluation methods for assessing whether image generation models can reliably function as GUI environments, as existing benchmarks focus on general visual quality rather than GUI-specific requirements like state transitions and interaction logic.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors created a 700-sample benchmark across five task categories (single-step, multi-step, fiction-app, real-app, grounding) and developed GE-Score, a five-dimensional metric evaluated by VLM judges across Goal Achievement, Interaction Logic, Consistency, UI Plausibility, and Visual Quality dimensions.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Results show that while current models perform well on single-step transitions (top models achieving 80+ scores), they struggle significantly with multi-step planning and spatial grounding tasks, with major bottlenecks in icon interpretation, text rendering, and localization precision.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>GEBench: Benchmarking Image Generation Models as GUI Environments</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#4CAF50;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#81C784;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#2196F3;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#64B5F6;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#FF9800;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#FFB74D;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#9C27B0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#BA68C8;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad5" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#F44336;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#EF5350;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-family="Arial" font-size="24" font-weight="bold" fill="#333">GEBench: Benchmarking Image Generation Models as GUI Environments</text>
  
  <!-- Data Collection Phase -->
  <rect x="50" y="60" width="180" height="80" rx="10" fill="url(#grad1)" stroke="#2E7D32" stroke-width="2"/>
  <text x="140" y="85" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Data Collection</text>
  <text x="140" y="105" text-anchor="middle" font-family="Arial" font-size="12" fill="white">Raw Screen Recording</text>
  <text x="140" y="120" text-anchor="middle" font-family="Arial" font-size="12" fill="white">Task Annotation</text>
  
  <!-- Quality Control -->
  <rect x="280" y="60" width="180" height="80" rx="10" fill="url(#grad2)" stroke="#1565C0" stroke-width="2"/>
  <text x="370" y="85" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Quality Control</text>
  <text x="370" y="105" text-anchor="middle" font-family="Arial" font-size="12" fill="white">Rule-based Preprocessing</text>
  <text x="370" y="120" text-anchor="middle" font-family="Arial" font-size="12" fill="white">Expert Verification</text>
  
  <!-- Dataset Construction -->
  <rect x="510" y="60" width="180" height="80" rx="10" fill="url(#grad3)" stroke="#E65100" stroke-width="2"/>
  <text x="600" y="85" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Dataset Construction</text>
  <text x="600" y="105" text-anchor="middle" font-family="Arial" font-size="12" fill="white">700 Samples</text>
  <text x="600" y="120" text-anchor="middle" font-family="Arial" font-size="12" fill="white">5 Task Categories</text>
  
  <!-- Task Categories -->
  <text x="500" y="180" text-anchor="middle" font-family="Arial" font-size="18" font-weight="bold" fill="#333">Five Task Categories</text>
  
  <!-- Single-step -->
  <circle cx="150" cy="220" r="40" fill="#4CAF50" stroke="#2E7D32" stroke-width="2"/>
  <text x="150" y="215" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Single-step</text>
  <text x="150" y="230" text-anchor="middle" font-family="Arial" font-size="12" fill="white">200 samples</text>
  
  <!-- Multi-step -->
  <circle cx="300" cy="220" r="40" fill="#2196F3" stroke="#1565C0" stroke-width="2"/>
  <text x="300" y="215" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Multi-step</text>
  <text x="300" y="230" text-anchor="middle" font-family="Arial" font-size="12" fill="white">200 samples</text>
  
  <!-- Fiction App -->
  <circle cx="450" cy="220" r="40" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="450" y="215" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Fiction App</text>
  <text x="450" y="230" text-anchor="middle" font-family="Arial" font-size="12" fill="white">100 samples</text>
  
  <!-- Real App -->
  <circle cx="600" cy="220" r="40" fill="#9C27B0" stroke="#6A1B9A" stroke-width="2"/>
  <text x="600" y="215" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Real App</text>
  <text x="600" y="230" text-anchor="middle" font-family="Arial" font-size="12" fill="white">100 samples</text>
  
  <!-- Grounding -->
  <circle cx="750" cy="220" r="40" fill="#F44336" stroke="#C62828" stroke-width="2"/>
  <text x="750" y="215" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Grounding</text>
  <text x="750" y="230" text-anchor="middle" font-family="Arial" font-size="12" fill="white">100 samples</text>
  
  <!-- Model Evaluation -->
  <rect x="100" y="300" width="300" height="100" rx="15" fill="url(#grad4)" stroke="#6A1B9A" stroke-width="2"/>
  <text x="250" y="330" text-anchor="middle" font-family="Arial" font-size="16" font-weight="bold" fill="white">Model Evaluation</text>
  <text x="250" y="350" text-anchor="middle" font-family="Arial" font-size="13" fill="white">12 Image Generation Models</text>
  <text x="250" y="370" text-anchor="middle" font-family="Arial" font-size="13" fill="white">8 Commercial + 4 Open-source</text>
  <text x="250" y="385" text-anchor="middle" font-family="Arial" font-size="13" fill="white">GPT-Image, Nano Banana, Flux, etc.</text>
  
  <!-- VLM-as-a-Judge -->
  <rect x="500" y="300" width="300" height="100" rx="15" fill="url(#grad5)" stroke="#C62828" stroke-width="2"/>
  <text x="650" y="330" text-anchor="middle" font-family="Arial" font-size="16" font-weight="bold" fill="white">VLM-as-a-Judge</text>
  <text x="650" y="350" text-anchor="middle" font-family="Arial" font-size="13" fill="white">3 Evaluator Models</text>
  <text x="650" y="370" text-anchor="middle" font-family="Arial" font-size="13" fill="white">GPT-4o, Gemini-3, Qwen3-VL</text>
  <text x="650" y="385" text-anchor="middle" font-family="Arial" font-size="13" fill="white">Cross-validation Strategy</text>
  
  <!-- GE-Score Dimensions -->
  <text x="500" y="450" text-anchor="middle" font-family="Arial" font-size="18" font-weight="bold" fill="#333">GE-Score: Five Evaluation Dimensions</text>
  
  <!-- GOAL -->
  <ellipse cx="120" cy="500" rx="70" ry="30" fill="#4CAF50" stroke="#2E7D32" stroke-width="2"/>
  <text x="120" y="490" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">GOAL</text>
  <text x="120" y="505" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Achievement</text>
  <text x="120" y="518" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Assessment</text>
  
  <!-- LOGIC -->
  <ellipse cx="280" cy="500" rx="70" ry="30" fill="#2196F3" stroke="#1565C0" stroke-width="2"/>
  <text x="280" y="490" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">LOGIC</text>
  <text x="280" y="505" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Interaction</text>
  <text x="280" y="518" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Coherence</text>
  
  <!-- CONS -->
  <ellipse cx="440" cy="500" rx="70" ry="30" fill="#FF9800" stroke="#E65100" stroke-width="2"/>
  <text x="440" y="490" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">CONS</text>
  <text x="440" y="505" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Content</text>
  <text x="440" y="518" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Consistency</text>
  
  <!-- UI -->
  <ellipse cx="600" cy="500" rx="70" ry="30" fill="#9C27B0" stroke="#6A1B9A" stroke-width="2"/>
  <text x="600" y="490" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">UI</text>
  <text x="600" y="505" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Plausibility</text>
  <text x="600" y="518" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Integrity</text>
  
  <!-- QUAL -->
  <ellipse cx="760" cy="500" rx="70" ry="30" fill="#F44336" stroke="#C62828" stroke-width="2"/>
  <text x="760" y="490" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">QUAL</text>
  <text x="760" y="505" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Visual</text>
  <text x="760" y="518" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Quality</text>
  
  <!-- Key Findings -->
  <rect x="100" y="580" width="800" height="120" rx="15" fill="#E8F5E8" stroke="#4CAF50" stroke-width="2"/>
  <text x="500" y="610" text-anchor="middle" font-family="Arial" font-size="16" font-weight="bold" fill="#2E7D32">Key Findings & Challenges</text>
  
  <text x="150" y="640" font-family="Arial" font-size="13" fill="#333">‚Ä¢ Models excel at single-step transitions but struggle with multi-step planning</text>
  <text x="150" y="660" font-family="Arial" font-size="13" fill="#333">‚Ä¢ Critical bottlenecks: Icon interpretation, Text rendering, Localization precision</text>
  <text x="150" y="680" font-family="Arial" font-size="13" fill="#333">‚Ä¢ Performance gap between commercial and open-source models</text>
  
  <!-- Score Formula -->
  <rect x="300" y="720" width="400" height="50" rx="10" fill="#F5F5F5" stroke="#666" stroke-width="1"/>
  <text x="500" y="740" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="#333">GE-Score = (1/5) √ó Œ£(GOAL + LOGIC + CONS + UI + QUAL)</text>
  <text x="500" y="755" text-anchor="middle" font-family="Arial" font-size="12" fill="#666">Normalized to [0, 100] scale</text>
  
  <!-- Connecting lines with minimal design -->
  <line x1="230" y1="100" x2="280" y2="100" stroke="#666" stroke-width="2"/>
  <line x1="460" y1="100" x2="510" y2="100" stroke="#666" stroke-width="2"/>
  <line x1="600" y1="140" x2="600" y2="180" stroke="#666" stroke-width="2"/>
  <line x1="250" y1="400" x2="250" y2="450" stroke="#666" stroke-width="2"/>
  <line x1="650" y1="400" x2="650" y2="450" stroke="#666" stroke-width="2"/>
  <line x1="500" y1="530" x2="500" y2="580" stroke="#666" stroke-width="2"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="They focus on general-domain visual fidelity rather than GUI-specific interaction logic and state transitions">
                        <div class="quiz-question">1. What is the primary limitation of existing image generation benchmarks when evaluating models as GUI environments?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="They focus on general-domain visual fidelity rather than GUI-specific interaction logic and state transitions">They focus on general-domain visual fidelity rather than GUI-specific interaction logic and state transitions</div><div class="quiz-choice" data-value="They only evaluate single images instead of video sequences">They only evaluate single images instead of video sequences</div><div class="quiz-choice" data-value="They require too much computational power to run effectively">They require too much computational power to run effectively</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="The dramatic drop from single-step transitions (80+ scores) to multi-step planning (often below 60 points)">
                        <div class="quiz-question">2. According to the evaluation results, what represents the biggest performance gap for current image generation models in GEBench?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Visual quality degradation in high-resolution images">Visual quality degradation in high-resolution images</div><div class="quiz-choice long-text" data-value="The dramatic drop from single-step transitions (80+ scores) to multi-step planning (often below 60 points)">The dramatic drop from single-step transitions (80+ scores) to multi-step planning (often below 60 points)</div><div class="quiz-choice" data-value="Inability to generate fictional app interfaces from scratch">Inability to generate fictional app interfaces from scratch</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Icon interpretation, text rendering accuracy, and localization precision">
                        <div class="quiz-question">3. What are the three main technical bottlenecks identified in the qualitative analysis of GUI generation failures?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Memory limitations, processing speed, and storage capacity">Memory limitations, processing speed, and storage capacity</div><div class="quiz-choice" data-value="Icon interpretation, text rendering accuracy, and localization precision">Icon interpretation, text rendering accuracy, and localization precision</div><div class="quiz-choice" data-value="Color accuracy, resolution scaling, and compression artifacts">Color accuracy, resolution scaling, and compression artifacts</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-paper.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>LLaDA2.1: Speeding Up Text Diffusion via Token Editing</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.08676" target="_blank">http://arxiv.org/pdf/2602.08676</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper presents LLaDA2.1, a diffusion-based large language model that accelerates text generation through token editing mechanisms in the natural language processing domain.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on LLaDA2.0 and previous discrete diffusion language models, proposing a novel "Draft-and-Edit" paradigm that combines Mask-to-Token (M2T) and Token-to-Token (T2T) operations with configurable threshold decoding to enable error correction during generation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper aims to solve the trade-off between decoding speed and generation quality in discrete diffusion language models, addressing exposure bias and token-level inconsistencies that occur during parallel decoding.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use dual probability thresholds for configurable decoding (Speedy Mode and Quality Mode), mixture of M2T and T2T training objectives, multi-turn forward data augmentation, and ELBO-based Block-level Policy Optimization (EBPO) for reinforcement learning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> LLaDA2.1 achieves significant speed improvements (892 TPS on HumanEval+, 801 TPS on BigCodeBench, 663 TPS on LiveCodeBench) while maintaining competitive performance across 33 benchmarks covering knowledge, reasoning, coding, math, and alignment tasks.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>LLaDA2.1: Speeding Up Text Diffusion via Token Editing</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8fafc"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="#1e293b">
    LLaDA2.1: Speeding Up Text Diffusion via Token Editing - Method Flow
  </text>
  
  <!-- Stage 1: Training Paradigm -->
  <rect x="50" y="70" width="280" height="180" rx="15" fill="#e0f2fe" stroke="#0277bd" stroke-width="2"/>
  <text x="190" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="#0277bd">Stage 1: Training Paradigm</text>
  
  <!-- CPT -->
  <rect x="70" y="110" width="100" height="50" rx="8" fill="#b3e5fc" stroke="#0288d1" stroke-width="1"/>
  <text x="120" y="130" text-anchor="middle" font-size="11" fill="#01579b">CPT</text>
  <text x="120" y="145" text-anchor="middle" font-size="9" fill="#01579b">M2T + T2T</text>
  
  <!-- SFT -->
  <rect x="190" y="110" width="100" height="50" rx="8" fill="#b3e5fc" stroke="#0288d1" stroke-width="1"/>
  <text x="240" y="130" text-anchor="middle" font-size="11" fill="#01579b">SFT</text>
  <text x="240" y="145" text-anchor="middle" font-size="9" fill="#01579b">Multi-Turn Forward</text>
  
  <!-- RL -->
  <rect x="130" y="180" width="120" height="50" rx="8" fill="#81c784" stroke="#388e3c" stroke-width="1"/>
  <text x="190" y="200" text-anchor="middle" font-size="11" fill="#1b5e20">RL (EBPO)</text>
  <text x="190" y="215" text-anchor="middle" font-size="9" fill="#1b5e20">Policy Optimization</text>
  
  <!-- Stage 2: Configurable Decoding -->
  <rect x="370" y="70" width="280" height="180" rx="15" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="510" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="#f57c00">Stage 2: Configurable Decoding</text>
  
  <!-- Threshold Control -->
  <rect x="390" y="110" width="240" height="40" rx="8" fill="#ffe0b2" stroke="#ff9800" stroke-width="1"/>
  <text x="510" y="130" text-anchor="middle" font-size="11" fill="#e65100">Dual Threshold Control</text>
  <text x="510" y="143" text-anchor="middle" font-size="9" fill="#e65100">œâmask + œâedit</text>
  
  <!-- Draft and Edit -->
  <rect x="390" y="165" width="110" height="40" rx="8" fill="#ffcc02" stroke="#ff8f00" stroke-width="1"/>
  <text x="445" y="182" text-anchor="middle" font-size="10" fill="#e65100">M2T Draft</text>
  <text x="445" y="195" text-anchor="middle" font-size="9" fill="#e65100">Mask‚ÜíToken</text>
  
  <rect x="520" y="165" width="110" height="40" rx="8" fill="#ffcc02" stroke="#ff8f00" stroke-width="1"/>
  <text x="575" y="182" text-anchor="middle" font-size="10" fill="#e65100">T2T Edit</text>
  <text x="575" y="195" text-anchor="middle" font-size="9" fill="#e65100">Token‚ÜíToken</text>
  
  <!-- Stage 3: Operating Modes -->
  <rect x="690" y="70" width="260" height="180" rx="15" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="820" y="95" text-anchor="middle" font-size="14" font-weight="bold" fill="#7b1fa2">Stage 3: Operating Modes</text>
  
  <!-- S Mode -->
  <rect x="710" y="115" width="100" height="50" rx="8" fill="#e1bee7" stroke="#8e24aa" stroke-width="1"/>
  <text x="760" y="133" text-anchor="middle" font-size="11" fill="#4a148c">S Mode</text>
  <text x="760" y="146" text-anchor="middle" font-size="9" fill="#4a148c">Speed Priority</text>
  <text x="760" y="157" text-anchor="middle" font-size="8" fill="#4a148c">Low œâmask</text>
  
  <!-- Q Mode -->
  <rect x="830" y="115" width="100" height="50" rx="8" fill="#e1bee7" stroke="#8e24aa" stroke-width="1"/>
  <text x="880" y="133" text-anchor="middle" font-size="11" fill="#4a148c">Q Mode</text>
  <text x="880" y="146" text-anchor="middle" font-size="9" fill="#4a148c">Quality Priority</text>
  <text x="880" y="157" text-anchor="middle" font-size="8" fill="#4a148c">High œâmask</text>
  
  <!-- MBE -->
  <rect x="770" y="180" width="100" height="50" rx="8" fill="#c8e6c9" stroke="#4caf50" stroke-width="1"/>
  <text x="820" y="200" text-anchor="middle" font-size="11" fill="#1b5e20">MBE</text>
  <text x="820" y="213" text-anchor="middle" font-size="9" fill="#1b5e20">Multi-Block Edit</text>
  
  <!-- Core Innovation Box -->
  <rect x="100" y="300" width="800" height="120" rx="15" fill="#e8f5e8" stroke="#2e7d32" stroke-width="3"/>
  <text x="500" y="330" text-anchor="middle" font-size="16" font-weight="bold" fill="#1b5e20">Core Innovation: Draft-and-Edit Paradigm</text>
  
  <!-- Unmasking Set -->
  <rect x="150" y="350" width="200" height="50" rx="8" fill="#c8e6c9" stroke="#4caf50" stroke-width="2"/>
  <text x="250" y="370" text-anchor="middle" font-size="12" fill="#1b5e20">Unmasking Set Œìt</text>
  <text x="250" y="385" text-anchor="middle" font-size="10" fill="#1b5e20">p(v|xt) > œâmask</text>
  
  <!-- Editing Set -->
  <rect x="650" y="350" width="200" height="50" rx="8" fill="#ffcdd2" stroke="#f44336" stroke-width="2"/>
  <text x="750" y="370" text-anchor="middle" font-size="12" fill="#c62828">Editing Set Œît</text>
  <text x="750" y="385" text-anchor="middle" font-size="10" fill="#c62828">p(v|xt) > œâedit</text>
  
  <!-- Performance Results -->
  <rect x="100" y="460" width="800" height="100" rx="15" fill="#fff8e1" stroke="#f9a825" stroke-width="2"/>
  <text x="500" y="485" text-anchor="middle" font-size="16" font-weight="bold" fill="#f57c00">Performance Achievements</text>
  
  <!-- Speed Results -->
  <circle cx="250" cy="520" r="30" fill="#4caf50" stroke="#2e7d32" stroke-width="2"/>
  <text x="250" y="518" text-anchor="middle" font-size="10" font-weight="bold" fill="white">892 TPS</text>
  <text x="250" y="530" text-anchor="middle" font-size="8" fill="white">HumanEval+</text>
  
  <circle cx="400" cy="520" r="30" fill="#2196f3" stroke="#1565c0" stroke-width="2"/>
  <text x="400" y="518" text-anchor="middle" font-size="10" font-weight="bold" fill="white">801 TPS</text>
  <text x="400" y="530" text-anchor="middle" font-size="8" fill="white">BigCodeBench</text>
  
  <circle cx="550" cy="520" r="30" fill="#9c27b0" stroke="#6a1b9a" stroke-width="2"/>
  <text x="550" y="518" text-anchor="middle" font-size="10" font-weight="bold" fill="white">663 TPS</text>
  <text x="550" y="530" text-anchor="middle" font-size="8" fill="white">LiveCodeBench</text>
  
  <circle cx="700" cy="520" r="30" fill="#ff5722" stroke="#d84315" stroke-width="2"/>
  <text x="700" y="518" text-anchor="middle" font-size="10" font-weight="bold" fill="white">33 Tasks</text>
  <text x="700" y="530" text-anchor="middle" font-size="8" fill="white">Benchmarks</text>
  
  <!-- Infrastructure -->
  <rect x="100" y="600" width="800" height="80" rx="15" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="500" y="625" text-anchor="middle" font-size="16" font-weight="bold" fill="#1976d2">Infrastructure Support</text>
  
  <!-- Infrastructure Components -->
  <rect x="150" y="645" width="120" height="25" rx="5" fill="#bbdefb" stroke="#1976d2" stroke-width="1"/>
  <text x="210" y="660" text-anchor="middle" font-size="10" fill="#0d47a1">dFactory Training</text>
  
  <rect x="290" y="645" width="120" height="25" rx="5" fill="#bbdefb" stroke="#1976d2" stroke-width="1"/>
  <text x="350" y="660" text-anchor="middle" font-size="10" fill="#0d47a1">SGLang Inference</text>
  
  <rect x="430" y="645" width="120" height="25" rx="5" fill="#bbdefb" stroke="#1976d2" stroke-width="1"/>
  <text x="490" y="660" text-anchor="middle" font-size="10" fill="#0d47a1">AReaL RL</text>
  
  <rect x="570" y="645" width="120" height="25" rx="5" fill="#bbdefb" stroke="#1976d2" stroke-width="1"/>
  <text x="630" y="660" text-anchor="middle" font-size="10" fill="#0d47a1">Alpha-MoE</text>
  
  <rect x="710" y="645" width="120" height="25" rx="5" fill="#bbdefb" stroke="#1976d2" stroke-width="1"/>
  <text x="770" y="660" text-anchor="middle" font-size="10" fill="#0d47a1">FP8 Quantization</text>
  
  <!-- Flow indicators -->
  <path d="M 190 250 Q 350 270 510 250" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 510 250 Q 650 270 820 250" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 500 420 L 500 460" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  <path d="M 500 560 L 500 600" stroke="#666" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>
  
  <!-- Key Innovation Label -->
  <text x="50" y="750" font-size="12" font-weight="bold" fill="#d32f2f">Key Innovation:</text>
  <text x="150" y="750" font-size="11" fill="#424242">Editable State Evolution enables dynamic speed-quality trade-off</text>
  
  <!-- Version Info -->
  <text x="50" y="770" font-size="10" fill="#757575">Models: LLaDA2.1-Mini (16B) + LLaDA2.1-Flash (100B)</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A dual-threshold 'Draft-and-Edit' paradigm that combines Mask-to-Token (M2T) and Token-to-Token (T2T) operations">
                        <div class="quiz-question">1. What is the key innovation that LLaDA2.1 introduces to address the speed-quality trade-off in discrete diffusion language models?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="A dual-threshold 'Draft-and-Edit' paradigm that combines Mask-to-Token (M2T) and Token-to-Token (T2T) operations">A dual-threshold 'Draft-and-Edit' paradigm that combines Mask-to-Token (M2T) and Token-to-Token (T2T) operations</div><div class="quiz-choice" data-value="A completely new autoregressive architecture that replaces the diffusion mechanism">A completely new autoregressive architecture that replaces the diffusion mechanism</div><div class="quiz-choice" data-value="A simple parameter scaling approach that increases model size to 200B parameters">A simple parameter scaling approach that increases model size to 200B parameters</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="892 TPS">
                        <div class="quiz-question">2. According to the paper, what is the peak throughput (TPS) that LLaDA2.1-Flash achieves on HumanEval+ coding benchmark?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="663 TPS">663 TPS</div><div class="quiz-choice" data-value="801 TPS">801 TPS</div><div class="quiz-choice" data-value="892 TPS">892 TPS</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="High-throughput generation by accepting lower-confidence tokens and relying on T2T correction">
                        <div class="quiz-question">3. What does the 'Speedy Mode (S Mode)' in LLaDA2.1 prioritize compared to 'Quality Mode (Q Mode)'?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Higher accuracy by using conservative thresholds and avoiding token editing">Higher accuracy by using conservative thresholds and avoiding token editing</div><div class="quiz-choice" data-value="High-throughput generation by accepting lower-confidence tokens and relying on T2T correction">High-throughput generation by accepting lower-confidence tokens and relying on T2T correction</div><div class="quiz-choice" data-value="Balanced performance by using identical thresholds for both M2T and T2T operations">Balanced performance by using identical thresholds for both M2T and T2T operations</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/robots.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-02-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2602.08439" target="_blank">http://arxiv.org/pdf/2602.08439</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> This paper introduces Demo-driven Video In-Context Learning for procedural video knowledge acquisition, focusing on enabling multimodal large language models to learn from video demonstrations rather than relying solely on pre-trained knowledge.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> The paper builds on existing multimodal video understanding and in-context learning research, proposing a novel paradigm where models learn from text instructions, video demonstrations, or selected demonstrations to answer questions about target videos, moving beyond static knowledge retrieval.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitation that current video understanding models primarily rely on internal pre-trained knowledge or visible facts rather than learning new skills from contextual demonstrations, which is crucial for human-like learning and adaptation.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors develop Demo-ICL using a two-stage training strategy: video supervised fine-tuning followed by information-assisted Direct Preference Optimization (DPO), along with constructing Demo-ICL-Bench benchmark with 1,200 questions from instructional YouTube videos.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Demo-ICL achieves superior performance compared to existing models, with state-of-the-art results showing significant improvements in demo-driven learning tasks, while current models like Gemini-2.5-Pro achieve only 46.6% and 32.0% accuracy on text and video demonstrations respectively, demonstrating the challenge's difficulty.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Demo-ICL: In-Context Learning for Procedural Video Knowledge Acquisition</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="20" font-weight="bold" fill="#2c3e50">Demo-ICL: Methodological Workflow</text>
  
  <!-- Stage 1: Data Collection & Processing -->
  <rect x="50" y="60" width="200" height="120" rx="10" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="150" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="#1976d2">Data Collection</text>
  <text x="150" y="105" text-anchor="middle" font-size="11" fill="#333">HowTo100M Videos</text>
  <text x="150" y="120" text-anchor="middle" font-size="11" fill="#333">ASR Transcripts</text>
  <text x="150" y="135" text-anchor="middle" font-size="11" fill="#333">Metadata Filtering</text>
  <text x="150" y="150" text-anchor="middle" font-size="11" fill="#333">Quality Control</text>
  
  <!-- Stage 2: Text Demo Generation -->
  <rect x="300" y="60" width="200" height="120" rx="10" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="400" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="#7b1fa2">Text Demo Generation</text>
  <text x="400" y="105" text-anchor="middle" font-size="11" fill="#333">Qwen2.5-72B Summarization</text>
  <text x="400" y="120" text-anchor="middle" font-size="11" fill="#333">Step Filtering & Merging</text>
  <text x="400" y="135" text-anchor="middle" font-size="11" fill="#333">Qwen2.5-VL Refinement</text>
  <text x="400" y="150" text-anchor="middle" font-size="11" fill="#333">Visual-Text Alignment</text>
  
  <!-- Stage 3: Video Demo Selection -->
  <rect x="550" y="60" width="200" height="120" rx="10" fill="#e8f5e8" stroke="#388e3c" stroke-width="2"/>
  <text x="650" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="#388e3c">Video Demo Selection</text>
  <text x="650" y="105" text-anchor="middle" font-size="11" fill="#333">Metadata Ranking</text>
  <text x="650" y="120" text-anchor="middle" font-size="11" fill="#333">Title Similarity</text>
  <text x="650" y="135" text-anchor="middle" font-size="11" fill="#333">LLM Validation</text>
  <text x="650" y="150" text-anchor="middle" font-size="11" fill="#333">Pair Construction</text>
  
  <!-- Stage 4: Question Generation -->
  <rect x="800" y="60" width="150" height="120" rx="10" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="875" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="#f57c00">Question Gen</text>
  <text x="875" y="105" text-anchor="middle" font-size="11" fill="#333">Step Selection</text>
  <text x="875" y="120" text-anchor="middle" font-size="11" fill="#333">QA Creation</text>
  <text x="875" y="135" text-anchor="middle" font-size="11" fill="#333">Human Review</text>
  <text x="875" y="150" text-anchor="middle" font-size="11" fill="#333">Quality Check</text>
  
  <!-- Three Task Types -->
  <rect x="100" y="220" width="180" height="80" rx="8" fill="#ffebee" stroke="#c62828" stroke-width="2"/>
  <text x="190" y="245" text-anchor="middle" font-size="13" font-weight="bold" fill="#c62828">Text-demo ICL</text>
  <text x="190" y="265" text-anchor="middle" font-size="10" fill="#333">Text Instructions</text>
  <text x="190" y="280" text-anchor="middle" font-size="10" fill="#333">as Context</text>
  
  <rect x="320" y="220" width="180" height="80" rx="8" fill="#e8f5e8" stroke="#2e7d32" stroke-width="2"/>
  <text x="410" y="245" text-anchor="middle" font-size="13" font-weight="bold" fill="#2e7d32">Video-demo ICL</text>
  <text x="410" y="265" text-anchor="middle" font-size="10" fill="#333">Video Demonstrations</text>
  <text x="410" y="280" text-anchor="middle" font-size="10" fill="#333">as Reference</text>
  
  <rect x="540" y="220" width="180" height="80" rx="8" fill="#f3e5f5" stroke="#6a1b9a" stroke-width="2"/>
  <text x="630" y="245" text-anchor="middle" font-size="13" font-weight="bold" fill="#6a1b9a">Demo Selection</text>
  <text x="630" y="265" text-anchor="middle" font-size="10" fill="#333">Choose from</text>
  <text x="630" y="280" text-anchor="middle" font-size="10" fill="#333">Video Pool</text>
  
  <!-- Training Pipeline -->
  <rect x="100" y="350" width="800" height="40" rx="5" fill="#e1f5fe" stroke="#0277bd" stroke-width="2"/>
  <text x="500" y="375" text-anchor="middle" font-size="16" font-weight="bold" fill="#0277bd">Two-Stage Training Strategy</text>
  
  <!-- Stage 1: SFT -->
  <rect x="150" y="420" width="250" height="100" rx="10" fill="#fff8e1" stroke="#ff8f00" stroke-width="2"/>
  <text x="275" y="445" text-anchor="middle" font-size="14" font-weight="bold" fill="#ff8f00">Stage 1: Video SFT</text>
  <text x="275" y="465" text-anchor="middle" font-size="11" fill="#333">Multi-source Dataset</text>
  <text x="275" y="480" text-anchor="middle" font-size="11" fill="#333">LLaVA-OneVision, Oryx</text>
  <text x="275" y="495" text-anchor="middle" font-size="11" fill="#333">COIN, Cross-Task</text>
  <text x="275" y="510" text-anchor="middle" font-size="11" fill="#333">Demo-ICL Samples</text>
  
  <!-- Stage 2: DPO -->
  <rect x="450" y="420" width="300" height="100" rx="10" fill="#fce4ec" stroke="#ad1457" stroke-width="2"/>
  <text x="600" y="445" text-anchor="middle" font-size="14" font-weight="bold" fill="#ad1457">Stage 2: Info-Assisted DPO</text>
  <text x="600" y="465" text-anchor="middle" font-size="11" fill="#333">Timestamp Assistance (Text-demo)</text>
  <text x="600" y="480" text-anchor="middle" font-size="11" fill="#333">Text Guidance (Video-demo)</text>
  <text x="600" y="495" text-anchor="middle" font-size="11" fill="#333">Preference Optimization</text>
  <text x="600" y="510" text-anchor="middle" font-size="11" fill="#333">Iterative Training</text>
  
  <!-- Final Model -->
  <ellipse cx="500" cy="600" rx="120" ry="40" fill="#e8f5e8" stroke="#4caf50" stroke-width="3"/>
  <text x="500" y="595" text-anchor="middle" font-size="16" font-weight="bold" fill="#2e7d32">Demo-ICL</text>
  <text x="500" y="615" text-anchor="middle" font-size="12" fill="#2e7d32">Enhanced MLLM</text>
  
  <!-- Evaluation Results -->
  <rect x="100" y="680" width="800" height="60" rx="8" fill="#f1f8e9" stroke="#689f38" stroke-width="2"/>
  <text x="500" y="705" text-anchor="middle" font-size="14" font-weight="bold" fill="#689f38">Evaluation on Demo-ICL-Bench</text>
  <text x="250" y="725" text-anchor="middle" font-size="11" fill="#333">Text-demo: 43.4%</text>
  <text x="500" y="725" text-anchor="middle" font-size="11" fill="#333">Video-demo: 32.0%</text>
  <text x="750" y="725" text-anchor="middle" font-size="11" fill="#333">Demo Selection: 58.0%</text>
  
  <!-- Connection lines -->
  <line x1="250" y1="120" x2="300" y2="120" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="120" x2="550" y2="120" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="750" y1="120" x2="800" y2="120" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <line x1="400" y1="300" x2="400" y2="350" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="400" y1="520" x2="500" y2="560" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="640" x2="500" y2="680" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="">
                        <div class="quiz-question">1. What is the fundamental difference between Demo-ICL's approach and existing video understanding benchmarks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Demo-ICL uses longer videos while existing benchmarks use short clips">Demo-ICL uses longer videos while existing benchmarks use short clips</div><div class="quiz-choice long-text" data-value="Demo-ICL requires models to learn from in-context demonstrations rather than relying on pre-trained knowledge or visible facts">Demo-ICL requires models to learn from in-context demonstrations rather than relying on pre-trained knowledge or visible facts</div><div class="quiz-choice" data-value="Demo-ICL focuses on audio understanding while existing benchmarks focus on visual content">Demo-ICL focuses on audio understanding while existing benchmarks focus on visual content</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="">
                        <div class="quiz-question">2. In the Demo-ICL training strategy, what is the purpose of the information-assisted Direct Preference Optimization (DPO) stage?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="To reduce the computational cost of video processing by using fewer frames">To reduce the computational cost of video processing by using fewer frames</div><div class="quiz-choice long-text" data-value="To generate high-quality responses by providing assistive information like timestamps and text guidance, overcoming current models' limitations in demo-driven learning">To generate high-quality responses by providing assistive information like timestamps and text guidance, overcoming current models' limitations in demo-driven learning</div><div class="quiz-choice" data-value="To compress video data into smaller file sizes for faster processing">To compress video data into smaller file sizes for faster processing</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="">
                        <div class="quiz-question">3. According to the experimental results, what does the poor performance of current state-of-the-art models on Demo-ICL-Bench reveal?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Current models need more computational power to process video data effectively">Current models need more computational power to process video data effectively</div><div class="quiz-choice" data-value="The benchmark questions are poorly designed and need to be simplified">The benchmark questions are poorly designed and need to be simplified</div><div class="quiz-choice long-text" data-value="Current models struggle with extracting and transferring knowledge from demonstrations, highlighting the need for specialized training approaches">Current models struggle with extracting and transferring knowledge from demonstrations, highlighting the need for specialized training approaches</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>

    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');

                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫ÊØè‰∏™Âç°ÁâáÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂ÔºàËÄå‰∏çÊòØÊï¥‰∏™ÂÆπÂô®Ôºâ
                cards.forEach(card => {
                    card.addEventListener('click', function(e) {
                        // Âè™ÊúâÁÇπÂáªÂú®Âç°ÁâáÂÜÖÈÉ®Êó∂ÊâçÂàáÊç¢
                        // Ê£ÄÊü•ÊòØÂê¶ÊòØÊµÅÁ®ãÂõæÂç°ÁâáÁöÑÊªöÂä®Êù°Âå∫Âüü
                        if (this.classList.contains('flowchart-card')) {
                            const rect = this.getBoundingClientRect();
                            const isScrollbarClick =
                                (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                                (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);

                            if (!isScrollbarClick) {
                                nextCard(e);
                            }
                        } else {
                            nextCard(e);
                        }
                    });
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
