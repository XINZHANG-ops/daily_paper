
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- AI Assistant Styles -->
    <link rel="stylesheet" href="../../css/ai-assistant.css">
    <title>2025-05-07 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }
    
        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            border-bottom: 3px solid rgba(255, 255, 255, 0.3);
            padding-bottom: 15px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    
    </style>
</head>
<body>
    <h1>2025-05-07 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/woven.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>Unified Multimodal Chain-of-Thought Reward Model through Reinforcement
  Fine-Tuning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-06</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.03318" target="_blank">http://arxiv.org/pdf/2505.03318</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper introduces a unified multimodal Chain-of-Thought (CoT) reward model for evaluating both visual understanding and generation tasks in AI.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous multimodal reward models that provided direct or shallow reasoning responses, this paper proposes incorporating explicit long chain-of-thought reasoning to enhance reliability and robustness.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitation of current reward models that lack rigorous logical structure and deep analysis capabilities, often leading to inaccurate reward signals in complex scenarios.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors use a three-stage approach: cold start with GPT-4o distillation for initial CoT format learning, rejection sampling for generalization, and Group Relative Policy Optimization (GRPO) for reinforcement fine-tuning.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The model demonstrated superior performance across various vision tasks, showing that incorporating long CoT reasoning significantly improved reward signal accuracy and enabled better implicit reasoning capabilities even without explicit reasoning traces.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>Unified Multimodal Chain-of-Thought Reward Model through Reinforcement
  Fine-Tuning</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <style>
      .title-text { font-family: '
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Their lack of rigorous logical structure and capacity for multi-dimensional, deep reasoning.">
                        <div class="quiz-question">1. What is the primary limitation of existing multimodal reward models that UNIFIED REWARD-THINK addresses?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Their inability to handle video generation tasks.">Their inability to handle video generation tasks.</div><div class="quiz-choice" data-value="Their lack of rigorous logical structure and capacity for multi-dimensional, deep reasoning.">Their lack of rigorous logical structure and capacity for multi-dimensional, deep reasoning.</div><div class="quiz-choice" data-value="Their reliance on outdated visual recognition techniques.">Their reliance on outdated visual recognition techniques.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Group Relative Policy Optimization (GRPO)">
                        <div class="quiz-question">2. Which reinforcement learning technique is used in the final stage of the UNIFIED REWARD-THINK training pipeline to enhance reasoning capabilities?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Proximal Policy Optimization (PPO)">Proximal Policy Optimization (PPO)</div><div class="quiz-choice" data-value="Deep Q-Networks (DQN)">Deep Q-Networks (DQN)</div><div class="quiz-choice" data-value="Group Relative Policy Optimization (GRPO)">Group Relative Policy Optimization (GRPO)</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="They are strengthened, leading to better performance even without explicit CoT traces.">
                        <div class="quiz-question">3. According to the paper, what happens to the model's implicit reasoning capabilities after it has mastered explicit Chain-of-Thought reasoning?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="They remain unchanged, only explicit reasoning improves.">They remain unchanged, only explicit reasoning improves.</div><div class="quiz-choice" data-value="They weaken, making the model rely solely on explicit CoT.">They weaken, making the model rely solely on explicit CoT.</div><div class="quiz-choice" data-value="They are strengthened, leading to better performance even without explicit CoT traces.">They are strengthened, leading to better performance even without explicit CoT traces.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/my-little-plaid-dark.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement
  Learning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-05</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.02835" target="_blank">http://arxiv.org/pdf/2505.02835</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on developing a multimodal reward model (R1-Reward) through reinforcement learning, operating in the domain of multimodal large language models and reward modeling.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Previous research focused on improving reward models through data and structural aspects, while this paper introduces a novel approach of using reinforcement learning to enhance reward modeling performance and long-term reasoning capabilities.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of training stable and effective multimodal reward models, particularly focusing on issues with training instability, advantage normalization limitations, and inconsistencies between reasoning and results in existing approaches.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The authors developed StableReinforce algorithm with pre-clipping, advantage filtering, and consistency rewards, combined with a progressive difficulty training strategy using 200K preference data samples collected from diverse datasets.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> R1-Reward achieved significant improvements over previous state-of-the-art models: 8.4% improvement on VL Reward-Bench, 14.3% improvement on Multimodal Reward Bench, and superior performance on MM-RLHF Reward Bench, with further enhancements through inference compute scaling.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>R1-Reward: Training Multimodal Reward Model Through Stable Reinforcement
  Learning</h2>
                        <svg width="100%" viewBox="0 0 1000 800" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="0" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#555" />
    </marker>
    <filter id="shadow" x="-20%" y="-20%" width="140%" height="140%">
      <feGaussianBlur in="SourceAlpha" stdDeviation="3"/>
      <feOffset dx="2" dy="2" result="offsetblur"/>
      <feMerge>
        <feMergeNode/>
        <feMergeNode in="SourceGraphic"/>
      </feMerge>
    </filter>
  </defs>

  <style>
    .title-text { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-weight: bold; fill: #2c3e50; text-anchor: middle; }
    .section-title { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-weight: bold; fill: #ffffff; text-anchor: middle; }
    .section-title-dark { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-weight: bold; fill: #333333; text-anchor: middle; }
    .content-text { font-family: 'Segoe UI', Arial, sans-serif; fill: #ffffff; }
    .content-text-dark { font-family: 'Segoe UI', Arial, sans-serif; fill: #333333; }
    .content-text-small { font-size: 11px; }
    .content-text-medium { font-size: 12px; }
    .content-text-bold { font-weight: bold; }
    .box { stroke: #333; stroke-width: 1px; filter: url(#shadow); }
  </style>

  <rect width="100%" height="100%" fill="#f0f4f8"/>

  <!-- Title -->
  <text x="500" y="35" class="title-text" font-size="24px">R1-Reward: Method Flowchart</text>

  <!-- Problem Block -->
  <g>
    <rect x="150" y="60" width="700" height="80" rx="10" ry="10" fill="#e74c3c" class="box"/>
    <text x="500" y="80" class="section-title" font-size="16px">Problem: Limitations in MRM & RL Training</text>
    <text x="170" y="100" class="content-text content-text-medium">
      <tspan x="170" dy="0em">- Existing RL (PPO, Reinforce++) instability for reward modeling.</tspan>
      <tspan x="170" dy="1.2em">- Advantage Normalization issues with low-variance rewards.</tspan>
      <tspan x="170" dy="1.2em">- Inconsistency between model's reasoning and final judgment.</tspan>
    </text>
  </g>

  <!-- Goal Block -->
  <g>
    <rect x="250" y="155" width="500" height="45" rx="10" ry="10" fill="#f1c40f" class="box"/>
    <text x="500" y="182" class="section-title-dark" font-size="15px">Goal: Enhance MRM Reasoning via Stable Reinforcement Learning</text>
  </g>

  <!-- R1-Reward Training Pipeline Block -->
  <g>
    <rect x="40" y="215" width="920" height="430" rx="15" ry="15" fill="#d6eaf8" class="box"/>
    <text x="500" y="240" class="section-title-dark" font-size="18px" style="fill:#2980b9;">R1-Reward Training Pipeline</text>

    <!-- Step 1: Data Prep & SFT -->
    <g>
      <rect x="60" y="260" width="880" height="95" rx="8" ry="8" fill="#3498db" class="box"/>
      <text x="500" y="280" class="section-title" font-size="14px">Step 1: Data Preparation & SFT (Cold Start)</text>
      <text x="75" y="300" class="content-text content-text-medium">
        <tspan x="75" dy="0em">- Collect 200K preference pairs (R1-Reward-200K dataset).</tspan>
        <tspan x="75" dy="1.2em">- GPT-4o generates "thinking processes" (Long-CoT) & records sample difficulty.</tspan>
        <tspan x="75" dy="1.2em">- Supervised Fine-Tuning (SFT) of base MLLM (QwenVL-2.5-7B-Instruct) for task familiarization.</tspan>
      </text>
    </g>

    <!-- Step 2: RL Training Data Selection -->
    <g>
      <rect x="60" y="365" width="880" height="55" rx="8" ry="8" fill="#1abc9c" class="box"/>
      <text x="500" y="383" class="section-title" font-size="14px">Step 2: RL Training Data Selection</text>
      <text x="75" y="403" class="content-text content-text-medium">
        <tspan x="75" dy="0em">- Select difficult samples (e.g., GPT-4o required ‚â•2 attempts or failed).</tspan>
      </text>
    </g>

    <!-- Step 3: RL Training with StableReinforce -->
    <g>
      <rect x="60" y="430" width="880" height="185" rx="8" ry="8" fill="#2
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Limited exploration into the effectiveness of long-term reasoning capabilities for reward modeling and how to activate these in MRMs.">
                        <div class="quiz-question">1. What is the primary limitation of existing Multimodal Reward Model (MRM) research that the R1-Reward paper aims to address using Reinforcement Learning (RL)?</div>
                        <div class="quiz-choices"><div class="quiz-choice long-text" data-value="Limited exploration into the effectiveness of long-term reasoning capabilities for reward modeling and how to activate these in MRMs.">Limited exploration into the effectiveness of long-term reasoning capabilities for reward modeling and how to activate these in MRMs.</div><div class="quiz-choice" data-value="The lack of diverse and large-scale multimodal preference datasets for training MRMs.">The lack of diverse and large-scale multimodal preference datasets for training MRMs.</div><div class="quiz-choice" data-value="Existing MRMs are computationally too expensive for practical use.">Existing MRMs are computationally too expensive for practical use.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Refinements to clipping operations and advantage normalization through Pre-CLIP and Advantage Filter.">
                        <div class="quiz-question">2. The StableReinforce algorithm, proposed in the paper to address training instability, includes which of the following key algorithmic modifications?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A completely new neural network architecture for the reward head.">A completely new neural network architecture for the reward head.</div><div class="quiz-choice" data-value="A progressive difficulty training strategy based on data samples' difficulty.">A progressive difficulty training strategy based on data samples' difficulty.</div><div class="quiz-choice long-text" data-value="Refinements to clipping operations and advantage normalization through Pre-CLIP and Advantage Filter.">Refinements to clipping operations and advantage normalization through Pre-CLIP and Advantage Filter.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="By using a majority voting strategy over multiple inference samples.">
                        <div class="quiz-question">3. How does the paper demonstrate that R1-Reward can achieve further performance improvements with more inference compute?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By fine-tuning the model on additional data during the inference phase.">By fine-tuning the model on additional data during the inference phase.</div><div class="quiz-choice" data-value="By significantly reducing the model's parameter count for faster inference.">By significantly reducing the model's parameter count for faster inference.</div><div class="quiz-choice" data-value="By using a majority voting strategy over multiple inference samples.">By using a majority voting strategy over multiple inference samples.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>RADLADS: Rapid Attention Distillation to Linear Attention Decoders at
  Scale</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-05-05</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2505.03005" target="_blank">http://arxiv.org/pdf/2505.03005</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper presents RADLADS, a method for converting large language models from traditional transformer architectures to linear attention models in natural language processing.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous work in model distillation and linear attention, it introduces new RWKV-variant architectures (RADFinch and RADGoose) and a more efficient conversion process requiring far fewer training tokens than previous methods.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the challenge of converting expensive transformer models to more efficient linear attention models while maintaining performance, as traditional training methods require prohibitive computational resources.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Uses a 3-step process: attention weights transfer, attention hidden state alignment, and knowledge distillation, followed by fine-tuning, requiring only 350-700M tokens of training data.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Achieved state-of-the-art performance for linear attention models across standard benchmarks, with converted models maintaining close to original transformer performance while requiring less than $2,000 USD in training costs for even the largest (72B parameter) model.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>RADLADS: Rapid Attention Distillation to Linear Attention Decoders at
  Scale</h2>
                        <svg width="100%" viewBox="0 0 1000 1650" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <style type="text/css">
      @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap');
      .title-text { font-family: 'Roboto', sans-serif; font-size: 32px; font-weight: 700; fill: #2C3E50; text-anchor: middle; }
      .box-title { font-family: 'Roboto', sans-serif; font-size: 20px; font-weight: 700; fill: #1A237E; text-anchor: middle; }
      .box-subtitle { font-family: 'Roboto', sans-serif; font-size: 16px; font-weight: 500; fill: #3F51B5; }
      .box-text { font-family: 'Roboto', sans-serif; font-size: 14px; fill: #37474F; }
      .box-text-small { font-family: 'Roboto', sans-serif; font-size: 12px; fill: #455A64; }
      .connector-line { stroke: #78909C; stroke-width: 2.5px; fill: none; }
      .connector-dot { fill: #78909C; }
    </style>
    <linearGradient id="gradInput" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#E1F5FE;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#B3E5FC;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradSetup" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#E8F5E9;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#C8E6C9;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradStep1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#FFFDE7;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#FFF9C4;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradStep2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#EDE7F6;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#D1C4E9;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradStep3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#E0F7FA;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#B2EBF2;stop-opacity:1" />
    </linearGradient>
     <linearGradient id="gradAltStep3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#FFF3E0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#FFE0B2;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="gradOutput" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#F1F8E9;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#DCEDC8;stop-opacity:1" />
    </linearGradient>
  </defs>

  <rect width="100%" height="100%" fill="#F4F6F8"/>

  <text x="500" y="50" class="title-text">RADLADS Conversion Protocol</text>

  <!-- Variables for layout -->
  
    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

        <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- MathJax for LaTeX rendering (only for takeaways section) -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\(', '\)']],
                displayMath: [['$$', '$$'], ['\[', '\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            },
            startup: {
                pageReady: () => {
                    // Disable automatic processing - we'll only process takeaways manually
                    return Promise.resolve();
                }
            }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script>
    let y_cursor = 80;
    const box_width = 550;
    const box_x = (1000 - box_width) / 2; // 225
    const line_x = 500;
    const space_between_boxes = 70;
    const text_margin_x = 20;
    const text_start_y_offset = 35;
    const line_height = 18;
    const dot_radius = 5;

    function drawConnector(y1, y2) {
      const g = document.createElementNS("http://www.w3.org/2000/svg", "g");
      const line = document.createElementNS("http://www.w3.org/2000/svg", "line");
      line.setAttribute("x1", line_x);
      line.setAttribute("y1", y1);
      line.setAttribute("x2", line_x);
      line.setAttribute("y2", y2);
      line.setAttribute("class", "connector-line");
      g.appendChild(line);
      
      const dot1 = document.createElementNS("http://www.w3.org/2000/svg", "circle");
      dot1.setAttribute("cx", line_x);
      dot1.setAttribute("cy", y1);
      dot1.setAttribute("r", dot_radius);
      dot1.setAttribute("class", "connector-dot");
      g.appendChild(dot1);
      
      const dot2 = document.createElementNS("http://www.w3.org/2000/svg", "circle");
      dot2.setAttribute("cx", line_x);
      dot2.setAttribute("cy", y2);
      dot2.setAttribute("r", dot_radius);
      dot2.setAttribute("class", "connector-dot");
      g.appendChild(dot2);
      return g;
    }
  </script>

  <!-- Input Model -->
  <g id="input_model">
    <rect x="${box_x}" y="${y_cursor}" width="${box_width}" height="90" rx="15" ry="15" fill="url(#gradInput)" stroke="#90CAF9" stroke-width="1.5"/>
    <text x="500" y="${y_cursor + text_start_y_offset}" class="box-title">Input: Pre-trained Teacher Model</text>
    <text x="${box_x + text_margin_x}" y="${y_cursor + text_start_y_offset + line_height * 1.5}" class="box-text">
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Type: Softmax Attention Transformer (e.g., Qwen2.5)</tspan>
    </text>
    <script>y_cursor += 90;</script>
  </g>
  
  <g transform="translate(0, ${y_cursor})">
    <path d="M ${line_x} 0 V ${space_between_boxes/2}" class="connector-line"/>
    <circle cx="${line_x}" cy="0" r="${dot_radius}" class="connector-dot"/>
    <circle cx="${line_x}" cy="${space_between_boxes/2}" r="${dot_radius}" class="connector-dot"/>
    <script>y_cursor += space_between_boxes/2;</script>
  </g>

  <!-- Setup Phase -->
  <g id="setup_phase" transform="translate(0, ${y_cursor})">
    <rect x="${box_x}" y="0" width="${box_width}" height="190" rx="15" ry="15" fill="url(#gradSetup)" stroke="#A5D6A7" stroke-width="1.5"/>
    <text x="500" y="${text_start_y_offset}" class="box-title">Setup: Attention Weights Transfer &amp; Student Init</text>
    <text class="box-text">
      <tspan x="${box_x + text_margin_x}" dy="${text_start_y_offset + line_height * 1.5}">Student Model Architecture:</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- MLPs &amp; Embeddings: Copied from Teacher.</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Attention Blocks: Replaced with recurrent mixers (e.g., RAD-RWKV6/7).</tspan>
      <tspan x="${box_x + text_margin_x}" dy="${line_height*1.5}">Weight Initialization:</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Attention (Wq, Wk, Wv, Wo): Transferred from Teacher to equivalent params.</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Other recurrent-specific weights: Standard pretraining init (e.g., 'w' in RWKV).</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Special weights (e.g., tokenshift): Init to mimic teacher, learnable.</tspan>
    </text>
    <script>y_cursor += 190;</script>
  </g>

  <g transform="translate(0, ${y_cursor})">
    <path d="M ${line_x} 0 V ${space_between_boxes}" class="connector-line"/>
    <circle cx="${line_x}" cy="0" r="${dot_radius}" class="connector-dot"/>
    <circle cx="${line_x}" cy="${space_between_boxes}" r="${dot_radius}" class="connector-dot"/>
    <script>y_cursor += space_between_boxes;</script>
  </g>
  
  <!-- Step 1 -->
  <g id="step_1" transform="translate(0, ${y_cursor})">
    <rect x="${box_x}" y="0" width="${box_width}" height="260" rx="15" ry="15" fill="url(#gradStep1)" stroke="#FFECB3" stroke-width="1.5"/>
    <text x="500" y="${text_start_y_offset}" class="box-title">Step 1: Attention Hidden State Alignment</text>
    <text class="box-text">
      <tspan x="${box_x + text_margin_x}" dy="${text_start_y_offset + line_height * 1.5}">Goal: Student recurrent attention layer outputs ‚âà Teacher attention layer outputs.</tspan>
      <tspan x="${box_x + text_margin_x}" dy="${line_height*1.5}">Process:</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Frozen Teacher Model (for hidden states reference).</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Trainable Student recurrent attention layers (all layers at once).</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Loss: L2 Distance (or MSE) between student &amp; teacher hidden states.</tspan>
      <tspan x="${box_x + text_margin_x}" dy="${line_height*1.5}">Hyperparameters:</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Dataset: DCLM</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Tokens: 100M</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Sequence Length: 512</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Learning Rate: 1e-3 to 1e-5 (cosine anneal)</tspan>
      <tspan x="${box_x + text_margin_x}" dy="${line_height*1.5}">Output: Student model with aligned recurrent attention (teacher attention layers removed).</tspan>
    </text>
    <script>y_cursor += 260;</script>
  </g>

  <g transform="translate(0, ${y_cursor})">
    <path d="M ${line_x} 0 V ${space_between_boxes}" class="connector-line"/>
    <circle cx="${line_x}" cy="0" r="${dot_radius}" class="connector-dot"/>
    <circle cx="${line_x}" cy="${space_between_boxes}" r="${dot_radius}" class="connector-dot"/>
    <script>y_cursor += space_between_boxes;</script>
  </g>

  <!-- Step 2 -->
  <g id="step_2" transform="translate(0, ${y_cursor})">
    <rect x="${box_x}" y="0" width="${box_width}" height="230" rx="15" ry="15" fill="url(#gradStep2)" stroke="#B39DDB" stroke-width="1.5"/>
    <text x="500" y="${text_start_y_offset}" class="box-title">Step 2: Knowledge Distillation</text>
    <text class="box-text">
      <tspan x="${box_x + text_margin_x}" dy="${text_start_y_offset + line_height * 1.5}">Goal: Student model output logits ‚âà Teacher model output logits.</tspan>
      <tspan x="${box_x + text_margin_x}" dy="${line_height*1.5}">Process:</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Frozen Teacher Model (for logits reference).</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Train all layers of the Student Model.</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">- Loss: Kullback-Leibler (KL) Divergence.</tspan>
      <tspan x="${box_x + text_margin_x}" dy="${line_height*1.5}">Hyperparameters:</tspan>
      <tspan x="${box_x + text_margin_x + 10}" dy="${line_height}">
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Hundreds of millions of tokens, less than 0.005% of the teacher's pre-training data.">
                        <div class="quiz-question">1. A key achievement of the RADLADS method highlighted in the paper is its efficiency in converting large transformer models. How many tokens are typically required for the conversion process?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Tens of trillions of tokens, similar to the original teacher model training.">Tens of trillions of tokens, similar to the original teacher model training.</div><div class="quiz-choice" data-value="Hundreds of billions of tokens, significantly less than pre-training but still substantial.">Hundreds of billions of tokens, significantly less than pre-training but still substantial.</div><div class="quiz-choice" data-value="Hundreds of millions of tokens, less than 0.005% of the teacher's pre-training data.">Hundreds of millions of tokens, less than 0.005% of the teacher's pre-training data.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Skipping Step 1 (Attention Hidden State Alignment) and starting directly with Step 2.">
                        <div class="quiz-question">2. The RADLADS protocol involves several steps. Which of the following approaches was explicitly found to *not* work well or resulted in significantly lower performance according to the paper's "What Did Not Work" section?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using a cosine annealed learning rate during Step 1.">Using a cosine annealed learning rate during Step 1.</div><div class="quiz-choice" data-value="Skipping Step 1 (Attention Hidden State Alignment) and starting directly with Step 2.">Skipping Step 1 (Attention Hidden State Alignment) and starting directly with Step 2.</div><div class="quiz-choice" data-value="Using a flat learning rate during Step 2.">Using a flat learning rate during Step 2.</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="RAD-RWKV6 (RADFinch) and RAD-RWKV7 (RADGoose)">
                        <div class="quiz-question">3. The paper introduces two new RWKV-variant architectures used in the conversion process. What are they named?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="RAD-RWKV5 and RAD-RWKV6">RAD-RWKV5 and RAD-RWKV6</div><div class="quiz-choice" data-value="RAD-RWKV6 (RADFinch) and RAD-RWKV7 (RADGoose)">RAD-RWKV6 (RADFinch) and RAD-RWKV7 (RADGoose)</div><div class="quiz-choice" data-value="RWKV-A and RWKV-B">RWKV-A and RWKV-B</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const markdownPath = `../notes/${date}.md`;

                // Fetch the markdown file
                const xhr = new XMLHttpRequest();
                xhr.open('GET', markdownPath, true);
                xhr.onload = function() {
                    if (xhr.status === 200) {
                        const markdownContent = xhr.responseText;
                        if (!markdownContent.trim()) {
                            console.log('Markdown file is empty');
                            return;
                        }

                        // Convert markdown to HTML
                        let htmlContent = marked.parse(markdownContent);

                        // Fix image paths
                        const fixedContent = htmlContent.replace(
                            /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)(.*?)"/g,
                            `src="../images/${date}/$1"`
                        );

                        // Wrap in styled divs
                        const wrappedHtml = `
                            <div class="takeaways-section">
                                <h2>üìù My Takeaways</h2>
                                <div class="takeaways-content">
                                    ${fixedContent}
                                </div>
                            </div>
                        `;

                        document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                        console.log('Takeaways section rendered');
                            // Trigger MathJax to render LaTeX equations
                            if (typeof MathJax !== 'undefined') {
                                MathJax.typesetPromise([document.getElementById('takeaways-container')])
                                    .then(() => {
                                        console.log('MathJax rendering complete');
                                    })
                                    .catch((err) => console.error('MathJax rendering error:', err));
                            }
                    } else {
                        console.log('XHR failed - Status:', xhr.status);
                    }
                };
                xhr.onerror = function() {
                    console.log('No takeaway file found for this date');
                };
                xhr.send();
            }
        });
    </script>


    <!-- AI Assistant Scripts - Load in correct order (relative paths for subpages) -->
    <script src="../../js/ai-assistant-constants.js"></script>
    <script src="../../js/ai-assistant-storage.js"></script>
    <script src="../../js/ai-assistant-positioning.js"></script>
    <script src="../../js/ai-assistant-templates.js"></script>
    <script src="../../js/ai-assistant-dom-utils.js"></script>
    <script src="../../js/ai-assistant-config.js"></script>
    <script src="../../js/ai-assistant.js"></script>
</body>
</html>
