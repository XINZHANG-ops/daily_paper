
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2026-01-07 Papers</title>
    <style>
        * {
            box-sizing: border-box; /* Á°Æ‰øùÊâÄÊúâÂÖÉÁ¥†‰ΩøÁî®border-boxÊ®°Âûã */
        }

        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('../../bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
            word-wrap: break-word;
            overflow-wrap: break-word;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* Âç°ÁâáÂÆπÂô®Ê†∑Âºè - Êñ∞Â¢û */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            min-height: 600px; /* Êîπ‰∏∫ÊúÄÂ∞èÈ´òÂ∫¶ËÄå‰∏çÊòØÂõ∫ÂÆöÈ´òÂ∫¶ */
            max-height: 90vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶Èò≤Ê≠¢Ê∫¢Âá∫ */
            height: auto; /* Ëá™ÈÄÇÂ∫îÂÜÖÂÆπÈ´òÂ∫¶ */ /* Âõ∫ÂÆöÈ´òÂ∫¶ */
            cursor: pointer; /* Â¢ûÂä†ÊåáÈíàÊ†∑ÂºèÊèêÁ§∫ÂèØÁÇπÂáª */
        }
        
        /* Âç°ÁâáÈÄöÁî®Ê†∑Âºè */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* ËΩÆÊí≠Âç°ÁâáÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%; /* ‰ΩøÁî®ÂÆπÂô®ÁöÑ100%È´òÂ∫¶ */
            transition: transform 0.5s ease, opacity 0.5s ease;
            overflow-y: auto; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
        }
        
        /* ÈùûÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* ÊøÄÊ¥ªÂç°ÁâáÁöÑÊ†∑Âºè - Êñ∞Â¢û */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* Á¨¨‰∏ÄÂº†Âç°ÁâáÔºàÊñáÊú¨ÂÜÖÂÆπÔºâ‰∏çÈúÄË¶ÅÊªöÂä® */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* Á¨¨‰∫åÂº†Âç°ÁâáÔºàÊµÅÁ®ãÂõæÔºâÊîØÊåÅÊªöÂä® */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow-y: auto !important; /* ÂÖÅËÆ∏ÂûÇÁõ¥ÊªöÂä® */
            overflow-x: hidden !important; /* Èò≤Ê≠¢Ê®™ÂêëÊªöÂä® */
            padding: 20px; /* Ê∑ªÂä†ÂÜÖËæπË∑ù */
            padding-bottom: 50px; /* Ê∑ªÂä†Â∫ïÈÉ®Â°´ÂÖÖÁ°Æ‰øùËÉΩÁúãÂà∞Â∫ïÈÉ® */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-width: 100%; /* Á°Æ‰øù‰∏çË∂ÖÂá∫ÂÆπÂô®ÂÆΩÂ∫¶ */
            display: block; /* Èò≤Ê≠¢Â∫ïÈÉ®Á©∫ÁôΩ */
            margin: 0 auto; /* Â±Ö‰∏≠ÊòæÁ§∫ */
        }
        
        /* ‰º†ÁªüÂç°ÁâáÊ†∑Âºè */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
        }
        
        .paper-card p {
            margin: 5px 0;
        word-wrap: break-word;
            overflow-wrap: break-word;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        word-wrap: break-word;
            overflow-wrap: break-word;
            overflow: hidden; /* Èò≤Ê≠¢ÂÜÖÂÆπÊ∫¢Âá∫ */
        }

        .category-chunk * {
            word-wrap: break-word;
            overflow-wrap: break-word;
            max-width: 100%;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* Âç°ÁâáËÆ°Êï∞Âô® - Êñ∞Â¢û */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* Êîπ‰∏∫Âõ∫ÂÆöÂÆö‰ΩçÔºå‰∏çÈöèÊªöÂä®ËÄåÁßªÂä® */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* Â±Ö‰∏≠ÊòæÁ§∫ */
            width: 90%;
            max-width: 500px; /* Â¢ûÂä†ÊúÄÂ§ßÂÆΩÂ∫¶ÔºåÈÄÇÂ∫îÈïøÂÜÖÂÆπ */
            max-height: 80vh; /* ÈôêÂà∂ÊúÄÂ§ßÈ´òÂ∫¶ */
            overflow-y: auto; /* ÂÜÖÂÆπËøáÂ§öÊó∂ÂèØÊªöÂä® */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* Á°Æ‰øùÊòæÁ§∫Âú®ÊúÄ‰∏äÂ±Ç */
        }
        
        /* Ê∑ªÂä†ÈÅÆÁΩ©Â±ÇÔºåÈò≤Ê≠¢ÈóÆÈ¢òÂç°Ë¢´ÂÖ∂‰ªñÂÜÖÂÆπÈÅÆÊå° */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* ‰ΩøÁî®JavaScriptÊéßÂà∂ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫ÂíåÈöêËóèÔºå‰∏çÂÜç‰ΩøÁî®hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            hyphens: auto; /* Âú®ÂøÖË¶ÅÊó∂‰ΩøÁî®ËøûÂ≠óÁ¨¶ */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* Á°Æ‰øùÈïøÂçïËØçËá™Âä®Êç¢Ë°å */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* ÈïøÊñáÊú¨Â∑¶ÂØπÈΩê */
            display: block; /* Á°Æ‰øùÊòØÂùóÁ∫ßÂÖÉÁ¥† */
            white-space: normal; /* ÂÖÅËÆ∏Ëá™Âä®Êç¢Ë°å */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* ÈïøÊñáÊú¨ÈÄâÈ°πÁöÑÁâπÊÆäÊ†∑Âºè */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* Á°Æ‰øùÂºπÁ™ó‰∏≠ÁöÑÊåâÈíÆÊñáÊú¨‰∏ç‰ºöÊ∫¢Âá∫ */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* ÈÄÇÂ∫îË∂ÖÈïøÈÄâÈ°πÊñáÊú¨ */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
                /* ‰∏≠Á≠âÂ±èÂπïËÆæÂ§áÔºàÂ¶ÇÂπ≥ÊùøÔºâ */
        @media (max-width: 1024px) {
            .card-deck {
                min-height: 500px;
            }

            .card-deck .paper-card {
                max-height: 88vh;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 10px; /* ÂáèÂ∞ëÁßªÂä®ËÆæÂ§á‰∏äÁöÑÂÜÖËæπË∑ù */
            }

            .paper-container {
                flex-direction: column;
            }

            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* ÁßªÂä®ËÆæÂ§á‰∏äÈ´òÂ∫¶Ë∞ÉÊï¥ */
            }

            .card-deck .paper-card {
                max-height: 85vh; /* ÁßªÂä®ËÆæÂ§á‰∏äÈôêÂà∂Êõ¥Â§ö */
                font-size: 0.95em; /* Á®çÂæÆÂáèÂ∞èÂ≠ó‰Ωì */
            }

            .paper-card h2 {
                font-size: 1.1em; /* ÁßªÂä®ËÆæÂ§á‰∏äË∞ÉÊï¥Ê†áÈ¢òÂ§ßÂ∞è */
            }

            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }

            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            width: 45px; /* ÁßªÂä®ËÆæÂ§á‰∏äÁ®çÂ∞èÁöÑÊåâÈíÆ */
                height: 45px;
                font-size: 14px;
            }
        }

        
        /* ÊûÅÂ∞èÂ±èÂπïÔºàÂ¶ÇÂ∞èÊâãÊú∫Ôºâ */
        @media (max-width: 480px) {
            body {
                padding: 5px;
            }

            .card-deck {
                min-height: 300px;
            }

            .card-deck .paper-card {
                max-height: 80vh;
                font-size: 0.9em;
                padding: 10px;
            }

            .paper-card h2 {
                font-size: 1em;
            }

            .category-chunk {
                padding: 8px;
                font-size: 0.9em;
            }

            .quiz-tab {
                width: 40px;
                height: 40px;
                font-size: 12px;
            }
        }

        /* Personal Takeaways Section Styles */
        .takeaways-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .takeaways-section h2 {
            color: #ffffff;
            font-size: 2em;
            margin-bottom: 20px;
            text-align: center;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }

        .takeaways-content {
            background-color: rgba(255, 255, 255, 0.95);
            border-radius: 8px;
            padding: 25px;
            line-height: 1.8;
            color: #333;
        }

        .takeaways-content h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
        }

        .takeaways-content img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 15px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }

        .takeaways-content p {
            margin: 15px 0;
        }

        .takeaways-content ul, .takeaways-content ol {
            margin: 15px 0;
            padding-left: 30px;
        }

        .takeaways-content li {
            margin: 8px 0;
        }

        .takeaways-content blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            font-style: italic;
            color: #555;
            background-color: #f8f9fa;
            padding: 15px 20px;
            border-radius: 4px;
        }

        .takeaways-content code {
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d73a49;
        }

        .takeaways-content pre {
            background-color: #f6f8fa;
            padding: 15px;
            border-radius: 6px;
            overflow-x: auto;
            border: 1px solid #e1e4e8;
        }

        .takeaways-content pre code {
            background-color: transparent;
            padding: 0;
            color: #333;
        }
    </style>
</head>
<body>
    <h1>2026-01-07 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/my-little-plaid-dark.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-06</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.03252" target="_blank">http://arxiv.org/pdf/2601.03252</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> The paper focuses on monocular depth estimation using neural implicit fields in computer vision, specifically for producing arbitrary-resolution and fine-grained depth maps from single RGB images.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Previous work used discrete grid-based depth representations which limited resolution and detail, while this paper proposes representing depth as continuous neural implicit fields that can be queried at any 2D coordinate.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> The paper addresses the limitations of traditional grid-based depth estimation methods which are constrained to fixed resolutions and struggle to capture fine geometric details.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> The method uses a Vision Transformer encoder with a multi-scale local implicit decoder that queries features from multiple layers and uses an MLP to predict depth at continuous coordinates, combined with a depth query strategy for uniform 3D point sampling.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> The approach achieves state-of-the-art performance on both synthetic (Synth4K) and real-world benchmarks across relative and metric depth estimation tasks, particularly excelling in fine-detail regions and novel view synthesis under large viewpoint shifts.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields</h2>
                        <svg width="100%" viewBox="0 0 1200 900">
  <!-- Background -->
  <defs>
    <linearGradient id="bgGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#f0f8ff;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e6f3ff;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="inputGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#4CAF50;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#66BB6A;stop-opacity:0.8" />
    </linearGradient>
    <linearGradient id="processGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#2196F3;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#42A5F5;stop-opacity:0.8" />
    </linearGradient>
    <linearGradient id="outputGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#FF9800;stop-opacity:0.8" />
      <stop offset="100%" style="stop-color:#FFB74D;stop-opacity:0.8" />
    </linearGradient>
  </defs>
  
  <rect width="100%" height="100%" fill="url(#bgGradient)"/>
  
  <!-- Title -->
  <text x="600" y="40" text-anchor="middle" font-family="Arial, sans-serif" font-size="24" font-weight="bold" fill="#2c3e50">
    InfiniDepth: Neural Implicit Fields for Depth Estimation
  </text>
  
  <!-- Input Stage -->
  <rect x="50" y="80" width="160" height="80" rx="10" fill="url(#inputGradient)" stroke="#388E3C" stroke-width="2"/>
  <text x="130" y="110" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Input RGB Image</text>
  <text x="130" y="130" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">I ‚àà R^(H√óW√ó3)</text>
  
  <!-- ViT Encoder -->
  <rect x="280" y="80" width="180" height="80" rx="10" fill="url(#processGradient)" stroke="#1976D2" stroke-width="2"/>
  <text x="370" y="110" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">ViT Encoder</text>
  <text x="370" y="130" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">DINOv3 ViT-Large</text>
  
  <!-- Feature Pyramid -->
  <rect x="520" y="80" width="180" height="80" rx="10" fill="url(#processGradient)" stroke="#1976D2" stroke-width="2"/>
  <text x="610" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Reassemble Block</text>
  <text x="610" y="125" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Feature Pyramid</text>
  <text x="610" y="145" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">{f^k}_{k=1}^L</text>
  
  <!-- Query Coordinates -->
  <rect x="50" y="220" width="160" height="80" rx="10" fill="url(#inputGradient)" stroke="#388E3C" stroke-width="2"/>
  <text x="130" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Query Coordinates</text>
  <text x="130" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">(x, y) ‚àà [0,W]√ó[0,H]</text>
  <text x="130" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Continuous 2D</text>
  
  <!-- Feature Query Module -->
  <rect x="280" y="220" width="180" height="120" rx="10" fill="url(#processGradient)" stroke="#1976D2" stroke-width="2"/>
  <text x="370" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Feature Query</text>
  <text x="370" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Multi-scale Local</text>
  <text x="370" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Bilinear Interpolation</text>
  <text x="370" y="305" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">f^k_{(x,y)}</text>
  <text x="370" y="325" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">for each scale k</text>
  
  <!-- Hierarchical Fusion -->
  <rect x="520" y="220" width="180" height="120" rx="10" fill="url(#processGradient)" stroke="#1976D2" stroke-width="2"/>
  <text x="610" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Depth Decoding</text>
  <text x="610" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Hierarchical Fusion</text>
  <text x="610" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Learnable Gates</text>
  <text x="610" y="305" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Feed Forward</text>
  <text x="610" y="325" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">h^{k+1} = FFN_k(...)</text>
  
  <!-- MLP Head -->
  <rect x="760" y="220" width="160" height="120" rx="10" fill="url(#processGradient)" stroke="#1976D2" stroke-width="2"/>
  <text x="840" y="250" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">MLP Head</text>
  <text x="840" y="275" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Depth Prediction</text>
  <text x="840" y="295" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">d_I(x,y) = MLP(h^L)</text>
  <text x="840" y="315" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Neural Implicit</text>
  <text x="840" y="335" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Function</text>
  
  <!-- Output Depth -->
  <rect x="980" y="220" width="160" height="80" rx="10" fill="url(#outputGradient)" stroke="#F57C00" stroke-width="2"/>
  <text x="1060" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Continuous Depth</text>
  <text x="1060" y="265" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Arbitrary Resolution</text>
  <text x="1060" y="285" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Fine-grained Details</text>
  
  <!-- Training Loss -->
  <rect x="280" y="400" width="180" height="80" rx="10" fill="#9C27B0" fill-opacity="0.8" stroke="#7B1FA2" stroke-width="2"/>
  <text x="370" y="425" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Training Loss</text>
  <text x="370" y="445" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">Sparse Supervision</text>
  <text x="370" y="465" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">L1 Loss on N samples</text>
  
  <!-- Applications -->
  <rect x="520" y="400" width="180" height="120" rx="10" fill="#E91E63" fill-opacity="0.8" stroke="#C2185B" stroke-width="2"/>
  <text x="610" y="425" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Applications</text>
  <text x="610" y="450" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Infinite Depth Query</text>
  <text x="610" y="470" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Uniform 3D Points</text>
  <text x="610" y="490" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Novel View Synthesis</text>
  <text x="610" y="510" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Surface Normal Estimation</text>
  
  <!-- Key Innovation Box -->
  <rect x="50" y="580" width="1100" height="120" rx="15" fill="#FF5722" fill-opacity="0.1" stroke="#FF5722" stroke-width="3" stroke-dasharray="10,5"/>
  <text x="600" y="610" text-anchor="middle" font-family="Arial, sans-serif" font-size="18" font-weight="bold" fill="#D84315">
    Key Innovation: Neural Implicit Fields for Depth Representation
  </text>
  <text x="600" y="635" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" fill="#BF360C">
    d_I(x,y) = N_Œ∏(I, (x,y)) - Maps continuous 2D coordinates to depth values
  </text>
  <text x="600" y="655" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" fill="#BF360C">
    Enables arbitrary resolution output without retraining ‚Ä¢ Preserves fine geometric details
  </text>
  <text x="600" y="675" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" fill="#BF360C">
    Localized prediction mechanism for better geometric variation capture
  </text>
  
  <!-- Evaluation Section -->
  <rect x="50" y="750" width="350" height="100" rx="10" fill="#607D8B" fill-opacity="0.8" stroke="#455A64" stroke-width="2"/>
  <text x="225" y="775" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Evaluation</text>
  <text x="225" y="795" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Synth4K: High-quality 4K benchmark</text>
  <text x="225" y="815" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Real-world datasets: KITTI, NYUv2, etc.</text>
  <text x="225" y="835" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ High-frequency detail evaluation</text>
  
  <!-- Results Section -->
  <rect x="450" y="750" width="350" height="100" rx="10" fill="#795548" fill-opacity="0.8" stroke="#5D4037" stroke-width="2"/>
  <text x="625" y="775" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Results</text>
  <text x="625" y="795" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ SOTA performance on Synth4K</text>
  <text x="625" y="815" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Superior fine-detail prediction</text>
  <text x="625" y="835" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Enhanced NVS quality</text>
  
  <!-- Technical Details -->
  <rect x="850" y="750" width="300" height="100" rx="10" fill="#3F51B5" fill-opacity="0.8" stroke="#303F9F" stroke-width="2"/>
  <text x="1000" y="775" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="white">Technical Details</text>
  <text x="1000" y="795" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Multi-scale feature pyramid</text>
  <text x="1000" y="815" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Bilinear feature interpolation</text>
  <text x="1000" y="835" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="white">‚Ä¢ Residual gated fusion</text>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Being restricted to fixed grid resolutions">
                        <div class="quiz-question">1. What is the main limitation of traditional depth estimation methods that InfiniDepth addresses?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="High computational cost">High computational cost</div><div class="quiz-choice" data-value="Being restricted to fixed grid resolutions">Being restricted to fixed grid resolutions</div><div class="quiz-choice" data-value="Requiring multiple input images">Requiring multiple input images</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="To generate uniform 3D points on object surfaces">
                        <div class="quiz-question">2. Why does InfiniDepth introduce a depth query strategy for novel view synthesis?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="To reduce computation time">To reduce computation time</div><div class="quiz-choice" data-value="To generate uniform 3D points on object surfaces">To generate uniform 3D points on object surfaces</div><div class="quiz-choice" data-value="To improve color accuracy">To improve color accuracy</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Synth4K: A high-quality 4K benchmark from five different games">
                        <div class="quiz-question">3. What unique dataset did the authors create to evaluate their method?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A collection of low-resolution real photos">A collection of low-resolution real photos</div><div class="quiz-choice" data-value="A dataset of synthetic indoor scenes">A dataset of synthetic indoor scenes</div><div class="quiz-choice" data-value="Synth4K: A high-quality 4K benchmark from five different games">Synth4K: A high-quality 4K benchmark from five different games</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/dark-wood.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>LTX-2: Efficient Joint Audio-Visual Foundation Model</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-06</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.03233" target="_blank">http://arxiv.org/pdf/2601.03233</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> A novel efficient joint audio-visual foundation model called LTX-2 for generating synchronized high-quality video and audio content from text descriptions.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous text-to-video and text-to-audio models, introduces new dual-stream transformer architecture with asymmetric design (14B video, 5B audio parameters) and bidirectional cross-attention for joint audio-visual generation.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Current text-to-video models generate silent videos lacking audio, while separate audio generation models don't capture the joint dependencies between visual and audio elements.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Uses dual-stream transformer with modality-specific VAEs, cross-attention layers, multilingual text conditioning, and modality-aware classifier-free guidance for synchronized audio-visual generation.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Achieves state-of-the-art audiovisual quality among open-source systems, with performance comparable to proprietary models but 18x faster inference speed, and can generate up to 20 seconds of synchronized content.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>LTX-2: Efficient Joint Audio-Visual Foundation Model</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-family="Arial, sans-serif" font-size="20" font-weight="bold" fill="#2c3e50">LTX-2: Efficient Joint Audio-Visual Foundation Model - Method Flow</text>
  
  <!-- Input Stage -->
  <rect x="50" y="80" width="120" height="60" fill="#e8f4fd" stroke="#3498db" stroke-width="2" rx="5"/>
  <text x="110" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Raw Video</text>
  <text x="110" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Input</text>
  
  <rect x="200" y="80" width="120" height="60" fill="#fef5e7" stroke="#f39c12" stroke-width="2" rx="5"/>
  <text x="260" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Raw Audio</text>
  <text x="260" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Input</text>
  
  <rect x="350" y="80" width="120" height="60" fill="#eafaf1" stroke="#27ae60" stroke-width="2" rx="5"/>
  <text x="410" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Text Prompt</text>
  <text x="410" y="120" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Input</text>
  
  <!-- VAE Encoding Stage -->
  <rect x="50" y="180" width="120" height="80" fill="#d6eaf8" stroke="#3498db" stroke-width="2" rx="5"/>
  <text x="110" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" font-weight="bold" fill="#2c3e50">Video VAE</text>
  <text x="110" y="220" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Spatiotemporal</text>
  <text x="110" y="235" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Causal Encoder</text>
  <text x="110" y="250" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">3D RoPE</text>
  
  <rect x="200" y="180" width="120" height="80" fill="#fdeaa7" stroke="#f39c12" stroke-width="2" rx="5"/>
  <text x="260" y="205" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" font-weight="bold" fill="#2c3e50">Audio VAE</text>
  <text x="260" y="220" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Mel Spectrogram</text>
  <text x="260" y="235" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">1D Temporal</text>
  <text x="260" y="250" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">1D RoPE</text>
  
  <!-- Text Processing -->
  <rect x="350" y="180" width="120" height="80" fill="#d5f4e6" stroke="#27ae60" stroke-width="2" rx="5"/>
  <text x="410" y="200" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" font-weight="bold" fill="#2c3e50">Gemma3-12B</text>
  <text x="410" y="215" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Multi-layer</text>
  <text x="410" y="230" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Feature Extractor</text>
  <text x="410" y="245" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">+ Thinking Tokens</text>
  
  <!-- Dual Stream Architecture -->
  <rect x="50" y="320" width="200" height="120" fill="#ebf3fd" stroke="#2980b9" stroke-width="3" rx="8"/>
  <text x="150" y="340" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2c3e50">Video Stream (14B)</text>
  <text x="150" y="360" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Self-Attention</text>
  <text x="150" y="375" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Text Cross-Attention</text>
  <text x="150" y="390" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Audio-Visual Cross-Attention</text>
  <text x="150" y="405" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Feed-Forward Network</text>
  <text x="150" y="425" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#7f8c8d">3D Positional Encoding</text>
  
  <rect x="280" y="320" width="200" height="120" fill="#fdf2e9" stroke="#e67e22" stroke-width="3" rx="8"/>
  <text x="380" y="340" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2c3e50">Audio Stream (5B)</text>
  <text x="380" y="360" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Self-Attention</text>
  <text x="380" y="375" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Text Cross-Attention</text>
  <text x="380" y="390" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Video-Audio Cross-Attention</text>
  <text x="380" y="405" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Feed-Forward Network</text>
  <text x="380" y="425" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#7f8c8d">1D Temporal Encoding</text>
  
  <!-- Cross-Modal Interaction -->
  <ellipse cx="265" cy="380" rx="40" ry="20" fill="#f8c471" stroke="#d68910" stroke-width="2"/>
  <text x="265" y="375" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Bidirectional</text>
  <text x="265" y="385" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Cross-Attention</text>
  
  <!-- CFG and Inference -->
  <rect x="520" y="320" width="180" height="120" fill="#f4ecf7" stroke="#8e44ad" stroke-width="2" rx="5"/>
  <text x="610" y="340" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" font-weight="bold" fill="#2c3e50">Modality-Aware CFG</text>
  <text x="610" y="360" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Text Guidance (st)</text>
  <text x="610" y="375" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Cross-Modal Guidance (sm)</text>
  <text x="610" y="395" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">MÃÇ(x,t,m) = M(x,t,m) +</text>
  <text x="610" y="410" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">st(M(x,t,m) - M(x,‚àÖ,m)) +</text>
  <text x="610" y="425" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">sm(M(x,t,m) - M(x,t,‚àÖ))</text>
  
  <!-- Decoding Stage -->
  <rect x="50" y="500" width="120" height="80" fill="#d6eaf8" stroke="#3498db" stroke-width="2" rx="5"/>
  <text x="110" y="525" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" font-weight="bold" fill="#2c3e50">Video VAE</text>
  <text x="110" y="540" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Decoder</text>
  <text x="110" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Multi-scale</text>
  <text x="110" y="570" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Multi-tile</text>
  
  <rect x="200" y="500" width="120" height="80" fill="#fdeaa7" stroke="#f39c12" stroke-width="2" rx="5"/>
  <text x="260" y="525" text-anchor="middle" font-family="Arial, sans-serif" font-size="11" font-weight="bold" fill="#2c3e50">Audio VAE</text>
  <text x="260" y="540" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Decoder +</text>
  <text x="260" y="555" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">HiFi-GAN</text>
  <text x="260" y="570" text-anchor="middle" font-family="Arial, sans-serif" font-size="10" fill="#2c3e50">Vocoder</text>
  
  <!-- Output Stage -->
  <rect x="50" y="630" width="120" height="60" fill="#e8f8f5" stroke="#16a085" stroke-width="2" rx="5"/>
  <text x="110" y="655" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">HD Video</text>
  <text x="110" y="670" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Output</text>
  
  <rect x="200" y="630" width="120" height="60" fill="#e8f8f5" stroke="#16a085" stroke-width="2" rx="5"/>
  <text x="260" y="655" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">Stereo Audio</text>
  <text x="260" y="670" text-anchor="middle" font-family="Arial, sans-serif" font-size="12" fill="#2c3e50">24kHz Output</text>
  
  <!-- Key Features Box -->
  <rect x="750" y="80" width="220" height="200" fill="#fdfefe" stroke="#34495e" stroke-width="2" rx="8"/>
  <text x="860" y="105" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2c3e50">Key Innovations</text>
  <text x="760" y="130" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Asymmetric Dual-Stream</text>
  <text x="760" y="145" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Bidirectional Cross-Attention</text>
  <text x="760" y="160" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Cross-Modality AdaLN</text>
  <text x="760" y="175" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Temporal 1D RoPE</text>
  <text x="760" y="190" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Thinking Tokens</text>
  <text x="760" y="205" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Modality-Aware CFG</text>
  <text x="760" y="220" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Decoupled Latent Spaces</text>
  <text x="760" y="235" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Multi-layer Feature Extract</text>
  <text x="760" y="250" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ 18x Faster Inference</text>
  <text x="760" y="265" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ 20s Generation Capability</text>
  
  <!-- Performance Box -->
  <rect x="750" y="320" width="220" height="120" fill="#f8f9fa" stroke="#95a5a6" stroke-width="2" rx="8"/>
  <text x="860" y="345" text-anchor="middle" font-family="Arial, sans-serif" font-size="14" font-weight="bold" fill="#2c3e50">Performance</text>
  <text x="760" y="365" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ 19B Total Parameters</text>
  <text x="760" y="380" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ 14B Video + 5B Audio</text>
  <text x="760" y="395" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ State-of-art Open Source</text>
  <text x="760" y="410" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ Comparable to Proprietary</text>
  <text x="760" y="425" font-family="Arial, sans-serif" font-size="11" fill="#2c3e50">‚Ä¢ 1.22s/step vs 22.3s (Wan)</text>
  
  <!-- Connection lines with gradient -->
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#3498db;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#e74c3c;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Flow connections -->
  <line x1="110" y1="140" x2="110" y2="180" stroke="url(#grad1)" stroke-width="3"/>
  <line x1="260" y1="140" x2="260" y2="180" stroke="url(#grad1)" stroke-width="3"/>
  <line x1="410" y1="140" x2="410" y2="180" stroke="url(#grad1)" stroke-width="3"/>
  
  <line x1="110" y1="260" x2="150" y2="320" stroke="url(#grad1)" stroke-width="3"/>
  <line x1="260" y1="260" x2="380" y2="320" stroke="url(#grad1)" stroke-width="3"/>
  <line x1="410" y1="260" x2="350" y2="320" stroke="url(#grad1)" stroke-width="3"/>
  
  <line x1="150" y1="440" x2="110" y2="500" stroke="url(#grad1)" stroke-width="3"/>
  <line x1="380" y1="440" x2="260" y2="500" stroke="url(#grad1)" stroke-width="3"/>
  
  <line x1="110" y1="580" x2="110" y2="630" stroke="url(#grad1)" stroke-width="3"/>
  <line x1="260" y1="580" x2="260" y2="630" stroke="url(#grad1)" stroke-width="3"/>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Having an asymmetric dual-stream design with different capacities for audio and video">
                        <div class="quiz-question">1. What is the main architectural innovation of LTX-2 compared to previous models?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using a single unified transformer for both audio and video">Using a single unified transformer for both audio and video</div><div class="quiz-choice" data-value="Having an asymmetric dual-stream design with different capacities for audio and video">Having an asymmetric dual-stream design with different capacities for audio and video</div><div class="quiz-choice" data-value="Using separate independent models for audio and video generation">Using separate independent models for audio and video generation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="20 seconds">
                        <div class="quiz-question">2. What is the maximum duration of synchronized audio-visual content that LTX-2 can generate?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="10 seconds">10 seconds</div><div class="quiz-choice" data-value="15 seconds">15 seconds</div><div class="quiz-choice" data-value="20 seconds">20 seconds</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Has inconsistent performance across different languages">
                        <div class="quiz-question">3. Which limitation does LTX-2 currently face?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Cannot generate high-resolution videos">Cannot generate high-resolution videos</div><div class="quiz-choice" data-value="Has inconsistent performance across different languages">Has inconsistent performance across different languages</div><div class="quiz-choice" data-value="Can only generate black and white videos">Can only generate black and white videos</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- Âç°ÁâáËÆ°Êï∞Âô® -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- Á¨¨‰∏ÄÂº†Âç°ÁâáÔºöËÆ∫ÊñáÊ¶ÇËø∞ -->
                    <div class="paper-card active" style="background-image: url('bg/black-lozenge.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>DreamStyle: A Unified Framework for Video Stylization</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2026-01-06</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2601.02785" target="_blank">http://arxiv.org/pdf/2601.02785</a></p>
                        <div><div class="category-chunk">1.  <strong>üìò Topic and Domain:</strong> Video stylization using a unified framework that supports multiple style conditions (text, style image, and first frame) for video-to-video transformation.</div><div class="category-chunk">2.  <strong>üí° Previous Research and New Ideas:</strong> Based on previous single-condition video stylization methods, this paper introduces a unified framework that combines multiple style conditions and proposes a novel token-specific LoRA architecture with a systematic data curation pipeline.</div><div class="category-chunk">3.  <strong>‚ùì Problem:</strong> Existing video stylization methods are limited to single style conditions, suffer from style inconsistency, and lack high-quality datasets for training.</div><div class="category-chunk">4.  <strong>üõ†Ô∏è Methods:</strong> Uses a two-stage training approach with CT and SFT datasets, builds on an I2V model with token-specific LoRA, and employs a data curation pipeline combining image stylization and I2V generation with ControlNets.</div><div class="category-chunk">5.  <strong>üìä Results and Evaluation:</strong> Outperforms competitors across all three stylization tasks (text-guided, style-image-guided, and first-frame-guided) in terms of style consistency and video quality, as demonstrated through both quantitative metrics and user studies.</div></div>
                    </div>
                    
                    <!-- Á¨¨‰∫åÂº†Âç°ÁâáÔºöÊµÅÁ®ãÂõæ -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>DreamStyle: A Unified Framework for Video Stylization</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#ff6b6b;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#4ecdc4;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#45b7d1;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#96ceb4;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#feca57;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#ff9ff3;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-family="Arial" font-size="24" font-weight="bold" fill="#2c3e50">DreamStyle Framework Workflow</text>
  
  <!-- Data Curation Pipeline -->
  <rect x="50" y="60" width="200" height="120" rx="10" fill="url(#grad1)" stroke="#2c3e50" stroke-width="2"/>
  <text x="150" y="85" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Data Curation Pipeline</text>
  <text x="150" y="105" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Step 1: Image Stylization</text>
  <text x="150" y="120" text-anchor="middle" font-family="Arial" font-size="10" fill="white">SDXL + InstantStyle</text>
  <text x="150" y="135" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Seedream 4.0</text>
  <text x="150" y="150" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Step 2: I2V Generation</text>
  <text x="150" y="165" text-anchor="middle" font-family="Arial" font-size="10" fill="white">ControlNet (Depth/Pose)</text>
  
  <!-- Dataset Construction -->
  <rect x="300" y="60" width="180" height="60" rx="10" fill="#e74c3c" stroke="#2c3e50" stroke-width="2"/>
  <text x="390" y="80" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">CT Dataset (40K)</text>
  <text x="390" y="95" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Large-scale + VLM Filtering</text>
  <text x="390" y="110" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Continual Training</text>
  
  <rect x="300" y="140" width="180" height="60" rx="10" fill="#9b59b6" stroke="#2c3e50" stroke-width="2"/>
  <text x="390" y="160" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">SFT Dataset (5K)</text>
  <text x="390" y="175" text-anchor="middle" font-family="Arial" font-size="10" fill="white">High-quality + Manual Filter</text>
  <text x="390" y="190" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Supervised Fine-tuning</text>
  
  <!-- Base Model -->
  <rect x="550" y="60" width="200" height="80" rx="10" fill="url(#grad2)" stroke="#2c3e50" stroke-width="2"/>
  <text x="650" y="85" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Wan14B-I2V Base Model</text>
  <text x="650" y="105" text-anchor="middle" font-family="Arial" font-size="11" fill="white">DiT Architecture</text>
  <text x="650" y="125" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Image Condition Channels</text>
  
  <!-- Condition Injection -->
  <rect x="100" y="240" width="150" height="80" rx="10" fill="#3498db" stroke="#2c3e50" stroke-width="2"/>
  <text x="175" y="265" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Text Condition</text>
  <text x="175" y="280" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Cross-Attention</text>
  <text x="175" y="295" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Original Layers</text>
  
  <rect x="280" y="240" width="150" height="80" rx="10" fill="#e67e22" stroke="#2c3e50" stroke-width="2"/>
  <text x="355" y="265" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Style Image</text>
  <text x="355" y="280" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Frame Concatenation</text>
  <text x="355" y="295" text-anchor="middle" font-family="Arial" font-size="10" fill="white">CLIP Features</text>
  
  <rect x="460" y="240" width="150" height="80" rx="10" fill="#27ae60" stroke="#2c3e50" stroke-width="2"/>
  <text x="535" y="265" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">First Frame</text>
  <text x="535" y="280" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Image Channels</text>
  <text x="535" y="295" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Mask = 1.0</text>
  
  <rect x="640" y="240" width="150" height="80" rx="10" fill="#8e44ad" stroke="#2c3e50" stroke-width="2"/>
  <text x="715" y="265" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Raw Video</text>
  <text x="715" y="280" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Channel Concat</text>
  <text x="715" y="295" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Mask = 0.0</text>
  
  <!-- Token-specific LoRA -->
  <rect x="350" y="360" width="300" height="100" rx="10" fill="url(#grad3)" stroke="#2c3e50" stroke-width="2"/>
  <text x="500" y="385" text-anchor="middle" font-family="Arial" font-size="14" font-weight="bold" fill="white">Token-specific LoRA</text>
  <text x="500" y="405" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Shared Down Matrix (W_down)</text>
  <text x="500" y="420" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Token-specific Up Matrices (W_up^i)</text>
  <text x="500" y="435" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Reduces Inter-token Confusion</text>
  <text x="500" y="450" text-anchor="middle" font-family="Arial" font-size="11" fill="white">Rank = 64</text>
  
  <!-- Training Strategy -->
  <rect x="100" y="500" width="200" height="80" rx="10" fill="#e74c3c" stroke="#2c3e50" stroke-width="2"/>
  <text x="200" y="525" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Stage 1: CT Training</text>
  <text x="200" y="545" text-anchor="middle" font-family="Arial" font-size="10" fill="white">6,000 iterations</text>
  <text x="200" y="560" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Foundation Capability</text>
  
  <rect x="320" y="500" width="200" height="80" rx="10" fill="#9b59b6" stroke="#2c3e50" stroke-width="2"/>
  <text x="420" y="525" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Stage 2: SFT Training</text>
  <text x="420" y="545" text-anchor="middle" font-family="Arial" font-size="10" fill="white">3,000 iterations</text>
  <text x="420" y="560" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Quality Enhancement</text>
  
  <!-- Flow Matching Loss -->
  <rect x="560" y="500" width="200" height="80" rx="10" fill="#16a085" stroke="#2c3e50" stroke-width="2"/>
  <text x="660" y="525" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Flow Matching Loss</text>
  <text x="660" y="545" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Sampling Ratio 1:2:1</text>
  <text x="660" y="560" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Text:Style:First-frame</text>
  
  <!-- Output Applications -->
  <rect x="150" y="620" width="150" height="60" rx="10" fill="#f39c12" stroke="#2c3e50" stroke-width="2"/>
  <text x="225" y="645" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Unified Framework</text>
  <text x="225" y="665" text-anchor="middle" font-family="Arial" font-size="10" fill="white">3 Stylization Tasks</text>
  
  <rect x="320" y="620" width="150" height="60" rx="10" fill="#e67e22" stroke="#2c3e50" stroke-width="2"/>
  <text x="395" y="645" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Multi-Style Fusion</text>
  <text x="395" y="665" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Extended Application</text>
  
  <rect x="490" y="620" width="150" height="60" rx="10" fill="#2ecc71" stroke="#2c3e50" stroke-width="2"/>
  <text x="565" y="645" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Long Video</text>
  <text x="565" y="665" text-anchor="middle" font-family="Arial" font-size="10" fill="white">Frame Chaining</text>
  
  <!-- Evaluation Metrics -->
  <rect x="680" y="620" width="150" height="60" rx="10" fill="#9b59b6" stroke="#2c3e50" stroke-width="2"/>
  <text x="755" y="645" text-anchor="middle" font-family="Arial" font-size="12" font-weight="bold" fill="white">Evaluation</text>
  <text x="755" y="665" text-anchor="middle" font-family="Arial" font-size="10" fill="white">CSD, DINO, VBench</text>
  
  <!-- Connection Lines (minimal as requested) -->
  <line x1="250" y1="120" x2="300" y2="120" stroke="#34495e" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="480" y1="120" x2="550" y2="120" stroke="#34495e" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="360" x2="500" y2="320" stroke="#34495e" stroke-width="2"/>
  <line x1="420" y1="460" x2="420" y2="500" stroke="#34495e" stroke-width="2"/>
  <line x1="420" y1="580" x2="420" y2="620" stroke="#34495e" stroke-width="2"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" 
     refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#34495e" />
    </marker>
  </defs>
  
  <!-- Key Innovation Highlights -->
  <circle cx="80" cy="750" r="8" fill="#e74c3c"/>
  <text x="100" y="755" font-family="Arial" font-size="12" fill="#2c3e50">Data Curation Pipeline</text>
  
  <circle cx="280" cy="750" r="8" fill="#3498db"/>
  <text x="300" y="755" font-family="Arial" font-size="12" fill="#2c3e50">Unified V2V Framework</text>
  
  <circle cx="480" cy="750" r="8" fill="#f39c12"/>
  <text x="500" y="755" font-family="Arial" font-size="12" fill="#2c3e50">Token-specific LoRA</text>
  
  <circle cx="680" cy="750" r="8" fill="#27ae60"/>
  <text x="700" y="755" font-family="Arial" font-size="12" fill="#2c3e50">Multi-modal Support</text>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Using a shared down matrix with token-specific up matrices">
                        <div class="quiz-question">1. What is the key innovation in DreamStyle's LoRA architecture that helps handle multiple style conditions?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Using multiple separate LoRA modules for each condition">Using multiple separate LoRA modules for each condition</div><div class="quiz-choice" data-value="Using a shared down matrix with token-specific up matrices">Using a shared down matrix with token-specific up matrices</div><div class="quiz-choice" data-value="Using parallel LoRA paths for different tokens">Using parallel LoRA paths for different tokens</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By using the last frame of a generated segment as the first frame for the next segment">
                        <div class="quiz-question">2. How does DreamStyle handle long video stylization beyond the 5-second duration limit?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By processing the entire video at once with expanded memory">By processing the entire video at once with expanded memory</div><div class="quiz-choice" data-value="By using the last frame of a generated segment as the first frame for the next segment">By using the last frame of a generated segment as the first frame for the next segment</div><div class="quiz-choice" data-value="By reducing video resolution for longer sequences">By reducing video resolution for longer sequences</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="To mitigate motion mismatches between paired videos">
                        <div class="quiz-question">3. In the data curation pipeline, why does DreamStyle generate both stylized and raw videos using the same control conditions?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="To reduce computation time during training">To reduce computation time during training</div><div class="quiz-choice" data-value="To create larger training datasets">To create larger training datasets</div><div class="quiz-choice" data-value="To mitigate motion mismatches between paired videos">To mitigate motion mismatches between paired videos</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            

    <!-- Personal Takeaways Section -->
    <div id="takeaways-container"></div>

    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Load and render markdown takeaways
            const dateMatch = document.querySelector('h1').textContent.match(/(\d{4}-\d{2}-\d{2})/);
            if (dateMatch) {
                const date = dateMatch[1];
                const mdPath = `../notes/${date}.md`;

                // Use XMLHttpRequest for better file:// protocol support
                const xhr = new XMLHttpRequest();
                xhr.onreadystatechange = function() {
                    if (xhr.readyState === 4) {
                        console.log('XHR Status:', xhr.status, 'Response length:', xhr.responseText.length);

                        if (xhr.status === 200 || xhr.status === 0) {  // status 0 for file://
                            const markdown = xhr.responseText;

                            if (!markdown || markdown.trim().length === 0) {
                                console.log('Empty markdown file');
                                return;
                            }

                            console.log('Markdown loaded, length:', markdown.length);

                            // Check if marked is loaded
                            if (typeof marked === 'undefined') {
                                console.error('marked.js library not loaded');
                                return;
                            }

                            // Convert markdown to HTML
                            const htmlContent = marked.parse(markdown);
                            console.log('HTML converted, length:', htmlContent.length);

                            // Fix image paths
                            const fixedContent = htmlContent.replace(
                                /src="(?!http:\/\/|https:\/\/|\/|\.\.\/)([^"]+)"/g,
                                `src="../images/${date}/$1"`
                            );

                            // Wrap in styled divs
                            const wrappedHtml = `
                                <div class="takeaways-section">
                                    <h2>üìù My Takeaways</h2>
                                    <div class="takeaways-content">
                                        ${fixedContent}
                                    </div>
                                </div>
                            `;

                            document.getElementById('takeaways-container').innerHTML = wrappedHtml;
                            console.log('Takeaways section rendered');
                        } else {
                            console.log('XHR failed - Status:', xhr.status);
                        }
                    }
                };
                xhr.open('GET', mdPath, true);
                console.log('Loading markdown from:', mdPath);
                xhr.send();
            }

            // ÂàõÂª∫ÈÅÆÁΩ©Â±Ç
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // Ëé∑ÂèñÊâÄÊúâÈóÆÈ¢òÊ†áÁ≠æ
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // ËÆæÁΩÆÁÇπÂáª‰∫ã‰ª∂Â§ÑÁêÜ
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // ÁÇπÂáªÊ†áÁ≠æÂàáÊç¢ÈóÆÈ¢òÂç°ÁöÑÊòæÁ§∫Áä∂ÊÄÅ
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // ÈòªÊ≠¢‰∫ã‰ª∂ÂÜíÊ≥°
                    
                    // Â¶ÇÊûúÂΩìÂâçÈóÆÈ¢òÂç°Â∑≤ÁªèÊòæÁ§∫ÔºåÂàôÈöêËóèÂÆÉ
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // ÂÖàÈöêËóèÊâÄÊúâÂÖ∂‰ªñÈóÆÈ¢òÂç°
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // Â∞ÜÂºπÁ™óÂÜÖÂÆπÂ§çÂà∂Âà∞È°µÈù¢ÊúÄÂ§ñÂ±ÇÁöÑÂºπÁ™ó‰∏≠
                        document.body.appendChild(popup);
                        
                        // ÊòæÁ§∫ÂΩìÂâçÈóÆÈ¢òÂç°ÂíåËÉåÊôØÈÅÆÁΩ©
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // Á°Æ‰øùÁÇπÂáªÈóÆÈ¢òÂç°ÂÜÖÈÉ®Êó∂‰∏ç‰ºöÂÖ≥Èó≠ÈóÆÈ¢òÂç°
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // ÁÇπÂáªÈÅÆÁΩ©Â±ÇÊàñÈ°µÈù¢‰ªª‰ΩïÂÖ∂‰ªñ‰ΩçÁΩÆÊó∂ÈöêËóèÊâÄÊúâÈóÆÈ¢òÂç°
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // ‰∏∫ÊØè‰∏™ÈÄâÈ°πÊ∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // ÈáçÁΩÆÊâÄÊúâÈÄâÈ°π
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // Ê†áËÆ∞ÂΩìÂâçÈÄâÈ°π‰∏∫Â∑≤ÈÄâ
                    this.classList.add('selected');
                    
                    // Ê£ÄÊü•ÊòØÂê¶Ê≠£Á°Æ
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '‚úîÔ∏è CorrectÔºÅ';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '‚ùå WrongÔºÅ';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // Âç°ÁâáËΩÆÊí≠ÂäüËÉΩ - Êñ∞Â¢û
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // Êõ¥Êñ∞ËÆ°Êï∞Âô®ÊòæÁ§∫
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // ÊòæÁ§∫ÊåáÂÆöÁ¥¢ÂºïÁöÑÂç°Áâá
                function showCard(index) {
                    // Â§ÑÁêÜÂæ™ÁéØ
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // Êõ¥Êñ∞ÂΩìÂâçÁ¥¢Âºï
                    currentIndex = index;
                    
                    // Êõ¥Êñ∞Âç°ÁâáÊòæÁ§∫
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // Êõ¥Êñ∞ËÆ°Êï∞Âô®
                    updateCounter();
                }
                
                // ‰∏ã‰∏ÄÂº†Âç°Áâá
                function nextCard(e) {
                    e.stopPropagation(); // Èò≤Ê≠¢‰∫ã‰ª∂ÂÜíÊ≥°ÂØºËá¥ÈóÆÈ¢òÂç°ÂÖ≥Èó≠
                    showCard(currentIndex + 1);
                }
                
                // ‰∏∫Âç°ÁâáÂÆπÂô®Ê∑ªÂä†ÁÇπÂáª‰∫ã‰ª∂
                cardDeck.addEventListener('click', function(e) {
                    // Ê£ÄÊü•ÁÇπÂáªÊòØÂê¶ÂèëÁîüÂú®ÊµÅÁ®ãÂõæÂç°ÁâáÂÜÖÈÉ®ÁöÑÊªöÂä®Âå∫Âüü
                    // Â¶ÇÊûúÊòØÂú®ÊªöÂä®Êù°‰∏äÁÇπÂáªÔºå‰∏çÂàáÊç¢Âç°Áâá
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // ËÆ°ÁÆóÁÇπÂáª‰ΩçÁΩÆÊòØÂê¶Âú®ÊªöÂä®Êù°Âå∫Âüü
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // ÈîÆÁõòÂØºËà™
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
