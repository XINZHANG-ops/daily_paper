Folks found even cheaper way to implement deepseek-r1 reasoning training (Tiny Reasoning Models via LoRA), the short answer is by combining LoRA. They achieved 9$ expenditure on good performance. The paper in my opinion is a PoC that LoRA method also works for reasoning capability rather than training on whole weights. What is also interesting is they found that unlike training on whole model, LoRA method suffers from more training FLOPs, i.e more training steps makes the performance worse, in their case 1e19 FLOPs works the best.
Github: [link](https://github.com/shangshang-wang/Tina)
Build upon: [link](https://github.com/huggingface/open-r1)
![My diagram notes](unnamed.png)
