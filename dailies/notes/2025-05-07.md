I got attracted by the name `Stable Reinforcement Learning`, since we know stable diffusion. But the stable here is different. So the paper point out the problem of traditiona PPO, even if it has the CLIP to prevent to aggressive of change, but for Instability Caused by Training Losses and Instability Caused by Advantage Normalization, PPO still can be instable. And the paper take the CLIP even earlier, this is like for old way, when the behavior is overstep, we detect and restrict it, but it may fail due to the above reason, and now we let the model dance with chains, it will be stable from the beginning.
![My diagram notes](unnamed.png)
