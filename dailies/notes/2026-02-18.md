# GLM-5: from Vibe Coding to Agentic Engineering

Today's title just got me in, no need to take deeper read I would like to read on this one, GLM-5 and vibe coding, a new model and a popular term recently, i just need to know what is going on.

This is a very technical report imo, massive improvements on the engineer of the training process.  So the paper realized the waste in the traditinal RL training, so here is how it happens, in traditional RL training, model need to run many rollouts to generate the training data - this is the fundenmental of Monte Carlo and to modern RL methods. And since each rollout is running by one GPU of the cluster, and in practice, when we run N runs, there might always be a run that takes much longer than the other runs, like the long tail distribution, so all GPU will idle to wait for that one rollout to finish, apprently, idling on those expensive GPU is a huge waste, thus the paper think about a different approach - no waiting, each worker keep generating rollouts, if one rollout is done, keep generating the next. And when a number of N runs are done, we collect them and train.

As we can see, this way the idling is solved, however, this has a huge issue, this might be a massive off-policy training, which means when the rollout data arrive and ready to be part of the training data to update weights of the model, the model might already changed, so how the paper solve this is the core of this paper imo.

In traditinal PPO, we keep one old PI as reference, but since this approach they need to keep a ton of old referece, obviously thats not valid. Instead, they smartly save the logprobs when generate the rollouts, use that as an estimiate of the old policy. 

Secondly, they will mask some token's grad from the training if the shift of certain token is too large and out of confidence level, this is kind of make sure the out of date data is not used.

And since the way they deploy the predictor and rewarder in different unit, the token transpotation between them has noise, which means the tokenizer and reverse tokenization might generate different tokens, they elimate this by entirely not decode Ids to text and encode into tokens, but direcly pass around the tokens, they call it TITO "Token-in-Token-out".

And lastly, if one rollout is too out of date, it will be abandoned.

github: https://github.com/zai-org/GLM-5

![My diagram notes](image_1.png)
![My diagram notes](image_2.png)