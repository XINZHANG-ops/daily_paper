I learnt something new from paper Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models. Previously I know quatilization will reduce the LLM performance because of loss of precision level. And this paper mentioned a reason I did not know before. When activate values have outliers. for example a layer with one extreme large values, due to normalization all small values are close to zero. and now with qualization all other values will be rounded as 0, now layer information is all gone, this is definitely a bad thing to happen. And this paper proposed a approach, they replaced Adam with a Muno optimizer, replace RMS or layer norm with Single-Scale RMSNorm, and also introduce a projector for embeddings, all the effort is to reduce the possibility of the extreme values of layers, and this helps with qualization even with aggressive like 4bit. From the image below we can see the extreme values from adm vs Muon.
Github: [link](https://github.com/dmis-lab/Outlier-Safe-Pre-Training)
![My diagram notes](unnamed.png)
