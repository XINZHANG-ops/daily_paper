One more paper applied deep-seek r1 paper but applied on visual-Saptial reasoning. But what makes me pay attention is this paper find KL-divergence regulation is so curial for the training. If they remove KL from their training, i.e, set beta = 0, the training collapse. Recently there are paper find KL is useless, and this paper find it is crucial, wondering what make this contradictive finds? Maybe because this paper is training on small and medium size models? as they also find CoT make it worse compare to vanilla model.
Github: https://github.com/zhijie-group/R1-Zero-VSI
![My diagram notes](unnamed.png)
