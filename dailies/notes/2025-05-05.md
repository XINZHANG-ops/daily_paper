For paper "Beyond the Last Answer: Your Reasoning Trace Uncovers More than You Think", I agree with it on some points that when I use the reasoning models, I have a feeling that the reasoning process is not fully leveraged in the end output. Sometimes I see great good thinking and expect the model outputs that as part of final answer but the model did not. The researcher from the paper make a method of interrupt the reasoning process at different spots, and add linguistic markers like "Hmm", "Wait" etc and send back to the LLM for new reasoning alternatives. And at the end do a mode vote to get the best answer. The end vote works for simple math output cause the simplicity of the format, I think ACE can taking about this approach too if we want to use a reasoning model, but we should think about how to vote against different SQL generation, maybe relevancy or not empty.
Github: [link](https://github.com/hammoudhasan/SubthoughtReasoner)
![My diagram notes](unnamed.png)
