# Qwen3-TTS Technical Report

A couple months ago, I used index-tts2 for me local agent framework to add my ai bot with my friend's voice, for that project I really wanted the tts model can make my voice sync in real time, so I prompt my agent to output responses in a brief way thus the voice model can produce voice faster. The voice quality was amazing, the only shortage was about the latency, I used a decent fast local LLM to generate text, but on average I still need to wait 5 to 10 seconds for the voice generation given my 4080s GPU. 

This new tts model from Qwen team focus on the real-time streaming part instead of a SOTA model, the key difference was, previous tts model understand the whole sentence first then generate the voice, like encoder instead of causal decoder, and in terms of quality that is indeed better since model has an idea of the entire sentence so it can capture more emotional and context. This paper instead focusing on streaming, it change the way of doing voice gen entirely, every single new token the model receive it generate the voice at that moment, one word no **look-ahead**, so that's why it can do it. This will be my must try model for my projects, the link is here:

github: https://github.com/QwenLM/Qwen3-TTS
huggingface: https://huggingface.co/collections/Qwen/qwen3-tts

![My diagram notes](image_1.png)