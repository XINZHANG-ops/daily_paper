One more paper innovated be deepseek reasoning RL approach. What they do here is they replace GRPO with PPO is also robust and stable. And they showed that rule based reward is not just enough but maybe optimal. And the K-L divergence is removed form the equation again. They also run into a step moment phenomenon, where response metrics suddenly increase during training.
Github: https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero
![My diagram notes](unnamed.png)
