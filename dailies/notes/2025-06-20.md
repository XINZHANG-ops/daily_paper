The paper Scaling Test-time Compute for LLM Agents is written by the Chinese phone company oppo. I learnt a new concept Test-time Compute from the paper, in fact we know this concept all the time just do not have a term for it. In short it is trading time and cost for performance in inference time. But the paper bring this idea also to agent actions. There are 4 things they add to the process, 1. parallel exploration, 2. reflection when needed, 3. explore with different settings for larger explore space, 4. List-wise PRM verifier(Final eval ask another model to pick the best one). and the paper found that these steps indeed significantly increases the agent performance. 
Github: [link](https://github.com/OPPO-PersonalAI/OAgents)
![My diagram notes](unnamed.png)
