The paper ProtoReasoning: Prototypes as the Foundation for Generalizable Reasoning in LLMs proposed a new thinking when train LLM to learn reasonings. The paper made an assumption that, although different tasks look like need different reasonings, but under the hood all reasoning jobs may share some common logical thinking skills. The kind of make sense in human I think, human who has strong logical thinking in one domain, may easily adapt the skill to other domains. Thus the paper training the LLM to learn reasoning on 2 very logical strong language, Prolog and PDDL. Prolog (Programming in Logic), is a programming language using logic, it shows relations and use that to do inference; PDDL (Planning Domain Definition Language) is the language used to do planning in AI. Both language is strongly logical embedded, which the goal is to let the model learn the essential of logics. And the experiremnts shows that this kind of training helped on other irrelevant tasks. Which means models has the ability to transfer their learnings too.
![My diagram notes](unnamed.png)
