The paper "DeepCritic" introduced a way to make the LLM critic its CoT process in order to get better answer. Even tho the paper does not sounds like a huge breakthrough or amazing findings, but I think this kind of paper is best for us to implement in our daily work, i.e ACE. The paper proposed two step SFT and RL training for this. Firstly they construct SFT deep critic data using a two step critic approach, which means generate first step critic then ask the model to critic from different angle or critic the critic itself. By doing so, I think SFT set up a general direction where the RL should go towards. Then the RL will further improve this critic ability they call it the "DeepCritic". I think text2SQL generation can take a very similar or exact same approach, write a SQL is very similar to tackle a math problem like what they do in this paper.
Github: [link](https://github.com/RUCBM/DeepCritic)
Dataset we can reference: [link](https://github.com/openai/prm800k/blob/main/prm800k/data/phase2_test.jsonl)
![My diagram notes](unnamed.png)
