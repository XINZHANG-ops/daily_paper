# Advancing Open-source World Models

I have to say what an amazing project. From their webpage demos, it is like the worldLabs project like Li FeiFei team is working on, but open sourced. They released the model weights, codes and demos. If you ever tried the worldlabs project you give it an image and it generates you an env you can explore with WASD, and this does similar thing.

The most important part this paper mentioned to train such model is data. You cannot just give the model random videos to learn about how the world behaves. They prepared 3 data sources:
1. Real video of walking, biking, driving etc
2. Game videos, each frame with corresponding WASD motion
3. UE data, with camera configs, trajectories etc

And they train it step by step too. Firstly pretraining with videos to make the model be able to generate realistic frames. Secondly they inject the world knowledge, by training with longer videos and the WASD corresponding data. Lastly using block-causal attention and distillation to make the generation fast, causal attention makes it not care the future, distillation makes it reduce the diffusion steps.

This is very similar to the LLM training imo, pretraining makes the model has the general knowledge, then sft makes it produce the data in a specific way.

Worth trying:

Website: https://technology.robbyant.com/lingbot-world

Github: https://github.com/robbyant/lingbot-world

Checkpoints: https://huggingface.co/robbyant/lingbot-world
![My diagram notes](image_1.png)