
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2025-10-10 Papers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #4d4042;
            background-image: url('bg.png');
            background-size: auto;
            background-repeat: repeat;
            overflow-x: hidden;
        }
        h1 {
            color: #333;
        }
        .paper-container {
            position: relative;
            display: flex;
            margin-bottom: 30px;
            justify-content: space-between;
            max-width: 100%;
            transition: all 0.3s ease;
        }
        
        /* 卡片容器样式 - 新增 */
        .card-deck {
            width: 100%;
            position: relative;
            margin-right: 20px;
            height: 600px; /* 固定高度 */
            cursor: pointer; /* 增加指针样式提示可点击 */
        }
        
        /* 卡片通用样式 */
        .paper-card {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            transition: all 0.3s ease;
            background-size: auto;
            background-repeat: repeat;
            background-position: center;
            background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('');
            background-blend-mode: overlay;
            overflow-wrap: break-word;
        }
        
        /* 轮播卡片样式 - 新增 */
        .card-deck .paper-card {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            box-sizing: border-box;
            height: 100%;
            transition: transform 0.5s ease, opacity 0.5s ease;
        }
        
        /* 非激活卡片的样式 - 新增 */
        .card-deck .paper-card:not(.active) {
            opacity: 0;
            pointer-events: none;
            transform: translateY(-10px);
        }
        
        /* 激活卡片的样式 - 新增 */
        .card-deck .paper-card.active {
            opacity: 1;
            pointer-events: auto;
            transform: translateY(0);
            z-index: 1;
        }
        
        /* 第一张卡片（文本内容）不需要滚动 */
        .card-deck .paper-card:first-child {
            overflow-y: auto;
        }

        .card-deck .paper-card:first-child:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        /* 第二张卡片（流程图）支持滚动 */
        .flowchart-card {
            text-align: center;
            background-color: #fff !important;
            overflow: auto !important;
            padding-bottom: 50px; /* 添加底部填充 */
        }

        .flowchart-card svg {
            width: 100%;
            height: auto;
            max-height: none; /* 移除任何高度限制 */
        }
        
        /* 传统卡片样式 */
        .paper-container > .paper-card {
            width: 100%;
            margin-right: 20px;
        }
        
        .paper-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }
        
        .paper-card h2 {
            margin: 0 0 10px;
            font-size: 1.2em;
        }
        
        .paper-card p {
            margin: 5px 0;
        }
        
        .paper-card a {
            color: #1a73e8;
            text-decoration: none;
        }
        
        .paper-card a:hover {
            text-decoration: underline;
        }
        
        .category-chunk {
            padding: 10px;
            margin: 5px 0;
            border-radius: 5px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .category-chunk:hover {
            transform: translateY(-3px);
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.15);
        }
        
        .category-chunk:nth-child(1) {
            background-color: #d3e3fd;
        }
        
        .category-chunk:nth-child(2) {
            background-color: #e6d6fa;
        }
        
        .category-chunk:nth-child(3) {
            background-color: #d4f8d9;
        }
        
        .category-chunk:nth-child(4) {
            background-color: #ffd7d5;
        }
        
        .category-chunk:nth-child(5) {
            background-color: #d3e3fd;
        }
        
        /* 卡片计数器 - 新增 */
        .card-counter {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(0, 0, 0, 0.6);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 12px;
            z-index: 2;
        }

        /* Quiz tabs and popup styles */
        .quiz-tabs {
            display: flex;
            flex-direction: column;
            position: sticky;
            top: 20px;
            align-self: flex-start;
            width: fit-content;
            min-width: 50px;
            margin-left: auto;
        }
        .quiz-tab {
            width: 50px;
            height: 50px;
            background-color: #1a73e8;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 15px;
            cursor: pointer;
            position: relative;
            font-weight: bold;
            font-size: 16px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
            transition: transform 0.2s, box-shadow 0.2s;
            z-index: 10;
        }
        .quiz-tab:hover {
            transform: scale(1.1);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);
        }
        .quiz-popup {
            position: fixed; /* 改为固定定位，不随滚动而移动 */
            left: 50%;
            top: 50%;
            transform: translate(-50%, -50%); /* 居中显示 */
            width: 90%;
            max-width: 500px; /* 增加最大宽度，适应长内容 */
            max-height: 80vh; /* 限制最大高度 */
            overflow-y: auto; /* 内容过多时可滚动 */
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            display: none;
            z-index: 9999; /* 确保显示在最上层 */
        }
        
        /* 添加遮罩层，防止问题卡被其他内容遮挡 */
        .popup-backdrop {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: rgba(0, 0, 0, 0.5);
            z-index: 9998;
            display: none;
        }
        
        .popup-backdrop.active {
            display: block;
        }
        /* 使用JavaScript控制问题卡的显示和隐藏，不再使用hover */
        .quiz-popup.active {
            display: block;
        }
        .quiz-question {
            font-weight: bold;
            margin-bottom: 20px;
            color: #333;
            font-size: 18px;
            line-height: 1.5;
            word-wrap: break-word; /* 确保长单词自动换行 */
            overflow-wrap: break-word;
            hyphens: auto; /* 在必要时使用连字符 */
        }
        .quiz-choices {
            display: flex;
            flex-direction: column;
        }
        .quiz-choice {
            padding: 12px 15px;
            margin: 8px 0;
            border: 1px solid #ddd;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.2s;
            color: #333;
            font-size: 15px;
            background-color: #f9f9f9;
            word-wrap: break-word; /* 确保长单词自动换行 */
            overflow-wrap: break-word;
            line-height: 1.4;
            text-align: left; /* 长文本左对齐 */
            display: block; /* 确保是块级元素 */
            white-space: normal; /* 允许自动换行 */
        }
        .quiz-choice:hover {
            background-color: #f0f0f0;
        }
        .quiz-choice.selected {
            background-color: #d3e3fd;
            border-color: #1a73e8;
        }
        .quiz-choice.correct {
            background-color: #d4f8d9;
            border-color: #0f9d58;
        }
        .quiz-choice.incorrect {
            background-color: #ffd7d5;
            border-color: #d93025;
        }
        .quiz-feedback {
            margin-top: 15px;
            padding: 10px;
            border-radius: 4px;
            display: none;
            font-weight: bold;
            text-align: center;
        }
        .quiz-feedback.correct {
            background-color: #d4f8d9;
            color: #0f9d58;
            display: block;
            border: 1px solid #0f9d58;
        }
        .quiz-feedback.incorrect {
            background-color: #ffd7d5;
            color: #d93025;
            display: block;
            border: 1px solid #d93025;
        }
        
        /* 长文本选项的特殊样式 */
        .quiz-choice.long-text {
            font-size: 13px;
            line-height: 1.3;
            padding: 10px 12px;
        }
        
        /* 确保弹窗中的按钮文本不会溢出 */
        .quiz-choice button,
        .quiz-choice a {
            word-break: break-word;
            white-space: normal;
            text-align: left;
            width: 100%;
        }
        
        /* 适应超长选项文本 */
        @media (max-width: 500px) {
            .quiz-popup {
                width: 95%;
                padding: 12px;
            }
            .quiz-question {
                font-size: 15px;
                margin-bottom: 12px;
            }
            .quiz-choice {
                padding: 8px 10px;
                font-size: 13px;
                line-height: 1.3;
            }
            .quiz-feedback {
                font-size: 13px;
                padding: 8px;
            }
        }
        
        @media (max-width: 768px) {
            .paper-container {
                flex-direction: column;
            }
            
            .card-deck {
                margin-right: 0;
                margin-bottom: 40px;
                height: 650px; /* 移动设备上高度调整 */
            }
            
            .paper-container > .paper-card {
                width: 100% !important;
                margin-bottom: 20px;
                margin-right: 0;
            }
            
            .quiz-tabs {
                width: 100%;
                flex-direction: row;
                flex-wrap: wrap;
                justify-content: flex-start;
                position: relative;
                margin-left: 0;
            }
            .quiz-tab {
                margin-right: 10px;
                margin-bottom: 10px;
            }
        }
    </style>
</head>
<body>
    <h1>2025-10-10 Papers</h1>
    
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/woven.png');">
                        <h2 style="color: #ffffff;">Paper 1</h2>
                        <p style="color: #badb12;"><strong>VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal
  Patches via In-Context Conditioning</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-10-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2510.08555" target="_blank">http://arxiv.org/pdf/2510.08555</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> Video generation and completion, specifically focusing on unified video synthesis from arbitrary spatiotemporal patches using diffusion models.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous work in controllable video generation and In-Context Conditioning (ICC), introduces a novel framework that unifies various video generation tasks under a single paradigm.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> Addresses the challenge of generating coherent videos from arbitrary patches placed at any spatial location and timestamp, while resolving temporal ambiguity in causal VAEs.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> Employs a hybrid conditioning strategy combining Spatial Zero-Padding and Temporal RoPE Interpolation within an In-Context Conditioning framework, requiring zero new parameters.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> Outperformed existing conditioning paradigms across multiple metrics in VideoCanvasBench, showing superior performance in visual quality, temporal coherence, and dynamic degree, with significantly higher user preference scores (60-70% vs 25-30% for baselines).</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal
  Patches via In-Context Conditioning</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">VideoCanvas Methodology Flow</text>
  
  <!-- Input Section -->
  <rect x="50" y="80" width="200" height="120" rx="10" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="150" y="110" text-anchor="middle" font-size="14" font-weight="bold" fill="#1976d2">Input Conditions</text>
  <text x="150" y="130" text-anchor="middle" font-size="11" fill="#1976d2">P = {(p_i, m_i, t_i)}</text>
  <text x="150" y="150" text-anchor="middle" font-size="10" fill="#1976d2">Patches at arbitrary</text>
  <text x="150" y="165" text-anchor="middle" font-size="10" fill="#1976d2">spatial-temporal locations</text>
  
  <!-- Spatial Conditioning -->
  <rect x="320" y="80" width="180" height="120" rx="10" fill="#e8f5e8" stroke="#388e3c" stroke-width="2"/>
  <text x="410" y="110" text-anchor="middle" font-size="14" font-weight="bold" fill="#388e3c">Spatial Conditioning</text>
  <text x="410" y="130" text-anchor="middle" font-size="11" fill="#388e3c">Zero-Padding</text>
  <text x="410" y="150" text-anchor="middle" font-size="10" fill="#388e3c">x_prep,i = m_i ⊙ p_i</text>
  <text x="410" y="170" text-anchor="middle" font-size="10" fill="#388e3c">Fill remaining with zeros</text>
  
  <!-- VAE Encoding -->
  <rect x="570" y="80" width="180" height="120" rx="10" fill="#fff3e0" stroke="#f57c00" stroke-width="2"/>
  <text x="660" y="110" text-anchor="middle" font-size="14" font-weight="bold" fill="#f57c00">VAE Encoding</text>
  <text x="660" y="130" text-anchor="middle" font-size="11" fill="#f57c00">Temporal Decoupling</text>
  <text x="660" y="150" text-anchor="middle" font-size="10" fill="#f57c00">z_cond,i = E(x_prep,i)</text>
  <text x="660" y="170" text-anchor="middle" font-size="10" fill="#f57c00">Independent encoding</text>
  
  <!-- Core Challenge Box -->
  <rect x="100" y="250" width="300" height="100" rx="10" fill="#ffebee" stroke="#d32f2f" stroke-width="2"/>
  <text x="250" y="280" text-anchor="middle" font-size="14" font-weight="bold" fill="#d32f2f">Core Challenge</text>
  <text x="250" y="300" text-anchor="middle" font-size="12" fill="#d32f2f">Temporal Ambiguity in Causal VAE</text>
  <text x="250" y="320" text-anchor="middle" font-size="10" fill="#d32f2f">Multiple frames → Single latent slot</text>
  
  <!-- Solution Box -->
  <rect x="500" y="250" width="300" height="100" rx="10" fill="#e8f5e8" stroke="#388e3c" stroke-width="2"/>
  <text x="650" y="280" text-anchor="middle" font-size="14" font-weight="bold" fill="#388e3c">Our Solution</text>
  <text x="650" y="300" text-anchor="middle" font-size="12" fill="#388e3c">Temporal RoPE Interpolation</text>
  <text x="650" y="320" text-anchor="middle" font-size="10" fill="#388e3c">pos_t(z_cond,i) = t_i / N</text>
  
  <!-- Sequence Construction -->
  <rect x="150" y="400" width="250" height="100" rx="10" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="275" y="430" text-anchor="middle" font-size="14" font-weight="bold" fill="#7b1fa2">Sequence Construction</text>
  <text x="275" y="450" text-anchor="middle" font-size="11" fill="#7b1fa2">In-Context Conditioning</text>
  <text x="275" y="470" text-anchor="middle" font-size="10" fill="#7b1fa2">z = Concat({z_cond,i}, z_source)</text>
  
  <!-- Training -->
  <rect x="450" y="400" width="200" height="100" rx="10" fill="#e1f5fe" stroke="#0277bd" stroke-width="2"/>
  <text x="550" y="430" text-anchor="middle" font-size="14" font-weight="bold" fill="#0277bd">Training</text>
  <text x="550" y="450" text-anchor="middle" font-size="11" fill="#0277bd">Flow Matching</text>
  <text x="550" y="470" text-anchor="middle" font-size="10" fill="#0277bd">Loss on non-conditional</text>
  <text x="550" y="485" text-anchor="middle" font-size="10" fill="#0277bd">regions only</text>
  
  <!-- Output -->
  <rect x="700" y="400" width="180" height="100" rx="10" fill="#fff8e1" stroke="#fbc02d" stroke-width="2"/>
  <text x="790" y="430" text-anchor="middle" font-size="14" font-weight="bold" fill="#fbc02d">Output</text>
  <text x="790" y="450" text-anchor="middle" font-size="11" fill="#fbc02d">Complete Video</text>
  <text x="790" y="470" text-anchor="middle" font-size="10" fill="#fbc02d">Arbitrary spatio-temporal</text>
  <text x="790" y="485" text-anchor="middle" font-size="10" fill="#fbc02d">completion</text>
  
  <!-- Applications -->
  <rect x="100" y="550" width="800" height="120" rx="10" fill="#f5f5f5" stroke="#666" stroke-width="2"/>
  <text x="500" y="580" text-anchor="middle" font-size="16" font-weight="bold" fill="#333">Unified Applications</text>
  
  <!-- Application boxes -->
  <rect x="120" y="600" width="120" height="40" rx="5" fill="#e3f2fd" stroke="#1976d2"/>
  <text x="180" y="625" text-anchor="middle" font-size="10" fill="#1976d2">Any-timestamp I2V</text>
  
  <rect x="260" y="600" width="120" height="40" rx="5" fill="#e8f5e8" stroke="#388e3c"/>
  <text x="320" y="625" text-anchor="middle" font-size="10" fill="#388e3c">Any-timestamp P2V</text>
  
  <rect x="400" y="600" width="120" height="40" rx="5" fill="#fff3e0" stroke="#f57c00"/>
  <text x="460" y="625" text-anchor="middle" font-size="10" fill="#f57c00">Video Transition</text>
  
  <rect x="540" y="600" width="120" height="40" rx="5" fill="#f3e5f5" stroke="#7b1fa2"/>
  <text x="600" y="625" text-anchor="middle" font-size="10" fill="#7b1fa2">Inpainting</text>
  
  <rect x="680" y="600" width="120" height="40" rx="5" fill="#ffebee" stroke="#d32f2f"/>
  <text x="740" y="625" text-anchor="middle" font-size="10" fill="#d32f2f">Outpainting</text>
  
  <!-- Key Innovation Highlight -->
  <ellipse cx="500" cy="720" rx="200" ry="40" fill="#fffde7" stroke="#f57f17" stroke-width="3"/>
  <text x="500" y="715" text-anchor="middle" font-size="14" font-weight="bold" fill="#f57f17">Key Innovation</text>
  <text x="500" y="735" text-anchor="middle" font-size="12" fill="#f57f17">Zero new parameters + Frozen VAE</text>
  
  <!-- Connection lines with minimal arrows -->
  <line x1="250" y1="140" x2="320" y2="140" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="500" y1="140" x2="570" y2="140" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="400" y1="300" x2="500" y2="300" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="275" y1="350" x2="275" y2="400" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="400" y1="450" x2="450" y2="450" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <line x1="650" y1="450" x2="700" y2="450" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Temporal ambiguity when mapping multiple frames to a single latent representation">
                        <div class="quiz-question">1. What is the main challenge addressed by the VideoCanvas framework regarding causal VAEs?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="High computational cost of video generation">High computational cost of video generation</div><div class="quiz-choice" data-value="Temporal ambiguity when mapping multiple frames to a single latent representation">Temporal ambiguity when mapping multiple frames to a single latent representation</div><div class="quiz-choice" data-value="Limited storage capacity for video data">Limited storage capacity for video data</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="Spatial Zero-Padding and Temporal RoPE Interpolation">
                        <div class="quiz-question">2. Which innovative combination does the paper's hybrid conditioning strategy use?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Channel Concatenation and Latent Replacement">Channel Concatenation and Latent Replacement</div><div class="quiz-choice" data-value="Cross-Attention and Channel Injection">Cross-Attention and Channel Injection</div><div class="quiz-choice" data-value="Spatial Zero-Padding and Temporal RoPE Interpolation">Spatial Zero-Padding and Temporal RoPE Interpolation</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It unifies multiple video tasks in one framework with zero new parameters">
                        <div class="quiz-question">3. What unique advantage does VideoCanvas offer compared to previous video generation approaches?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It requires extensive model retraining for each new task">It requires extensive model retraining for each new task</div><div class="quiz-choice" data-value="It can only handle first-frame video generation">It can only handle first-frame video generation</div><div class="quiz-choice" data-value="It unifies multiple video tasks in one framework with zero new parameters">It unifies multiple video tasks in one framework with zero new parameters</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood-colored.png');">
                        <h2 style="color: #ffffff;">Paper 2</h2>
                        <p style="color: #badb12;"><strong>UniVideo: Unified Understanding, Generation, and Editing for Videos</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-10-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2510.08377" target="_blank">http://arxiv.org/pdf/2510.08377</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> A unified AI framework called UniVideo for video understanding, generation, and editing that combines multimodal capabilities in a single system.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous unified text-image models and task-specific video models, proposes a novel dual-stream architecture combining a Multimodal Large Language Model (MLLM) for understanding with a Multimodal DiT (MMDiT) for generation.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> Addresses the limitation of current video AI models being restricted to single tasks or modalities, lacking unified capabilities for understanding complex instructions and performing diverse video tasks.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> Uses a two-stream architecture with frozen MLLM for instruction understanding and MMDiT for video generation, trained across multiple tasks including text/image-to-video generation and video editing through a three-stage training process.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> Achieves state-of-the-art performance across multiple video tasks, demonstrates zero-shot generalization to unseen tasks, and shows strong capabilities in visual prompt understanding and task composition, evaluated through both human assessment and automatic metrics.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>UniVideo: Unified Understanding, Generation, and Editing for Videos</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <!-- Background -->
  <rect width="1000" height="800" fill="#f8f9fa"/>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2c3e50">UniVideo: Unified Understanding, Generation, and Editing for Videos</text>
  
  <!-- Stage 1: Connector Alignment -->
  <rect x="50" y="80" width="280" height="120" rx="10" fill="#e3f2fd" stroke="#1976d2" stroke-width="2"/>
  <text x="190" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#1976d2">Stage 1: Connector Alignment</text>
  <text x="190" y="125" text-anchor="middle" font-size="12" fill="#424242">Train MLP connector only</text>
  <text x="190" y="140" text-anchor="middle" font-size="12" fill="#424242">MLLM & MMDiT frozen</text>
  <text x="190" y="155" text-anchor="middle" font-size="12" fill="#424242">40M T2I + 10M T2V samples</text>
  <text x="190" y="170" text-anchor="middle" font-size="12" fill="#424242">Image reconstruction task</text>
  <text x="190" y="185" text-anchor="middle" font-size="12" fill="#424242">15K steps</text>
  
  <!-- Stage 2: Fine-tuning -->
  <rect x="360" y="80" width="280" height="120" rx="10" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2"/>
  <text x="500" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#7b1fa2">Stage 2: Fine-tuning</text>
  <text x="500" y="125" text-anchor="middle" font-size="12" fill="#424242">MLLM frozen</text>
  <text x="500" y="140" text-anchor="middle" font-size="12" fill="#424242">Fine-tune connector & MMDiT</text>
  <text x="500" y="155" text-anchor="middle" font-size="12" fill="#424242">10K high-quality T2I & T2V</text>
  <text x="500" y="170" text-anchor="middle" font-size="12" fill="#424242">5K steps</text>
  <text x="500" y="185" text-anchor="middle" font-size="12" fill="#424242">EMA ratio: 0.9999</text>
  
  <!-- Stage 3: Multi-task Training -->
  <rect x="670" y="80" width="280" height="120" rx="10" fill="#e8f5e8" stroke="#388e3c" stroke-width="2"/>
  <text x="810" y="105" text-anchor="middle" font-size="16" font-weight="bold" fill="#388e3c">Stage 3: Multi-task Training</text>
  <text x="810" y="125" text-anchor="middle" font-size="12" fill="#424242">MLLM frozen</text>
  <text x="810" y="140" text-anchor="middle" font-size="12" fill="#424242">Train connector & MMDiT</text>
  <text x="810" y="155" text-anchor="middle" font-size="12" fill="#424242">All tasks unified</text>
  <text x="810" y="170" text-anchor="middle" font-size="12" fill="#424242">15K steps</text>
  <text x="810" y="185" text-anchor="middle" font-size="12" fill="#424242">Mixed task sampling</text>
  
  <!-- Architecture Overview -->
  <rect x="50" y="240" width="900" height="200" rx="15" fill="#fff3e0" stroke="#f57c00" stroke-width="3"/>
  <text x="500" y="265" text-anchor="middle" font-size="18" font-weight="bold" fill="#f57c00">Dual-Stream Architecture</text>
  
  <!-- Understanding Stream -->
  <rect x="80" y="290" width="200" height="130" rx="10" fill="#e1f5fe" stroke="#0277bd" stroke-width="2"/>
  <text x="180" y="315" text-anchor="middle" font-size="14" font-weight="bold" fill="#0277bd">Understanding Stream</text>
  <text x="180" y="335" text-anchor="middle" font-size="12" fill="#424242">MLLM (Qwen2.5VL-7B)</text>
  <text x="180" y="350" text-anchor="middle" font-size="12" fill="#424242">Semantic Encoder</text>
  <text x="180" y="365" text-anchor="middle" font-size="12" fill="#424242">Multimodal Instructions</text>
  <text x="180" y="380" text-anchor="middle" font-size="12" fill="#424242">Text + Image + Video</text>
  <text x="180" y="395" text-anchor="middle" font-size="12" fill="#424242">Visual Prompt Understanding</text>
  
  <!-- Generation Stream -->
  <rect x="720" y="290" width="200" height="130" rx="10" fill="#fce4ec" stroke="#c2185b" stroke-width="2"/>
  <text x="820" y="315" text-anchor="middle" font-size="14" font-weight="bold" fill="#c2185b">Generation Stream</text>
  <text x="820" y="335" text-anchor="middle" font-size="12" fill="#424242">MMDiT (HunyuanVideo-13B)</text>
  <text x="820" y="350" text-anchor="middle" font-size="12" fill="#424242">VAE Encoder</text>
  <text x="820" y="365" text-anchor="middle" font-size="12" fill="#424242">Fine-grained Details</text>
  <text x="820" y="380" text-anchor="middle" font-size="12" fill="#424242">Visual Generation</text>
  <text x="820" y="395" text-anchor="middle" font-size="12" fill="#424242">Cross-stream Consistency</text>
  
  <!-- MLP Connector -->
  <ellipse cx="500" cy="355" rx="80" ry="30" fill="#fff59d" stroke="#f9a825" stroke-width="2"/>
  <text x="500" y="350" text-anchor="middle" font-size="12" font-weight="bold" fill="#f9a825">MLP Connector</text>
  <text x="500" y="365" text-anchor="middle" font-size="10" fill="#424242">4x expansion</text>
  
  <!-- Task Unification -->
  <rect x="50" y="480" width="900" height="140" rx="15" fill="#f1f8e9" stroke="#689f38" stroke-width="3"/>
  <text x="500" y="505" text-anchor="middle" font-size="18" font-weight="bold" fill="#689f38">Unified Task Framework</text>
  
  <!-- Task boxes -->
  <rect x="80" y="520" width="120" height="80" rx="8" fill="#e8eaf6" stroke="#3f51b5" stroke-width="1"/>
  <text x="140" y="540" text-anchor="middle" font-size="11" font-weight="bold" fill="#3f51b5">Text-to-Video</text>
  <text x="140" y="555" text-anchor="middle" font-size="10" fill="#424242">T2V Generation</text>
  <text x="140" y="570" text-anchor="middle" font-size="10" fill="#424242">Multimodal</text>
  <text x="140" y="585" text-anchor="middle" font-size="10" fill="#424242">Instructions</text>
  
  <rect x="220" y="520" width="120" height="80" rx="8" fill="#fce4ec" stroke="#e91e63" stroke-width="1"/>
  <text x="280" y="540" text-anchor="middle" font-size="11" font-weight="bold" fill="#e91e63">Image-to-Video</text>
  <text x="280" y="555" text-anchor="middle" font-size="10" fill="#424242">I2V Generation</text>
  <text x="280" y="570" text-anchor="middle" font-size="10" fill="#424242">ID Preservation</text>
  
  <rect x="360" y="520" width="120" height="80" rx="8" fill="#e0f2f1" stroke="#00695c" stroke-width="1"/>
  <text x="420" y="540" text-anchor="middle" font-size="11" font-weight="bold" fill="#00695c">In-Context Gen</text>
  <text x="420" y="555" text-anchor="middle" font-size="10" fill="#424242">Multi-ID Video</text>
  <text x="420" y="570" text-anchor="middle" font-size="10" fill="#424242">Reference Images</text>
  
  <rect x="500" y="520" width="120" height="80" rx="8" fill="#fff3e0" stroke="#ff8f00" stroke-width="1"/>
  <text x="560" y="540" text-anchor="middle" font-size="11" font-weight="bold" fill="#ff8f00">Video Editing</text>
  <text x="560" y="555" text-anchor="middle" font-size="10" fill="#424242">Swap/Delete/Add</text>
  <text x="560" y="570" text-anchor="middle" font-size="10" fill="#424242">Mask-free</text>
  
  <rect x="640" y="520" width="120" height="80" rx="8" fill="#f3e5f5" stroke="#8e24aa" stroke-width="1"/>
  <text x="700" y="540" text-anchor="middle" font-size="11" font-weight="bold" fill="#8e24aa">Style Transfer</text>
  <text x="700" y="555" text-anchor="middle" font-size="10" fill="#424242">Artistic Style</text>
  <text x="700" y="570" text-anchor="middle" font-size="10" fill="#424242">Motion Preserve</text>
  
  <rect x="780" y="520" width="120" height="80" rx="8" fill="#e8f5e8" stroke="#2e7d32" stroke-width="1"/>
  <text x="840" y="540" text-anchor="middle" font-size="11" font-weight="bold" fill="#2e7d32">Visual Prompting</text>
  <text x="840" y="555" text-anchor="middle" font-size="10" fill="#424242">Canvas Drawing</text>
  <text x="840" y="570" text-anchor="middle" font-size="10" fill="#424242">Annotation</text>
  
  <!-- Key Features -->
  <rect x="50" y="650" width="900" height="120" rx="15" fill="#fafafa" stroke="#616161" stroke-width="2"/>
  <text x="500" y="675" text-anchor="middle" font-size="18" font-weight="bold" fill="#616161">Key Capabilities & Generalization</text>
  
  <rect x="80" y="690" width="180" height="60" rx="8" fill="#e3f2fd" stroke="#1976d2" stroke-width="1"/>
  <text x="170" y="710" text-anchor="middle" font-size="12" font-weight="bold" fill="#1976d2">Zero-shot Transfer</text>
  <text x="170" y="725" text-anchor="middle" font-size="10" fill="#424242">Image→Video Editing</text>
  <text x="170" y="740" text-anchor="middle" font-size="10" fill="#424242">Free-form Instructions</text>
  
  <rect x="280" y="690" width="180" height="60" rx="8" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="1"/>
  <text x="370" y="710" text-anchor="middle" font-size="12" font-weight="bold" fill="#7b1fa2">Task Composition</text>
  <text x="370" y="725" text-anchor="middle" font-size="10" fill="#424242">Multiple Operations</text>
  <text x="370" y="740" text-anchor="middle" font-size="10" fill="#424242">Single Instruction</text>
  
  <rect x="480" y="690" width="180" height="60" rx="8" fill="#e8f5e8" stroke="#388e3c" stroke-width="1"/>
  <text x="570" y="710" text-anchor="middle" font-size="12" font-weight="bold" fill="#388e3c">Unified Framework</text>
  <text x="570" y="725" text-anchor="middle" font-size="10" fill="#424242">Single Model</text>
  <text x="570" y="740" text-anchor="middle" font-size="10" fill="#424242">All Video Tasks</text>
  
  <rect x="680" y="690" width="180" height="60" rx="8" fill="#fff3e0" stroke="#f57c00" stroke-width="1"/>
  <text x="770" y="710" text-anchor="middle" font-size="12" font-weight="bold" fill="#f57c00">SOTA Performance</text>
  <text x="770" y="725" text-anchor="middle" font-size="10" fill="#424242">Competitive Results</text>
  <text x="770" y="740" text-anchor="middle" font-size="10" fill="#424242">All Benchmarks</text>
  
  <!-- Flow indicators -->
  <path d="M 330 140 L 360 140" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <path d="M 640 140 L 670 140" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <path d="M 280 355 L 420 355" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  <path d="M 580 355 L 720 355" stroke="#666" stroke-width="2" marker-end="url(#arrowhead)"/>
  
  <!-- Arrow marker definition -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
      <polygon points="0 0, 10 3.5, 0 7" fill="#666"/>
    </marker>
  </defs>
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="A dual-stream design combining MLLM for understanding and MMDiT for generation">
                        <div class="quiz-question">1. What is the key architectural innovation of UniVideo that enables it to handle both understanding and generation tasks?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="A single stream architecture with multiple task-specific modules">A single stream architecture with multiple task-specific modules</div><div class="quiz-choice" data-value="A dual-stream design combining MLLM for understanding and MMDiT for generation">A dual-stream design combining MLLM for understanding and MMDiT for generation</div><div class="quiz-choice" data-value="A transformer-based architecture with learnable query tokens">A transformer-based architecture with learnable query tokens</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="It can perform free-form video editing despite not being trained on such tasks">
                        <div class="quiz-question">2. What unique capability does UniVideo demonstrate in terms of generalization?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It can only perform tasks it was explicitly trained on">It can only perform tasks it was explicitly trained on</div><div class="quiz-choice" data-value="It can generate high-resolution videos but cannot edit them">It can generate high-resolution videos but cannot edit them</div><div class="quiz-choice" data-value="It can perform free-form video editing despite not being trained on such tasks">It can perform free-form video editing despite not being trained on such tasks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="It can edit videos based on natural language instructions without requiring masks">
                        <div class="quiz-question">3. How does UniVideo handle video editing differently from existing methods?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="It requires explicit mask inputs like all other video editing models">It requires explicit mask inputs like all other video editing models</div><div class="quiz-choice" data-value="It only works with pre-defined editing templates">It only works with pre-defined editing templates</div><div class="quiz-choice" data-value="It can edit videos based on natural language instructions without requiring masks">It can edit videos based on natural language instructions without requiring masks</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
            <div class="paper-container">
                <div class="card-deck">
                    <!-- 卡片计数器 -->
                    <div class="card-counter">1/2</div>
                    
                    <!-- 第一张卡片：论文概述 -->
                    <div class="paper-card active" style="background-image: url('bg/tileable-wood.png');">
                        <h2 style="color: #ffffff;">Paper 3</h2>
                        <p style="color: #badb12;"><strong>DeepPrune: Parallel Scaling without Inter-trace Redundancy</strong></p>
                        <p style="color: #ffffff;"><strong>Published: </strong>2025-10-09</p>
                        <p><strong>Link: </strong><a href="http://arxiv.org/pdf/2510.08483" target="_blank">http://arxiv.org/pdf/2510.08483</a></p>
                        <div><div class="category-chunk">1.  <strong>📘 Topic and Domain:</strong> The paper focuses on efficient parallel scaling for large language models' reasoning capabilities through dynamic pruning of redundant reasoning traces.</div><div class="category-chunk">2.  <strong>💡 Previous Research and New Ideas:</strong> Based on previous parallel scaling methods that generate multiple Chain-of-Thought traces simultaneously, the paper proposes a novel framework called DeepPrune that reduces computational redundancy while preserving answer diversity.</div><div class="category-chunk">3.  <strong>❓ Problem:</strong> The paper addresses the inefficiency in parallel reasoning where over 80% of computational resources are wasted on generating equivalent reasoning paths that lead to identical answers.</div><div class="category-chunk">4.  <strong>🛠️ Methods:</strong> The authors developed a specialized judge model trained with focal loss and oversampling techniques to predict answer equivalence from partial reasoning traces, combined with an online greedy clustering algorithm for dynamic pruning.</div><div class="category-chunk">5.  <strong>📊 Results and Evaluation:</strong> DeepPrune achieved remarkable token reduction by over 80% compared to conventional consensus sampling while maintaining competitive accuracy within 3 percentage points, with the judge model reaching 0.87 AUROC on equivalence prediction.</div></div>
                    </div>
                    
                    <!-- 第二张卡片：流程图 -->
                    <div class="paper-card flowchart-card" style="background-color: white;">
                        <h2>DeepPrune: Parallel Scaling without Inter-trace Redundancy</h2>
                        <svg width="100%" viewBox="0 0 1000 800">
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#4CAF50;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#81C784;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad2" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#2196F3;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#64B5F6;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad3" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#FF9800;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#FFB74D;stop-opacity:1" />
    </linearGradient>
    <linearGradient id="grad4" x1="0%" y1="0%" x2="100%" y2="0%">
      <stop offset="0%" style="stop-color:#9C27B0;stop-opacity:1" />
      <stop offset="100%" style="stop-color:#BA68C8;stop-opacity:1" />
    </linearGradient>
  </defs>
  
  <!-- Title -->
  <text x="500" y="30" text-anchor="middle" font-size="24" font-weight="bold" fill="#2E7D32">DeepPrune Workflow</text>
  
  <!-- Phase 1: Problem Analysis -->
  <rect x="50" y="60" width="200" height="80" fill="url(#grad1)" rx="10" stroke="#2E7D32" stroke-width="2"/>
  <text x="150" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Problem Analysis</text>
  <text x="150" y="105" text-anchor="middle" font-size="12" fill="white">Identify Inter-trace</text>
  <text x="150" y="120" text-anchor="middle" font-size="12" fill="white">Redundancy (80%+)</text>
  
  <!-- Phase 2: Offline Training -->
  <rect x="300" y="60" width="180" height="120" fill="url(#grad2)" rx="10" stroke="#1976D2" stroke-width="2"/>
  <text x="390" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Offline Training</text>
  
  <!-- Sub-components of Offline Training -->
  <rect x="310" y="95" width="160" height="25" fill="rgba(255,255,255,0.3)" rx="5"/>
  <text x="390" y="110" text-anchor="middle" font-size="11" fill="white">Trace Pair Collection</text>
  
  <rect x="310" y="125" width="160" height="25" fill="rgba(255,255,255,0.3)" rx="5"/>
  <text x="390" y="140" text-anchor="middle" font-size="11" fill="white">Judge Model Training</text>
  
  <rect x="310" y="155" width="160" height="20" fill="rgba(255,255,255,0.3)" rx="5"/>
  <text x="390" y="167" text-anchor="middle" font-size="10" fill="white">Focal Loss + Oversampling</text>
  
  <!-- Phase 3: Online Pruning -->
  <rect x="520" y="60" width="180" height="120" fill="url(#grad3)" rx="10" stroke="#F57C00" stroke-width="2"/>
  <text x="610" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Online Pruning</text>
  
  <!-- Sub-components of Online Pruning -->
  <rect x="530" y="95" width="160" height="25" fill="rgba(255,255,255,0.3)" rx="5"/>
  <text x="610" y="110" text-anchor="middle" font-size="11" fill="white">Greedy Clustering</text>
  
  <rect x="530" y="125" width="160" height="25" fill="rgba(255,255,255,0.3)" rx="5"/>
  <text x="610" y="140" text-anchor="middle" font-size="11" fill="white">Dynamic Pruning</text>
  
  <rect x="530" y="155" width="160" height="20" fill="rgba(255,255,255,0.3)" rx="5"/>
  <text x="610" y="167" text-anchor="middle" font-size="10" fill="white">Similarity Threshold τ</text>
  
  <!-- Phase 4: Final Answer -->
  <rect x="750" y="60" width="180" height="80" fill="url(#grad4)" rx="10" stroke="#7B1FA2" stroke-width="2"/>
  <text x="840" y="85" text-anchor="middle" font-size="14" font-weight="bold" fill="white">Final Answer</text>
  <text x="840" y="105" text-anchor="middle" font-size="12" fill="white">Majority Voting</text>
  <text x="840" y="120" text-anchor="middle" font-size="12" fill="white">80%+ Token Reduction</text>
  
  <!-- Data Flow -->
  <rect x="100" y="220" width="800" height="200" fill="#F5F5F5" stroke="#BDBDBD" stroke-width="2" rx="15"/>
  <text x="500" y="245" text-anchor="middle" font-size="16" font-weight="bold" fill="#424242">Data Processing Flow</text>
  
  <!-- Input Data -->
  <circle cx="150" cy="300" r="30" fill="#E3F2FD" stroke="#1976D2" stroke-width="2"/>
  <text x="150" y="305" text-anchor="middle" font-size="12" fill="#1976D2">Problem</text>
  
  <!-- Multiple Traces -->
  <rect x="230" y="270" width="80" height="60" fill="#FFF3E0" stroke="#F57C00" stroke-width="2" rx="8"/>
  <text x="270" y="290" text-anchor="middle" font-size="11" fill="#F57C00">Generate</text>
  <text x="270" y="305" text-anchor="middle" font-size="11" fill="#F57C00">Multiple</text>
  <text x="270" y="320" text-anchor="middle" font-size="11" fill="#F57C00">Traces</text>
  
  <!-- Judge Model -->
  <rect x="350" y="270" width="80" height="60" fill="#E8F5E8" stroke="#4CAF50" stroke-width="2" rx="8"/>
  <text x="390" y="290" text-anchor="middle" font-size="11" fill="#4CAF50">Judge</text>
  <text x="390" y="305" text-anchor="middle" font-size="11" fill="#4CAF50">Model</text>
  <text x="390" y="320" text-anchor="middle" font-size="11" fill="#4CAF50">Prediction</text>
  
  <!-- Clustering -->
  <rect x="470" y="270" width="80" height="60" fill="#F3E5F5" stroke="#9C27B0" stroke-width="2" rx="8"/>
  <text x="510" y="290" text-anchor="middle" font-size="11" fill="#9C27B0">Greedy</text>
  <text x="510" y="305" text-anchor="middle" font-size="11" fill="#9C27B0">Clustering</text>
  <text x="510" y="320" text-anchor="middle" font-size="11" fill="#9C27B0">Algorithm</text>
  
  <!-- Pruned Traces -->
  <rect x="590" y="270" width="80" height="60" fill="#FFEBEE" stroke="#F44336" stroke-width="2" rx="8"/>
  <text x="630" y="290" text-anchor="middle" font-size="11" fill="#F44336">Pruned</text>
  <text x="630" y="305" text-anchor="middle" font-size="11" fill="#F44336">Diverse</text>
  <text x="630" y="320" text-anchor="middle" font-size="11" fill="#F44336">Traces</text>
  
  <!-- Final Answer -->
  <circle cx="750" cy="300" r="30" fill="#E1F5FE" stroke="#0277BD" stroke-width="2"/>
  <text x="750" y="295" text-anchor="middle" font-size="11" fill="#0277BD">Final</text>
  <text x="750" y="308" text-anchor="middle" font-size="11" fill="#0277BD">Answer</text>
  
  <!-- Key Components Detail -->
  <rect x="100" y="460" width="800" height="180" fill="#FAFAFA" stroke="#9E9E9E" stroke-width="2" rx="15"/>
  <text x="500" y="485" text-anchor="middle" font-size="16" font-weight="bold" fill="#424242">Key Technical Components</text>
  
  <!-- Truncation Strategies -->
  <rect x="120" y="510" width="180" height="60" fill="#E8EAF6" stroke="#3F51B5" stroke-width="2" rx="8"/>
  <text x="210" y="530" text-anchor="middle" font-size="12" font-weight="bold" fill="#3F51B5">Truncation Strategies</text>
  <text x="210" y="545" text-anchor="middle" font-size="10" fill="#3F51B5">• Fixed-length prefix</text>
  <text x="210" y="558" text-anchor="middle" font-size="10" fill="#3F51B5">• Reasoning-step alignment</text>
  
  <!-- Training Techniques -->
  <rect x="320" y="510" width="180" height="60" fill="#E0F2F1" stroke="#00695C" stroke-width="2" rx="8"/>
  <text x="410" y="530" text-anchor="middle" font-size="12" font-weight="bold" fill="#00695C">Training Techniques</text>
  <text x="410" y="545" text-anchor="middle" font-size="10" fill="#00695C">• Focal Loss</text>
  <text x="410" y="558" text-anchor="middle" font-size="10" fill="#00695C">• Oversampling</text>
  
  <!-- Performance Metrics -->
  <rect x="520" y="510" width="180" height="60" fill="#FFF8E1" stroke="#FF8F00" stroke-width="2" rx="8"/>
  <text x="610" y="530" text-anchor="middle" font-size="12" font-weight="bold" fill="#FF8F00">Performance</text>
  <text x="610" y="545" text-anchor="middle" font-size="10" fill="#FF8F00">• AUROC: 0.87</text>
  <text x="610" y="558" text-anchor="middle" font-size="10" fill="#FF8F00">• TNR@0.2: 0.82</text>
  
  <!-- Results -->
  <rect x="720" y="510" width="160" height="60" fill="#FCE4EC" stroke="#C2185B" stroke-width="2" rx="8"/>
  <text x="800" y="530" text-anchor="middle" font-size="12" font-weight="bold" fill="#C2185B">Results</text>
  <text x="800" y="545" text-anchor="middle" font-size="10" fill="#C2185B">• 80%+ Token Reduction</text>
  <text x="800" y="558" text-anchor="middle" font-size="10" fill="#C2185B">• Accuracy Maintained</text>
  
  <!-- Evaluation Datasets -->
  <rect x="250" y="590" width="500" height="40" fill="#F1F8E9" stroke="#689F38" stroke-width="2" rx="8"/>
  <text x="500" y="610" text-anchor="middle" font-size="12" font-weight="bold" fill="#689F38">Evaluation: AIME 2024/2025, GPQA | Models: DeepSeek-8B, Qwen3-32B, GPT-OSS-20B</text>
  
  <!-- Flow connections (simplified lines) -->
  <line x1="180" y1="300" x2="230" y2="300" stroke="#666" stroke-width="2"/>
  <line x1="310" y1="300" x2="350" y2="300" stroke="#666" stroke-width="2"/>
  <line x1="430" y1="300" x2="470" y2="300" stroke="#666" stroke-width="2"/>
  <line x1="550" y1="300" x2="590" y2="300" stroke="#666" stroke-width="2"/>
  <line x1="670" y1="300" x2="720" y2="300" stroke="#666" stroke-width="2"/>
  
</svg>
                    </div>
                </div>
                <div class="quiz-tabs">
                <div class="quiz-tab" title="Click To Open Question #1">Q1
                    <div class="quiz-popup" data-answer="Over 80% of parallel reasoning traces yielding identical answers">
                        <div class="quiz-question">1. What is the main efficiency problem that DeepPrune aims to solve in parallel reasoning?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="High computational costs from using too many tokens">High computational costs from using too many tokens</div><div class="quiz-choice" data-value="Over 80% of parallel reasoning traces yielding identical answers">Over 80% of parallel reasoning traces yielding identical answers</div><div class="quiz-choice" data-value="Slow processing speed of language models">Slow processing speed of language models</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #2">Q2
                    <div class="quiz-popup" data-answer="By combining focal loss with oversampling techniques">
                        <div class="quiz-question">2. How does DeepPrune's judge model handle the class imbalance problem in training data?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="By using data augmentation techniques">By using data augmentation techniques</div><div class="quiz-choice" data-value="By discarding excess majority class samples">By discarding excess majority class samples</div><div class="quiz-choice" data-value="By combining focal loss with oversampling techniques">By combining focal loss with oversampling techniques</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                
                <div class="quiz-tab" title="Click To Open Question #3">Q3
                    <div class="quiz-popup" data-answer="Up to 91.6% on AIME25 dataset">
                        <div class="quiz-question">3. What was the most significant token reduction achieved by DeepPrune while maintaining accuracy?</div>
                        <div class="quiz-choices"><div class="quiz-choice" data-value="Up to 91.6% on AIME25 dataset">Up to 91.6% on AIME25 dataset</div><div class="quiz-choice" data-value="Around 50% across all datasets">Around 50% across all datasets</div><div class="quiz-choice" data-value="Up to 75% on GPQA dataset">Up to 75% on GPQA dataset</div></div>
                        <div class="quiz-feedback"></div>
                    </div>
                </div>
                </div>
            </div>
            
    
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // 创建遮罩层
            const backdrop = document.createElement('div');
            backdrop.className = 'popup-backdrop';
            document.body.appendChild(backdrop);
            
            // 获取所有问题标签
            const quizTabs = document.querySelectorAll('.quiz-tab');
            
            // 设置点击事件处理
            quizTabs.forEach(tab => {
                const popup = tab.querySelector('.quiz-popup');
                
                // 点击标签切换问题卡的显示状态
                tab.addEventListener('click', function(e) {
                    e.stopPropagation(); // 阻止事件冒泡
                    
                    // 如果当前问题卡已经显示，则隐藏它
                    if (popup.classList.contains('active')) {
                        popup.classList.remove('active');
                        backdrop.classList.remove('active');
                    } else {
                        // 先隐藏所有其他问题卡
                        document.querySelectorAll('.quiz-popup').forEach(p => {
                            p.classList.remove('active');
                        });
                        
                        // 将弹窗内容复制到页面最外层的弹窗中
                        document.body.appendChild(popup);
                        
                        // 显示当前问题卡和背景遮罩
                        popup.classList.add('active');
                        backdrop.classList.add('active');
                    }
                });
                
                // 确保点击问题卡内部时不会关闭问题卡
                popup.addEventListener('click', function(e) {
                    e.stopPropagation();
                });
            });
            
            // 点击遮罩层或页面任何其他位置时隐藏所有问题卡
            backdrop.addEventListener('click', closeAllPopups);
            document.addEventListener('click', closeAllPopups);
            
            function closeAllPopups() {
                document.querySelectorAll('.quiz-popup').forEach(popup => {
                    popup.classList.remove('active');
                });
                backdrop.classList.remove('active');
            }
            
            // 为每个选项添加点击事件
            document.querySelectorAll('.quiz-choice').forEach(choice => {
                choice.addEventListener('click', function() {
                    const choiceContainer = this.closest('.quiz-choices');
                    const popupContainer = this.closest('.quiz-popup');
                    const feedbackElement = popupContainer.querySelector('.quiz-feedback');
                    const correctAnswer = popupContainer.getAttribute('data-answer');
                    
                    // 重置所有选项
                    choiceContainer.querySelectorAll('.quiz-choice').forEach(c => {
                        c.classList.remove('selected', 'correct', 'incorrect');
                    });
                    
                    // 标记当前选项为已选
                    this.classList.add('selected');
                    
                    // 检查是否正确
                    if (this.getAttribute('data-value') === correctAnswer) {
                        this.classList.add('correct');
                        feedbackElement.textContent = '✔️ Correct！';
                        feedbackElement.classList.add('correct');
                        feedbackElement.classList.remove('incorrect');
                    } else {
                        this.classList.add('incorrect');
                        feedbackElement.textContent = '❌ Wrong！';
                        feedbackElement.classList.add('incorrect');
                        feedbackElement.classList.remove('correct');
                    }
                    
                    feedbackElement.style.display = 'block';
                });
            });
            
            // 卡片轮播功能 - 新增
            const cardDecks = document.querySelectorAll('.card-deck');
            
            cardDecks.forEach(cardDeck => {
                const cards = cardDeck.querySelectorAll('.paper-card');
                const counter = cardDeck.querySelector('.card-counter');
                let currentIndex = 0;
                const totalCards = cards.length;
                
                // 更新计数器显示
                function updateCounter() {
                    if (counter) {
                        counter.textContent = `${currentIndex + 1}/${totalCards}`;
                    }
                }
                
                // 显示指定索引的卡片
                function showCard(index) {
                    // 处理循环
                    if (index >= totalCards) index = 0;
                    if (index < 0) index = totalCards - 1;
                    
                    // 更新当前索引
                    currentIndex = index;
                    
                    // 更新卡片显示
                    cards.forEach((card, i) => {
                        if (i === currentIndex) {
                            card.classList.add('active');
                        } else {
                            card.classList.remove('active');
                        }
                    });
                    
                    // 更新计数器
                    updateCounter();
                }
                
                // 下一张卡片
                function nextCard(e) {
                    e.stopPropagation(); // 防止事件冒泡导致问题卡关闭
                    showCard(currentIndex + 1);
                }
                
                // 为卡片容器添加点击事件
                cardDeck.addEventListener('click', function(e) {
                    // 检查点击是否发生在流程图卡片内部的滚动区域
                    // 如果是在滚动条上点击，不切换卡片
                    const targetCard = e.target.closest('.paper-card');
                    if (targetCard && targetCard.classList.contains('flowchart-card')) {
                        // 计算点击位置是否在滚动条区域
                        const rect = targetCard.getBoundingClientRect();
                        const isScrollbarClick = 
                            (e.clientY >= rect.top && e.clientY <= rect.bottom && e.clientX >= rect.right - 20 && e.clientX <= rect.right) ||
                            (e.clientX >= rect.left && e.clientX <= rect.right && e.clientY >= rect.bottom - 20 && e.clientY <= rect.bottom);
                        
                        if (!isScrollbarClick) {
                            nextCard(e);
                        }
                    } else {
                        nextCard(e);
                    }
                });
                
                // 键盘导航
                document.addEventListener('keydown', (e) => {
                    if (e.key === 'ArrowRight') {
                        showCard(currentIndex + 1);
                    } else if (e.key === 'ArrowLeft') {
                        showCard(currentIndex - 1);
                    }
                });
            });
        });
    </script>
</body>
</html>
